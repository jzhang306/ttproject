<?xml version="1.0" encoding="UTF-8"?>
<articles>
   <article>
      <title>Hierarchical Reinforcement Learning with the MAXQ Value Function
  Decomposition</title>
      <author>Thomas G. Dietterich</author>
      <date>1999-05-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents the MAXQ approach to hierarchical <term>reinforcement learning</term> based on decomposing the target Markov decision process (MDP) into a hierarchy of smaller MDPs and decomposing the value function of the target MDP into an additive combination of the value functions of the smaller MDPs. The paper defines the MAXQ hierarchy, proves formal results on its representational power, and establishes five conditions for the safe use of state abstractions. The paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges wih probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even in the presence of the five kinds of state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q through a series of experiments in three domains and shows experimentally that MAXQ-Q (with state abstractions) converges to a recursively optimal policy much faster than flat Q learning. The fact that MAXQ learns a representation of the value function has an important benefit: it makes it possible to compute and execute an improved, non-hierarchical policy via a procedure similar to the policy improvement step of policy iteration. The paper demonstrates the effectiveness of this non-hierarchical execution experimentally. Finally, the paper concludes with a comparison to related work and a discussion of the design tradeoffs in hierarchical <term>reinforcement learning</term>.</abstract>
   </article>
   <article>
      <title>State Abstraction in MAXQ Hierarchical Reinforcement Learning</title>
      <author>Thomas G. Dietterich</author>
      <date>1999-05-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many researchers have explored methods for hierarchical <term>reinforcement learning</term> (RL) with temporal abstractions, in which abstract actions are defined that can perform many primitive actions before terminating. However, little is known about learning with state abstractions, in which aspects of the state space are ignored. In previous work, we developed the MAXQ method for hierarchical RL. In this paper, we define five conditions under which state abstraction can be combined with the MAXQ value function decomposition. We prove that the MAXQ-Q learning algorithm converges under these conditions and show experimentally that state abstraction is important for the successful application of MAXQ-Q learning.</abstract>
   </article>
   <article>
      <title>Multiplicative Algorithm for Orthgonal Groups and Independent Component
  Analysis</title>
      <author>Toshinao Akuzawa</author>
      <date>2000-01-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The multiplicative Newton-like method developed by the author et al. is extended to the situation where the dynamics is restricted to the orthogonal group. A general framework is constructed without specifying the cost function. Though the restriction to the orthogonal groups makes the problem somewhat complicated, an explicit expression for the amount of individual jumps is obtained. This algorithm is exactly second-order-convergent. The global instability inherent in the Newton method is remedied by a Levenberg-Marquardt-type variation. The method thus constructed can readily be applied to the independent component analysis. Its remarkable performance is illustrated by a numerical simulation.</abstract>
   </article>
   <article>
      <title>Multiplicative Nonholonomic/Newton -like Algorithm</title>
      <author>Toshinao Akuzawa, Noboru Murata</author>
      <date>2000-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We construct new algorithms from scratch, which use the fourth order cumulant of stochastic variables for the cost function. The multiplicative updating rule here constructed is natural from the homogeneous nature of the Lie group and has numerous merits for the rigorous treatment of the dynamics. As one consequence, the second order convergence is shown. For the cost function, functions invariant under the componentwise scaling are choosen. By identifying points which can be transformed to each other by the scaling, we assume that the dynamics is in a coset space. In our method, a point can move toward any direction in this coset. Thus, no prewhitening is required.</abstract>
   </article>
   <article>
      <title>Complexity analysis for algorithmically simple strings</title>
      <author>Andrei N. Soklakov</author>
      <date>2000-09-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Given a reference computer, Kolmogorov complexity is a well defined function on all binary strings. In the standard approach, however, only the asymptotic properties of such functions are considered because they do not depend on the reference computer. We argue that this approach can be more useful if it is refined to include an important practical case of simple binary strings. Kolmogorov complexity calculus may be developed for this case if we restrict the class of available reference computers. The interesting problem is to define a class of computers which is restricted in a {\it natural} way modeling the real-life situation where only a limited class of computers is physically available to us. We give an example of what such a natural restriction might look like mathematically, and show that under such restrictions some error terms, even logarithmic in complexity, can disappear from the standard complexity calculus.   Keywords: Kolmogorov complexity; Algorithmic information theory.</abstract>
   </article>
   <article>
      <title>Robust Classification for Imprecise Environments</title>
      <author>Foster Provost, Tom Fawcett</author>
      <date>2000-09-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In real-world environments it usually is difficult to specify target operating conditions precisely, for example, target misclassification costs. This uncertainty makes building robust classification systems problematic. We show that it is possible to build a hybrid classifier that will perform at least as well as the best available classifier for any target conditions. In some cases, the performance of the hybrid actually can surpass that of the best known classifier. This robust performance extends across a wide variety of comparison frameworks, including the optimization of metrics such as accuracy, expected cost, lift, precision, recall, and workforce utilization. The hybrid also is efficient to build, to store, and to update. The hybrid is based on a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs. The ROC convex hull (ROCCH) method combines techniques from ROC analysis, decision analysis and computational geometry, and adapts them to the particulars of analyzing learned classifiers. The method is efficient and incremental, minimizes the management of classifier performance data, and allows for clear visual comparisons and sensitivity analyses. Finally, we point to empirical evidence that a robust hybrid classifier indeed is needed for many real-world problems.</abstract>
   </article>
   <article>
      <title>Top-down induction of clustering trees</title>
      <author>Hendrik Blockeel, Luc De Raedt, Jan Ramon</author>
      <date>2000-11-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>An approach to clustering is presented that adapts the basic top-down induction of decision trees method towards clustering. To this aim, it employs the principles of instance based learning. The resulting methodology is implemented in the TIC (Top down Induction of Clustering trees) system for first order clustering. The TIC system employs the first order logical decision tree representation of the inductive logic programming system Tilde. Various experiments with TIC are presented, in both propositional and relational domains.</abstract>
   </article>
   <article>
      <title>Scaling Up Inductive Logic Programming by Learning from Interpretations</title>
      <author>Hendrik Blockeel, Luc De Raedt, Nico Jacobs, Bart Demoen</author>
      <date>2000-11-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>When comparing inductive logic programming (ILP) and attribute-value learning techniques, there is a trade-off between expressive power and efficiency. Inductive logic programming techniques are typically more expressive but also less efficient. Therefore, the data sets handled by current inductive logic programming systems are small according to general standards within the data mining community. The main source of inefficiency lies in the assumption that several examples may be related to each other, so they cannot be handled independently.   Within the learning from interpretations framework for inductive logic programming this assumption is unnecessary, which allows to scale up existing ILP algorithms. In this paper we explain this learning setting in the context of relational databases. We relate the setting to propositional data mining and to the classical ILP setting, and show that learning from interpretations corresponds to learning from multiple relations and thus extends the expressiveness of propositional learning, while maintaining its efficiency to a large extent (which is not the case in the classical ILP setting).   As a case study, we present two alternative implementations of the ILP system Tilde (Top-down Induction of Logical DEcision trees): Tilde-classic, which loads all data in main memory, and Tilde-LDS, which loads the examples one by one. We experimentally compare the implementations, showing Tilde-LDS can handle large data sets (in the order of 100,000 examples or 100 MB) and indeed scales up linearly in the number of examples.</abstract>
   </article>
   <article>
      <title>Learning Policies with External Memory</title>
      <author>Leonid Peshkin, Nicolas Meuleau, Leslie Kaelbling</author>
      <date>2001-03-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In order for an agent to perform well in partially observable domains, it is usually necessary for actions to depend on the history of observations. In this paper, we explore a {\it stigmergic} approach, in which the agent's actions include the ability to set and clear bits in an external memory, and the external memory is included as part of the input to the agent. In this case, we need to learn a reactive policy in a highly non-Markovian domain. We explore two algorithms: SARSA(\lambda), which has had empirical success in partially observable domains, and VAPS, a new algorithm due to Baird and Moore, with convergence guarantees in partially observable domains. We compare the performance of these two algorithms on benchmark problems.</abstract>
   </article>
   <article>
      <title>Efficient algorithms for decision tree cross-validation</title>
      <author>Hendrik Blockeel, Jan Struyf</author>
      <date>2001-10-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Cross-validation is a useful and generally applicable technique often employed in machine learning, including decision tree induction. An important disadvantage of straightforward implementation of the technique is its computational overhead. In this paper we show that, for decision trees, the computational overhead of cross-validation can be reduced significantly by integrating the cross-validation with the normal decision tree induction process. We discuss how existing decision tree algorithms can be adapted to this aim, and provide an analysis of the speedups these adaptations may yield. The analysis is supported by experimental results.</abstract>
   </article>
   <article>
      <title>Evaluation of the Performance of the Markov Blanket Bayesian Classifier
  Algorithm</title>
      <author>Michael G. Madden</author>
      <date>2002-11-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The Markov Blanket Bayesian Classifier is a recently-proposed algorithm for construction of probabilistic classifiers. This paper presents an empirical comparison of the MBBC algorithm with three other Bayesian classifiers: Naive Bayes, Tree-Augmented Naive Bayes and a general Bayesian network. All of these are implemented using the K2 framework of Cooper and Herskovits. The classifiers are compared in terms of their performance (using simple accuracy measures and ROC curves) and speed, on a range of standard benchmark data sets. It is concluded that MBBC is competitive in terms of speed and accuracy with the other algorithms considered.</abstract>
   </article>
   <article>
      <title>Approximating Incomplete Kernel Matrices by the em Algorithm</title>
      <author>Koji Tsuda, Shotaro Akaho, Kiyoshi Asai</author>
      <date>2002-11-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In biological data, it is often the case that observed data are available only for a subset of samples. When a kernel matrix is derived from such data, we have to leave the entries for unavailable samples as missing. In this paper, we make use of a parametric model of kernel matrices, and estimate missing entries by fitting the model to existing entries. The parametric model is created as a set of spectral variants of a complete kernel matrix derived from another information source. For model fitting, we adopt the em algorithm based on the information geometry of positive definite matrices. We will report promising results on bacteria clustering experiments using two marker sequences: 16S and gyrB.</abstract>
   </article>
   <article>
      <title>Reliable and Efficient Inference of Bayesian Networks from Sparse Data
  by Statistical Learning Theory</title>
      <author>Dominik Janzing, Daniel Herrmann</author>
      <date>2003-09-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>To learn (statistical) dependencies among random variables requires exponentially large sample size in the number of observed random variables if any arbitrary joint probability distribution can occur.   We consider the case that sparse data strongly suggest that the probabilities can be described by a simple Bayesian network, i.e., by a graph with small in-degree \Delta. Then this simple law will also explain further data with high confidence. This is shown by calculating bounds on the VC dimension of the set of those probability measures that correspond to simple graphs. This allows to select networks by structural risk minimization and gives reliability bounds on the error of the estimated joint measure without (in contrast to a previous paper) any prior assumptions on the set of possible joint measures.   The complexity for searching the optimal Bayesian networks of in-degree \Delta increases only polynomially in the number of random varibales for constant \Delta and the optimal joint measure associated with a given graph can be found by convex optimization.</abstract>
   </article>
   <article>
      <title>Toward Attribute Efficient Learning Algorithms</title>
      <author>Adam R. Klivans, Rocco A. Servedio</author>
      <date>2003-11-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We make progress on two important problems regarding attribute efficient learnability.   First, we give an algorithm for learning decision lists of length $k$ over $n$ variables using $2^{\tilde{O}(k^{1/3})} \log n$ examples and time $n^{\tilde{O}(k^{1/3})}$. This is the first algorithm for learning decision lists that has both subexponential sample complexity and subexponential running time in the relevant parameters. Our approach establishes a relationship between attribute efficient learning and polynomial threshold functions and is based on a new construction of low degree, low weight polynomial threshold functions for decision lists. For a wide range of parameters our construction matches a 1994 lower bound due to Beigel for the ODDMAXBIT predicate and gives an essentially optimal tradeoff between polynomial threshold function degree and weight.   Second, we give an algorithm for learning an unknown parity function on $k$ out of $n$ variables using $O(n^{1-1/k})$ examples in time polynomial in $n$. For $k=o(\log n)$ this yields a polynomial time algorithm with sample complexity $o(n)$. This is the first polynomial time algorithm for learning parity on a superconstant number of variables with sublinear sample complexity.</abstract>
   </article>
   <article>
      <title>Improving spam filtering by combining Naive Bayes with simple k-nearest
  neighbor searches</title>
      <author>Daniel Etzold</author>
      <date>2003-11-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Using naive Bayes for email classification has become very popular within the last few months. They are quite easy to implement and very efficient. In this paper we want to present empirical results of email classification using a combination of naive Bayes and k-nearest neighbor searches. Using this technique we show that the accuracy of a Bayes filter can be improved slightly for a high number of features and significantly for a small number of features.</abstract>
   </article>
   <article>
      <title>About Unitary Rating Score Constructing</title>
      <author>Kromer Victor</author>
      <date>2004-01-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It is offered to pool test points of different subjects and different aspects of the same subject together in order to get the unitary rating score, by the way of nonlinear transformation of indicator points in accordance with Zipf's distribution. It is proposed to use the well-studied distribution of Intellectuality Quotient IQ as the reference distribution for latent variable "progress in studies".</abstract>
   </article>
   <article>
      <title>Mining Heterogeneous Multivariate Time-Series for Learning Meaningful
  Patterns: Application to Home Health Telecare</title>
      <author>Florence Duchene, Catherine Garbay, Vincent Rialle</author>
      <date>2004-12-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>For the last years, time-series mining has become a challenging issue for researchers. An important application lies in most monitoring purposes, which require analyzing large sets of time-series for learning usual patterns. Any deviation from this learned profile is then considered as an unexpected situation. Moreover, complex applications may involve the temporal study of several heterogeneous parameters. In that paper, we propose a method for mining heterogeneous multivariate time-series for learning meaningful patterns. The proposed approach allows for mixed time-series -- containing both pattern and non-pattern data -- such as for imprecise matches, outliers, stretching and global translating of patterns instances in time. We present the early results of our approach in the context of monitoring the health status of a person at home. The purpose is to build a behavioral profile of a person by analyzing the time variations of several quantitative or qualitative parameters recorded through a provision of sensors installed in the home.</abstract>
   </article>
   <article>
      <title>Stability Analysis for Regularized Least Squares Regression</title>
      <author>Cynthia Rudin</author>
      <date>2005-02-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We discuss stability for a class of learning algorithms with respect to noisy labels. The algorithms we consider are for regression, and they involve the minimization of regularized risk functionals, such as L(f) := 1/N sum_i (f(x_i)-y_i)^2+ lambda ||f||_H^2. We shall call the algorithm `stable' if, when y_i is a noisy version of f*(x_i) for some function f* in H, the output of the algorithm converges to f* as the regularization term and noise simultaneously vanish. We consider two flavors of this problem, one where a data set of N points remains fixed, and the other where N -&gt; infinity. For the case where N -&gt; infinity, we give conditions for convergence to f_E (the function which is the expectation of y(x) for each x), as lambda -&gt; 0. For the fixed N case, we describe the limiting 'non-noisy', 'non-regularized' function f*, and give conditions for convergence. In the process, we develop a set of tools for dealing with functionals such as L(f), which are applicable to many other problems in learning theory.</abstract>
   </article>
   <article>
      <title>Probabilistic and Team PFIN-type Learning: General Properties</title>
      <author>Andris Ambainis</author>
      <date>2005-03-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the probability hierarchy for Popperian FINite learning and study the general properties of this hierarchy. We prove that the probability hierarchy is decidable, i.e. there exists an algorithm that receives p_1 and p_2 and answers whether PFIN-type learning with the probability of success p_1 is equivalent to PFIN-type learning with the probability of success p_2.   To prove our result, we analyze the topological structure of the probability hierarchy. We prove that it is well-ordered in descending ordering and order-equivalent to ordinal epsilon_0. This shows that the structure of the hierarchy is very complicated.   Using similar methods, we also prove that, for PFIN-type learning, team learning and probabilistic learning are of the same power.</abstract>
   </article>
   <article>
      <title>Non-asymptotic calibration and resolution</title>
      <author>Vladimir Vovk</author>
      <date>2005-06-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We analyze a new algorithm for probability forecasting of binary observations on the basis of the available data, without making any assumptions about the way the observations are generated. The algorithm is shown to be well calibrated and to have good resolution for long enough sequences of observations and for a suitable choice of its parameter, a kernel on the Cartesian product of the forecast space $[0,1]$ and the data space. Our main results are non-asymptotic: we establish explicit inequalities, shown to be tight, for the performance of the algorithm.</abstract>
   </article>
   <article>
      <title>Defensive forecasting for linear protocols</title>
      <author>Vladimir Vovk, Ilia Nouretdinov, Akimichi Takemura, Glenn Shafer</author>
      <date>2005-06-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a general class of forecasting protocols, called "linear protocols", and discuss several important special cases, including multi-class forecasting. Forecasting is formalized as a game between three players: Reality, whose role is to generate observations; Forecaster, whose goal is to predict the observations; and Skeptic, who tries to make money on any lack of agreement between Forecaster's predictions and the actual observations. Our main mathematical result is that for any continuous strategy for Skeptic in a linear protocol there exists a strategy for Forecaster that does not allow Skeptic's capital to grow. This result is a meta-theorem that allows one to transform any continuous law of probability in a linear protocol into a forecasting strategy whose predictions are guaranteed to satisfy this law. We apply this meta-theorem to a weak law of large numbers in Hilbert spaces to obtain a version of the K29 prediction algorithm for linear protocols and show that this version also satisfies the attractive properties of proper calibration and resolution under a suitable choice of its kernel parameter, with no assumptions about the way the data is generated.</abstract>
   </article>
   <article>
      <title>About one 3-parameter Model of Testing</title>
      <author>Kromer Victor</author>
      <date>2005-06-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This article offers a 3-parameter model of testing, with 1) the difference between the ability level of the examinee and item difficulty; 2) the examinee discrimination and 3) the item discrimination as model parameters.</abstract>
   </article>
   <article>
      <title>On the Job Training</title>
      <author>Jason E. Holt</author>
      <date>2005-06-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a new framework for building and evaluating machine learning algorithms. We argue that many real-world problems require an agent which must quickly learn to respond to demands, yet can continue to perform and respond to new training throughout its useful life. We give a framework for how such agents can be built, describe several metrics for evaluating them, and show that subtle changes in system construction can significantly affect agent performance.</abstract>
   </article>
   <article>
      <title>Multiresolution Kernels</title>
      <author>Marco Cuturi, Kenji Fukumizu</author>
      <date>2005-07-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present in this work a new methodology to design kernels on data which is structured with smaller components, such as text, images or sequences. This methodology is a template procedure which can be applied on most kernels on measures and takes advantage of a more detailed "bag of components" representation of the objects. To obtain such a detailed description, we consider possible decompositions of the original bag into a collection of nested bags, following a prior knowledge on the objects' structure. We then consider these smaller bags to compare two objects both in a detailed perspective, stressing local matches between the smaller bags, and in a global or coarse perspective, by considering the entire bag. This multiresolution approach is likely to be best suited for tasks where the coarse approach is not precise enough, and where a more subtle mixture of both local and global similarities is necessary to compare objects. The approach presented here would not be computationally tractable without a factorization trick that we introduce before presenting promising results on an image retrieval task.</abstract>
   </article>
   <article>
      <title>Defensive Universal Learning with Experts</title>
      <author>Jan Poland, Marcus Hutter</author>
      <date>2005-07-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper shows how universal learning can be achieved with expert advice. To this aim, we specify an experts algorithm with the following characteristics: (a) it uses only feedback from the actions actually chosen (bandit setup), (b) it can be applied with countably infinite expert classes, and (c) it copes with losses that may grow in time appropriately slowly. We prove loss bounds against an adaptive adversary. From this, we obtain a master algorithm for "reactive" experts problems, which means that the master's actions may influence the behavior of the adversary. Our algorithm can significantly outperform standard experts algorithms on such problems. Finally, we combine it with a universal expert class. The resulting universal learner performs -- in a certain sense -- almost as well as any computable strategy, for any online decision problem. We also specify the (worst-case) convergence speed, which is very slow.</abstract>
   </article>
   <article>
      <title>FPL Analysis for Adaptive Bandits</title>
      <author>Jan Poland</author>
      <date>2005-07-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A main problem of "Follow the Perturbed Leader" strategies for online decision problems is that regret bounds are typically proven against oblivious adversary. In partial observation cases, it was not clear how to obtain performance guarantees against adaptive adversary, without worsening the bounds. We propose a conceptually simple argument to resolve this problem. Using this, a regret bound of O(t^(2/3)) for FPL in the adversarial multi-armed bandit problem is shown. This bound holds for the common FPL variant using only the observations from designated exploration rounds. Using all observations allows for the stronger bound of O(t^(1/2)), matching the best bound known so far (and essentially the known lower bound) for adversarial bandits. Surprisingly, this variant does not even need explicit exploration, it is self-stabilizing. However the sampling probabilities have to be either externally provided or approximated to sufficient accuracy, using O(t^2 log t) samples in each step.</abstract>
   </article>
   <article>
      <title>Learning Optimal Augmented Bayes Networks</title>
      <author>Vikas Hamine, Paul Helman</author>
      <date>2005-09-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Naive Bayes is a simple Bayesian classifier with strong independence assumptions among the attributes. This classifier, desipte its strong independence assumptions, often performs well in practice. It is believed that relaxing the independence assumptions of a naive Bayes classifier may improve the classification accuracy of the resulting structure. While finding an optimal unconstrained Bayesian Network (for most any reasonable scoring measure) is an NP-hard problem, it is possible to learn in polynomial time optimal networks obeying various structural restrictions. Several authors have examined the possibilities of adding augmenting arcs between attributes of a Naive Bayes classifier. Friedman, Geiger and Goldszmidt define the TAN structure in which the augmenting arcs form a tree on the attributes, and present a polynomial time algorithm that learns an optimal TAN with respect to MDL score. Keogh and Pazzani define Augmented Bayes Networks in which the augmenting arcs form a forest on the attributes (a collection of trees, hence a relaxation of the stuctural restriction of TAN), and present heuristic search methods for learning good, though not optimal, augmenting arc sets. The authors, however, evaluate the learned structure only in terms of observed misclassification error and not against a scoring metric, such as MDL. In this paper, we present a simple, polynomial time greedy algorithm for learning an optimal Augmented Bayes Network with respect to MDL score.</abstract>
   </article>
   <article>
      <title>Learning Unions of $ω(1)$-Dimensional Rectangles</title>
      <author>Alp Atici, Rocco A. Servedio</author>
      <date>2005-10-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of learning unions of rectangles over the domain $[b]^n$, in the uniform distribution membership query learning setting, where both b and n are "large". We obtain poly$(n, \log b)$-time algorithms for the following classes:   - poly$(n \log b)$-way Majority of $O(\frac{\log(n \log b)} {\log \log(n \log b)})$-dimensional rectangles.   - Union of poly$(\log(n \log b))$ many $O(\frac{\log^2 (n \log b)} {(\log \log(n \log b) \log \log \log (n \log b))^2})$-dimensional rectangles.   - poly$(n \log b)$-way Majority of poly$(n \log b)$-Or of disjoint $O(\frac{\log(n \log b)} {\log \log(n \log b)})$-dimensional rectangles.   Our main algorithmic tool is an extension of Jackson's boosting- and Fourier-based Harmonic Sieve algorithm [Jackson 1997] to the domain $[b]^n$, building on work of [Akavia, Goldwasser, Safra 2003]. Other ingredients used to obtain the results stated above are techniques from exact learning [Beimel, Kushilevitz 1998] and ideas from recent work on learning augmented $AC^{0}$ circuits [Jackson, Klivans, Servedio 2002] and on representing Boolean functions as thresholds of parities [Klivans, Servedio 2001].</abstract>
   </article>
   <article>
      <title>On-line regression competitive with reproducing kernel Hilbert spaces</title>
      <author>Vladimir Vovk</author>
      <date>2005-11-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of on-line prediction of real-valued labels, assumed bounded in absolute value by a known constant, of new objects from known labeled objects. The prediction algorithm's performance is measured by the squared deviation of the predictions from the actual labels. No stochastic assumptions are made about the way the labels and objects are generated. Instead, we are given a benchmark class of prediction rules some of which are hoped to produce good predictions. We show that for a wide range of infinite-dimensional benchmark classes one can construct a prediction algorithm whose cumulative loss over the first N examples does not exceed the cumulative loss of any prediction rule in the class plus O(sqrt(N)); the main differences from the known results are that we do not impose any upper bound on the norm of the considered prediction rules and that we achieve an optimal leading term in the excess loss of our algorithm. If the benchmark class is "universal" (dense in the class of continuous functions on each compact set), this provides an on-line non-stochastic analogue of universally consistent prediction in non-parametric statistics. We use two proof techniques: one is based on the Aggregating Algorithm and the other on the recently developed method of defensive forecasting.</abstract>
   </article>
   <article>
      <title>Bounds on Query Convergence</title>
      <author>Barak A. Pearlmutter</author>
      <date>2005-11-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The problem of finding an optimum using noisy evaluations of a smooth cost function arises in many contexts, including economics, business, medicine, experiment design, and foraging theory. We derive an asymptotic bound E[ (x_t - x*)^2 ] &gt;= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1, &gt;...) generated by an unbiased feedback process observing noisy evaluations of an unknown quadratic function maximised at x*. The bound is tight, as the proof leads to a simple algorithm which meets it. We further establish a bound on the total regret, E[ sum_{i=1..t} (x_i - x*)^2 ] &gt;= O(sqrt(t)) These bounds may impose practical limitations on an agent's performance, as O(eps^-4) queries are made before the queries converge to x* with eps accuracy.</abstract>
   </article>
   <article>
      <title>Preference Learning in Terminology Extraction: A ROC-based approach</title>
      <author>Jérôme Azé, Mathieu Roche, Yves Kodratoff, Michèle Sebag</author>
      <date>2005-12-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A key data preparation step in Text Mining, Term Extraction selects the terms, or collocation of words, attached to specific concepts. In this paper, the task of extracting relevant collocations is achieved through a supervised learning algorithm, exploiting a few collocations manually labelled as relevant/irrelevant. The candidate terms are described along 13 standard statistical criteria measures. From these examples, an evolutionary learning algorithm termed Roger, based on the optimization of the Area under the ROC curve criterion, extracts an order on the candidate terms. The robustness of the approach is demonstrated on two real-world domain applications, considering different domains (biology and human resources) and different languages (English and French).</abstract>
   </article>
   <article>
      <title>Competing with wild prediction rules</title>
      <author>Vladimir Vovk</author>
      <date>2005-12-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of on-line prediction competitive with a benchmark class of continuous but highly irregular prediction rules. It is known that if the benchmark class is a reproducing kernel Hilbert space, there exists a prediction algorithm whose average loss over the first N examples does not exceed the average loss of any prediction rule in the class plus a "regret term" of O(N^(-1/2)). The elements of some natural benchmark classes, however, are so irregular that these classes are not Hilbert spaces. In this paper we develop Banach-space methods to construct a prediction algorithm with a regret term of O(N^(-1/p)), where p is in [2,infty) and p-2 reflects the degree to which the benchmark class fails to be a Hilbert space.</abstract>
   </article>
   <article>
      <title>Genetic Programming, Validation Sets, and Parsimony Pressure</title>
      <author>Christian Gagné, Marc Schoenauer, Marc Parizeau, Marco Tomassini</author>
      <date>2006-01-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Fitness functions based on test cases are very common in Genetic Programming (GP). This process can be assimilated to a learning task, with the inference of models from a limited number of samples. This paper is an investigation on two methods to improve generalization in GP-based learning: 1) the selection of the best-of-run individuals using a three data sets methodology, and 2) the application of parsimony pressure in order to reduce the complexity of the solutions. Results using GP in a binary classification setup show that while the accuracy on the test sets is preserved, with less variances compared to baseline results, the mean tree size obtained with the tested methods is significantly reduced.</abstract>
   </article>
   <article>
      <title>Processing of Test Matrices with Guessing Correction</title>
      <author>Kromer Victor</author>
      <date>2006-01-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It is suggested to insert into test matrix 1s for correct responses, 0s for response refusals, and negative corrective elements for incorrect responses. With the classical test theory approach test scores of examinees and items are calculated traditionally as sums of matrix elements, organized in rows and columns. Correlation coefficients are estimated using correction coefficients. In item response theory approach examinee and item logits are estimated using maximum likelihood method and probabilities of all matrix elements.</abstract>
   </article>
   <article>
      <title>Learning rational stochastic languages</title>
      <author>François Denis, Yann Esposito, Amaury Habrard</author>
      <date>2006-02-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Given a finite set of words w1,...,wn independently drawn according to a fixed unknown distribution law P called a stochastic language, an usual goal in Grammatical Inference is to infer an estimate of P in some class of probabilistic models, such as Probabilistic Automata (PA). Here, we study the class of rational stochastic languages, which consists in stochastic languages that can be generated by Multiplicity Automata (MA) and which strictly includes the class of stochastic languages generated by PA. Rational stochastic languages have minimal normal representation which may be very concise, and whose parameters can be efficiently estimated from stochastic samples. We design an efficient inference algorithm DEES which aims at building a minimal normal representation of the target. Despite the fact that no recursively enumerable class of MA computes exactly the set of rational stochastic languages over Q, we show that DEES strongly identifies tis set in the limit. We study the intermediary MA output by DEES and show that they compute rational series which converge absolutely to one and which can be used to provide stochastic languages which closely estimate the target.</abstract>
   </article>
   <article>
      <title>General Discounting versus Average Reward</title>
      <author>Marcus Hutter</author>
      <date>2006-05-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Consider an agent interacting with an environment in cycles. In every interaction cycle the agent is rewarded for its performance. We compare the average reward U from cycle 1 to m (average value) with the future discounted reward V from cycle k to infinity (discounted value). We consider essentially arbitrary (non-geometric) discount sequences and arbitrary reward sequences (non-MDP environments). We show that asymptotically U for m-&gt;infinity and V for k-&gt;infinity are equal, provided both limits exist. Further, if the effective horizon grows linearly with k or faster, then existence of the limit of U implies that the limit of V exists. Conversely, if the effective horizon grows linearly with k or slower, then existence of the limit of V implies that the limit of U exists.</abstract>
   </article>
   <article>
      <title>On Sequence Prediction for Arbitrary Measures</title>
      <author>Daniil Ryabko, Marcus Hutter</author>
      <date>2006-06-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Suppose we are given two probability measures on the set of one-way infinite finite-alphabet sequences and consider the question when one of the measures predicts the other, that is, when conditional probabilities converge (in a certain sense) when one of the measures is chosen to generate the sequence. This question may be considered a refinement of the problem of sequence prediction in its most general formulation: for a given class of probability measures, does there exist a measure which predicts all of the measures in the class? To address this problem, we find some conditions on local absolute continuity which are sufficient for prediction and which generalize several different notions which are known to be sufficient for prediction. We also formulate some open questions to outline a direction for finding the conditions on classes of measures for which prediction is possible.</abstract>
   </article>
   <article>
      <title>Predictions as statements and decisions</title>
      <author>Vladimir Vovk</author>
      <date>2006-06-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Prediction is a complex notion, and different predictors (such as people, computer programs, and probabilistic theories) can pursue very different goals. In this paper I will review some popular kinds of prediction and argue that the theory of competitive on-line learning can benefit from the kinds of prediction that are now foreign to it.</abstract>
   </article>
   <article>
      <title>PAC Classification based on PAC Estimates of Label Class Distributions</title>
      <author>Nick Palmer, Paul W. Goldberg</author>
      <date>2006-07-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A standard approach in pattern classification is to estimate the distributions of the label classes, and then to apply the Bayes classifier to the estimates of the distributions in order to classify unlabeled examples. As one might expect, the better our estimates of the label class distributions, the better the resulting classifier will be. In this paper we make this observation precise by identifying risk bounds of a classifier in terms of the quality of the estimates of the label class distributions. We show how PAC learnability relates to estimates of the distributions that have a PAC guarantee on their $L_1$ distance from the true distribution, and we bound the increase in negative log likelihood risk in terms of PAC bounds on the KL-divergence. We give an inefficient but general-purpose smoothing method for converting an estimated distribution that is good under the $L_1$ metric into a distribution that is good under the KL-divergence.</abstract>
   </article>
   <article>
      <title>Competing with stationary prediction strategies</title>
      <author>Vladimir Vovk</author>
      <date>2006-07-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we introduce the class of stationary prediction strategies and construct a prediction algorithm that asymptotically performs as well as the best continuous stationary strategy. We make mild compactness assumptions but no stochastic assumptions about the environment. In particular, no assumption of stationarity is made about the environment, and the stationarity of the considered strategies only means that they do not depend explicitly on time; we argue that it is natural to consider only stationary strategies even for highly non-stationary environments.</abstract>
   </article>
   <article>
      <title>Using Pseudo-Stochastic Rational Languages in Probabilistic Grammatical
  Inference</title>
      <author>Amaury Habrard, Francois Denis, Yann Esposito</author>
      <date>2006-07-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In probabilistic grammatical inference, a usual goal is to infer a good approximation of an unknown distribution P called a stochastic language. The estimate of P stands in some class of probabilistic models such as probabilistic automata (PA). In this paper, we focus on probabilistic models based on multiplicity automata (MA). The stochastic languages generated by MA are called rational stochastic languages; they strictly include stochastic languages generated by PA; they also admit a very concise canonical representation. Despite the fact that this class is not recursively enumerable, it is efficiently identifiable in the limit by using the algorithm DEES, introduced by the authors in a previous paper. However, the identification is not proper and before the convergence of the algorithm, DEES can produce MA that do not define stochastic languages. Nevertheless, it is possible to use these MA to define stochastic languages. We show that they belong to a broader class of rational series, that we call pseudo-stochastic rational languages. The aim of this paper is twofold. First we provide a theoretical study of pseudo-stochastic rational languages, the languages output by DEES, showing for example that this class is decidable within polynomial time. Second, we have carried out a lot of experiments in order to compare DEES to classical inference algorithms such as ALERGIA and MDI. They show that DEES outperforms them in most cases.</abstract>
   </article>
   <article>
      <title>Logical settings for concept learning from incomplete examples in First
  Order Logic</title>
      <author>Dominique Bouthinon, Henry Soldano, Véronique Ventos</author>
      <date>2006-07-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We investigate here concept learning from incomplete examples. Our first purpose is to discuss to what extent logical learning settings have to be modified in order to cope with data incompleteness. More precisely we are interested in extending the learning from interpretations setting introduced by L. De Raedt that extends to relational representations the classical propositional (or attribute-value) concept learning from examples framework. We are inspired here by ideas presented by H. Hirsh in a work extending the Version space inductive paradigm to incomplete data. H. Hirsh proposes to slightly modify the notion of solution when dealing with incomplete examples: a solution has to be a hypothesis compatible with all pieces of information concerning the examples. We identify two main classes of incompleteness. First, uncertainty deals with our state of knowledge concerning an example. Second, generalization (or abstraction) deals with what part of the description of the example is sufficient for the learning purpose. These two main sources of incompleteness can be mixed up when only part of the useful information is known. We discuss a general learning setting, referred to as "learning from possibilities" that formalizes these ideas, then we present a more specific learning setting, referred to as "assumption-based learning" that cope with examples which uncertainty can be reduced when considering contextual information outside of the proper description of the examples. Assumption-based learning is illustrated on a recent work concerning the prediction of a consensus secondary structure common to a set of RNA sequences.</abstract>
   </article>
   <article>
      <title>A Theory of Probabilistic Boosting, Decision Trees and Matryoshki</title>
      <author>Etienne Grossmann</author>
      <date>2006-07-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a theory of boosting probabilistic classifiers. We place ourselves in the situation of a user who only provides a stopping parameter and a probabilistic weak learner/classifier and compare three types of boosting algorithms: probabilistic Adaboost, decision tree, and tree of trees of ... of trees, which we call matryoshka. "Nested tree," "embedded tree" and "recursive tree" are also appropriate names for this algorithm, which is one of our contributions. Our other contribution is the theoretical analysis of the algorithms, in which we give training error bounds. This analysis suggests that the matryoshka leverages probabilistic weak classifiers more efficiently than simple decision trees.</abstract>
   </article>
   <article>
      <title>Leading strategies in competitive on-line prediction</title>
      <author>Vladimir Vovk</author>
      <date>2006-07-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We start from a simple asymptotic result for the problem of on-line regression with the quadratic loss function: the class of continuous limited-memory prediction strategies admits a "leading prediction strategy", which not only asymptotically performs at least as well as any continuous limited-memory strategy but also satisfies the property that the excess loss of any continuous limited-memory strategy is determined by how closely it imitates the leading strategy. More specifically, for any class of prediction strategies constituting a reproducing kernel Hilbert space we construct a leading strategy, in the sense that the loss of any prediction strategy whose norm is not too large is determined by how closely it imitates the leading strategy. This result is extended to the loss functions given by Bregman divergences and by strictly proper scoring rules.</abstract>
   </article>
   <article>
      <title>Competing with Markov prediction strategies</title>
      <author>Vladimir Vovk</author>
      <date>2006-07-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Assuming that the loss function is convex in the prediction, we construct a prediction strategy universal for the class of Markov prediction strategies, not necessarily continuous. Allowing randomization, we remove the requirement of convexity.</abstract>
   </article>
   <article>
      <title>A Study on Learnability for Rigid Lambek Grammars</title>
      <author>Roberto Bonato</author>
      <date>2006-08-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present basic notions of Gold's "learnability in the limit" paradigm, first presented in 1967, a formalization of the cognitive process by which a native speaker gets to grasp the underlying grammar of his/her own native language by being exposed to well formed sentences generated by that grammar. Then we present Lambek grammars, a formalism issued from categorial grammars which, although not as expressive as needed for a full formalization of natural languages, is particularly suited to easily implement a natural interface between syntax and semantics. In the last part of this work, we present a learnability result for Rigid Lambek grammars from structured examples.</abstract>
   </article>
   <article>
      <title>A Massive Local Rules Search Approach to the Classification Problem</title>
      <author>Vladislav Malyshkin, Ray Bakhramov, Andrey Gorodetsky</author>
      <date>2006-09-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>An approach to the classification problem of machine learning, based on building local classification rules, is developed. The local rules are considered as projections of the global classification rules to the event we want to classify. A massive global optimization algorithm is used for optimization of quality criterion. The algorithm, which has polynomial complexity in typical case, is used to find all high--quality local rules. The other distinctive feature of the algorithm is the integration of attributes levels selection (for ordered attributes) with rules searching and original conflicting rules resolution strategy. The algorithm is practical; it was tested on a number of data sets from UCI repository, and a comparison with the other predicting techniques is presented.</abstract>
   </article>
   <article>
      <title>Metric entropy in competitive on-line prediction</title>
      <author>Vladimir Vovk</author>
      <date>2006-09-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Competitive on-line prediction (also known as universal prediction of individual sequences) is a strand of learning theory avoiding making any stochastic assumptions about the way the observations are generated. The predictor's goal is to compete with a benchmark class of prediction rules, which is often a proper Banach function space. Metric entropy provides a unifying framework for competitive on-line prediction: the numerous known upper bounds on the metric entropy of various compact sets in function spaces readily imply bounds on the performance of on-line prediction strategies. This paper discusses strengths and limitations of the direct approach to competitive on-line prediction via metric entropy, including comparisons to other approaches.</abstract>
   </article>
   <article>
      <title>PAC Learning Mixtures of Axis-Aligned Gaussians with No Separation
  Assumption</title>
      <author>Jon Feldman, Ryan O'Donnell, Rocco A. Servedio</author>
      <date>2006-09-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose and analyze a new vantage point for the learning of mixtures of Gaussians: namely, the PAC-style model of learning probability distributions introduced by Kearns et al. Here the task is to construct a hypothesis mixture of Gaussians that is statistically indistinguishable from the actual mixture generating the data; specifically, the KL-divergence should be at most epsilon.   In this scenario, we give a poly(n/epsilon)-time algorithm that learns the class of mixtures of any constant number of axis-aligned Gaussians in n-dimensional Euclidean space. Our algorithm makes no assumptions about the separation between the means of the Gaussians, nor does it have any dependence on the minimum mixing weight. This is in contrast to learning results known in the ``clustering'' model, where such assumptions are unavoidable.   Our algorithm relies on the method of moments, and a subalgorithm developed in previous work by the authors (FOCS 2005) for a discrete mixture-learning problem.</abstract>
   </article>
   <article>
      <title>Hedging predictions in machine learning</title>
      <author>Alexander Gammerman, Vladimir Vovk</author>
      <date>2006-11-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recent advances in machine learning make it possible to design efficient prediction algorithms for data sets with huge numbers of parameters. This paper describes a new technique for "hedging" the predictions output by many such algorithms, including <term>support vector machine</term>s, kernel ridge regression, kernel nearest neighbours, and by many other state-of-the-art methods. The hedged predictions for the labels of new objects include quantitative measures of their own accuracy and reliability. These measures are provably valid under the assumption of randomness, traditional in machine learning: the objects and their labels are assumed to be generated independently from the same probability distribution. In particular, it becomes possible to control (up to statistical fluctuations) the number of erroneous predictions by selecting a suitable confidence level. Validity being achieved automatically, the remaining goal of hedged prediction is efficiency: taking full account of the new objects' features and other available information to produce as accurate predictions as possible. This can be done successfully using the powerful machinery of modern machine learning.</abstract>
   </article>
   <article>
      <title>A Unified View of TD Algorithms; Introducing Full-Gradient TD and
  Equi-Gradient Descent TD</title>
      <author>Manuel Loth, Philippe Preux</author>
      <date>2006-11-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper addresses the issue of policy evaluation in Markov Decision Processes, using linear function approximation. It provides a unified view of algorithms such as TD(lambda), LSTD(lambda), iLSTD, residual-gradient TD. It is asserted that they all consist in minimizing a gradient function and differ by the form of this function and their means of minimizing it. Two new schemes are introduced in that framework: Full-gradient TD which uses a generalization of the principle introduced in iLSTD, and EGD TD, which reduces the gradient by successive equi-<term>gradient descent</term>s. These three algorithms form a new intermediate family with the interesting property of making much better use of the samples than TD while keeping a <term>gradient descent</term> scheme, which is useful for complexity issues and optimistic policy iteration.</abstract>
   </article>
   <article>
      <title>Bandit Algorithms for Tree Search</title>
      <author>Pierre-Arnaud Coquelin, Rémi Munos</author>
      <date>2007-03-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Bandit based methods for tree search have recently gained popularity when applied to huge trees, e.g. in the game of go (Gelly et al., 2006). The UCT algorithm (Kocsis and Szepesvari, 2006), a tree search method based on Upper Confidence Bounds (UCB) (Auer et al., 2002), is believed to adapt locally to the effective smoothness of the tree. However, we show that UCT is too ``optimistic'' in some cases, leading to a regret O(exp(exp(D))) where D is the depth of the tree. We propose alternative bandit algorithms for tree search. First, a modification of UCT using a confidence sequence that scales exponentially with the horizon depth is proven to have a regret O(2^D \sqrt{n}), but does not adapt to possible smoothness in the tree. We then analyze Flat-UCB performed on the leaves and provide a finite regret bound with high probability. Then, we introduce a UCB-based Bandit Algorithm for Smooth Trees which takes into account actual smoothness of the rewards for performing efficient ``cuts'' of sub-optimal branches with high confidence. Finally, we present an incremental tree search version which applies when the full tree is too big (possibly infinite) to be entirely represented and show that with high probability, essentially only the optimal branches is indefinitely developed. We illustrate these methods on a global optimization problem of a Lipschitz function, given noisy data.</abstract>
   </article>
   <article>
      <title>Intrinsic dimension of a dataset: what properties does one expect?</title>
      <author>Vladimir Pestov</author>
      <date>2007-03-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose an axiomatic approach to the concept of an intrinsic dimension of a dataset, based on a viewpoint of geometry of high-dimensional structures. Our first axiom postulates that high values of dimension be indicative of the presence of the curse of dimensionality (in a certain precise mathematical sense). The second axiom requires the dimension to depend smoothly on a distance between datasets (so that the dimension of a dataset and that of an approximating principal manifold would be close to each other). The third axiom is a normalization condition: the dimension of the Euclidean $n$-sphere $\s^n$ is $\Theta(n)$. We give an example of a dimension function satisfying our axioms, even though it is in general computationally unfeasible, and discuss a computationally cheap function satisfying most but not all of our axioms (the ``intrinsic dimensionality'' of Ch\'avez et al.)</abstract>
   </article>
   <article>
      <title>Parametric Learning and Monte Carlo Optimization</title>
      <author>David H. Wolpert, Dev G. Rajnarayan</author>
      <date>2007-04-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper uncovers and explores the close relationship between Monte Carlo Optimization of a parametrized integral (MCO), Parametric machine-Learning (PL), and `blackbox' or `oracle'-based optimization (BO). We make four contributions. First, we prove that MCO is mathematically identical to a broad class of PL problems. This identity potentially provides a new application domain for all broadly applicable PL techniques: MCO. Second, we introduce immediate sampling, a new version of the Probability Collectives (PC) algorithm for blackbox optimization. Immediate sampling transforms the original BO problem into an MCO problem. Accordingly, by combining these first two contributions, we can apply all PL techniques to BO. In our third contribution we validate this way of improving BO by demonstrating that cross-validation and bagging improve immediate sampling. Finally, conventional MC and MCO procedures ignore the relationship between the sample point locations and the associated values of the integrand; only the values of the integrand at those locations are considered. We demonstrate that one can exploit the sample location information using PL techniques, for example by forming a fit of the sample locations to the associated values of the integrand. This provides an additional way to apply PL techniques to improve MCO.</abstract>
   </article>
   <article>
      <title>Supervised Feature Selection via Dependence Estimation</title>
      <author>Le Song, Alex Smola, Arthur Gretton, Karsten Borgwardt, Justin Bedo</author>
      <date>2007-04-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a framework for filtering features that employs the Hilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence between the features and the labels. The key idea is that good features should maximise such dependence. Feature selection for various supervised learning problems (including classification and regression) is unified under this framework, and the solutions can be approximated using a backward-elimination algorithm. We demonstrate the usefulness of our method on both artificial and real world datasets.</abstract>
   </article>
   <article>
      <title>HMM Speaker Identification Using Linear and Non-linear Merging
  Techniques</title>
      <author>Unathi Mahola, Fulufhelo V. Nelwamondo, Tshilidzi Marwala</author>
      <date>2007-05-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Speaker identification is a powerful, non-invasive and in-expensive biometric technique. The recognition accuracy, however, deteriorates when noise levels affect a specific band of frequency. In this paper, we present a sub-band based speaker identification that intends to improve the live testing performance. Each frequency sub-band is processed and classified independently. We also compare the linear and non-linear merging techniques for the sub-bands recognizer. Support vector machines and Gaussian Mixture models are the non-linear merging techniques that are investigated. Results showed that the sub-band based method used with linear merging techniques enormously improved the performance of the speaker identification over the performance of wide-band recognizers when tested live. A live testing improvement of 9.78% was achieved</abstract>
   </article>
   <article>
      <title>Scale-sensitive Psi-dimensions: the Capacity Measures for Classifiers
  Taking Values in R^Q</title>
      <author>Yann Guermeur</author>
      <date>2007-06-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Bounds on the risk play a crucial role in statistical learning theory. They usually involve as capacity measure of the model studied the VC dimension or one of its extensions. In classification, such "VC dimensions" exist for models taking values in {0, 1}, {1,..., Q} and R. We introduce the generalizations appropriate for the missing case, the one of models with values in R^Q. This provides us with a new guaranteed risk for M-SVMs which appears superior to the existing one.</abstract>
   </article>
   <article>
      <title>Consistency of the group Lasso and multiple kernel learning</title>
      <author>Francis Bach</author>
      <date>2007-07-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the least-square regression problem with regularization by a block 1-norm, i.e., a sum of Euclidean norms over spaces of dimensions larger than one. This problem, referred to as the group Lasso, extends the usual regularization by the 1-norm where all spaces have dimension one, where it is commonly referred to as the Lasso. In this paper, we study the asymptotic model consistency of the group Lasso. We derive necessary and sufficient conditions for the consistency of group Lasso under practical assumptions, such as model misspecification. When the linear predictors and Euclidean norms are replaced by functions and reproducing kernel Hilbert norms, the problem is usually referred to as multiple kernel learning and is commonly used for learning from heterogeneous data sources and for non linear variable selection. Using tools from functional analysis, and in particular covariance operators, we extend the consistency results to this infinite dimensional case and also propose an adaptive scheme to obtain a consistent model estimate, even when the necessary condition required for the non adaptive scheme is not satisfied.</abstract>
   </article>
   <article>
      <title>Cost-minimising strategies for data labelling : optimal stopping and
  active learning</title>
      <author>Christos Dimitrakakis, Christian Savu-Krohn</author>
      <date>2007-08-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Supervised learning deals with the inference of a distribution over an output or label space $\CY$ conditioned on points in an observation space $\CX$, given a training dataset $D$ of pairs in $\CX \times \CY$. However, in a lot of applications of interest, acquisition of large amounts of observations is easy, while the process of generating labels is time-consuming or costly. One way to deal with this problem is {\em active} learning, where points to be labelled are selected with the aim of creating a model with better performance than that of an model trained on an equal number of randomly sampled points. In this paper, we instead propose to deal with the labelling cost directly: The learning goal is defined as the minimisation of a cost which is a function of the expected model performance and the total cost of the labels used. This allows the development of general strategies and specific algorithms for (a) optimal stopping, where the expected cost dictates whether label acquisition should continue (b) empirical evaluation, where the cost is used as a performance metric for a given combination of inference, stopping and sampling methods. Though the main focus of the paper is optimal stopping, we also aim to provide the background for further developments and discussion in the related field of active learning.</abstract>
   </article>
   <article>
      <title>Defensive forecasting for optimal prediction with expert advice</title>
      <author>Vladimir Vovk</author>
      <date>2007-08-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The method of defensive forecasting is applied to the problem of prediction with expert advice for binary outcomes. It turns out that defensive forecasting is not only competitive with the Aggregating Algorithm but also handles the case of "second-guessing" experts, whose advice depends on the learner's prediction; this paper assumes that the dependence on the learner's prediction is continuous.</abstract>
   </article>
   <article>
      <title>Continuous and randomized defensive forecasting: unified view</title>
      <author>Vladimir Vovk</author>
      <date>2007-08-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Defensive forecasting is a method of transforming laws of probability (stated in game-theoretic terms as strategies for Sceptic) into forecasting algorithms. There are two known varieties of defensive forecasting: "continuous", in which Sceptic's moves are assumed to depend on the forecasts in a (semi)continuous manner and which produces deterministic forecasts, and "randomized", in which the dependence of Sceptic's moves on the forecasts is arbitrary and Forecaster's moves are allowed to be randomized. This note shows that the randomized variety can be obtained from the continuous variety by smearing Sceptic's moves to make them continuous.</abstract>
   </article>
   <article>
      <title>Filtering Additive Measurement Noise with Maximum Entropy in the Mean</title>
      <author>Henryk Gzyl, Enrique ter Horst</author>
      <date>2007-09-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The purpose of this note is to show how the method of maximum entropy in the mean (MEM) may be used to improve parametric estimation when the measurements are corrupted by large level of noise. The method is developed in the context on a concrete example: that of estimation of the parameter in an exponential distribution. We compare the performance of our method with the bayesian and maximum likelihood approaches.</abstract>
   </article>
   <article>
      <title>Prediction with expert advice for the Brier game</title>
      <author>Vladimir Vovk, Fedor Zhdanov</author>
      <date>2007-10-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We show that the Brier game of prediction is mixable and find the optimal learning rate and substitution function for it. The resulting prediction algorithm is applied to predict results of football and tennis matches. The theoretical performance guarantee turns out to be rather tight on these data sets, especially in the case of the more extensive tennis data.</abstract>
   </article>
   <article>
      <title>Consistency of trace norm minimization</title>
      <author>Francis Bach</author>
      <date>2007-10-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Regularization by the sum of singular values, also referred to as the trace norm, is a popular technique for estimating low rank rectangular matrices. In this paper, we extend some of the consistency results of the Lasso to provide necessary and sufficient conditions for rank consistency of trace norm minimization with the square loss. We also provide an adaptive version that is rank consistent even when the necessary condition for the non adaptive version is not fulfilled.</abstract>
   </article>
   <article>
      <title>Clustering with Transitive Distance and K-Means Duality</title>
      <author>Chunjing Xu, Jianzhuang Liu, Xiaoou Tang</author>
      <date>2007-11-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recent spectral clustering methods are a propular and powerful technique for data clustering. These methods need to solve the eigenproblem whose computational complexity is $O(n^3)$, where $n$ is the number of data samples. In this paper, a non-eigenproblem based clustering method is proposed to deal with the clustering problem. Its performance is comparable to the spectral clustering algorithms but it is more efficient with computational complexity $O(n^2)$. We show that with a transitive distance and an observed property, called K-means duality, our algorithm can be used to handle data sets with complex cluster shapes, multi-scale clusters, and noise. Moreover, no parameters except the number of clusters need to be set in our algorithm.</abstract>
   </article>
   <article>
      <title>Covariance and PCA for Categorical Variables</title>
      <author>Hirotaka Niitsuma, Takashi Okada</author>
      <date>2007-11-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Covariances from categorical variables are defined using a regular simplex expression for categories. The method follows the variance definition by Gini, and it gives the covariance as a solution of simultaneous equations. The calculated results give reasonable values for test data. A method of principal component analysis (RS-PCA) is also proposed using regular simplex expressions, which allows easy interpretation of the principal components. The proposed methods apply to variable selection problem of categorical data USCensus1990 data. The proposed methods give appropriate criterion for the variable selection problem of categorical</abstract>
   </article>
   <article>
      <title>On the Relationship between the Posterior and Optimal Similarity</title>
      <author>Thomas M. Breuel</author>
      <date>2007-12-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>For a classification problem described by the joint density $P(\omega,x)$, models of $P(\omega\eq\omega'|x,x')$ (the ``Bayesian similarity measure'') have been shown to be an optimal similarity measure for nearest neighbor classification. This paper analyzes demonstrates several additional properties of that conditional distribution. The paper first shows that we can reconstruct, up to class labels, the class posterior distribution $P(\omega|x)$ given $P(\omega\eq\omega'|x,x')$, gives a procedure for recovering the class labels, and gives an asymptotically Bayes-optimal classification procedure. It also shows, given such an optimal similarity measure, how to construct a classifier that outperforms the nearest neighbor classifier and achieves Bayes-optimal classification rates. The paper then analyzes Bayesian similarity in a framework where a classifier faces a number of related classification tasks (multitask learning) and illustrates that reconstruction of the class posterior distribution is not possible in general. Finally, the paper identifies a distinct class of classification problems using $P(\omega\eq\omega'|x,x')$ and shows that using $P(\omega\eq\omega'|x,x')$ to solve those problems is the Bayes optimal solution.</abstract>
   </article>
   <article>
      <title>Equations of States in Singular Statistical Estimation</title>
      <author>Sumio Watanabe</author>
      <date>2007-12-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Learning machines which have hierarchical structures or hidden variables are singular statistical models because they are nonidentifiable and their Fisher information matrices are singular. In singular statistical models, neither the Bayes a posteriori distribution converges to the normal distribution nor the maximum likelihood estimator satisfies asymptotic normality. This is the main reason why it has been difficult to predict their generalization performances from trained states. In this paper, we study four errors, (1) Bayes generalization error, (2) Bayes training error, (3) Gibbs generalization error, and (4) Gibbs training error, and prove that there are mathematical relations among these errors. The formulas proved in this paper are equations of states in statistical estimation because they hold for any true distribution, any parametric model, and any a priori distribution. Also we show that Bayes and Gibbs generalization errors are estimated by Bayes and Gibbs training errors, and propose widely applicable information criteria which can be applied to both regular and singular statistical models.</abstract>
   </article>
   <article>
      <title>Density estimation in linear time</title>
      <author>Satyaki Mahalanabis, Daniel Stefankovic</author>
      <date>2007-12-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of choosing a density estimate from a set of distributions F, minimizing the L1-distance to an unknown distribution (Devroye, Lugosi 2001). Devroye and Lugosi analyze two algorithms for the problem: Scheffe tournament winner and minimum distance estimate. The Scheffe tournament estimate requires fewer computations than the minimum distance estimate, but has strictly weaker guarantees than the latter.   We focus on the computational aspect of density estimation. We present two algorithms, both with the same guarantee as the minimum distance estimate. The first one, a modification of the minimum distance estimate, uses the same number (quadratic in |F|) of computations as the Scheffe tournament. The second one, called ``efficient minimum loss-weight estimate,'' uses only a linear number of computations, assuming that F is preprocessed.   We also give examples showing that the guarantees of the algorithms cannot be improved and explore randomized algorithms for density estimation.</abstract>
   </article>
   <article>
      <title>Graph kernels between point clouds</title>
      <author>Francis Bach</author>
      <date>2007-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Point clouds are sets of points in two or three dimensions. Most kernel methods for learning on sets of points have not yet dealt with the specific geometrical invariances and practical constraints associated with point clouds in computer vision and graphics. In this paper, we present extensions of graph kernels for point clouds, which allow to use kernel methods for such ob jects as shapes, line drawings, or any three-dimensional point clouds. In order to design rich and numerically efficient kernels with as few free parameters as possible, we use kernels between covariance matrices and their factorizations on graphical models. We derive polynomial time dynamic programming recursions and present applications to recognition of handwritten digits and Chinese characters from few training examples.</abstract>
   </article>
   <article>
      <title>Online variants of the cross-entropy method</title>
      <author>Istvan Szita, Andras Lorincz</author>
      <date>2008-01-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The cross-entropy method is a simple but efficient method for global optimization. In this paper we provide two online variants of the basic CEM, together with a proof of convergence.</abstract>
   </article>
   <article>
      <title>The optimal assignment kernel is not positive definite</title>
      <author>Jean-Philippe Vert</author>
      <date>2008-01-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We prove that the optimal assignment kernel, proposed recently as an attempt to embed labeled graphs and more generally tuples of basic data to a Hilbert space, is in fact not always positive definite.</abstract>
   </article>
   <article>
      <title>New Estimation Procedures for PLS Path Modelling</title>
      <author>Xavier Bry</author>
      <date>2008-02-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Given R groups of numerical variables X1, ... XR, we assume that each group is the result of one underlying latent variable, and that all latent variables are bound together through a linear equation system. Moreover, we assume that some explanatory latent variables may interact pairwise in one or more equations. We basically consider PLS Path Modelling's algorithm to estimate both latent variables and the model's coefficients. New "external" estimation schemes are proposed that draw latent variables towards strong group structures in a more flexible way. New "internal" estimation schemes are proposed to enable PLSPM to make good use of variable group complementarity and to deal with interactions. Application examples are given.</abstract>
   </article>
   <article>
      <title>A New Approach to Collaborative Filtering: Operator Estimation with
  Spectral Regularization</title>
      <author>Jacob Abernethy, Francis Bach, Theodoros Evgeniou, Jean-Philippe Vert</author>
      <date>2008-02-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a general approach for collaborative filtering (CF) using spectral regularization to learn linear operators from "users" to the "objects" they rate. Recent low-rank type matrix completion approaches to CF are shown to be special cases. However, unlike existing regularization based CF methods, our approach can be used to also incorporate information such as attributes of the users or the objects -- a limitation of existing regularization based CF methods. We then provide novel representer theorems that we use to develop new estimation methods. We provide learning algorithms based on low-rank decompositions, and test them on a standard CF dataset. The experiments indicate the advantages of generalizing the existing regularization based CF methods to incorporate related information about users and objects. Finally, we show that certain multi-task learning methods can be also seen as special cases of our proposed approach.</abstract>
   </article>
   <article>
      <title>Multiple Random Oracles Are Better Than One</title>
      <author>Jan Arpe, Elchanan Mossel</author>
      <date>2008-04-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the problem of learning k-juntas given access to examples drawn from a number of different product distributions. Thus we wish to learn a function f : {-1,1}^n -&gt; {-1,1} that depends on k (unknown) coordinates. While the best known algorithms for the general problem of learning a k-junta require running time of n^k * poly(n,2^k), we show that given access to k different product distributions with biases separated by \gamma&gt;0, the functions may be learned in time poly(n,2^k,\gamma^{-k}). More generally, given access to t &lt;= k different product distributions, the functions may be learned in time n^{k/t} * poly(n,2^k,\gamma^{-k}). Our techniques involve novel results in Fourier analysis relating Fourier expansions with respect to different biases and a generalization of Russo's formula.</abstract>
   </article>
   <article>
      <title>Introduction to Relational Networks for Classification</title>
      <author>Vukosi Marivate, Tshilidzi Marwala</author>
      <date>2008-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The use of computational intelligence techniques for classification has been used in numerous applications. This paper compares the use of a Multi Layer Perceptron Neural Network and a new Relational Network on classifying the HIV status of women at ante-natal clinics. The paper discusses the architecture of the relational network and its merits compared to a <term>neural network</term> and most other computational intelligence classifiers. Results gathered from the study indicate comparable classification accuracies as well as revealed relationships between data features in the classification data. Much higher classification accuracies are recommended for future research in the area of HIV classification as well as missing data estimation.</abstract>
   </article>
   <article>
      <title>The Effect of Structural Diversity of an Ensemble of Classifiers on
  Classification Accuracy</title>
      <author>Lesedi Masisi, Fulufhelo V. Nelwamondo, Tshilidzi Marwala</author>
      <date>2008-04-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper aims to showcase the measure of structural diversity of an ensemble of 9 classifiers and then map a relationship between this structural diversity and accuracy. The structural diversity was induced by having different architectures or structures of the classifiers The Genetical Algorithms (GA) were used to derive the relationship between diversity and the classification accuracy by evolving the classifiers and then picking 9 classifiers out on an ensemble of 60 classifiers. It was found that as the ensemble became diverse the accuracy improved. However at a certain diversity measure the accuracy began to drop. The Kohavi-Wolpert variance method is used to measure the diversity of the ensemble. A method of voting is used to aggregate the results from each classifier. The lowest error was observed at a diversity measure of 0.16 with a mean square error of 0.274, when taking 0.2024 as maximum diversity measured. The parameters that were varied were: the number of hidden nodes, learning rate and the activation function.</abstract>
   </article>
   <article>
      <title>A Quadratic Loss Multi-Class SVM</title>
      <author>Emmanuel Monfrini, Yann Guermeur</author>
      <date>2008-04-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Using a <term>support vector machine</term> requires to set two types of hyperparameters: the soft margin parameter C and the parameters of the kernel. To perform this model selection task, the method of choice is cross-validation. Its leave-one-out variant is known to produce an estimator of the generalization error which is almost unbiased. Its major drawback rests in its time requirement. To overcome this difficulty, several upper bounds on the leave-one-out error of the pattern recognition SVM have been derived. Among those bounds, the most popular one is probably the radius-margin bound. It applies to the hard margin pattern recognition SVM, and by extension to the 2-norm SVM. In this report, we introduce a quadratic loss M-SVM, the M-SVM^2, as a direct extension of the 2-norm SVM to the multi-class case. For this machine, a generalized radius-margin bound is then established.</abstract>
   </article>
   <article>
      <title>On Recovery of Sparse Signals via $\ell_1$ Minimization</title>
      <author>T. Tony Cai, Guangwu Xu, Jun Zhang</author>
      <date>2008-05-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This article considers constrained $\ell_1$ minimization methods for the recovery of high dimensional sparse signals in three settings: noiseless, bounded error and Gaussian noise. A unified and elementary treatment is given in these noise settings for two $\ell_1$ minimization methods: the Dantzig selector and $\ell_1$ minimization with an $\ell_2$ constraint. The results of this paper improve the existing results in the literature by weakening the conditions and tightening the error bounds. The improvement on the conditions shows that signals with larger support can be recovered accurately. This paper also establishes connections between restricted isometry property and the mutual incoherence property. Some results of Candes, Romberg and Tao (2006) and Donoho, Elad, and Temlyakov (2006) are extended.</abstract>
   </article>
   <article>
      <title>The Margitron: A Generalised Perceptron with Margin</title>
      <author>Constantinos Panagiotakopoulos, Petroula Tsampouka</author>
      <date>2008-05-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We identify the classical Perceptron algorithm with margin as a member of a broader family of large margin classifiers which we collectively call the Margitron. The Margitron, (despite its) sharing the same update rule with the Perceptron, is shown in an incremental setting to converge in a finite number of updates to solutions possessing any desirable fraction of the maximum margin. Experiments comparing the Margitron with decomposition SVMs on tasks involving linear kernels and 2-norm soft margin are also reported.</abstract>
   </article>
   <article>
      <title>Sample Selection Bias Correction Theory</title>
      <author>Corinna Cortes, Mehryar Mohri, Michael Riley, Afshin Rostamizadeh</author>
      <date>2008-05-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a theoretical analysis of sample selection bias correction. The sample bias correction technique commonly used in machine learning consists of reweighting the cost of an error on each training point of a biased sample to more closely reflect the unbiased distribution. This relies on weights derived by various estimation techniques based on finite samples. We analyze the effect of an error in that estimation on the accuracy of the hypothesis returned by the learning algorithm for two estimation techniques: a cluster-based estimation technique and kernel mean matching. We also report the results of sample bias correction experiments with several data sets using these techniques. Our analysis is based on the novel concept of distributional stability which generalizes the existing concept of point-based stability. Much of our work and proof techniques can be used to analyze other importance weighting techniques and their effect on accuracy when using a distributionally stable algorithm.</abstract>
   </article>
   <article>
      <title>From Data Topology to a Modular Classifier</title>
      <author>Abdel Ennaji, Arnaud Ribert, Yves Lecourtier</author>
      <date>2008-05-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This article describes an approach to designing a distributed and modular neural classifier. This approach introduces a new hierarchical clustering that enables one to determine reliable regions in the representation space by exploiting supervised information. A multilayer perceptron is then associated with each of these detected clusters and charged with recognizing elements of the associated cluster while rejecting all others. The obtained global classifier is comprised of a set of cooperating <term>neural network</term>s and completed by a K-nearest neighbor classifier charged with treating elements rejected by all the <term>neural network</term>s. Experimental results for the handwritten digit recognition problem and comparison with neural and statistical nonmodular classifiers are given.</abstract>
   </article>
   <article>
      <title>Utilisation des grammaires probabilistes dans les tâches de
  segmentation et d'annotation prosodique</title>
      <author>Irina Nesterenko, Stéphane Rauzy</author>
      <date>2008-06-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Nous pr\'esentons dans cette contribution une approche \`a la fois symbolique et probabiliste permettant d'extraire l'information sur la segmentation du signal de parole \`a partir d'information prosodique. Nous utilisons pour ce faire des grammaires probabilistes poss\'edant une structure hi\'erarchique minimale. La phase de construction des grammaires ainsi que leur pouvoir de pr\'ediction sont \'evalu\'es qualitativement ainsi que quantitativement.   -----   Methodologically oriented, the present work sketches an approach for prosodic information retrieval and speech segmentation, based on both symbolic and probabilistic information. We have recourse to probabilistic grammars, within which we implement a minimal hierarchical structure. Both the stages of probabilistic grammar building and its testing in prediction are explored and quantitatively and qualitatively evaluated.</abstract>
   </article>
   <article>
      <title>Statistical Learning of Arbitrary Computable Classifiers</title>
      <author>David Soloveichik</author>
      <date>2008-06-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Statistical learning theory chiefly studies restricted hypothesis classes, particularly those with finite Vapnik-Chervonenkis (VC) dimension. The fundamental quantity of interest is the sample complexity: the number of samples required to learn to a specified level of accuracy. Here we consider learning over the set of all computable labeling functions. Since the VC-dimension is infinite and a priori (uniform) bounds on the number of samples are impossible, we let the learning algorithm decide when it has seen sufficient samples to have learned. We first show that learning in this setting is indeed possible, and develop a learning algorithm. We then show, however, that bounding sample complexity independently of the distribution is impossible. Notably, this impossibility is entirely due to the requirement that the learning algorithm be computable, and not due to the statistical nature of the problem.</abstract>
   </article>
   <article>
      <title>Agnostically Learning Juntas from Random Walks</title>
      <author>Jan Arpe, Elchanan Mossel</author>
      <date>2008-06-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We prove that the class of functions g:{-1,+1}^n -&gt; {-1,+1} that only depend on an unknown subset of k&lt;&lt;n variables (so-called k-juntas) is agnostically learnable from a random walk in time polynomial in n, 2^{k^2}, epsilon^{-k}, and log(1/delta). In other words, there is an algorithm with the claimed running time that, given epsilon, delta &gt; 0 and access to a random walk on {-1,+1}^n labeled by an arbitrary function f:{-1,+1}^n -&gt; {-1,+1}, finds with probability at least 1-delta a k-junta that is (opt(f)+epsilon)-close to f, where opt(f) denotes the distance of a closest k-junta to f.</abstract>
   </article>
   <article>
      <title>Computationally Efficient Estimators for Dimension Reductions Using
  Stable Random Projections</title>
      <author>Ping Li</author>
      <date>2008-06-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The method of stable random projections is a tool for efficiently computing the $l_\alpha$ distances using low memory, where $0&lt;\alpha \leq 2$ is a tuning parameter. The method boils down to a statistical estimation task and various estimators have been proposed, based on the geometric mean, the harmonic mean, and the fractional power etc.   This study proposes the optimal quantile estimator, whose main operation is selecting, which is considerably less expensive than taking fractional power, the main operation in previous estimators. Our experiments report that the optimal quantile estimator is nearly one order of magnitude more computationally efficient than previous estimators. For large-scale learning tasks in which storing and computing pairwise distances is a serious bottleneck, this estimator should be desirable.   In addition to its computational advantages, the optimal quantile estimator exhibits nice theoretical properties. It is more accurate than previous estimators when $\alpha&gt;1$. We derive its theoretical error bounds and establish the explicit (i.e., no hidden constants) sample complexity bound.</abstract>
   </article>
   <article>
      <title>On Approximating the Lp Distances for p&gt;2</title>
      <author>Ping Li</author>
      <date>2008-06-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Applications in machine learning and data mining require computing pairwise Lp distances in a data matrix A. For massive high-dimensional data, computing all pairwise distances of A can be infeasible. In fact, even storing A or all pairwise distances of A in the memory may be also infeasible. This paper proposes a simple method for p = 2, 4, 6, ... We first decompose the l_p (where p is even) distances into a sum of 2 marginal norms and p-1 ``inner products'' at different orders. Then we apply normal or sub-Gaussian random projections to approximate the resultant ``inner products,'' assuming that the marginal norms can be computed exactly by a linear scan. We propose two strategies for applying random projections. The basic projection strategy requires only one projection matrix but it is more difficult to analyze, while the alternative projection strategy requires p-1 projection matrices but its theoretical analysis is much easier. In terms of the accuracy, at least for p=4, the basic strategy is always more accurate than the alternative strategy if the data are non-negative, which is common in reality.</abstract>
   </article>
   <article>
      <title>Graph Kernels</title>
      <author>S. V. N. Vishwanathan, Karsten M. Borgwardt, Imre Risi Kondor, Nicol N. Schraudolph</author>
      <date>2008-07-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a unified framework to study graph kernels, special cases of which include the random walk graph kernel \citep{GaeFlaWro03,BorOngSchVisetal05}, marginalized graph kernel \citep{KasTsuIno03,KasTsuIno04,MahUedAkuPeretal04}, and geometric kernel on graphs \citep{Gaertner02}. Through extensions of linear algebra to Reproducing Kernel Hilbert Spaces (RKHS) and reduction to a Sylvester equation, we construct an algorithm that improves the time complexity of kernel computation from $O(n^6)$ to $O(n^3)$. When the graphs are sparse, conjugate gradient solvers or fixed-point iterations bring our algorithm into the sub-cubic domain. Experiments on graphs from bioinformatics and other application domains show that it is often more than a thousand times faster than previous approaches. We then explore connections between diffusion kernels \citep{KonLaf02}, regularization on graphs \citep{SmoKon03}, and graph kernels, and use these connections to propose new graph kernels. Finally, we show that rational kernels \citep{CorHafMoh02,CorHafMoh03,CorHafMoh04} when specialized to graphs reduce to the random walk graph kernel.</abstract>
   </article>
   <article>
      <title>On Probability Distributions for Trees: Representations, Inference and
  Learning</title>
      <author>François Denis, Amaury Habrard, Rémi Gilleron, Marc Tommasi, Édouard Gilbert</author>
      <date>2008-07-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study probability distributions over free algebras of trees. Probability distributions can be seen as particular (formal power) tree series [Berstel et al 82, Esik et al 03], i.e. mappings from trees to a semiring K . A widely studied class of tree series is the class of rational (or recognizable) tree series which can be defined either in an algebraic way or by means of multiplicity tree automata. We argue that the algebraic representation is very convenient to model probability distributions over a free algebra of trees. First, as in the string case, the algebraic representation allows to design learning algorithms for the whole class of probability distributions defined by rational tree series. Note that learning algorithms for rational tree series correspond to learning algorithms for weighted tree automata where both the structure and the weights are learned. Second, the algebraic representation can be easily extended to deal with unranked trees (like XML trees where a symbol may have an unbounded number of children). Both properties are particularly relevant for applications: nondeterministic automata are required for the inference problem to be relevant (recall that Hidden Markov Models are equivalent to nondeterministic string automata); nowadays applications for Web Information Extraction, Web Services and document processing consider unranked trees.</abstract>
   </article>
   <article>
      <title>Positive factor networks: A graphical framework for modeling
  non-negative sequential data</title>
      <author>Brian K. Vogel</author>
      <date>2008-07-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a novel graphical framework for modeling non-negative sequential data with hierarchical structure. Our model corresponds to a network of coupled non-negative matrix factorization (NMF) modules, which we refer to as a positive factor network (PFN). The data model is linear, subject to non-negativity constraints, so that observation data consisting of an additive combination of individually representable observations is also representable by the network. This is a desirable property for modeling problems in computational auditory scene analysis, since distinct sound sources in the environment are often well-modeled as combining additively in the corresponding magnitude spectrogram. We propose inference and learning algorithms that leverage existing NMF algorithms and that are straightforward to implement. We present a target tracking example and provide results for synthetic observation data which serve to illustrate the interesting properties of PFNs and motivate their potential usefulness in applications such as music transcription, source separation, and speech recognition. We show how a target process characterized by a hierarchical state transition model can be represented as a PFN. Our results illustrate that a PFN which is defined in terms of a single target observation can then be used to effectively track the states of multiple simultaneous targets. Our results show that the quality of the inferred target states degrades gradually as the observation noise is increased. We also present results for an example in which meaningful hierarchical features are extracted from a spectrogram. Such a hierarchical representation could be useful for music transcription and source separation applications. We also propose a network for language modeling.</abstract>
   </article>
   <article>
      <title>When is there a representer theorem? Vector versus matrix regularizers</title>
      <author>Andreas Argyriou, Charles Micchelli, Massimiliano Pontil</author>
      <date>2008-09-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a general class of regularization methods which learn a vector of parameters on the basis of linear measurements. It is well known that if the regularizer is a nondecreasing function of the inner product then the learned vector is a linear combination of the input data. This result, known as the {\em representer theorem}, is at the basis of kernel-based methods in machine learning. In this paper, we prove the necessity of the above condition, thereby completing the characterization of kernel methods based on regularization. We further extend our analysis to regularization methods which learn a matrix, a problem which is motivated by the application to multi-task learning. In this context, we study a more general representer theorem, which holds for a larger class of regularizers. We provide a necessary and sufficient condition for these class of matrix regularizers and highlight them with some concrete examples of practical importance. Our analysis uses basic principles from matrix theory, especially the useful notion of matrix nondecreasing function.</abstract>
   </article>
   <article>
      <title>Clustered Multi-Task Learning: A Convex Formulation</title>
      <author>Laurent Jacob, Francis Bach, Jean-Philippe Vert</author>
      <date>2008-09-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may benefit from the others. In the context of learning linear functions for supervised classification or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other. In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors. We design a new spectral norm that encodes this a priori assumption, without the prior knowledge of the partition of tasks into groups, resulting in a new convex optimization formulation for multi-task learning. We show in simulations on synthetic examples and on the IEDB MHC-I binding dataset, that our approach outperforms well-known convex methods for multi-task learning, as well as related non convex methods dedicated to the same problem.</abstract>
   </article>
   <article>
      <title>Surrogate Learning - An Approach for Semi-Supervised Classification</title>
      <author>Sriharsha Veeramachaneni, Ravikumar Kondadadi</author>
      <date>2008-09-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the task of learning a classifier from the feature space $\mathcal{X}$ to the set of classes $\mathcal{Y} = \{0, 1\}$, when the features can be partitioned into class-conditionally independent feature sets $\mathcal{X}_1$ and $\mathcal{X}_2$. We show the surprising fact that the class-conditional independence can be used to represent the original learning task in terms of 1) learning a classifier from $\mathcal{X}_2$ to $\mathcal{X}_1$ and 2) learning the class-conditional distribution of the feature set $\mathcal{X}_1$. This fact can be exploited for semi-supervised learning because the former task can be accomplished purely from unlabeled samples. We present experimental evaluation of the idea in two real world applications.</abstract>
   </article>
   <article>
      <title>Learning Isometric Separation Maps</title>
      <author>Nikolaos Vasiloglou, Alexander G. Gray, David V. Anderson</author>
      <date>2008-10-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Maximum Variance Unfolding (MVU) and its variants have been very successful in embedding data-manifolds in lower dimensional spaces, often revealing the true intrinsic dimension. In this paper we show how to also incorporate supervised class information into an MVU-like method without breaking its convexity. We call this method the Isometric Separation Map and we show that the resulting kernel matrix can be used as a binary/multiclass Support Vector Machine-like method in a semi-supervised (transductive) framework. We also show that the method always finds a kernel matrix that linearly separates the training data exactly without projecting them in infinite dimensional spaces. In traditional SVMs we choose a kernel and hope that the data become linearly separable in the kernel space. In this paper we show how the hyperplane can be chosen ad-hoc and the kernel is trained so that data are always linearly separable. Comparisons with Large Margin SVMs show comparable performance.</abstract>
   </article>
   <article>
      <title>Entropy, Perception, and Relativity</title>
      <author>Stefan Jaeger</author>
      <date>2008-11-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, I expand Shannon's definition of entropy into a new form of entropy that allows integration of information from different random events. Shannon's notion of entropy is a special case of my more general definition of entropy. I define probability using a so-called performance function, which is de facto an exponential distribution. Assuming that my general notion of entropy reflects the true uncertainty about a probabilistic event, I understand that our perceived uncertainty differs. I claim that our perception is the result of two opposing forces similar to the two famous antagonists in Chinese philosophy: Yin and Yang. Based on this idea, I show that our perceived uncertainty matches the true uncertainty in points determined by the golden ratio. I demonstrate that the well-known sigmoid function, which we typically employ in artificial <term>neural network</term>s as a non-linear threshold function, describes the actual performance. Furthermore, I provide a motivation for the time dilation in Einstein's Special Relativity, basically claiming that although time dilation conforms with our perception, it does not correspond to reality. At the end of the paper, I show how to apply this theoretical framework to practical applications. I present recognition rates for a pattern recognition problem, and also propose a network architecture that can take advantage of general entropy to solve complex decision problems.</abstract>
   </article>
   <article>
      <title>Stability Bound for Stationary Phi-mixing and Beta-mixing Processes</title>
      <author>Mehryar Mohri, Afshin Rostamizadeh</author>
      <date>2008-11-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, independently of any algorithm. In contrast, the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties. However, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed. In many machine learning applications, however, this assumption does not hold. The observations received by the learning algorithm often have some inherent temporal dependence.   This paper studies the scenario where the observations are drawn from a stationary phi-mixing or beta-mixing sequence, a widely adopted assumption in the study of non-i.i.d. processes that implies a dependence between observations weakening over time. We prove novel and distinct stability-based generalization bounds for stationary phi-mixing and beta-mixing sequences. These bounds strictly generalize the bounds given in the i.i.d. case and apply to all stable learning algorithms, thereby extending the use of stability-bounds to non-i.i.d. scenarios.   We also illustrate the application of our phi-mixing generalization bounds to general classes of learning algorithms, including Support Vector Regression, Kernel Ridge Regression, and Support Vector Machines, and many other kernel regularization-based and relative entropy-based regularization algorithms. These novel bounds can thus be viewed as the first theoretical basis for the use of these algorithms in non-i.i.d. scenarios.</abstract>
   </article>
   <article>
      <title>Land Cover Mapping Using Ensemble Feature Selection Methods</title>
      <author>A. Gidudu, B. Abe, T. Marwala</author>
      <date>2008-11-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Ensemble classification is an emerging approach to land cover mapping whereby the final classification output is a result of a consensus of classifiers. Intuitively, an ensemble system should consist of base classifiers which are diverse i.e. classifiers whose decision boundaries err differently. In this paper ensemble feature selection is used to impose diversity in ensembles. The features of the constituent base classifiers for each ensemble were created through an exhaustive search algorithm using different separability indices. For each ensemble, the classification accuracy was derived as well as a diversity measure purported to give a measure of the inensemble diversity. The correlation between ensemble classification accuracy and diversity measure was determined to establish the interplay between the two variables. From the findings of this paper, diversity measures as currently formulated do not provide an adequate means upon which to constitute ensembles for land cover mapping.</abstract>
   </article>
   <article>
      <title>A Novel Clustering Algorithm Based on Quantum Random Walk</title>
      <author>Qiang Li, Yan He, Jing-ping Jiang</author>
      <date>2008-12-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The enormous successes have been made by quantum algorithms during the last decade. In this paper, we combine the quantum random walk (QRW) with the problem of data clustering, and develop two clustering algorithms based on the one dimensional QRW. Then, the probability distributions on the positions induced by QRW in these algorithms are investigated, which also indicates the possibility of obtaining better results. Consequently, the experimental results have demonstrated that data points in datasets are clustered reasonably and efficiently, and the clustering algorithms are of fast rates of convergence. Moreover, the comparison with other algorithms also provides an indication of the effectiveness of the proposed approach.</abstract>
   </article>
   <article>
      <title>Convex Sparse Matrix Factorizations</title>
      <author>Francis Bach, Julien Mairal, Jean Ponce</author>
      <date>2008-12-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a convex formulation of dictionary learning for sparse signal decomposition. Convexity is obtained by replacing the usual explicit upper bound on the dictionary size by a convex rank-reducing term similar to the trace norm. In particular, our formulation introduces an explicit trade-off between size and sparsity of the decomposition of rectangular matrices. Using a large set of synthetic examples, we compare the estimation abilities of the convex and non-convex approaches, showing that while the convex formulation has a single local minimum, this may lead in some cases to performance which is inferior to the local minima of the non-convex formulation.</abstract>
   </article>
   <article>
      <title>Binary Classification Based on Potentials</title>
      <author>Erik Boczko, Andrew DiLullo, Todd Young</author>
      <date>2008-12-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a simple and computationally trivial method for binary classification based on the evaluation of potential functions. We demonstrate that despite the conceptual and computational simplicity of the method its performance can match or exceed that of standard Support Vector Machine methods.</abstract>
   </article>
   <article>
      <title>Linearly Parameterized Bandits</title>
      <author>Paat Rusmevichientong, John N. Tsitsiklis</author>
      <date>2008-12-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider bandit problems involving a large (possibly infinite) collection of arms, in which the expected reward of each arm is a linear function of an $r$-dimensional random vector $\mathbf{Z} \in \mathbb{R}^r$, where $r \geq 2$. The objective is to minimize the cumulative regret and Bayes risk. When the set of arms corresponds to the unit sphere, we prove that the regret and Bayes risk is of order $\Theta(r \sqrt{T})$, by establishing a lower bound for an arbitrary policy, and showing that a matching upper bound is obtained through a policy that alternates between exploration and exploitation phases. The phase-based policy is also shown to be effective if the set of arms satisfies a strong convexity condition. For the case of a general set of arms, we describe a near-optimal policy whose regret and Bayes risk admit upper bounds of the form $O(r \sqrt{T} \log^{3/2} T)$.</abstract>
   </article>
   <article>
      <title>Importance Weighted Active Learning</title>
      <author>Alina Beygelzimer, Sanjoy Dasgupta, John Langford</author>
      <date>2008-12-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a practical and statistically consistent scheme for actively learning binary classifiers under general loss functions. Our algorithm uses importance weighting to correct sampling bias, and by controlling the variance, we are able to give rigorous label complexity bounds for the learning process. Experiments on passively labeled data show that this approach reduces the label complexity required to achieve good predictive performance on many learning problems.</abstract>
   </article>
   <article>
      <title>Distributed Preemption Decisions: Probabilistic Graphical Model,
  Algorithm and Near-Optimality</title>
      <author>Sung-eok Jeon, Chuanyi Ji</author>
      <date>2009-01-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Cooperative decision making is a vision of future network management and control. Distributed connection preemption is an important example where nodes can make intelligent decisions on allocating resources and controlling traffic flows for multi-class service networks. A challenge is that nodal decisions are spatially dependent as traffic flows trespass multiple nodes in a network. Hence the performance-complexity trade-off becomes important, i.e., how accurate decisions are versus how much information is exchanged among nodes. Connection preemption is known to be NP-complete. Centralized preemption is optimal but computationally intractable. Decentralized preemption is computationally efficient but may result in a poor performance. This work investigates distributed preemption where nodes decide whether and which flows to preempt using only local information exchange with neighbors. We develop, based on the probabilistic graphical models, a near-optimal distributed algorithm. The algorithm is used by each node to make collectively near-optimal preemption decisions. We study trade-offs between near-optimal performance and complexity that corresponds to the amount of information-exchange of the distributed algorithm. The algorithm is validated by both analysis and simulation.</abstract>
   </article>
   <article>
      <title>A Limit Theorem in Singular Regression Problem</title>
      <author>Sumio Watanabe</author>
      <date>2009-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In statistical problems, a set of parameterized probability distributions is used to estimate the true probability distribution. If Fisher information matrix at the true distribution is singular, then it has been left unknown what we can estimate about the true distribution from random samples. In this paper, we study a singular regression problem and prove a limit theorem which shows the relation between the singular regression problem and two birational invariants, a real log canonical threshold and a singular fluctuation. The obtained theorem has an important application to statistics, because it enables us to estimate the generalization error from the training error without any knowledge of the true probability distribution.</abstract>
   </article>
   <article>
      <title>Cross-situational and supervised learning in the emergence of
  communication</title>
      <author>José F. Fontanari, Angelo Cangelosi</author>
      <date>2009-01-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Scenarios for the emergence or bootstrap of a lexicon involve the repeated interaction between at least two agents who must reach a consensus on how to name N objects using H words. Here we consider minimal models of two types of learning algorithms: cross-situational learning, in which the individuals determine the meaning of a word by looking for something in common across all observed uses of that word, and supervised operant conditioning learning, in which there is strong feedback between individuals about the intended meaning of the words. Despite the stark differences between these learning schemes, we show that they yield the same communication accuracy in the realistic limits of large N and H, which coincides with the result of the classical occupancy problem of randomly assigning N objects to H words.</abstract>
   </article>
   <article>
      <title>Extraction de concepts sous contraintes dans des données d'expression
  de gènes</title>
      <author>Baptiste Jeudy, François Rioult</author>
      <date>2009-02-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose a technique to extract constrained formal concepts.</abstract>
   </article>
   <article>
      <title>Database Transposition for Constrained (Closed) Pattern Mining</title>
      <author>Baptiste Jeudy, François Rioult</author>
      <date>2009-02-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently, different works proposed a new way to mine patterns in databases with pathological size. For example, experiments in genome biology usually provide databases with thousands of attributes (genes) but only tens of objects (experiments). In this case, mining the "transposed" database runs through a smaller search space, and the Galois connection allows to infer the closed patterns of the original database. We focus here on constrained pattern mining for those unusual databases and give a theoretical framework for database and constraint transposition. We discuss the properties of constraint transposition and look into classical constraints. We then address the problem of generating the closed patterns of the original database satisfying the constraint, starting from those mined in the "transposed" database. Finally, we show how to generate all the patterns satisfying the constraint from the closed ones.</abstract>
   </article>
   <article>
      <title>Multi-Label Prediction via Compressed Sensing</title>
      <author>Daniel Hsu, Sham M. Kakade, John Langford, Tong Zhang</author>
      <date>2009-02-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider multi-label prediction problems with large output spaces under the assumption of output sparsity -- that the target (label) vectors have small support. We develop a general theory for a variant of the popular error correcting output code scheme, using ideas from compressed sensing for exploiting this sparsity. The method can be regarded as a simple reduction from multi-label regression problems to binary regression problems. We show that the number of subproblems need only be logarithmic in the total number of possible labels, making this approach radically more efficient than others. We also state and prove robustness guarantees for this method in the form of regret transform bounds (in general), and also provide a more detailed analysis for the linear prediction setting.</abstract>
   </article>
   <article>
      <title>Learning rules from multisource data for cardiac monitoring</title>
      <author>Marie-Odile Cordier, Elisa Fromont, René Quiniou</author>
      <date>2009-02-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper formalises the concept of learning symbolic rules from multisource data in a cardiac monitoring context. Our sources, electrocardiograms and arterial blood pressure measures, describe cardiac behaviours from different viewpoints. To learn interpretable rules, we use an Inductive Logic Programming (ILP) method. We develop an original strategy to cope with the dimensionality issues caused by using this ILP technique on a rich multisource language. The results show that our method greatly improves the feasibility and the efficiency of the process while staying accurate. They also confirm the benefits of using multiple sources to improve the diagnosis of cardiac arrhythmias.</abstract>
   </article>
   <article>
      <title>Uniqueness of Low-Rank Matrix Completion by Rigidity Theory</title>
      <author>Amit Singer, Mihai Cucuringu</author>
      <date>2009-02-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The problem of completing a low-rank matrix from a subset of its entries is often encountered in the analysis of incomplete data sets exhibiting an underlying factor model with applications in collaborative filtering, computer vision and control. Most recent work had been focused on constructing efficient algorithms for exact or approximate recovery of the missing matrix entries and proving lower bounds for the number of known entries that guarantee a successful recovery with high probability. A related problem from both the mathematical and algorithmic point of view is the distance geometry problem of realizing points in a Euclidean space from a given subset of their pairwise distances. Rigidity theory answers basic questions regarding the uniqueness of the realization satisfying a given partial set of distances. We observe that basic ideas and tools of rigidity theory can be adapted to determine uniqueness of low-rank matrix completion, where inner products play the role that distances play in rigidity theory. This observation leads to an efficient randomized algorithm for testing both local and global unique completion. Crucial to our analysis is a new matrix, which we call the completion matrix, that serves as the analogue of the rigidity matrix.</abstract>
   </article>
   <article>
      <title>Prediction with expert evaluators' advice</title>
      <author>Alexey Chernov, Vladimir Vovk</author>
      <date>2009-02-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a new protocol for prediction with expert advice in which each expert evaluates the learner's and his own performance using a loss function that may change over time and may be different from the loss functions used by the other experts. The learner's goal is to perform better or not much worse than each expert, as evaluated by that expert, for all experts simultaneously. If the loss functions used by the experts are all proper scoring rules and all mixable, we show that the defensive forecasting algorithm enjoys the same performance guarantee as that attainable by the Aggregating Algorithm in the standard setting and known to be optimal. This result is also applied to the case of "specialist" (or "sleeping") experts. In this case, the defensive forecasting algorithm reduces to a simple modification of the Aggregating Algorithm.</abstract>
   </article>
   <article>
      <title>Multiplicative updates For Non-Negative Kernel SVM</title>
      <author>Vamsi K. Potluru, Sergey M. Plis, Morten Morup, Vince D. Calhoun, Terran Lane</author>
      <date>2009-02-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present multiplicative updates for solving hard and soft margin <term>support vector machine</term>s (SVM) with non-negative kernels. They follow as a natural extension of the updates for non-negative matrix factorization. No additional param- eter setting, such as choosing learning, rate is required. Ex- periments demonstrate rapid convergence to good classifiers. We analyze the rates of asymptotic convergence of the up- dates and establish tight bounds. We test the performance on several datasets using various non-negative kernels and report equivalent generalization errors to that of a standard SVM.</abstract>
   </article>
   <article>
      <title>Efficient Human Computation</title>
      <author>Ran Gilad-Bachrach, Aharon Bar-Hillel, Liat Ein-Dor</author>
      <date>2009-03-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Collecting large labeled data sets is a laborious and expensive task, whose scaling up requires division of the labeling workload between many teachers. When the number of classes is large, miscorrespondences between the labels given by the different teachers are likely to occur, which, in the extreme case, may reach total inconsistency. In this paper we describe how globally consistent labels can be obtained, despite the absence of teacher coordination, and discuss the possible efficiency of this process in terms of human labor. We define a notion of label efficiency, measuring the ratio between the number of globally consistent labels obtained and the number of labels provided by distributed teachers. We show that the efficiency depends critically on the ratio alpha between the number of data instances seen by a single teacher, and the number of classes. We suggest several algorithms for the distributed labeling problem, and analyze their efficiency as a function of alpha. In addition, we provide an upper bound on label efficiency for the case of completely uncoordinated teachers, and show that efficiency approaches 0 as the ratio between the number of labels each teacher provides and the number of classes drops (i.e. alpha goes to 0).</abstract>
   </article>
   <article>
      <title>Differential Contrastive Divergence</title>
      <author>David McAllester</author>
      <date>2009-03-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper has been retracted.</abstract>
   </article>
   <article>
      <title>On $p$-adic Classification</title>
      <author>Patrick Erik Bradley</author>
      <date>2009-03-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A $p$-adic modification of the split-LBG classification method is presented in which first clusterings and then cluster centers are computed which locally minimise an energy function. The outcome for a fixed dataset is independent of the prime number $p$ with finitely many exceptions. The methods are applied to the construction of $p$-adic classifiers in the context of learning.</abstract>
   </article>
   <article>
      <title>Stability Analysis and Learning Bounds for Transductive Regression
  Algorithms</title>
      <author>Corinna Cortes, Mehryar Mohri, Dmitry Pechyony, Ashish Rastogi</author>
      <date>2009-04-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper uses the notion of algorithmic stability to derive novel generalization bounds for several families of transductive regression algorithms, both by using convexity and closed-form solutions. Our analysis helps compare the stability of these algorithms. It also shows that a number of widely used transductive regression algorithms are in fact unstable. Finally, it reports the results of experiments with local transductive regression demonstrating the benefit of our stability bounds for model selection, for one of the algorithms, in particular for determining the radius of the local neighborhood used by the algorithm.</abstract>
   </article>
   <article>
      <title>Inferring Dynamic Bayesian Networks using Frequent Episode Mining</title>
      <author>Debprakash Patnaik, Srivatsan Laxman, Naren Ramakrishnan</author>
      <date>2009-04-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Motivation: Several different threads of research have been proposed for modeling and mining temporal data. On the one hand, approaches such as dynamic Bayesian networks (DBNs) provide a formal probabilistic basis to model relationships between time-indexed random variables but these models are intractable to learn in the general case. On the other, algorithms such as frequent episode mining are scalable to large datasets but do not exhibit the rigorous probabilistic interpretations that are the mainstay of the graphical models literature.   Results: We present a unification of these two seemingly diverse threads of research, by demonstrating how dynamic (discrete) Bayesian networks can be inferred from the results of frequent episode mining. This helps bridge the modeling emphasis of the former with the counting emphasis of the latter. First, we show how, under reasonable assumptions on data characteristics and on influences of random variables, the optimal DBN structure can be computed using a greedy, local, algorithm. Next, we connect the optimality of the DBN structure with the notion of fixed-delay episodes and their counts of distinct occurrences. Finally, to demonstrate the practical feasibility of our approach, we focus on a specific (but broadly applicable) class of networks, called excitatory networks, and show how the search for the optimal DBN structure can be conducted using just information from frequent episodes. Application on datasets gathered from mathematical models of spiking neurons as well as real neuroscience datasets are presented.   Availability: Algorithmic implementations, simulator codebases, and datasets are available from our website at http://neural-code.cs.vt.edu/dbn</abstract>
   </article>
   <article>
      <title>Introduction to Machine Learning: Class Notes 67577</title>
      <author>Amnon Shashua</author>
      <date>2009-04-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Introduction to Machine learning covering Statistical Inference (Bayes, EM, ML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering), and PAC learning (the Formal model, VC dimension, Double Sampling theorem).</abstract>
   </article>
   <article>
      <title>Limits of Learning about a Categorical Latent Variable under Prior
  Near-Ignorance</title>
      <author>Alberto Piatti, Marco Zaffalon, Fabio Trojani, Marcus Hutter</author>
      <date>2009-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we consider the coherent theory of (epistemic) uncertainty of Walley, in which beliefs are represented through sets of probability distributions, and we focus on the problem of modeling prior ignorance about a categorical random variable. In this setting, it is a known result that a state of prior ignorance is not compatible with learning. To overcome this problem, another state of beliefs, called \emph{near-ignorance}, has been proposed. Near-ignorance resembles ignorance very closely, by satisfying some principles that can arguably be regarded as necessary in a state of ignorance, and allows learning to take place. What this paper does, is to provide new and substantial evidence that also near-ignorance cannot be really regarded as a way out of the problem of starting statistical inference in conditions of very weak beliefs. The key to this result is focusing on a setting characterized by a variable of interest that is \emph{latent}. We argue that such a setting is by far the most common case in practice, and we provide, for the case of categorical latent variables (and general \emph{manifest} variables) a condition that, if satisfied, prevents learning to take place under prior near-ignorance. This condition is shown to be easily satisfied even in the most common statistical problems. We regard these results as a strong form of evidence against the possibility to adopt a condition of prior near-ignorance in real statistical problems.</abstract>
   </article>
   <article>
      <title>Temporal data mining for root-cause analysis of machine faults in
  automotive assembly lines</title>
      <author>Srivatsan Laxman, Basel Shadid, P. S. Sastry, K. P. Unnikrishnan</author>
      <date>2009-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Engine assembly is a complex and heavily automated distributed-control process, with large amounts of faults data logged everyday. We describe an application of temporal data mining for analyzing fault logs in an engine assembly plant. Frequent episode discovery framework is a model-free method that can be used to deduce (temporal) correlations among events from the logs in an efficient manner. In addition to being theoretically elegant and computationally efficient, frequent episodes are also easy to interpret in the form actionable recommendations. Incorporation of domain-specific information is critical to successful application of the method for analyzing fault logs in the manufacturing domain. We show how domain-specific knowledge can be incorporated using heuristic rules that act as pre-filters and post-filters to frequent episode discovery. The system described here is currently being used in one of the engine assembly plants of General Motors and is planned for adaptation in other plants. To the best of our knowledge, this paper presents the first real, large-scale application of temporal data mining in the manufacturing domain. We believe that the ideas presented in this paper can help practitioners engineer tools for analysis in other similar or related application domains as well.</abstract>
   </article>
   <article>
      <title>Combining Supervised and Unsupervised Learning for GIS Classification</title>
      <author>Juan-Manuel Torres-Moreno, Laurent Bougrain, Frdéric Alexandre</author>
      <date>2009-05-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a new hybrid learning algorithm for unsupervised classification tasks. We combined Fuzzy c-means learning algorithm and a supervised version of Minimerror to develop a hybrid incremental strategy allowing unsupervised classifications. We applied this new approach to a real-world database in order to know if the information contained in unlabeled features of a Geographic Information System (GIS), allows to well classify it. Finally, we compared our results to a classical supervised classification obtained by a multilayer perceptron.</abstract>
   </article>
   <article>
      <title>Average-Case Active Learning with Costs</title>
      <author>Andrew Guillory, Jeff Bilmes</author>
      <date>2009-05-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We analyze the expected cost of a greedy active learning algorithm. Our analysis extends previous work to a more general setting in which different queries have different costs. Moreover, queries may have more than two possible responses and the distribution over hypotheses may be non uniform. Specific applications include active learning with label costs, active learning for multiclass and partial label queries, and batch mode active learning. We also discuss an approximate version of interest when there are very many queries.</abstract>
   </article>
   <article>
      <title>Transfer Learning Using Feature Selection</title>
      <author>Paramveer S. Dhillon, Dean Foster, Lyle Ungar</author>
      <date>2009-05-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present three related ways of using Transfer Learning to improve feature selection. The three methods address different problems, and hence share different kinds of information between tasks or feature classes, but all three are based on the information theoretic Minimum Description Length (MDL) principle and share the same underlying Bayesian interpretation. The first method, MIC, applies when predictive models are to be built simultaneously for multiple tasks (``simultaneous transfer'') that share the same set of features. MIC allows each feature to be added to none, some, or all of the task models and is most beneficial for selecting a small set of predictive features from a large pool of features, as is common in genomic and biological datasets. Our second method, TPC (Three Part Coding), uses a similar methodology for the case when the features can be divided into feature classes. Our third method, Transfer-TPC, addresses the ``sequential transfer'' problem in which the task to which we want to transfer knowledge may not be known in advance and may have different amounts of data than the other tasks. Transfer-TPC is most beneficial when we want to transfer knowledge between tasks which have unequal amounts of labeled data, for example the data for disambiguating the senses of different verbs. We demonstrate the effectiveness of these approaches with experimental results on real world data pertaining to genomics and to Word Sense Disambiguation (WSD).</abstract>
   </article>
   <article>
      <title>Equations of States in Statistical Learning for a Nonparametrizable and
  Regular Case</title>
      <author>Sumio Watanabe</author>
      <date>2009-06-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many learning machines that have hierarchical structure or hidden variables are now being used in information science, artificial intelligence, and bioinformatics. However, several learning machines used in such fields are not regular but singular statistical models, hence their generalization performance is still left unknown. To overcome these problems, in the previous papers, we proved new equations in statistical learning, by which we can estimate the Bayes generalization loss from the Bayes training loss and the functional variance, on the condition that the true distribution is a singularity contained in a learning machine. In this paper, we prove that the same equations hold even if a true distribution is not contained in a parametric model. Also we prove that, the proposed equations in a regular case are asymptotically equivalent to the Takeuchi information criterion. Therefore, the proposed equations are always applicable without any condition on the unknown true distribution.</abstract>
   </article>
   <article>
      <title>An optimal linear separator for the Sonar Signals Classification task</title>
      <author>Juan-Manuel Torres-Moreno, Mirta B. Gordon</author>
      <date>2009-06-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The problem of classifying sonar signals from rocks and mines first studied by Gorman and Sejnowski has become a benchmark against which many learning algorithms have been tested. We show that both the training set and the test set of this benchmark are linearly separable, although with different hyperplanes. Moreover, the complete set of learning and test patterns together, is also linearly separable. We give the weights that separate these sets, which may be used to compare results found by other algorithms.</abstract>
   </article>
   <article>
      <title>Bayesian History Reconstruction of Complex Human Gene Clusters on a
  Phylogeny</title>
      <author>Tomáš Vinař, Broňa Brejová, Giltae Song, Adam Siepel</author>
      <date>2009-06-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Clusters of genes that have evolved by repeated segmental duplication present difficult challenges throughout genomic analysis, from sequence assembly to functional analysis. Improved understanding of these clusters is of utmost importance, since they have been shown to be the source of evolutionary innovation, and have been linked to multiple diseases, including HIV and a variety of cancers. Previously, Zhang et al. (2008) developed an algorithm for reconstructing parsimonious evolutionary histories of such gene clusters, using only human genomic sequence data. In this paper, we propose a probabilistic model for the evolution of gene clusters on a phylogeny, and an MCMC algorithm for reconstruction of duplication histories from genomic sequences in multiple species. Several projects are underway to obtain high quality BAC-based assemblies of duplicated clusters in multiple species, and we anticipate that our method will be useful in analyzing these valuable new data sets.</abstract>
   </article>
   <article>
      <title>Bayesian two-sample tests</title>
      <author>Karsten M. Borgwardt, Zoubin Ghahramani</author>
      <date>2009-06-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we present two classes of Bayesian approaches to the two-sample problem. Our first class of methods extends the Bayesian t-test to include all parametric models in the exponential family and their conjugate priors. Our second class of methods uses Dirichlet process mixtures (DPM) of such conjugate-exponential distributions as flexible nonparametric priors over the unknown distributions.</abstract>
   </article>
   <article>
      <title>Acquiring Knowledge for Evaluation of Teachers Performance in Higher
  Education using a Questionnaire</title>
      <author>Hafeez Ullah Amin, Abdur Rashid Khan</author>
      <date>2009-06-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we present the step by step knowledge acquisition process by choosing a structured method through using a questionnaire as a knowledge acquisition tool. Here we want to depict the problem domain as, how to evaluate teachers performance in higher education through the use of expert system technology. The problem is how to acquire the specific knowledge for a selected problem efficiently and effectively from human experts and encode it in the suitable computer format. Acquiring knowledge from human experts in the process of expert systems development is one of the most common problems cited till yet. This questionnaire was sent to 87 domain experts within all public and private universities in Pakistani. Among them 25 domain experts sent their valuable opinions. Most of the domain experts were highly qualified, well experienced and highly responsible persons. The whole questionnaire was divided into 15 main groups of factors, which were further divided into 99 individual questions. These facts were analyzed further to give a final shape to the questionnaire. This knowledge acquisition technique may be used as a learning tool for further research work.</abstract>
   </article>
   <article>
      <title>Unsupervised Search-based Structured Prediction</title>
      <author>Hal Daumé III</author>
      <date>2009-06-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We describe an adaptation and application of a search-based structured prediction algorithm "Searn" to <term>unsupervised learning</term> problems. We show that it is possible to reduce <term>unsupervised learning</term> to supervised learning and demonstrate a high-quality unsupervised shift-reduce parsing model. We additionally show a close connection between unsupervised Searn and expectation maximization. Finally, we demonstrate the efficacy of a semi-supervised extension. The key idea that enables this is an application of the predict-self idea for <term>unsupervised learning</term>.</abstract>
   </article>
   <article>
      <title>Random DFAs are Efficiently PAC Learnable</title>
      <author>Leonid Aryeh Kontorovich</author>
      <date>2009-07-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper has been withdrawn due to an error found by Dana Angluin and Lev Reyzin.</abstract>
   </article>
   <article>
      <title>Bayesian Multitask Learning with Latent Hierarchies</title>
      <author>Hal Daumé III</author>
      <date>2009-07-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We learn multiple hypotheses for related tasks under a latent hierarchical relationship between tasks. We exploit the intuition that for domain adaptation, we wish to share classifier structure, but for multitask learning, we wish to share covariance structure. Our hierarchical model is seen to subsume several previously proposed multitask learning models and performs well on three distinct real-world data sets.</abstract>
   </article>
   <article>
      <title>A Bayesian Model for Supervised Clustering with the Dirichlet Process
  Prior</title>
      <author>Hal Daumé III, Daniel Marcu</author>
      <date>2009-07-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We develop a Bayesian framework for tackling the supervised clustering problem, the generic problem encountered in tasks such as reference matching, coreference resolution, identity uncertainty and record linkage. Our clustering model is based on the Dirichlet process prior, which enables us to define distributions over the countably infinite sets that naturally arise in this problem. We add supervision to our model by positing the existence of a set of unobserved random variables (we call these "reference types") that are generic across all clusters. Inference in our framework, which requires integrating over infinitely many parameters, is solved using Markov chain Monte Carlo techniques. We present algorithms for both conjugate and non-conjugate priors. We present a simple--but general--parameterization of our model based on a Gaussian assumption. We evaluate this model on one artificial task and three real-world tasks, comparing it against both unsupervised and state-of-the-art supervised algorithms. Our results show that our model is able to outperform other models across a variety of tasks and performance metrics.</abstract>
   </article>
   <article>
      <title>Fast search for Dirichlet process mixture models</title>
      <author>Hal Daumé III</author>
      <date>2009-07-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Dirichlet process (DP) mixture models provide a flexible Bayesian framework for density estimation. Unfortunately, their flexibility comes at a cost: inference in DP mixture models is computationally expensive, even when conjugate distributions are used. In the common case when one seeks only a maximum a posteriori assignment of data points to clusters, we show that search algorithms provide a practical alternative to expensive MCMC and variational techniques. When a true posterior sample is desired, the solution found by search can serve as a good initializer for MCMC. Experimental results show that using these techniques is it possible to apply DP mixture models to very large data sets.</abstract>
   </article>
   <article>
      <title>Clustering for Improved Learning in Maze Traversal Problem</title>
      <author>Eddie White</author>
      <date>2009-08-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The maze traversal problem (finding the shortest distance to the goal from any position in a maze) has been an interesting challenge in computational intelligence. Recent work has shown that the cellular simultaneous recurrent <term>neural network</term> (CSRN) can solve this problem for simple mazes. This thesis focuses on exploiting relevant information about the maze to improve learning and decrease the training time for the CSRN to solve mazes. Appropriate variables are identified to create useful clusters using relevant information. The CSRN was next modified to allow for an additional external input. With this additional input, several methods were tested and results show that clustering the mazes improves the overall learning of the traversal problem for the CSRN.</abstract>
   </article>
   <article>
      <title>Randomized Algorithms for Large scale SVMs</title>
      <author>Vinay Jethava, Krishnan Suresh, Chiranjib Bhattacharyya, Ramesh Hariharan</author>
      <date>2009-09-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a randomized algorithm for training Support vector machines(SVMs) on large datasets. By using ideas from Random projections we show that the combinatorial dimension of SVMs is $O({log} n)$ with high probability. This estimate of combinatorial dimension is used to derive an iterative algorithm, called RandSVM, which at each step calls an existing solver to train SVMs on a randomly chosen subset of size $O({log} n)$. The algorithm has probabilistic guarantees and is capable of training SVMs with Kernels for both classification and regression problems. Experiments done on synthetic and real life data sets demonstrate that the algorithm scales up existing SVM learners, without loss of accuracy.</abstract>
   </article>
   <article>
      <title>Scalable Inference for Latent Dirichlet Allocation</title>
      <author>James Petterson, Tiberio Caetano</author>
      <date>2009-09-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We investigate the problem of learning a topic model - the well-known Latent Dirichlet Allocation - in a distributed manner, using a cluster of C processors and dividing the corpus to be learned equally among them. We propose a simple approximated method that can be tuned, trading speed for accuracy according to the task at hand. Our approach is asynchronous, and therefore suitable for clusters of heterogenous machines.</abstract>
   </article>
   <article>
      <title>Post-Processing of Discovered Association Rules Using Ontologies</title>
      <author>Claudia Marinica, Fabrice Guillet, Henri Briand</author>
      <date>2009-10-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In Data Mining, the usefulness of association rules is strongly limited by the huge amount of delivered rules. In this paper we propose a new approach to prune and filter discovered rules. Using Domain Ontologies, we strengthen the integration of user knowledge in the post-processing task. Furthermore, an interactive and iterative framework is designed to assist the user along the analyzing task. On the one hand, we represent user domain knowledge using a Domain Ontology over database. On the other hand, a novel technique is suggested to prune and to filter discovered rules. The proposed framework was applied successfully over the client database provided by Nantes Habitat.</abstract>
   </article>
   <article>
      <title>Variable sigma Gaussian processes: An expectation propagation
  perspective</title>
      <author>Yuan Qi, Ahmed H. Abdel-Gawad, Thomas P. Minka</author>
      <date>2009-10-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Gaussian processes (GPs) provide a probabilistic nonparametric representation of functions in regression, classification, and other problems. Unfortunately, exact learning with GPs is intractable for large datasets. A variety of approximate GP methods have been proposed that essentially map the large dataset into a small set of basis points. The most advanced of these, the variable-sigma GP (VSGP) (Walder et al., 2008), allows each basis point to have its own length scale. However, VSGP was only derived for regression. We describe how VSGP can be applied to classification and other problems, by deriving it as an expectation propagation algorithm. In this view, sparse GP approximations correspond to a KL-projection of the true posterior onto a compact exponential family of GPs. VSGP constitutes one such family, and we show how to enlarge this family to get additional accuracy. In particular, we show that endowing each basis point with its own full covariance matrix provides a significant increase in approximation power.</abstract>
   </article>
   <article>
      <title>Effectiveness and Limitations of Statistical Spam Filters</title>
      <author>M. Tariq Banday, Tariq R. Jan</author>
      <date>2009-10-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we discuss the techniques involved in the design of the famous statistical spam filters that include Naive Bayes, Term Frequency-Inverse Document Frequency, K-Nearest Neighbor, Support Vector Machine, and Bayes Additive Regression Tree. We compare these techniques with each other in terms of accuracy, recall, precision, etc. Further, we discuss the effectiveness and limitations of statistical filters in filtering out various types of spam from legitimate e-mails.</abstract>
   </article>
   <article>
      <title>Competing with Gaussian linear experts</title>
      <author>Fedor Zhdanov, Vladimir Vovk</author>
      <date>2009-10-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the problem of online regression. We prove a theoretical bound on the square loss of Ridge Regression. We do not make any assumptions about input vectors or outcomes. We also show that Bayesian Ridge Regression can be thought of as an online algorithm competing with all the Gaussian linear experts.</abstract>
   </article>
   <article>
      <title>Anomaly Detection with Score functions based on Nearest Neighbor Graphs</title>
      <author>Manqi Zhao, Venkatesh Saligrama</author>
      <date>2009-10-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a novel non-parametric adaptive anomaly detection algorithm for high dimensional data based on score functions derived from nearest neighbor graphs on $n$-point nominal data. Anomalies are declared whenever the score of a test sample falls below $\alpha$, which is supposed to be the desired false alarm level. The resulting anomaly detector is shown to be asymptotically optimal in that it is uniformly most powerful for the specified false alarm level, $\alpha$, for the case when the anomaly density is a mixture of the nominal and a known density. Our algorithm is computationally efficient, being linear in dimension and quadratic in data size. It does not require choosing complicated tuning parameters or function approximation classes and it can adapt to local structure such as local change in dimensionality. We demonstrate the algorithm on both artificial and real data sets in high dimensional feature spaces.</abstract>
   </article>
   <article>
      <title>A Mirroring Theorem and its Application to a New Method of Unsupervised
  Hierarchical Pattern Classification</title>
      <author>Dasika Ratna Deepthi, K. Eswaran</author>
      <date>2009-11-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we prove a crucial theorem called Mirroring Theorem which affirms that given a collection of samples with enough information in it such that it can be classified into classes and subclasses then (i) There exists a mapping which classifies and subclassifies these samples (ii) There exists a hierarchical classifier which can be constructed by using Mirroring Neural Networks (MNNs) in combination with a clustering algorithm that can approximate this mapping. Thus, the proof of the Mirroring theorem provides a theoretical basis for the existence and a practical feasibility of constructing hierarchical classifiers, given the maps. Our proposed Mirroring Theorem can also be considered as an extension to Kolmogrovs theorem in providing a realistic solution for unsupervised classification. The techniques we develop, are general in nature and have led to the construction of learning machines which are (i) tree like in structure, (ii) modular (iii) with each module running on a common algorithm (tandem algorithm) and (iv) selfsupervised. We have actually built the architecture, developed the tandem algorithm of such a hierarchical classifier and demonstrated it on an example problem.</abstract>
   </article>
   <article>
      <title>Sequential anomaly detection in the presence of noise and limited
  feedback</title>
      <author>Maxim Raginsky, Rebecca Willett, Corinne Horn, Jorge Silva, Roummel Marcia</author>
      <date>2009-11-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper describes a methodology for detecting anomalies from sequentially observed and potentially noisy data. The proposed approach consists of two main elements: (1) {\em filtering}, or assigning a belief or likelihood to each successive measurement based upon our ability to predict it from previous noisy observations, and (2) {\em hedging}, or flagging potential anomalies by comparing the current belief against a time-varying and data-adaptive threshold. The threshold is adjusted based on the available feedback from an end user. Our algorithms, which combine universal prediction with recent work on online convex programming, do not require computing posterior distributions given all current observations and involve simple primal-dual parameter updates. At the heart of the proposed approach lie exponential-family models which can be used in a wide variety of contexts and applications, and which yield methods that achieve sublinear per-round regret against both static and slowly varying product distributions with marginals drawn from the same exponential family. Moreover, the regret against static distributions coincides with the minimax value of the corresponding online strongly convex game. We also prove bounds on the number of mistakes made during the hedging step relative to the best offline choice of the threshold with access to all estimated beliefs and feedback signals. We validate the theory on synthetic data drawn from a time-varying distribution over binary vectors of high dimensionality, as well as on the Enron email dataset.</abstract>
   </article>
   <article>
      <title>Keystroke Dynamics Authentication For Collaborative Systems</title>
      <author>Romain Giot, Mohamad El-Abed, Christophe Rosenberger</author>
      <date>2009-11-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present in this paper a study on the ability and the benefits of using a keystroke dynamics authentication method for collaborative systems. Authentication is a challenging issue in order to guarantee the security of use of collaborative systems during the access control step. Many solutions exist in the state of the art such as the use of one time passwords or smart-cards. We focus in this paper on biometric based solutions that do not necessitate any additional sensor. Keystroke dynamics is an interesting solution as it uses only the keyboard and is invisible for users. Many methods have been published in this field. We make a comparative study of many of them considering the operational constraints of use for collaborative systems.</abstract>
   </article>
   <article>
      <title>Statistical exponential families: A digest with flash cards</title>
      <author>Frank Nielsen, Vincent Garcia</author>
      <date>2009-11-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This document describes concisely the ubiquitous class of exponential family distributions met in statistics. The first part recalls definitions and summarizes main properties and duality with Bregman divergences (all proofs are skipped). The second part lists decompositions and related formula of common exponential family distributions. We recall the Fisher-Rao-Riemannian geometries and the dual affine connection information geometries of statistical manifolds. It is intended to maintain and update this document and catalog by adding new distribution items.</abstract>
   </article>
   <article>
      <title>Learning Mixtures of Gaussians using the k-means Algorithm</title>
      <author>Kamalika Chaudhuri, Sanjoy Dasgupta, Andrea Vattani</author>
      <date>2009-12-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>One of the most popular algorithms for clustering in Euclidean space is the $k$-means algorithm; $k$-means is difficult to analyze mathematically, and few theoretical guarantees are known about it, particularly when the data is {\em well-clustered}. In this paper, we attempt to fill this gap in the literature by analyzing the behavior of $k$-means on well-clustered data. In particular, we study the case when each cluster is distributed as a different Gaussian -- or, in other words, when the input comes from a mixture of Gaussians.   We analyze three aspects of the $k$-means algorithm under this assumption. First, we show that when the input comes from a mixture of two spherical Gaussians, a variant of the 2-means algorithm successfully isolates the subspace containing the means of the mixture components. Second, we show an exact expression for the convergence of our variant of the 2-means algorithm, when the input is a very large number of samples from a mixture of spherical Gaussians. Our analysis does not require any lower bound on the separation between the mixture components.   Finally, we study the sample requirement of $k$-means; for a mixture of 2 spherical Gaussians, we show an upper bound on the number of samples required by a variant of 2-means to get close to the true solution. The sample requirement grows with increasing dimensionality of the data, and decreasing separation between the means of the Gaussians. To match our upper bound, we show an information-theoretic lower bound on any algorithm that learns mixtures of two spherical Gaussians; our lower bound indicates that in the case when the overlap between the probability masses of the two distributions is small, the sample requirement of $k$-means is {\em near-optimal}.</abstract>
   </article>
   <article>
      <title>Delay-Optimal Power and Subcarrier Allocation for OFDMA Systems via
  Stochastic Approximation</title>
      <author>Vincent K. N. Lau, Ying Cui</author>
      <date>2009-12-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we consider delay-optimal power and subcarrier allocation design for OFDMA systems with $N_F$ subcarriers, $K$ mobiles and one base station. There are $K$ queues at the base station for the downlink traffic to the $K$ mobiles with heterogeneous packet arrivals and delay requirements. We shall model the problem as a $K$-dimensional infinite horizon average reward Markov Decision Problem (MDP) where the control actions are assumed to be a function of the instantaneous Channel State Information (CSI) as well as the joint Queue State Information (QSI). This problem is challenging because it corresponds to a stochastic Network Utility Maximization (NUM) problem where general solution is still unknown. We propose an {\em online stochastic value iteration} solution using {\em stochastic approximation}. The proposed power control algorithm, which is a function of both the CSI and the QSI, takes the form of multi-level water-filling. We prove that under two mild conditions in Theorem 1 (One is the stepsize condition. The other is the condition on accessibility of the Markov Chain, which can be easily satisfied in most of the cases we are interested.), the proposed solution converges to the optimal solution almost surely (with probability 1) and the proposed framework offers a possible solution to the general stochastic NUM problem. By exploiting the birth-death structure of the queue dynamics, we obtain a reduced complexity decomposed solution with linear $\mathcal{O}(KN_F)$ complexity and $\mathcal{O}(K)$ memory requirement.</abstract>
   </article>
   <article>
      <title>Association Rule Pruning based on Interestingness Measures with
  Clustering</title>
      <author>S. Kannan, R. Bhaskaran</author>
      <date>2009-12-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Association rule mining plays vital part in knowledge mining. The difficult task is discovering knowledge or useful rules from the large number of rules generated for reduced support. For pruning or grouping rules, several techniques are used such as rule structure cover methods, informative cover methods, rule clustering, etc. Another way of selecting association rules is based on interestingness measures such as support, confidence, correlation, and so on. In this paper, we study how rule clusters of the pattern Xi - Y are distributed over different interestingness measures.</abstract>
   </article>
   <article>
      <title>Early Detection of Breast Cancer using SVM Classifier Technique</title>
      <author>Y. Ireaneus Anna Rejani, S. Thamarai Selvi</author>
      <date>2009-12-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a tumor detection algorithm from mammogram. The proposed system focuses on the solution of two problems. One is how to detect tumors as suspicious regions with a very weak contrast to their background and another is how to extract features which categorize tumors. The tumor detection method follows the scheme of (a) mammogram enhancement. (b) The segmentation of the tumor area. (c) The extraction of features from the segmented tumor area. (d) The use of SVM classifier. The enhancement can be defined as conversion of the image quality to a better and more understandable level. The mammogram enhancement procedure includes filtering, top hat operation, DWT. Then the contrast stretching is used to increase the contrast of the image. The segmentation of mammogram images has been playing an important role to improve the detection and diagnosis of breast cancer. The most common segmentation method used is thresholding. The features are extracted from the segmented breast area. Next stage include, which classifies the regions using the SVM classifier. The method was tested on 75 mammographic images, from the mini-MIAS database. The methodology achieved a sensitivity of 88.75%.</abstract>
   </article>
   <article>
      <title>Performance Analysis of AIM-K-means &amp; K-means in Quality Cluster
  Generation</title>
      <author>Samarjeet Borah, Mrinal Kanti Ghose</author>
      <date>2009-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Among all the partition based clustering algorithms K-means is the most popular and well known method. It generally shows impressive results even in considerably large data sets. The computational complexity of K-means does not suffer from the size of the data set. The main disadvantage faced in performing this clustering is that the selection of initial means. If the user does not have adequate knowledge about the data set, it may lead to erroneous results. The algorithm Automatic Initialization of Means (AIM), which is an extension to K-means, has been proposed to overcome the problem of initial mean generation. In this paper an attempt has been made to compare the performance of the algorithms through implementation</abstract>
   </article>
   <article>
      <title>Gaussian Process Optimization in the Bandit Setting: No Regret and
  Experimental Design</title>
      <author>Niranjan Srinivas, Andreas Krause, Sham M. Kakade, Matthias Seeger</author>
      <date>2009-12-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.</abstract>
   </article>
   <article>
      <title>Optimal Query Complexity for Reconstructing Hypergraphs</title>
      <author>Nader H. Bshouty, Hanna Mazzawi</author>
      <date>2010-01-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we consider the problem of reconstructing a hidden weighted hypergraph of constant rank using additive queries. We prove the following: Let $G$ be a weighted hidden hypergraph of constant rank with n vertices and $m$ hyperedges. For any $m$ there exists a non-adaptive algorithm that finds the edges of the graph and their weights using $$ O(\frac{m\log n}{\log m}) $$ additive queries. This solves the open problem in [S. Choi, J. H. Kim. Optimal Query Complexity Bounds for Finding Graphs. {\em STOC}, 749--758,~2008].   When the weights of the hypergraph are integers that are less than $O(poly(n^d/m))$ where $d$ is the rank of the hypergraph (and therefore for unweighted hypergraphs) there exists a non-adaptive algorithm that finds the edges of the graph and their weights using $$ O(\frac{m\log \frac{n^d}{m}}{\log m}). $$ additive queries.   Using the information theoretic bound the above query complexities are tight.</abstract>
   </article>
   <article>
      <title>Linear Probability Forecasting</title>
      <author>Fedor Zhdanov, Yuri Kalnishkan</author>
      <date>2010-01-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multi-class classification is one of the most important tasks in machine learning. In this paper we consider two online multi-class classification problems: classification by a linear model and by a kernelized model. The quality of predictions is measured by the Brier loss function. We suggest two computationally efficient algorithms to work with these problems and prove theoretical guarantees on their losses. We kernelize one of the algorithms and prove theoretical guarantees on its loss. We perform experiments and compare our algorithms with logistic regression.</abstract>
   </article>
   <article>
      <title>Measuring Latent Causal Structure</title>
      <author>Ricardo Silva</author>
      <date>2010-01-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Discovering latent representations of the observed world has become increasingly more relevant in data analysis. Much of the effort concentrates on building latent variables which can be used in prediction problems, such as classification and regression. A related goal of learning latent structure from data is that of identifying which hidden common causes generate the observations, such as in applications that require predicting the effect of policies. This will be the main problem tackled in our contribution: given a dataset of indicators assumed to be generated by unknown and unmeasured common causes, we wish to discover which hidden common causes are those, and how they generate our data. This is possible under the assumption that observed variables are linear functions of the latent causes with additive noise. Previous results in the literature present solutions for the case where each observed variable is a noisy function of a single latent variable. We show how to extend the existing results for some cases where observed variables measure more than one latent variable.</abstract>
   </article>
   <article>
      <title>Asymptotic Learning Curve and Renormalizable Condition in Statistical
  Learning Theory</title>
      <author>Sumio Watanabe</author>
      <date>2010-01-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Bayes statistics and statistical physics have the common mathematical structure, where the log likelihood function corresponds to the random Hamiltonian. Recently, it was discovered that the asymptotic learning curves in Bayes estimation are subject to a universal law, even if the log likelihood function can not be approximated by any quadratic form. However, it is left unknown what mathematical property ensures such a universal law. In this paper, we define a renormalizable condition of the statistical estimation problem, and show that, under such a condition, the asymptotic learning curves are ensured to be subject to the universal law, even if the true distribution is unrealizable and singular for a statistical model. Also we study a nonrenormalizable case, in which the learning curves have the different asymptotic behaviors from the universal law.</abstract>
   </article>
   <article>
      <title>Role of Interestingness Measures in CAR Rule Ordering for Associative
  Classifier: An Empirical Approach</title>
      <author>S. Kannan, R. Bhaskaran</author>
      <date>2010-01-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Associative Classifier is a novel technique which is the integration of Association Rule Mining and Classification. The difficult task in building Associative Classifier model is the selection of relevant rules from a large number of class association rules (CARs). A very popular method of ordering rules for selection is based on confidence, support and antecedent size (CSA). Other methods are based on hybrid orderings in which CSA method is combined with other measures. In the present work, we study the effect of using different interestingness measures of Association rules in CAR rule ordering and selection for associative classifier.</abstract>
   </article>
   <article>
      <title>Trajectory Clustering and an Application to Airspace Monitoring</title>
      <author>Maxime Gariel, Ashok N. Srivastava, Eric Feron</author>
      <date>2010-01-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a framework aimed at monitoring the behavior of aircraft in a given airspace. Nominal trajectories are determined and learned using data driven methods. Standard procedures are used by air traffic controllers (ATC) to guide aircraft, ensure the safety of the airspace, and to maximize the runway occupancy. Even though standard procedures are used by ATC, the control of the aircraft remains with the pilots, leading to a large variability in the flight patterns observed. Two methods to identify typical operations and their variability from recorded radar tracks are presented. This knowledge base is then used to monitor the conformance of current operations against operations previously identified as standard. A tool called AirTrajectoryMiner is presented, aiming at monitoring the instantaneous health of the airspace, in real time. The airspace is "healthy" when all aircraft are flying according to the nominal procedures. A measure of complexity is introduced, measuring the conformance of current flight to nominal flight patterns. When an aircraft does not conform, the complexity increases as more attention from ATC is required to ensure a safe separation between aircraft.</abstract>
   </article>
   <article>
      <title>Aggregating Algorithm competing with Banach lattices</title>
      <author>Fedor Zhdanov, Alexey Chernov, Yuri Kalnishkan</author>
      <date>2010-02-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The paper deals with on-line regression settings with signals belonging to a Banach lattice. Our algorithms work in a semi-online setting where all the inputs are known in advance and outcomes are unknown and given step by step. We apply the Aggregating Algorithm to construct a prediction method whose cumulative loss over all the input vectors is comparable with the cumulative loss of any linear functional on the Banach lattice. As a by-product we get an algorithm that takes signals from an arbitrary domain. Its cumulative loss is comparable with the cumulative loss of any predictor function from Besov and Triebel-Lizorkin spaces. We describe several applications of our setting.</abstract>
   </article>
   <article>
      <title>A CHAID Based Performance Prediction Model in Educational Data Mining</title>
      <author>M. Ramaswami, R. Bhaskaran</author>
      <date>2010-02-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The performance in higher secondary school education in India is a turning point in the academic lives of all students. As this academic performance is influenced by many factors, it is essential to develop predictive data mining model for students' performance so as to identify the slow learners and study the influence of the dominant factors on their academic performance. In the present investigation, a survey cum experimental methodology was adopted to generate a database and it was constructed from a primary and a secondary source. While the primary data was collected from the regular students, the secondary data was gathered from the school and office of the Chief Educational Officer (CEO). A total of 1000 datasets of the year 2006 from five different schools in three different districts of Tamilnadu were collected. The raw data was preprocessed in terms of filling up missing values, transforming values in one form into another and relevant attribute/ variable selection. As a result, we had 772 student records, which were used for CHAID prediction model construction. A set of prediction rules were extracted from CHIAD prediction model and the efficiency of the generated CHIAD prediction model was found. The accuracy of the present model was compared with other model and it has been found to be satisfactory.</abstract>
   </article>
   <article>
      <title>Dimensionality Reduction: An Empirical Study on the Usability of IFE-CF
  (Independent Feature Elimination- by C-Correlation and F-Correlation)
  Measures</title>
      <author>M. Babu Reddy, L. S. S. Reddy</author>
      <date>2010-02-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The recent increase in dimensionality of data has thrown a great challenge to the existing dimensionality reduction methods in terms of their effectiveness. Dimensionality reduction has emerged as one of the significant preprocessing steps in machine learning applications and has been effective in removing inappropriate data, increasing learning accuracy, and improving comprehensibility. Feature redundancy exercises great influence on the performance of classification process. Towards the better classification performance, this paper addresses the usefulness of truncating the highly correlated and redundant attributes. Here, an effort has been made to verify the utility of dimensionality reduction by applying LVQ (Learning Vector Quantization) method on two Benchmark datasets of 'Pima Indian Diabetic patients' and 'Lung cancer patients'.</abstract>
   </article>
   <article>
      <title>Online Distributed Sensor Selection</title>
      <author>Daniel Golovin, Matthew Faulkner, Andreas Krause</author>
      <date>2010-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A key problem in sensor networks is to decide which sensors to query when, in order to obtain the most useful information (e.g., for performing accurate prediction), subject to constraints (e.g., on power and bandwidth). In many applications the utility function is not known a priori, must be learned from data, and can even change over time. Furthermore for large sensor networks solving a centralized optimization problem to select sensors is not feasible, and thus we seek a fully distributed solution. In this paper, we present Distributed Online Greedy (DOG), an efficient, distributed algorithm for repeatedly selecting sensors online, only receiving feedback about the utility of the selected sensors. We prove very strong theoretical no-regret guarantees that apply whenever the (unknown) utility function satisfies a natural diminishing returns property called submodularity. Our algorithm has extremely low communication requirements, and scales well to large sensor deployments. We extend DOG to allow observation-dependent sensor selection. We empirically demonstrate the effectiveness of our algorithm on several real-world sensing tasks.</abstract>
   </article>
   <article>
      <title>On the Stability of Empirical Risk Minimization in the Presence of
  Multiple Risk Minimizers</title>
      <author>Benjamin I. P. Rubinstein, Aleksandr Simma</author>
      <date>2010-02-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently Kutin and Niyogi investigated several notions of algorithmic stability--a property of a learning map conceptually similar to continuity--showing that training-stability is sufficient for consistency of Empirical Risk Minimization while distribution-free CV-stability is necessary and sufficient for having finite VC-dimension. This paper concerns a phase transition in the training stability of ERM, conjectured by the same authors. Kutin and Niyogi proved that ERM on finite hypothesis spaces containing a unique risk minimizer has training stability that scales exponentially with sample size, and conjectured that the existence of multiple risk minimizers prevents even super-quadratic convergence. We prove this result for the strictly weaker notion of CV-stability, positively resolving the conjecture.</abstract>
   </article>
   <article>
      <title>Collaborative Filtering in a Non-Uniform World: Learning with the
  Weighted Trace Norm</title>
      <author>Ruslan Salakhutdinov, Nathan Srebro</author>
      <date>2010-02-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We show that matrix completion with trace-norm regularization can be significantly hurt when entries of the matrix are sampled non-uniformly. We introduce a weighted version of the trace-norm regularizer that works well also with non-uniform sampling. Our experimental results demonstrate that the weighted trace-norm regularization indeed yields significant gains on the (highly non-uniformly sampled) Netflix dataset.</abstract>
   </article>
   <article>
      <title>Interactive Submodular Set Cover</title>
      <author>Andrew Guillory, Jeff Bilmes</author>
      <date>2010-02-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a natural generalization of submodular set cover and exact active learning with a finite hypothesis class (query learning). We call this new problem interactive submodular set cover. Applications include advertising in social networks with hidden information. We give an approximation guarantee for a novel greedy algorithm and give a hardness of approximation result which matches up to constant factors. We also discuss negative results for simpler approaches and present encouraging early experimental results.</abstract>
   </article>
   <article>
      <title>Word level Script Identification from Bangla and Devanagri Handwritten
  Texts mixed with Roman Script</title>
      <author>Ram Sarkar, Nibaran Das, Subhadip Basu, Mahantapas Kundu, Mita Nasipuri, Dipak Kumar Basu</author>
      <date>2010-02-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>India is a multi-lingual country where Roman script is often used alongside different Indic scripts in a text document. To develop a script specific handwritten Optical Character Recognition (OCR) system, it is therefore necessary to identify the scripts of handwritten text correctly. In this paper, we present a system, which automatically separates the scripts of handwritten words from a document, written in Bangla or Devanagri mixed with Roman scripts. In this script separation technique, we first, extract the text lines and words from document pages using a script independent Neighboring Component Analysis technique. Then we have designed a Multi Layer Perceptron (MLP) based classifier for script separation, trained with 8 different wordlevel holistic features. Two equal sized datasets, one with Bangla and Roman scripts and the other with Devanagri and Roman scripts, are prepared for the system evaluation. On respective independent text samples, word-level script identification accuracies of 99.29% and 98.43% are achieved.</abstract>
   </article>
   <article>
      <title>Contextual Bandit Algorithms with Supervised Learning Guarantees</title>
      <author>Alina Beygelzimer, John Langford, Lihong Li, Lev Reyzin, Robert E. Schapire</author>
      <date>2010-02-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We address the problem of learning in an online, bandit setting where the learner must repeatedly select among $K$ actions, but only receives partial feedback based on its choices. We establish two new facts: First, using a new algorithm called Exp4.P, we show that it is possible to compete with the best in a set of $N$ experts with probability $1-\delta$ while incurring regret at most $O(\sqrt{KT\ln(N/\delta)})$ over $T$ time steps. The new algorithm is tested empirically in a large-scale, real-world dataset. Second, we give a new algorithm called VE that competes with a possibly infinite set of policies of VC-dimension $d$ while incurring regret at most $O(\sqrt{T(d\ln(T) + \ln (1/\delta))})$ with probability $1-\delta$. These guarantees improve on those of all previous algorithms, whether in a stochastic or adversarial environment, and bring us closer to providing supervised learning type guarantees for the contextual bandit setting.</abstract>
   </article>
   <article>
      <title>Adaptive Bound Optimization for Online Convex Optimization</title>
      <author>H. Brendan McMahan, Matthew Streeter</author>
      <date>2010-02-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a new online convex optimization algorithm that adaptively chooses its regularization function based on the loss functions observed so far. This is in contrast to previous algorithms that use a fixed regularization function such as L2-squared, and modify it only via a single time-dependent parameter. Our algorithm's regret bounds are worst-case optimal, and for certain realistic classes of loss functions they are much better than existing bounds. These bounds are problem-dependent, which means they can exploit the structure of the actual problem instance. Critically, however, our algorithm does not need to know this structure in advance. Rather, we prove competitive guarantees that show the algorithm provides a bound within a constant factor of the best possible bound (of a certain functional form) in hindsight.</abstract>
   </article>
   <article>
      <title>Asymptotic Analysis of Generative Semi-Supervised Learning</title>
      <author>Joshua V Dillon, Krishnakumar Balasubramanian, Guy Lebanon</author>
      <date>2010-02-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Semisupervised learning has emerged as a popular framework for improving modeling accuracy while controlling labeling cost. Based on an extension of stochastic composite likelihood we quantify the asymptotic accuracy of generative semi-supervised learning. In doing so, we complement distribution-free analysis by providing an alternative framework to measure the value associated with different labeling policies and resolve the fundamental question of how much data to label and in what manner. We demonstrate our approach with both simulation studies and real world experiments using naive Bayes for text classification and MRFs and CRFs for structured prediction in NLP.</abstract>
   </article>
   <article>
      <title>Unsupervised Supervised Learning II: Training Margin Based Classifiers
  without Labels</title>
      <author>Krishnakumar Balasubramanian, Pinar Donmez, Guy Lebanon</author>
      <date>2010-03-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many popular linear classifiers, such as logistic regression, boosting, or SVM, are trained by optimizing a margin-based risk function. Traditionally, these risk functions are computed based on a labeled dataset. We develop a novel technique for estimating such risks using only unlabeled data and the marginal label distribution. We prove that the proposed risk estimator is consistent on high-dimensional datasets and demonstrate it on synthetic and real-world data. In particular, we show how the estimate is used for evaluating classifiers in transfer learning, and for training classifiers with no labeled data whatsoever.</abstract>
   </article>
   <article>
      <title>Model Selection with the Loss Rank Principle</title>
      <author>Marcus Hutter, Minh-Ngoc Tran</author>
      <date>2010-03-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A key issue in statistics and machine learning is to automatically select the "right" model complexity, e.g., the number of neighbors to be averaged over in k nearest neighbor (kNN) regression or the polynomial degree in regression with polynomials. We suggest a novel principle - the Loss Rank Principle (LoRP) - for model selection in regression and classification. It is based on the loss rank, which counts how many other (fictitious) data would be fitted better. LoRP selects the model that has minimal loss rank. Unlike most penalized maximum likelihood variants (AIC, BIC, MDL), LoRP depends only on the regression functions and the loss function. It works without a stochastic noise model, and is directly applicable to any non-parametric regressor, like kNN.</abstract>
   </article>
   <article>
      <title>Statistical and Computational Tradeoffs in Stochastic Composite
  Likelihood</title>
      <author>Joshua V Dillon, Guy Lebanon</author>
      <date>2010-03-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Maximum likelihood estimators are often of limited practical use due to the intensive computation they require. We propose a family of alternative estimators that maximize a stochastic variation of the composite likelihood function. Each of the estimators resolve the computation-accuracy tradeoff differently, and taken together they span a continuous spectrum of computation-accuracy tradeoff resolutions. We prove the consistency of the estimators, provide formulas for their asymptotic variance, statistical robustness, and computational complexity. We discuss experimental results in the context of Boltzmann machines and conditional random fields. The theoretical and experimental studies demonstrate the effectiveness of the estimators when the computational resources are insufficient. They also demonstrate that in some cases reduced computational complexity is associated with robustness thereby increasing statistical accuracy.</abstract>
   </article>
   <article>
      <title>Exponential Family Hybrid Semi-Supervised Learning</title>
      <author>Arvind Agarwal, Hal Daume III</author>
      <date>2010-03-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present an approach to semi-supervised learning based on an exponential family characterization. Our approach generalizes previous work on coupled priors for hybrid generative/discriminative models. Our model is more flexible and natural than previous approaches. Experimental results on several data sets show that our approach also performs better in practice.</abstract>
   </article>
   <article>
      <title>A New Clustering Approach based on Page's Path Similarity for Navigation
  Patterns Mining</title>
      <author>Heidar Mamosian, Amir Masoud Rahmani, Mashalla Abbasi Dezfouli</author>
      <date>2010-03-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In recent years, predicting the user's next request in web navigation has received much attention. An information source to be used for dealing with such problem is the left information by the previous web users stored at the web access log on the web servers. Purposed systems for this problem work based on this idea that if a large number of web users request specific pages of a website on a given session, it can be concluded that these pages are satisfying similar information needs, and therefore they are conceptually related. In this study, a new clustering approach is introduced that employs logical path storing of a website pages as another parameter which is regarded as a similarity parameter and conceptual relation between web pages. The results of simulation have shown that the proposed approach is more than others precise in determining the clusters.</abstract>
   </article>
   <article>
      <title>Hierarchical Web Page Classification Based on a Topic Model and
  Neighboring Pages Integration</title>
      <author>Wongkot Sriurai, Phayung Meesad, Choochart Haruechaiyasak</author>
      <date>2010-03-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Most Web page classification models typically apply the bag of words (BOW) model to represent the feature space. The original BOW representation, however, is unable to recognize semantic relationships between terms. One possible solution is to apply the topic model approach based on the Latent Dirichlet Allocation algorithm to cluster the term features into a set of latent topics. Terms assigned into the same topic are semantically related. In this paper, we propose a novel hierarchical classification method based on a topic model and by integrating additional term features from neighboring pages. Our hierarchical classification method consists of two phases: (1) feature representation by using a topic model and integrating neighboring pages, and (2) hierarchical Support Vector Machines (SVM) classification model constructed from a confusion matrix. From the experimental results, the approach of using the proposed hierarchical SVM model by integrating current page with neighboring pages via the topic model yielded the best performance with the accuracy equal to 90.33% and the F1 measure of 90.14%; an improvement of 5.12% and 5.13% over the original SVM model, respectively.</abstract>
   </article>
   <article>
      <title>Supermartingales in Prediction with Expert Advice</title>
      <author>Alexey Chernov, Yuri Kalnishkan, Fedor Zhdanov, Vladimir Vovk</author>
      <date>2010-03-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We apply the method of defensive forecasting, based on the use of game-theoretic supermartingales, to prediction with expert advice. In the traditional setting of a countable number of experts and a finite number of outcomes, the Defensive Forecasting Algorithm is very close to the well-known Aggregating Algorithm. Not only the performance guarantees but also the predictions are the same for these two methods of fundamentally different nature. We discuss also a new setting where the experts can give advice conditional on the learner's future decision. Both the algorithms can be adapted to the new setting and give the same performance guarantees as in the traditional setting. Finally, we outline an application of defensive forecasting to a setting with several loss functions.</abstract>
   </article>
   <article>
      <title>State-Space Dynamics Distance for Clustering Sequential Data</title>
      <author>Darío García-García, Emilio Parrado-Hernández, Fernando Díaz-de-María</author>
      <date>2010-04-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper proposes a novel similarity measure for clustering sequential data. We first construct a common state-space by training a single probabilistic model with all the sequences in order to get a unified representation for the dataset. Then, distances are obtained attending to the transition matrices induced by each sequence in that state-space. This approach solves some of the usual overfitting and scalability issues of the existing semi-parametric techniques, that rely on training a model for each sequence. Empirical studies on both synthetic and real-world datasets illustrate the advantages of the proposed similarity measure for clustering sequences.</abstract>
   </article>
   <article>
      <title>Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable
  Information Criterion in Singular Learning Theory</title>
      <author>Sumio Watanabe</author>
      <date>2010-04-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In regular statistical models, the leave-one-out cross-validation is asymptotically equivalent to the Akaike information criterion. However, since many learning machines are singular statistical models, the asymptotic behavior of the cross-validation remains unknown. In previous studies, we established the singular learning theory and proposed a widely applicable information criterion, the expectation value of which is asymptotically equal to the average Bayes generalization loss. In the present paper, we theoretically compare the Bayes cross-validation loss and the widely applicable information criterion and prove two theorems. First, the Bayes cross-validation loss is asymptotically equivalent to the widely applicable information criterion as a random variable. Therefore, model selection and hyperparameter optimization using these two values are asymptotically equivalent. Second, the sum of the Bayes generalization error and the Bayes cross-validation error is asymptotically equal to $2\lambda/n$, where $\lambda$ is the real log canonical threshold and $n$ is the number of training samples. Therefore the relation between the cross-validation error and the generalization error is determined by the algebraic geometrical structure of a learning machine. We also clarify that the deviance information criteria are different from the Bayes cross-validation and the widely applicable information criterion.</abstract>
   </article>
   <article>
      <title>Generation and Interpretation of Temporal Decision Rules</title>
      <author>Kamran Karimi, Howard J. Hamilton</author>
      <date>2010-04-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a solution to the problem of understanding a system that produces a sequence of temporally ordered observations. Our solution is based on generating and interpreting a set of temporal decision rules. A temporal decision rule is a decision rule that can be used to predict or retrodict the value of a decision attribute, using condition attributes that are observed at times other than the decision attribute's time of observation. A rule set, consisting of a set of temporal decision rules with the same decision attribute, can be interpreted by our Temporal Investigation Method for Enregistered Record Sequences (TIMERS) to signify an instantaneous, an acausal or a possibly causal relationship between the condition attributes and the decision attribute. We show the effectiveness of our method, by describing a number of experiments with both synthetic and real temporal data.</abstract>
   </article>
   <article>
      <title>Bregman Distance to L1 Regularized Logistic Regression</title>
      <author>Mithun Das Gupta, Thomas S. Huang</author>
      <date>2010-04-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this work we investigate the relationship between Bregman distances and regularized Logistic Regression model. We present a detailed study of Bregman Distance minimization, a family of generalized entropy measures associated with convex functions. We convert the L1-regularized logistic regression into this more general framework and propose a primal-dual method based algorithm for learning the parameters. We pose L1-regularized logistic regression into Bregman distance minimization and then apply non-linear constrained optimization techniques to estimate the parameters of the logistic model.</abstract>
   </article>
   <article>
      <title>Efficient Learning with Partially Observed Attributes</title>
      <author>Nicolò Cesa-Bianchi, Shai Shalev-Shwartz, Ohad Shamir</author>
      <date>2010-04-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We describe and analyze efficient algorithms for learning a linear predictor from examples when the learner can only view a few attributes of each training example. This is the case, for instance, in medical research, where each patient participating in the experiment is only willing to go through a small number of tests. Our analysis bounds the number of additional examples sufficient to compensate for the lack of full information on each training example. We demonstrate the efficiency of our algorithms by showing that when running on digit recognition data, they obtain a high prediction accuracy even when the learner gets to see only four pixels of each image.</abstract>
   </article>
   <article>
      <title>Learning from Multiple Outlooks</title>
      <author>Maayan Harel, Shie Mannor</author>
      <date>2010-04-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a novel problem formulation of learning a single task when the data are provided in different feature spaces. Each such space is called an outlook, and is assumed to contain both labeled and unlabeled data. The objective is to take advantage of the data from all the outlooks to better classify each of the outlooks. We devise an algorithm that computes optimal affine mappings from different outlooks to a target outlook by matching moments of the empirical distributions. We further derive a probabilistic interpretation of the resulting algorithm and a sample complexity bound indicating how many samples are needed to adequately find the mapping. We report the results of extensive experiments on activity recognition tasks that show the value of the proposed approach in boosting performance.</abstract>
   </article>
   <article>
      <title>A Geometric View of Conjugate Priors</title>
      <author>Arvind Agarwal, Hal Daume III</author>
      <date>2010-05-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In Bayesian machine learning, conjugate priors are popular, mostly due to mathematical convenience. In this paper, we show that there are deeper reasons for choosing a conjugate prior. Specifically, we formulate the conjugate prior in the form of Bregman divergence and show that it is the inherent geometry of conjugate priors that makes them appropriate and intuitive. This geometric interpretation allows one to view the hyperparameters of conjugate priors as the {\it effective} sample points, thus providing additional intuition. We use this geometric understanding of conjugate priors to derive the hyperparameters and expression of the prior used to couple the generative and discriminative components of a hybrid model for semi-supervised learning.</abstract>
   </article>
   <article>
      <title>Distributive Stochastic Learning for Delay-Optimal OFDMA Power and
  Subband Allocation</title>
      <author>Ying Cui, Vincent K. N. Lau</author>
      <date>2010-05-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we consider the distributive queue-aware power and subband allocation design for a delay-optimal OFDMA uplink system with one base station, $K$ users and $N_F$ independent subbands. Each mobile has an uplink queue with heterogeneous packet arrivals and delay requirements. We model the problem as an infinite horizon average reward Markov Decision Problem (MDP) where the control actions are functions of the instantaneous Channel State Information (CSI) as well as the joint Queue State Information (QSI). To address the distributive requirement and the issue of exponential memory requirement and computational complexity, we approximate the subband allocation Q-factor by the sum of the per-user subband allocation Q-factor and derive a distributive online stochastic learning algorithm to estimate the per-user Q-factor and the Lagrange multipliers (LM) simultaneously and determine the control actions using an auction mechanism. We show that under the proposed auction mechanism, the distributive online learning converges almost surely (with probability 1). For illustration, we apply the proposed distributive stochastic learning framework to an application example with exponential packet size distribution. We show that the delay-optimal power control has the {\em multi-level water-filling} structure where the CSI determines the instantaneous power allocation and the QSI determines the water-level. The proposed algorithm has linear signaling overhead and computational complexity $\mathcal O(KN)$, which is desirable from an implementation perspective.</abstract>
   </article>
   <article>
      <title>Statistical Learning in Automated Troubleshooting: Application to LTE
  Interference Mitigation</title>
      <author>Moazzam Islam Tiwana, Berna Sayrac, Zwi Altman</author>
      <date>2010-05-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a method for automated healing as part of off-line automated troubleshooting. The method combines statistical learning with constraint optimization. The automated healing aims at locally optimizing radio resource management (RRM) or system parameters of cells with poor performance in an iterative manner. The statistical learning processes the data using Logistic Regression (LR) to extract closed form (functional) relations between Key Performance Indicators (KPIs) and Radio Resource Management (RRM) parameters. These functional relations are then processed by an optimization engine which proposes new parameter values. The advantage of the proposed formulation is the small number of iterations required by the automated healing method to converge, making it suitable for off-line implementation. The proposed method is applied to heal an Inter-Cell Interference Coordination (ICIC) process in a 3G Long Term Evolution (LTE) network which is based on soft-frequency reuse scheme. Numerical simulations illustrate the benefits of the proposed approach.</abstract>
   </article>
   <article>
      <title>The Complex Gaussian Kernel LMS algorithm</title>
      <author>Pantelis Bouboulis, Sergios Theodoridis</author>
      <date>2010-05-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Although the real reproducing kernels are used in an increasing number of machine learning problems, complex kernels have not, yet, been used, in spite of their potential interest in applications such as communications. In this work, we focus our attention on the complex gaussian kernel and its possible application in the complex Kernel LMS algorithm. In order to derive the gradients needed to develop the complex kernel LMS (CKLMS), we employ the powerful tool of Wirtinger's Calculus, which has recently attracted much attention in the signal processing community. Writinger's calculus simplifies computations and offers an elegant tool for treating complex signals. To this end, the notion of Writinger's calculus is extended to include complex RKHSs. Experiments verify that the CKLMS offers significant performance improvements over the traditional complex LMS or Widely Linear complex LMS (WL-LMS) algorithms, when dealing with nonlinearities.</abstract>
   </article>
   <article>
      <title>Extension of Wirtinger Calculus in RKH Spaces and the Complex Kernel LMS</title>
      <author>Pantelis Bouboulis, Sergios Theodoridis</author>
      <date>2010-05-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Over the last decade, kernel methods for nonlinear processing have successfully been used in the machine learning community. However, so far, the emphasis has been on batch techniques. It is only recently, that online adaptive techniques have been considered in the context of signal processing tasks. To the best of our knowledge, no kernel-based strategy has been developed, so far, that is able to deal with complex valued signals. In this paper, we take advantage of a technique called complexification of real RKHSs to attack this problem. In order to derive gradients and subgradients of operators that need to be defined on the associated complex RKHSs, we employ the powerful tool ofWirtinger's Calculus, which has recently attracted much attention in the signal processing community. Writinger's calculus simplifies computations and offers an elegant tool for treating complex signals. To this end, in this paper, the notion of Writinger's calculus is extended, for the first time, to include complex RKHSs and use it to derive the Complex Kernel Least-Mean-Square (CKLMS) algorithm. Experiments verify that the CKLMS can be used to derive nonlinear stable algorithms, which offer significant performance improvements over the traditional complex LMS orWidely Linear complex LMS (WL-LMS) algorithms, when dealing with nonlinearities.</abstract>
   </article>
   <article>
      <title>Improving Semi-Supervised Support Vector Machines Through Unlabeled
  Instances Selection</title>
      <author>Yu-Feng Li, Zhi-Hua Zhou</author>
      <date>2010-05-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Semi-supervised <term>support vector machine</term>s (S3VMs) are a kind of popular approaches which try to improve learning performance by exploiting unlabeled data. Though S3VMs have been found helpful in many situations, they may degenerate performance and the resultant generalization ability may be even worse than using the labeled data only. In this paper, we try to reduce the chance of performance degeneration of S3VMs. Our basic idea is that, rather than exploiting all unlabeled data, the unlabeled instances should be selected such that only the ones which are very likely to be helpful are exploited, while some highly risky unlabeled instances are avoided. We propose the S3VM-\emph{us} method by using hierarchical clustering to select the unlabeled instances. Experiments on a broad range of data sets over eighty-eight different settings show that the chance of performance degeneration of S3VM-\emph{us} is much smaller than that of existing S3VMs.</abstract>
   </article>
   <article>
      <title>Prediction with Expert Advice under Discounted Loss</title>
      <author>Alexey Chernov, Fedor Zhdanov</author>
      <date>2010-05-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study prediction with expert advice in the setting where the losses are accumulated with some discounting---the impact of old losses may gradually vanish. We generalize the Aggregating Algorithm and the Aggregating Algorithm for Regression to this case, propose a suitable new variant of exponential weights algorithm, and prove respective loss bounds.</abstract>
   </article>
   <article>
      <title>Detecting Blackholes and Volcanoes in Directed Networks</title>
      <author>Zhongmou Li, Hui Xiong, Yanchi Liu</author>
      <date>2010-05-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we formulate a novel problem for finding blackhole and volcano patterns in a large directed graph. Specifically, a blackhole pattern is a group which is made of a set of nodes in a way such that there are only inlinks to this group from the rest nodes in the graph. In contrast, a volcano pattern is a group which only has outlinks to the rest nodes in the graph. Both patterns can be observed in real world. For instance, in a trading network, a blackhole pattern may represent a group of traders who are manipulating the market. In the paper, we first prove that the blackhole mining problem is a dual problem of finding volcanoes. Therefore, we focus on finding the blackhole patterns. Along this line, we design two pruning schemes to guide the blackhole finding process. In the first pruning scheme, we strategically prune the search space based on a set of pattern-size-independent pruning rules and develop an iBlackhole algorithm. The second pruning scheme follows a divide-and-conquer strategy to further exploit the pruning results from the first pruning scheme. Indeed, a target directed graphs can be divided into several disconnected subgraphs by the first pruning scheme, and thus the blackhole finding can be conducted in each disconnected subgraph rather than in a large graph. Based on these two pruning schemes, we also develop an iBlackhole-DC algorithm. Finally, experimental results on real-world data show that the iBlackhole-DC algorithm can be several orders of magnitude faster than the iBlackhole algorithm, which has a huge computational advantage over a brute-force method.</abstract>
   </article>
   <article>
      <title>Robustness and Generalization</title>
      <author>Huan Xu, Shie Mannor</author>
      <date>2010-05-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We derive generalization bounds for learning algorithms based on their robustness: the property that if a testing sample is "similar" to a training sample, then the testing error is close to the training error. This provides a novel approach, different from the complexity or stability arguments, to study generalization of learning algorithms. We further show that a weak notion of robustness is both sufficient and necessary for generalizability, which implies that robustness is a fundamental property for learning algorithms to work.</abstract>
   </article>
   <article>
      <title>Online Learning of Noisy Data with Kernels</title>
      <author>Nicolò Cesa-Bianchi, Shai Shalev-Shwartz, Ohad Shamir</author>
      <date>2010-05-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study online learning when individual instances are corrupted by adversarially chosen random noise. We assume the noise distribution is unknown, and may change over time with no restriction other than having zero mean and bounded variance. Our technique relies on a family of unbiased estimators for non-linear functions, which may be of independent interest. We show that a variant of online <term>gradient descent</term> can learn functions in any dot-product (e.g., polynomial) or Gaussian kernel space with any analytic convex loss function. Our variant uses randomized estimates that need to query a random number of noisy copies of each instance, where with high probability this number is upper bounded by a constant. Allowing such multiple queries cannot be avoided: Indeed, we show that online learning is in general impossible when only one noisy copy of each instance can be accessed.</abstract>
   </article>
   <article>
      <title>Evolution with Drifting Targets</title>
      <author>Varun Kanade, Leslie G. Valiant, Jennifer Wortman Vaughan</author>
      <date>2010-05-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the question of the stability of evolutionary algorithms to gradual changes, or drift, in the target concept. We define an algorithm to be resistant to drift if, for some inverse polynomial drift rate in the target function, it converges to accuracy 1 -- \epsilon , with polynomial resources, and then stays within that accuracy indefinitely, except with probability \epsilon , at any one time. We show that every evolution algorithm, in the sense of Valiant (2007; 2009), can be converted using the Correlational Query technique of Feldman (2008), into such a drift resistant algorithm. For certain evolutionary algorithms, such as for Boolean conjunctions, we give bounds on the rates of drift that they can resist. We develop some new evolution algorithms that are resistant to significant drift. In particular, we give an algorithm for evolving linear separators over the spherically symmetric distribution that is resistant to a drift rate of O(\epsilon /n), and another algorithm over the more general product normal distributions that resists a smaller drift rate.   The above translation result can be also interpreted as one on the robustness of the notion of evolvability itself under changes of definition. As a second result in that direction we show that every evolution algorithm can be converted to a quasi-monotonic one that can evolve from any starting point without the performance ever dipping significantly below that of the starting point. This permits the somewhat unnatural feature of arbitrary performance degradations to be removed from several known robustness translations.</abstract>
   </article>
   <article>
      <title>Learning Kernel-Based Halfspaces with the Zero-One Loss</title>
      <author>Shai Shalev-Shwartz, Ohad Shamir, Karthik Sridharan</author>
      <date>2010-05-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We describe and analyze a new algorithm for agnostically learning kernel-based halfspaces with respect to the \emph{zero-one} loss function. Unlike most previous formulations which rely on surrogate convex loss functions (e.g. hinge-loss in SVM and log-loss in logistic regression), we provide finite time/sample guarantees with respect to the more natural zero-one loss function. The proposed algorithm can learn kernel-based halfspaces in worst-case time $\poly(\exp(L\log(L/\epsilon)))$, for $\emph{any}$ distribution, where $L$ is a Lipschitz constant (which can be thought of as the reciprocal of the margin), and the learned classifier is worse than the optimal halfspace by at most $\epsilon$. We also prove a hardness result, showing that under a certain cryptographic assumption, no algorithm can learn kernel-based halfspaces in time polynomial in $L$.</abstract>
   </article>
   <article>
      <title>On the clustering aspect of nonnegative matrix factorization</title>
      <author>Andri Mirzal, Masashi Furukawa</author>
      <date>2010-05-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper provides a theoretical explanation on the clustering aspect of nonnegative matrix factorization (NMF). We prove that even without imposing orthogonality nor sparsity constraint on the basis and/or coefficient matrix, NMF still can give clustering results, thus providing a theoretical support for many works, e.g., Xu et al. [1] and Kim et al. [2], that show the superiority of the standard NMF as a clustering method.</abstract>
   </article>
   <article>
      <title>Multi-View Active Learning in the Non-Realizable Case</title>
      <author>Wei Wang, Zhi-Hua Zhou</author>
      <date>2010-05-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The sample complexity of active learning under the realizability assumption has been well-studied. The realizability assumption, however, rarely holds in practice. In this paper, we theoretically characterize the sample complexity of active learning in the non-realizable case under multi-view setting. We prove that, with unbounded Tsybakov noise, the sample complexity of multi-view active learning can be $\widetilde{O}(\log\frac{1}{\epsilon})$, contrasting to single-view setting where the polynomial improvement is the best possible achievement. We also prove that in general multi-view setting the sample complexity of active learning with unbounded Tsybakov noise is $\widetilde{O}(\frac{1}{\epsilon})$, where the order of $1/\epsilon$ is independent of the parameter in Tsybakov noise, contrasting to previous polynomial bounds where the order of $1/\epsilon$ is related to the parameter in Tsybakov noise.</abstract>
   </article>
   <article>
      <title>Prediction with Advice of Unknown Number of Experts</title>
      <author>Alexey Chernov, Vladimir Vovk</author>
      <date>2010-06-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In the framework of prediction with expert advice, we consider a recently introduced kind of regret bounds: the bounds that depend on the effective instead of nominal number of experts. In contrast to the NormalHedge bound, which mainly depends on the effective number of experts and also weakly depends on the nominal one, we obtain a bound that does not contain the nominal number of experts at all. We use the defensive forecasting method and introduce an application of defensive forecasting to multivalued supermartingales.</abstract>
   </article>
   <article>
      <title>Predictive PAC learnability: a paradigm for learning from exchangeable
  input data</title>
      <author>Vladimir Pestov</author>
      <date>2010-06-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Exchangeable random variables form an important and well-studied generalization of i.i.d. variables, however simple examples show that no nontrivial concept or function classes are PAC learnable under general exchangeable data inputs $X_1,X_2,\ldots$. Inspired by the work of Berti and Rigo on a Glivenko--Cantelli theorem for exchangeable inputs, we propose a new paradigm, adequate for learning from exchangeable data: predictive PAC learnability. A learning rule $\mathcal L$ for a function class $\mathscr F$ is predictive PAC if for every $\e,\delta&gt;0$ and each function $f\in {\mathscr F}$, whenever $\abs{\sigma}\geq s(\delta,\e)$, we have with confidence $1-\delta$ that the expected difference between $f(X_{n+1})$ and the image of $f\vert\sigma$ under $\mathcal L$ does not exceed $\e$ conditionally on $X_1,X_2,\ldots,X_n$. Thus, instead of learning the function $f$ as such, we are learning to a given accuracy $\e$ the predictive behaviour of $f$ at the future points $X_i(\omega)$, $i&gt;n$ of the sample path. Using de Finetti's theorem, we show that if a universally separable function class $\mathscr F$ is distribution-free PAC learnable under i.i.d. inputs, then it is distribution-free predictive PAC learnable under exchangeable inputs, with a slightly worse sample complexity.</abstract>
   </article>
   <article>
      <title>Regression on fixed-rank positive semidefinite matrices: a Riemannian
  approach</title>
      <author>Gilles Meyer, Silvere Bonnabel, Rodolphe Sepulchre</author>
      <date>2010-06-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The paper addresses the problem of learning a regression model parameterized by a fixed-rank positive semidefinite matrix. The focus is on the nonlinear nature of the search space and on scalability to high-dimensional problems. The mathematical developments rely on the theory of <term>gradient descent</term> algorithms adapted to the Riemannian geometry that underlies the set of fixed-rank positive semidefinite matrices. In contrast with previous contributions in the literature, no restrictions are imposed on the range space of the learned matrix. The resulting algorithms maintain a linear complexity in the problem size and enjoy important invariance properties. We apply the proposed algorithms to the problem of learning a distance function parameterized by a positive semidefinite matrix. Good performance is observed on classical benchmarks.</abstract>
   </article>
   <article>
      <title>Dyadic Prediction Using a Latent Feature Log-Linear Model</title>
      <author>Aditya Krishna Menon, Charles Elkan</author>
      <date>2010-06-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In dyadic prediction, labels must be predicted for pairs (dyads) whose members possess unique identifiers and, sometimes, additional features called side-information. Special cases of this problem include collaborative filtering and link prediction. We present the first model for dyadic prediction that satisfies several important desiderata: (i) labels may be ordinal or nominal, (ii) side-information can be easily exploited if present, (iii) with or without side-information, latent features are inferred for dyad members, (iv) it is resistant to sample-selection bias, (v) it can learn well-calibrated probabilities, and (vi) it can scale to very large datasets. To our knowledge, no existing method satisfies all the above criteria. In particular, many methods assume that the labels are ordinal and ignore side-information when it is present. Experimental results show that the new method is competitive with state-of-the-art methods for the special cases of collaborative filtering and link prediction, and that it makes accurate predictions on nominal data.</abstract>
   </article>
   <article>
      <title>Agnostic Active Learning Without Constraints</title>
      <author>Alina Beygelzimer, Daniel Hsu, John Langford, Tong Zhang</author>
      <date>2010-06-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classification.</abstract>
   </article>
   <article>
      <title>Extension of Wirtinger's Calculus to Reproducing Kernel Hilbert Spaces
  and the Complex Kernel LMS</title>
      <author>Pantelis Bouboulis, Sergios Theodoridis</author>
      <date>2010-06-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Over the last decade, kernel methods for nonlinear processing have successfully been used in the machine learning community. The primary mathematical tool employed in these methods is the notion of the Reproducing Kernel Hilbert Space. However, so far, the emphasis has been on batch techniques. It is only recently, that online techniques have been considered in the context of adaptive signal processing tasks. Moreover, these efforts have only been focussed on real valued data sequences. To the best of our knowledge, no adaptive kernel-based strategy has been developed, so far, for complex valued signals. Furthermore, although the real reproducing kernels are used in an increasing number of machine learning problems, complex kernels have not, yet, been used, in spite of their potential interest in applications that deal with complex signals, with Communications being a typical example. In this paper, we present a general framework to attack the problem of adaptive filtering of complex signals, using either real reproducing kernels, taking advantage of a technique called \textit{complexification} of real RKHSs, or complex reproducing kernels, highlighting the use of the complex gaussian kernel. In order to derive gradients of operators that need to be defined on the associated complex RKHSs, we employ the powerful tool of Wirtinger's Calculus, which has recently attracted attention in the signal processing community. To this end, in this paper, the notion of Wirtinger's calculus is extended, for the first time, to include complex RKHSs and use it to derive several realizations of the Complex Kernel Least-Mean-Square (CKLMS) algorithm. Experiments verify that the CKLMS offers significant performance improvements over several linear and nonlinear algorithms, when dealing with nonlinearities.</abstract>
   </article>
   <article>
      <title>MINLIP for the Identification of Monotone Wiener Systems</title>
      <author>Kristiaan Pelckmans</author>
      <date>2010-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper studies the MINLIP estimator for the identification of Wiener systems consisting of a sequence of a linear FIR dynamical model, and a monotonically increasing (or decreasing) static function. Given $T$ observations, this algorithm boils down to solving a convex quadratic program with $O(T)$ variables and inequality constraints, implementing an inference technique which is based entirely on model complexity control. The resulting estimates of the linear submodel are found to be almost consistent when no noise is present in the data, under a condition of smoothness of the true nonlinearity and local Persistency of Excitation (local PE) of the data. This result is novel as it does not rely on classical tools as a 'linearization' using a Taylor decomposition, nor exploits stochastic properties of the data. It is indicated how to extend the method to cope with noisy data, and empirical evidence contrasts performance of the estimator against other recently proposed techniques.</abstract>
   </article>
   <article>
      <title>PAC learnability of a concept class under non-atomic measures: a problem
  by Vidyasagar</title>
      <author>Vladimir Pestov</author>
      <date>2010-06-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In response to a 1997 problem of M. Vidyasagar, we state a necessary and sufficient condition for distribution-free PAC learnability of a concept class $\mathscr C$ under the family of all non-atomic (diffuse) measures on the domain $\Omega$. Clearly, finiteness of the classical Vapnik-Chervonenkis dimension of $\mathscr C$ is a sufficient, but no longer necessary, condition. Besides, learnability of $\mathscr C$ under non-atomic measures does not imply the uniform Glivenko-Cantelli property with regard to non-atomic measures. Our learnability criterion is stated in terms of a combinatorial parameter $\VC({\mathscr C}\,{\mathrm{mod}}\,\omega_1)$ which we call the VC dimension of $\mathscr C$ modulo countable sets. The new parameter is obtained by ``thickening up'' single points in the definition of VC dimension to uncountable ``clusters''. Equivalently, $\VC(\mathscr C\modd\omega_1)\leq d$ if and only if every countable subclass of $\mathscr C$ has VC dimension $\leq d$ outside a countable subset of $\Omega$. The new parameter can be also expressed as the classical VC dimension of $\mathscr C$ calculated on a suitable subset of a compactification of $\Omega$. We do not make any measurability assumptions on $\mathscr C$, assuming instead the validity of Martin's Axiom (MA).</abstract>
   </article>
   <article>
      <title>The Latent Bernoulli-Gauss Model for Data Analysis</title>
      <author>Amnon Shashua, Gabi Pragier</author>
      <date>2010-07-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a new latent-variable model employing a Gaussian mixture integrated with a feature selection procedure (the Bernoulli part of the model) which together form a "Latent Bernoulli-Gauss" distribution. The model is applied to MAP estimation, clustering, feature selection and collaborative filtering and fares favorably with the state-of-the-art latent-variable models.</abstract>
   </article>
   <article>
      <title>Filtrage vaste marge pour l'étiquetage séquentiel à noyaux de
  signaux</title>
      <author>Rémi Flamary, Benjamin Labbé, Alain Rakotomamonjy</author>
      <date>2010-07-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We address in this paper the problem of multi-channel signal sequence labeling. In particular, we consider the problem where the signals are contaminated by noise or may present some dephasing with respect to their labels. For that, we propose to jointly learn a SVM sample classifier with a temporal filtering of the channels. This will lead to a large margin filtering that is adapted to the specificity of each channel (noise and time-lag). We derive algorithms to solve the optimization problem and we discuss different filter regularizations for automated scaling or selection of channels. Our approach is tested on a non-linear toy example and on a BCI dataset. Results show that the classification performance on these problems can be improved by learning a large margin filtering.</abstract>
   </article>
   <article>
      <title>A note on sample complexity of learning binary output neural networks
  under fixed input distributions</title>
      <author>Vladimir Pestov</author>
      <date>2010-07-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We show that the learning sample complexity of a sigmoidal <term>neural network</term> constructed by Sontag (1992) required to achieve a given misclassification error under a fixed purely atomic distribution can grow arbitrarily fast: for any prescribed rate of growth there is an input distribution having this rate as the sample complexity, and the bound is asymptotically tight. The rate can be superexponential, a non-recursive function, etc. We further observe that Sontag's ANN is not Glivenko-Cantelli under any input distribution having a non-atomic part.</abstract>
   </article>
   <article>
      <title>Reinforcement Learning via AIXI Approximation</title>
      <author>Joel Veness, Kee Siong Ng, Marcus Hutter, David Silver</author>
      <date>2010-07-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper introduces a principled approach for the design of a scalable general <term>reinforcement learning</term> agent. This approach is based on a direct approximation of AIXI, a Bayesian optimality notion for general <term>reinforcement learning</term> agents. Previously, it has been unclear whether the theory of AIXI could motivate the design of practical algorithms. We answer this hitherto open question in the affirmative, by providing the first computationally feasible approximation to the AIXI agent. To develop our approximation, we introduce a Monte Carlo Tree Search algorithm along with an agent-specific extension of the Context Tree Weighting algorithm. Empirically, we present a set of encouraging results on a number of stochastic, unknown, and partially observable domains.</abstract>
   </article>
   <article>
      <title>Adapting to the Shifting Intent of Search Queries</title>
      <author>Umar Syed, Aleksandrs Slivkins, Nina Mishra</author>
      <date>2010-07-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Search engines today present results that are often oblivious to abrupt shifts in intent. For example, the query `independence day' usually refers to a US holiday, but the intent of this query abruptly changed during the release of a major film by that name. While no studies exactly quantify the magnitude of intent-shifting traffic, studies suggest that news events, seasonal topics, pop culture, etc account for 50% of all search queries. This paper shows that the signals a search engine receives can be used to both determine that a shift in intent has happened, as well as find a result that is now more relevant. We present a meta-algorithm that marries a classifier with a bandit algorithm to achieve regret that depends logarithmically on the number of query impressions, under certain assumptions. We provide strong evidence that this regret is close to the best achievable. Finally, via a series of experiments, we demonstrate that our algorithm outperforms prior approaches, particularly as the amount of intent-shifting traffic increases.</abstract>
   </article>
   <article>
      <title>Comparison of Support Vector Machine and Back Propagation Neural Network
  in Evaluating the Enterprise Financial Distress</title>
      <author>Ming-Chang Lee, Chang To</author>
      <date>2010-07-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently, applying the novel data mining techniques for evaluating enterprise financial distress has received much research alternation. Support Vector Machine (SVM) and back propagation neural (BPN) network has been applied successfully in many areas with excellent generalization results, such as rule extraction, classification and evaluation. In this paper, a model based on SVM with Gaussian RBF kernel is proposed here for enterprise financial distress evaluation. BPN network is considered one of the simplest and are most general methods used for supervised training of multilayered <term>neural network</term>. The comparative results show that through the difference between the performance measures is marginal; SVM gives higher precision and lower error rates.</abstract>
   </article>
   <article>
      <title>Close Clustering Based Automated Color Image Annotation</title>
      <author>Ankit Garg, Rahul Dwivedi, Krishna Asawa</author>
      <date>2010-08-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Most image-search approaches today are based on the text based tags associated with the images which are mostly human generated and are subject to various kinds of errors. The results of a query to the image database thus can often be misleading and may not satisfy the requirements of the user. In this work we propose our approach to automate this tagging process of images, where image results generated can be fine filtered based on a probabilistic tagging mechanism. We implement a tool which helps to automate the tagging process by maintaining a training database, wherein the system is trained to identify certain set of input images, the results generated from which are used to create a probabilistic tagging mechanism. Given a certain set of segments in an image it calculates the probability of presence of particular keywords. This probability table is further used to generate the candidate tags for input images.</abstract>
   </article>
   <article>
      <title>Bounded Coordinate-Descent for Biological Sequence Classification in
  High Dimensional Predictor Space</title>
      <author>Georgiana Ifrim, Carsten Wiuf</author>
      <date>2010-08-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a framework for discriminative sequence classification where the learner works directly in the high dimensional predictor space of all subsequences in the training set. This is possible by employing a new coordinate-descent algorithm coupled with bounding the magnitude of the gradient for selecting discriminative subsequences fast. We characterize the loss functions for which our generic learning algorithm can be applied and present concrete implementations for logistic regression (binomial log-likelihood loss) and <term>support vector machine</term>s (squared hinge loss). Application of our algorithm to protein remote homology detection and remote fold recognition results in performance comparable to that of state-of-the-art methods (e.g., kernel <term>support vector machine</term>s). Unlike state-of-the-art classifiers, the resulting classification models are simply lists of weighted discriminative subsequences and can thus be interpreted and related to the biological problem.</abstract>
   </article>
   <article>
      <title>Semi-Supervised Kernel PCA</title>
      <author>Christian Walder, Ricardo Henao, Morten Mørup, Lars Kai Hansen</author>
      <date>2010-08-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present three generalisations of Kernel Principal Components Analysis (KPCA) which incorporate knowledge of the class labels of a subset of the data points. The first, MV-KPCA, penalises within class variances similar to Fisher discriminant analysis. The second, LSKPCA is a hybrid of least squares regression and kernel PCA. The final LR-KPCA is an iteratively reweighted version of the previous which achieves a sigmoid loss function on the labeled points. We provide a theoretical risk bound as well as illustrative experiments on real and toy data sets.</abstract>
   </article>
   <article>
      <title>Online Learning in Case of Unbounded Losses Using the Follow Perturbed
  Leader Algorithm</title>
      <author>Vladimir V. V'yugin</author>
      <date>2010-08-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper the sequential prediction problem with expert advice is considered for the case where losses of experts suffered at each step cannot be bounded in advance. We present some modification of Kalai and Vempala algorithm of following the perturbed leader where weights depend on past losses of the experts. New notions of a volume and a scaled fluctuation of a game are introduced. We present a probabilistic algorithm protected from unrestrictedly large one-step losses. This algorithm has the optimal performance in the case when the scaled fluctuations of one-step losses of experts of the pool tend to zero.</abstract>
   </article>
   <article>
      <title>Switching between Hidden Markov Models using Fixed Share</title>
      <author>Wouter M. Koolen, Tim van Erven</author>
      <date>2010-08-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In prediction with expert advice the goal is to design online prediction algorithms that achieve small regret (additional loss on the whole data) compared to a reference scheme. In the simplest such scheme one compares to the loss of the best expert in hindsight. A more ambitious goal is to split the data into segments and compare to the best expert on each segment. This is appropriate if the nature of the data changes between segments. The standard fixed-share algorithm is fast and achieves small regret compared to this scheme.   Fixed share treats the experts as black boxes: there are no assumptions about how they generate their predictions. But if the experts are learning, the following question arises: should the experts learn from all data or only from data in their own segment? The original algorithm naturally addresses the first case. Here we consider the second option, which is more appropriate exactly when the nature of the data changes between segments. In general extending fixed share to this second case will slow it down by a factor of T on T outcomes. We show, however, that no such slowdown is necessary if the experts are hidden Markov models.</abstract>
   </article>
   <article>
      <title>Freezing and Sleeping: Tracking Experts that Learn by Evolving Past
  Posteriors</title>
      <author>Wouter M. Koolen, Tim van Erven</author>
      <date>2010-08-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A problem posed by Freund is how to efficiently track a small pool of experts out of a much larger set. This problem was solved when Bousquet and Warmuth introduced their mixing past posteriors (MPP) algorithm in 2001.   In Freund's problem the experts would normally be considered black boxes. However, in this paper we re-examine Freund's problem in case the experts have internal structure that enables them to learn. In this case the problem has two possible interpretations: should the experts learn from all data or only from the subsequence on which they are being tracked? The MPP algorithm solves the first case. Our contribution is to generalise MPP to address the second option. The results we obtain apply to any expert structure that can be formalised using (expert) hidden Markov models. Curiously enough, for our interpretation there are \emph{two} natural reference schemes: freezing and sleeping. For each scheme, we provide an efficient prediction strategy and prove the relevant loss bound.</abstract>
   </article>
   <article>
      <title>Exploring Language-Independent Emotional Acoustic Features via Feature
  Selection</title>
      <author>Arslan Shaukat, Ke Chen</author>
      <date>2010-09-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a novel feature selection strategy to discover language-independent acoustic features that tend to be responsible for emotions regardless of languages, linguistics and other factors. Experimental results suggest that the language-independent feature subset discovered yields the performance comparable to the full feature set on various emotional speech corpora.</abstract>
   </article>
   <article>
      <title>Fast Overlapping Group Lasso</title>
      <author>Jun Liu, Jieping Ye</author>
      <date>2010-09-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The group Lasso is an extension of the Lasso for feature selection on (predefined) non-overlapping groups of features. The non-overlapping group structure limits its applicability in practice. There have been several recent attempts to study a more general formulation, where groups of features are given, potentially with overlaps between the groups. The resulting optimization is, however, much more challenging to solve due to the group overlaps. In this paper, we consider the efficient optimization of the overlapping group Lasso penalized problem. We reveal several key properties of the proximal operator associated with the overlapping group Lasso, and compute the proximal operator by solving the smooth and convex dual problem, which allows the use of the <term>gradient descent</term> type of algorithms for the optimization. We have performed empirical evaluations using the breast cancer gene expression data set, which consists of 8,141 genes organized into (overlapping) gene sets. Experimental results demonstrate the efficiency and effectiveness of the proposed algorithm.</abstract>
   </article>
   <article>
      <title>Reinforcement Learning by Comparing Immediate Reward</title>
      <author>Punit Pandey, Deepshikha Pandey, Shishir Kumar</author>
      <date>2010-09-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper introduces an approach to Reinforcement Learning Algorithm by comparing their immediate rewards using a variation of Q-Learning algorithm. Unlike the conventional Q-Learning, the proposed algorithm compares current reward with immediate reward of past move and work accordingly. Relative reward based Q-learning is an approach towards interactive learning. Q-Learning is a model free <term>reinforcement learning</term> method that used to learn the agents. It is observed that under normal circumstances algorithm take more episodes to reach optimal Q-value due to its normal reward or sometime negative reward. In this new form of algorithm agents select only those actions which have a higher immediate reward signal in comparison to previous one. The contribution of this article is the presentation of new Q-Learning Algorithm in order to maximize the performance of algorithm and reduce the number of episode required to reach optimal Q-value. Effectiveness of proposed algorithm is simulated in a 20 x20 Grid world deterministic environment and the result for the two forms of Q-Learning Algorithms is given.</abstract>
   </article>
   <article>
      <title>A Unified View of Regularized Dual Averaging and Mirror Descent with
  Implicit Updates</title>
      <author>H. Brendan McMahan</author>
      <date>2010-09-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study three families of online convex optimization algorithms: follow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual averaging (RDA), and composite-objective mirror descent. We first prove equivalence theorems that show all of these algorithms are instantiations of a general FTRL update. This provides theoretical insight on previous experimental observations. In particular, even though the FOBOS composite mirror descent algorithm handles L1 regularization explicitly, it has been observed that RDA is even more effective at producing sparsity. Our results demonstrate that FOBOS uses subgradient approximations to the L1 penalty from previous rounds, leading to less sparsity than RDA, which handles the cumulative penalty in closed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two, and outperforms both on a large, real-world dataset.   Our second contribution is a unified analysis which produces regret bounds that match (up to logarithmic terms) or improve the best previously known bounds. This analysis also extends these algorithms in two important ways: we support a more general type of composite objective and we analyze implicit updates, which replace the subgradient approximation of the current loss function with an exact optimization.</abstract>
   </article>
   <article>
      <title>Conditional Random Fields and Support Vector Machines: A Hybrid Approach</title>
      <author>Qinfeng Shi, Mark D. Reid, Tiberio Caetano</author>
      <date>2010-09-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a novel hybrid loss for multiclass and structured prediction problems that is a convex combination of log loss for Conditional Random Fields (CRFs) and a multiclass hinge loss for Support Vector Machines (SVMs). We provide a sufficient condition for when the hybrid loss is Fisher consistent for classification. This condition depends on a measure of dominance between labels - specifically, the gap in per observation probabilities between the most likely labels. We also prove Fisher consistency is necessary for parametric consistency when learning models such as CRFs.   We demonstrate empirically that the hybrid loss typically performs as least as well as - and often better than - both of its constituent losses on variety of tasks. In doing so we also provide an empirical comparison of the efficacy of probabilistic and margin based approaches to multiclass and structured prediction and the effects of label dominance on these results.</abstract>
   </article>
   <article>
      <title>Geometric Decision Tree</title>
      <author>Naresh Manwani, P. S. Sastry</author>
      <date>2010-09-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we present a new algorithm for learning oblique decision trees. Most of the current decision tree algorithms rely on impurity measures to assess the goodness of hyperplanes at each node while learning a decision tree in a top-down fashion. These impurity measures do not properly capture the geometric structures in the data. Motivated by this, our algorithm uses a strategy to assess the hyperplanes in such a way that the geometric structure in the data is taken into account. At each node of the decision tree, we find the clustering hyperplanes for both the classes and use their angle bisectors as the split rule at that node. We show through empirical studies that this idea leads to small decision trees and better performance. We also present some analysis to show that the angle bisectors of clustering hyperplanes that we use as the split rules at each node, are solutions of an interesting optimization problem and hence argue that this is a principled method of learning a decision tree.</abstract>
   </article>
   <article>
      <title>On the Doubt about Margin Explanation of Boosting</title>
      <author>Wei Gao, Zhi-Hua Zhou</author>
      <date>2010-09-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Margin theory provides one of the most popular explanations to the success of \texttt{AdaBoost}, where the central point lies in the recognition that \textit{margin} is the key for characterizing the performance of \texttt{AdaBoost}. This theory has been very influential, e.g., it has been used to argue that \texttt{AdaBoost} usually does not overfit since it tends to enlarge the margin even after the training error reaches zero. Previously the \textit{minimum margin bound} was established for \texttt{AdaBoost}, however, \cite{Breiman1999} pointed out that maximizing the minimum margin does not necessarily lead to a better generalization. Later, \cite{Reyzin:Schapire2006} emphasized that the margin distribution rather than minimum margin is crucial to the performance of \texttt{AdaBoost}. In this paper, we first present the \textit{$k$th margin bound} and further study on its relationship to previous work such as the minimum margin bound and Emargin bound. Then, we improve the previous empirical Bernstein bounds \citep{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009}, and based on such findings, we defend the margin-based explanation against Breiman's doubts by proving a new generalization error bound that considers exactly the same factors as \cite{Schapire:Freund:Bartlett:Lee1998} but is sharper than \cite{Breiman1999}'s minimum margin bound. By incorporating factors such as average margin and variance, we present a generalization error bound that is heavily related to the whole margin distribution. We also provide margin distribution bounds for generalization error of voting classifiers in finite VC-dimension space.</abstract>
   </article>
   <article>
      <title>Totally Corrective Multiclass Boosting with Binary Weak Learners</title>
      <author>Zhihui Hao, Chunhua Shen, Nick Barnes, Bo Wang</author>
      <date>2010-09-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this work, we propose a new optimization framework for multiclass boosting learning. In the literature, AdaBoost.MO and AdaBoost.ECC are the two successful multiclass boosting algorithms, which can use binary weak learners. We explicitly derive these two algorithms' Lagrange dual problems based on their regularized loss functions. We show that the Lagrange dual formulations enable us to design totally-corrective multiclass algorithms by using the primal-dual optimization technique. Experiments on benchmark data sets suggest that our multiclass boosting can achieve a comparable generalization capability with state-of-the-art, but the convergence speed is much faster than stage-wise <term>gradient descent</term> boosting. In other words, the new totally corrective algorithms can maximize the margin more aggressively.</abstract>
   </article>
   <article>
      <title>Optimistic Rates for Learning with a Smooth Loss</title>
      <author>Nathan Srebro, Karthik Sridharan, Ambuj Tewari</author>
      <date>2010-09-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We establish an excess risk bound of O(H R_n^2 + R_n \sqrt{H L*}) for empirical risk minimization with an H-smooth loss function and a hypothesis class with Rademacher complexity R_n, where L* is the best risk achievable by the hypothesis class. For typical hypothesis classes where R_n = \sqrt{R/n}, this translates to a learning rate of O(RH/n) in the separable (L*=0) case and O(RH/n + \sqrt{L^* RH/n}) more generally. We also provide similar guarantees for online and stochastic convex optimization with a smooth non-negative objective.</abstract>
   </article>
   <article>
      <title>Efficient L1/Lq Norm Regularization</title>
      <author>Jun Liu, Jieping Ye</author>
      <date>2010-09-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Sparse learning has recently received increasing attention in many areas including machine learning, statistics, and applied mathematics. The mixed-norm regularization based on the L1/Lq norm with q &gt; 1 is attractive in many applications of regression and classification in that it facilitates group sparsity in the model. The resulting optimization problem is, however, challenging to solve due to the structure of the L1/Lq -regularization. Existing work deals with special cases including q = 2,infinity, and they cannot be easily extended to the general case. In this paper, we propose an efficient algorithm based on the accelerated gradient method for solving the L1/Lq -regularized problem, which is applicable for all values of q larger than 1, thus significantly extending existing work. One key building block of the proposed algorithm is the L1/Lq -regularized Euclidean projection (EP1q). Our theoretical analysis reveals the key properties of EP1q and illustrates why EP1q for the general q is significantly more challenging to solve than the special cases. Based on our theoretical analysis, we develop an efficient algorithm for EP1q by solving two zero finding problems. Experimental results demonstrate the efficiency of the proposed algorithm.</abstract>
   </article>
   <article>
      <title>Multi-parametric Solution-path Algorithm for Instance-weighted Support
  Vector Machines</title>
      <author>Masayuki Karasuyama, Naoyuki Harada, Masashi Sugiyama, Ichiro Takeuchi</author>
      <date>2010-09-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>An instance-weighted variant of the <term>support vector machine</term> (SVM) has attracted considerable attention recently since they are useful in various machine learning tasks such as non-stationary data analysis, heteroscedastic data modeling, transfer learning, learning to rank, and transduction. An important challenge in these scenarios is to overcome the computational bottleneck---instance weights often change dynamically or adaptively, and thus the weighted SVM solutions must be repeatedly computed. In this paper, we develop an algorithm that can efficiently and exactly update the weighted SVM solutions for arbitrary change of instance weights. Technically, this contribution can be regarded as an extension of the conventional solution-path algorithm for a single regularization parameter to multiple instance-weight parameters. However, this extension gives rise to a significant problem that breakpoints (at which the solution path turns) have to be identified in high-dimensional space. To facilitate this, we introduce a parametric representation of instance weights. We also provide a geometric interpretation in weight space using a notion of critical region: a polyhedron in which the current affine solution remains to be optimal. Then we find breakpoints at intersections of the solution path and boundaries of polyhedrons. Through extensive experiments on various practical applications, we demonstrate the usefulness of the proposed algorithm.</abstract>
   </article>
   <article>
      <title>Portfolio Allocation for Bayesian Optimization</title>
      <author>Eric Brochu, Matthew W. Hoffman, Nando de Freitas</author>
      <date>2010-09-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Bayesian optimization with Gaussian processes has become an increasingly popular tool in the machine learning community. It is efficient and can be used when very little is known about the objective function, making it popular in expensive black-box optimization scenarios. It uses Bayesian methods to sample the objective efficiently using an acquisition function which incorporates the model's estimate of the objective and the uncertainty at any given point. However, there are several different parameterized acquisition functions in the literature, and it is often unclear which one to use. Instead of using a single acquisition function, we adopt a portfolio of acquisition functions governed by an online multi-armed bandit strategy. We propose several portfolio strategies, the best of which we call GP-Hedge, and show that this method outperforms the best individual acquisition function. We also provide a theoretical bound on the algorithm's performance.</abstract>
   </article>
   <article>
      <title>Fast Reinforcement Learning for Energy-Efficient Wireless Communications</title>
      <author>Nicholas Mastronarde, Mihaela van der Schaar</author>
      <date>2010-09-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of energy-efficient point-to-point transmission of delay-sensitive data (e.g. multimedia data) over a fading channel. Existing research on this topic utilizes either physical-layer centric solutions, namely power-control and adaptive modulation and coding (AMC), or system-level solutions based on dynamic power management (DPM); however, there is currently no rigorous and unified framework for simultaneously utilizing both physical-layer centric and system-level techniques to achieve the minimum possible energy consumption, under delay constraints, in the presence of stochastic and a priori unknown traffic and channel conditions. In this report, we propose such a framework. We formulate the stochastic optimization problem as a Markov decision process (MDP) and solve it online using <term>reinforcement learning</term>. The advantages of the proposed online method are that (i) it does not require a priori knowledge of the traffic arrival and channel statistics to determine the jointly optimal power-control, AMC, and DPM policies; (ii) it exploits partial information about the system so that less information needs to be learned than when using conventional <term>reinforcement learning</term> algorithms; and (iii) it obviates the need for action exploration, which severely limits the adaptation speed and run-time performance of conventional <term>reinforcement learning</term> algorithms. Our results show that the proposed learning algorithms can converge up to two orders of magnitude faster than a state-of-the-art learning algorithm for physical layer power-control and up to three orders of magnitude faster than conventional <term>reinforcement learning</term> algorithms.</abstract>
   </article>
   <article>
      <title>The Attentive Perceptron</title>
      <author>Raphael Pelossof, Zhiliang Ying</author>
      <date>2010-09-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a focus of attention mechanism to speed up the Perceptron algorithm. Focus of attention speeds up the Perceptron algorithm by lowering the number of features evaluated throughout training and prediction. Whereas the traditional Perceptron evaluates all the features of each example, the Attentive Perceptron evaluates less features for easy to classify examples, thereby achieving significant speedups and small losses in prediction accuracy. Focus of attention allows the Attentive Perceptron to stop the evaluation of features at any interim point and filter the example. This creates an attentive filter which concentrates computation at examples that are hard to classify, and quickly filters examples that are easy to classify.</abstract>
   </article>
   <article>
      <title>Queue-Aware Distributive Resource Control for Delay-Sensitive Two-Hop
  MIMO Cooperative Systems</title>
      <author>Rui Wang, Vincent K. N. Lau, Ying Cui</author>
      <date>2010-10-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we consider a queue-aware distributive resource control algorithm for two-hop MIMO cooperative systems. We shall illustrate that relay buffering is an effective way to reduce the intrinsic half-duplex penalty in cooperative systems. The complex interactions of the queues at the source node and the relays are modeled as an average-cost infinite horizon Markov Decision Process (MDP). The traditional approach solving this MDP problem involves centralized control with huge complexity. To obtain a distributive and low complexity solution, we introduce a linear structure which approximates the value function of the associated Bellman equation by the sum of per-node value functions. We derive a distributive two-stage two-winner auction-based control policy which is a function of the local CSI and local QSI only. Furthermore, to estimate the best fit approximation parameter, we propose a distributive online stochastic learning algorithm using stochastic approximation theory. Finally, we establish technical conditions for almost-sure convergence and show that under heavy traffic, the proposed low complexity distributive control is global optimal.</abstract>
   </article>
   <article>
      <title>Time Series Classification by Class-Specific Mahalanobis Distance
  Measures</title>
      <author>Zoltán Prekopcsák, Daniel Lemire</author>
      <date>2010-10-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>To classify time series by nearest neighbors, we need to specify or learn one or several distance measures. We consider variations of the Mahalanobis distance measures which rely on the inverse covariance matrix of the data. Unfortunately --- for time series data --- the covariance matrix has often low rank. To alleviate this problem we can either use a pseudoinverse, covariance shrinking or limit the matrix to its diagonal. We review these alternatives and benchmark them against competitive methods such as the related Large Margin Nearest Neighbor Classification (LMNN) and the Dynamic Time Warping (DTW) distance. As we expected, we find that the DTW is superior, but the Mahalanobis distance measures are one to two orders of magnitude faster. To get best results with Mahalanobis distance measures, we recommend learning one distance measure per class using either covariance shrinking or the diagonal approach.</abstract>
   </article>
   <article>
      <title>Algorithms for nonnegative matrix factorization with the beta-divergence</title>
      <author>Cédric Févotte, Jérôme Idier</author>
      <date>2010-10-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper describes algorithms for nonnegative matrix factorization (NMF) with the beta-divergence (beta-NMF). The beta-divergence is a family of cost functions parametrized by a single shape parameter beta that takes the Euclidean distance, the Kullback-Leibler divergence and the Itakura-Saito divergence as special cases (beta = 2,1,0, respectively). The proposed algorithms are based on a surrogate auxiliary function (a local majorization of the criterion function). We first describe a majorization-minimization (MM) algorithm that leads to multiplicative updates, which differ from standard heuristic multiplicative updates by a beta-dependent power exponent. The monotonicity of the heuristic algorithm can however be proven for beta in (0,1) using the proposed auxiliary function. Then we introduce the concept of majorization-equalization (ME) algorithm which produces updates that move along constant level sets of the auxiliary function and lead to larger steps than MM. Simulations on synthetic and real data illustrate the faster convergence of the ME approach. The paper also describes how the proposed algorithms can be adapted to two common variants of NMF : penalized NMF (i.e., when a penalty function of the factors is added to the criterion function) and convex-NMF (when the dictionary is assumed to belong to a known subspace).</abstract>
   </article>
   <article>
      <title>Hardness Results for Agnostically Learning Low-Degree Polynomial
  Threshold Functions</title>
      <author>Ilias Diakonikolas, Ryan O'Donnell, Rocco A. Servedio, Yi Wu</author>
      <date>2010-10-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Hardness results for maximum agreement problems have close connections to hardness results for proper learning in computational learning theory. In this paper we prove two hardness results for the problem of finding a low degree polynomial threshold function (PTF) which has the maximum possible agreement with a given set of labeled examples in $\R^n \times \{-1,1\}.$ We prove that for any constants $d\geq 1, \eps &gt; 0$,   {itemize}   Assuming the Unique Games Conjecture, no polynomial-time algorithm can find a degree-$d$ PTF that is consistent with a $(\half + \eps)$ fraction of a given set of labeled examples in $\R^n \times \{-1,1\}$, even if there exists a degree-$d$ PTF that is consistent with a $1-\eps$ fraction of the examples.   It is $\NP$-hard to find a degree-2 PTF that is consistent with a $(\half + \eps)$ fraction of a given set of labeled examples in $\R^n \times \{-1,1\}$, even if there exists a halfspace (degree-1 PTF) that is consistent with a $1 - \eps$ fraction of the examples.   {itemize}   These results immediately imply the following hardness of learning results: (i) Assuming the Unique Games Conjecture, there is no better-than-trivial proper learning algorithm that agnostically learns degree-$d$ PTFs under arbitrary distributions; (ii) There is no better-than-trivial learning algorithm that outputs degree-2 PTFs and agnostically learns halfspaces (i.e. degree-1 PTFs) under arbitrary distributions.</abstract>
   </article>
   <article>
      <title>Efficient Matrix Completion with Gaussian Models</title>
      <author>Flavien Léger, Guoshen Yu, Guillermo Sapiro</author>
      <date>2010-10-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A general framework based on Gaussian models and a MAP-EM algorithm is introduced in this paper for solving matrix/table completion problems. The numerical experiments with the standard and challenging movie ratings data show that the proposed approach, based on probably one of the simplest probabilistic models, leads to the results in the same ballpark as the state-of-the-art, at a lower computational cost.</abstract>
   </article>
   <article>
      <title>Large-Scale Clustering Based on Data Compression</title>
      <author>Xudong Ma</author>
      <date>2010-10-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper considers the clustering problem for large data sets. We propose an approach based on distributed optimization. The clustering problem is formulated as an optimization problem of maximizing the classification gain. We show that the optimization problem can be reformulated and decomposed into small-scale sub optimization problems by using the Dantzig-Wolfe decomposition method. Generally speaking, the Dantzig-Wolfe method can only be used for convex optimization problems, where the duality gaps are zero. Even though, the considered optimization problem in this paper is non-convex, we prove that the duality gap goes to zero, as the problem size goes to infinity. Therefore, the Dantzig-Wolfe method can be applied here. In the proposed approach, the clustering problem is iteratively solved by a group of computers coordinated by one center processor, where each computer solves one independent small-scale sub optimization problem during each iteration, and only a small amount of data communication is needed between the computers and center processor. Numerical results show that the proposed approach is effective and efficient.</abstract>
   </article>
   <article>
      <title>Sublinear Optimization for Machine Learning</title>
      <author>Kenneth L. Clarkson, Elad Hazan, David P. Woodruff</author>
      <date>2010-10-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We give sublinear-time approximation algorithms for some optimization problems arising in machine learning, such as training linear classifiers and finding minimum enclosing balls. Our algorithms can be extended to some kernelized versions of these problems, such as SVDD, hard margin SVM, and L2-SVM, for which sublinear-time algorithms were not known before. These new algorithms use a combination of a novel sampling techniques and a new multiplicative update algorithm. We give lower bounds which show the running times of many of our algorithms to be nearly best possible in the unit-cost RAM model. We also give implementations of our algorithms in the semi-streaming setting, obtaining the first low pass polylogarithmic space and sublinear time algorithms achieving arbitrary approximation factor.</abstract>
   </article>
   <article>
      <title>Regularized Risk Minimization by Nesterov's Accelerated Gradient
  Methods: Algorithmic Extensions and Empirical Studies</title>
      <author>Xinhua Zhang, Ankan Saha, S. V. N. Vishwanathan</author>
      <date>2010-11-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Nesterov's accelerated gradient methods (AGM) have been successfully applied in many machine learning areas. However, their empirical performance on training max-margin models has been inferior to existing specialized solvers. In this paper, we first extend AGM to strongly convex and composite objective functions with Bregman style prox-functions. Our unifying framework covers both the $\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constant adaptively, and bounds the duality gap. Then we demonstrate various ways to apply this framework of methods to a wide range of machine learning problems. Emphasis will be given on their rate of convergence and how to efficiently compute the gradient and optimize the models. The experimental results show that with our extensions AGM outperforms state-of-the-art solvers on max-margin models.</abstract>
   </article>
   <article>
      <title>Online Importance Weight Aware Updates</title>
      <author>Nikos Karampatziakis, John Langford</author>
      <date>2010-11-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>An importance weight quantifies the relative importance of one example over another, coming up in applications of boosting, asymmetric classification costs, reductions, and active learning. The standard approach for dealing with importance weights in <term>gradient descent</term> is via multiplication of the gradient. We first demonstrate the problems of this approach when importance weights are large, and argue in favor of more sophisticated ways for dealing with them. We then develop an approach which enjoys an invariance property: that updating twice with importance weight $h$ is equivalent to updating once with importance weight $2h$. For many important losses this has a closed form update which satisfies standard regret guarantees when all examples have $h=1$. We also briefly discuss two other reasonable approaches for handling large importance weights. Empirically, these approaches yield substantially superior prediction with similar computational performance while reducing the sensitivity of the algorithm to the exact setting of the learning rate. We apply these to online active learning yielding an extraordinarily fast active learning algorithm that works even in the presence of adversarial noise.</abstract>
   </article>
   <article>
      <title>On Theorem 2.3 in "Prediction, Learning, and Games" by Cesa-Bianchi and
  Lugosi</title>
      <author>Alexey Chernov</author>
      <date>2010-11-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The note presents a modified proof of a loss bound for the exponentially weighted average forecaster with time-varying potential. The regret term of the algorithm is upper-bounded by sqrt{n ln(N)} (uniformly in n), where N is the number of experts and n is the number of steps.</abstract>
   </article>
   <article>
      <title>Estimating Probabilities in Recommendation Systems</title>
      <author>Mingxuan Sun, Guy Lebanon, Paul Kidwell</author>
      <date>2010-12-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recommendation systems are emerging as an important business application with significant economic impact. Currently popular systems include Amazon's book recommendations, Netflix's movie recommendations, and Pandora's music recommendations. In this paper we address the problem of estimating probabilities associated with recommendation system data using non-parametric kernel smoothing. In our estimation we interpret missing items as randomly censored observations and obtain efficient computation schemes using combinatorial properties of generating functions. We demonstrate our approach with several case studies involving real world movie recommendation data. The results are comparable with state-of-the-art techniques while also providing probabilistic preference estimates outside the scope of traditional recommender systems.</abstract>
   </article>
   <article>
      <title>A Tutorial on Bayesian Optimization of Expensive Cost Functions, with
  Application to Active User Modeling and Hierarchical Reinforcement Learning</title>
      <author>Eric Brochu, Vlad M. Cora, Nando de Freitas</author>
      <date>2010-12-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical <term>reinforcement learning</term>---and a discussion of the pros and cons of Bayesian optimization based on our experiences.</abstract>
   </article>
   <article>
      <title>Queue-Aware Dynamic Clustering and Power Allocation for Network MIMO
  Systems via Distributive Stochastic Learning</title>
      <author>Ying Cui, Qingqing Huang, Vincent K. N. Lau</author>
      <date>2010-12-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose a two-timescale delay-optimal dynamic clustering and power allocation design for downlink network MIMO systems. The dynamic clustering control is adaptive to the global queue state information (GQSI) only and computed at the base station controller (BSC) over a longer time scale. On the other hand, the power allocations of all the BSs in one cluster are adaptive to both intra-cluster channel state information (CCSI) and intra-cluster queue state information (CQSI), and computed at the cluster manager (CM) over a shorter time scale. We show that the two-timescale delay-optimal control can be formulated as an infinite-horizon average cost Constrained Partially Observed Markov Decision Process (CPOMDP). By exploiting the special problem structure, we shall derive an equivalent Bellman equation in terms of Pattern Selection Q-factor to solve the CPOMDP. To address the distributive requirement and the issue of exponential memory requirement and computational complexity, we approximate the Pattern Selection Q-factor by the sum of Per-cluster Potential functions and propose a novel distributive online learning algorithm to estimate the Per-cluster Potential functions (at each CM) as well as the Lagrange multipliers (LM) (at each BS). We show that the proposed distributive online learning algorithm converges almost surely (with probability 1). By exploiting the birth-death structure of the queue dynamics, we further decompose the Per-cluster Potential function into sum of Per-cluster Per-user Potential functions and formulate the instantaneous power allocation as a Per-stage QSI-aware Interference Game played among all the CMs. We also propose a QSI-aware Simultaneous Iterative Water-filling Algorithm (QSIWFA) and show that it can achieve the Nash Equilibrium (NE).</abstract>
   </article>
   <article>
      <title>Survey &amp; Experiment: Towards the Learning Accuracy</title>
      <author>Zeyuan Allen Zhu</author>
      <date>2010-12-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>To attain the best learning accuracy, people move on with difficulties and frustrations. Though one can optimize the empirical objective using a given set of samples, its generalization ability to the entire sample distribution remains questionable. Even if a fair generalization guarantee is offered, one still wants to know what is to happen if the regularizer is removed, and/or how well the artificial loss (like the hinge loss) relates to the accuracy.   For such reason, this report surveys four different trials towards the learning accuracy, embracing the major advances in supervised learning theory in the past four years. Starting from the generic setting of learning, the first two trials introduce the best optimization and generalization bounds for convex learning, and the third trial gets rid of the regularizer. As an innovative attempt, the fourth trial studies the optimization when the objective is exactly the accuracy, in the special case of binary classification. This report also analyzes the last trial through experiments.</abstract>
   </article>
   <article>
      <title>Travel Time Estimation Using Floating Car Data</title>
      <author>Raffi Sevlian, Ram Rajagopal</author>
      <date>2010-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This report explores the use of machine learning techniques to accurately predict travel times in city streets and highways using floating car data (location information of user vehicles on a road network). The aim of this report is twofold, first we present a general architecture of solving this problem, then present and evaluate few techniques on real floating car data gathered over a month on a 5 Km highway in New Delhi.</abstract>
   </article>
   <article>
      <title>How I won the "Chess Ratings - Elo vs the Rest of the World" Competition</title>
      <author>Yannis Sismanis</author>
      <date>2010-12-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This article discusses in detail the rating system that won the kaggle competition "Chess Ratings: Elo vs the rest of the world". The competition provided a historical dataset of outcomes for chess games, and aimed to discover whether novel approaches can predict the outcomes of future games, more accurately than the well-known Elo rating system. The winning rating system, called Elo++ in the rest of the article, builds upon the Elo rating system. Like Elo, Elo++ uses a single rating per player and predicts the outcome of a game, by using a logistic curve over the difference in ratings of the players. The major component of Elo++ is a regularization technique that avoids overfitting these ratings. The dataset of chess games and outcomes is relatively small and one has to be careful not to draw "too many conclusions" out of the limited data. Many approaches tested in the competition showed signs of such an overfitting. The leader-board was dominated by attempts that did a very good job on a small test dataset, but couldn't generalize well on the private hold-out dataset. The Elo++ regularization takes into account the number of games per player, the recency of these games and the ratings of the opponents. Finally, Elo++ employs a stochastic <term>gradient descent</term> scheme for training the ratings, and uses only two global parameters (white's advantage and regularization constant) that are optimized using cross-validation.</abstract>
   </article>
   <article>
      <title>EigenNet: A Bayesian hybrid of generative and conditional models for
  sparse learning</title>
      <author>Yuan Qi, Feng Yan</author>
      <date>2011-02-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It is a challenging task to select correlated variables in a high dimensional space. To address this challenge, the elastic net has been developed and successfully applied to many applications. Despite its great success, the elastic net does not explicitly use correlation information embedded in data to select correlated variables. To overcome this limitation, we present a novel Bayesian hybrid model, the EigenNet, that uses the eigenstructures of data to guide variable selection. Specifically, it integrates a sparse conditional classification model with a generative model capturing variable correlations in a principled Bayesian framework. We reparameterize the hybrid model in the eigenspace to avoid overfiting and to increase the computational efficiency of its MCMC sampler. Furthermore, we provide an alternative view to the EigenNet from a regularization perspective: the EigenNet has an adaptive eigenspace-based composite regularizer, which naturally generalizes the $l_{1/2}$ regularizer used by the elastic net. Experiments on synthetic and real data show that the EigenNet significantly outperforms the lasso, the elastic net, and the Bayesian lasso in terms of prediction accuracy, especially when the number of training samples is smaller than the number of variables.</abstract>
   </article>
   <article>
      <title>Transductive Ordinal Regression</title>
      <author>Chun-Wei Seah, Ivor W. Tsang, Yew-Soon Ong</author>
      <date>2011-02-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Ordinal regression is commonly formulated as a multi-class problem with ordinal constraints. The challenge of designing accurate classifiers for ordinal regression generally increases with the number of classes involved, due to the large number of labeled patterns that are needed. The availability of ordinal class labels, however, is often costly to calibrate or difficult to obtain. Unlabeled patterns, on the other hand, often exist in much greater abundance and are freely available. To take benefits from the abundance of unlabeled patterns, we present a novel transductive learning paradigm for ordinal regression in this paper, namely Transductive Ordinal Regression (TOR). The key challenge of the present study lies in the precise estimation of both the ordinal class label of the unlabeled data and the decision functions of the ordinal classes, simultaneously. The core elements of the proposed TOR include an objective function that caters to several commonly used loss functions casted in transductive settings, for general ordinal regression. A label swapping scheme that facilitates a strictly monotonic decrease in the objective function value is also introduced. Extensive numerical studies on commonly used benchmark datasets including the real world sentiment prediction problem are then presented to showcase the characteristics and efficacies of the proposed transductive ordinal regression. Further, comparisons to recent state-of-the-art ordinal regression methods demonstrate the introduced transductive learning paradigm for ordinal regression led to the robust and improved performance.</abstract>
   </article>
   <article>
      <title>Learning transformed product distributions</title>
      <author>Constantinos Daskalakis, Ilias Diakonikolas, Rocco A. Servedio</author>
      <date>2011-03-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of learning an unknown product distribution $X$ over $\{0,1\}^n$ using samples $f(X)$ where $f$ is a \emph{known} transformation function. Each choice of a transformation function $f$ specifies a learning problem in this framework.   Information-theoretic arguments show that for every transformation function $f$ the corresponding learning problem can be solved to accuracy $\eps$, using $\tilde{O}(n/\eps^2)$ examples, by a generic algorithm whose running time may be exponential in $n.$ We show that this learning problem can be computationally intractable even for constant $\eps$ and rather simple transformation functions. Moreover, the above sample complexity bound is nearly optimal for the general problem, as we give a simple explicit linear transformation function $f(x)=w \cdot x$ with integer weights $w_i \leq n$ and prove that the corresponding learning problem requires $\Omega(n)$ samples.   As our main positive result we give a highly efficient algorithm for learning a sum of independent unknown Bernoulli random variables, corresponding to the transformation function $f(x)= \sum_{i=1}^n x_i$. Our algorithm learns to $\eps$-accuracy in poly$(n)$ time, using a surprising poly$(1/\eps)$ number of samples that is independent of $n.$ We also give an efficient algorithm that uses $\log n \cdot \poly(1/\eps)$ samples but has running time that is only $\poly(\log n, 1/\eps).$</abstract>
   </article>
   <article>
      <title>A Feature Selection Method for Multivariate Performance Measures</title>
      <author>Qi Mao, Ivor W. Tsang</author>
      <date>2011-03-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Feature selection with specific multivariate performance measures is the key to the success of many applications, such as image retrieval and text classification. The existing feature selection methods are usually designed for classification error. In this paper, we propose a generalized sparse regularizer. Based on the proposed regularizer, we present a unified feature selection framework for general loss functions. In particular, we study the novel feature selection paradigm by optimizing multivariate performance measures. The resultant formulation is a challenging problem for high-dimensional data. Hence, a two-layer cutting plane algorithm is proposed to solve this problem, and the convergence is presented. In addition, we adapt the proposed method to optimize multivariate measures for multiple instance learning problems. The analyses by comparing with the state-of-the-art feature selection methods show that the proposed method is superior to others. Extensive experiments on large-scale and high-dimensional real world datasets show that the proposed method outperforms $l_1$-SVM and SVM-RFE when choosing a small subset of features, and achieves significantly improved performances over SVM$^{perf}$ in terms of $F_1$-score.</abstract>
   </article>
   <article>
      <title>Parallel Online Learning</title>
      <author>Daniel Hsu, Nikos Karampatziakis, John Langford, Alex Smola</author>
      <date>2011-03-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this work we study parallelization of online learning, a core primitive in machine learning. In a parallel environment all known approaches for parallel online learning lead to delayed updates, where the model is updated using out-of-date information. In the worst case, or when examples are temporally correlated, delay can have a very adverse effect on the learning algorithm. Here, we analyze and present preliminary empirical results on a set of learning architectures based on a feature sharding approach that present various tradeoffs between delay, degree of parallelism, representation power and empirical performance.</abstract>
   </article>
   <article>
      <title>Gaussian Robust Classification</title>
      <author>Ido Ginodi, Amir Globerson</author>
      <date>2011-04-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Supervised learning is all about the ability to generalize knowledge. Specifically, the goal of the learning is to train a classifier using training data, in such a way that it will be capable of classifying new unseen data correctly. In order to acheive this goal, it is important to carefully design the learner, so it will not overfit the training data. The later can is done usually by adding a regularization term. The statistical learning theory explains the success of this method by claiming that it restricts the complexity of the learned model. This explanation, however, is rather abstract and does not have a geometric intuition. The generalization error of a classifier may be thought of as correlated with its robustness to perturbations of the data: a classifier that copes with disturbance is expected to generalize well. Indeed, Xu et al. [2009] have shown that the SVM formulation is equivalent to a robust optimization (RO) formulation, in which an adversary displaces the training and testing points within a ball of pre-determined radius. In this work we explore a different kind of robustness, namely changing each data point with a Gaussian cloud centered at the sample. Loss is evaluated as the expectation of an underlying loss function on the cloud. This setup fits the fact that in many applications, the data is sampled along with noise. We develop an RO framework, in which the adversary chooses the covariance of the noise. In our algorithm named GURU, the tuning parameter is a spectral bound on the noise, thus it can be estimated using physical or applicative considerations. Our experiments show that this framework performs as well as SVM and even slightly better in some cases. Generalizations for Mercer kernels and for the multiclass case are presented as well. We also show that our framework may be further generalized, using the technique of convex perspective functions.</abstract>
   </article>
   <article>
      <title>Meaningful Clustered Forest: an Automatic and Robust Clustering
  Algorithm</title>
      <author>Mariano Tepper, Pablo Musé, Andrés Almansa</author>
      <date>2011-04-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a new clustering technique that can be regarded as a numerical method to compute the proximity gestalt. The method analyzes edge length statistics in the MST of the dataset and provides an a contrario cluster detection criterion. The approach is fully parametric on the chosen distance and can detect arbitrarily shaped clusters. The method is also automatic, in the sense that only a single parameter is left to the user. This parameter has an intuitive interpretation as it controls the expected number of false detections. We show that the iterative application of our method can (1) provide robustness to noise and (2) solve a masking phenomenon in which a highly populated and salient cluster dominates the scene and inhibits the detection of less-populated, but still salient, clusters.</abstract>
   </article>
   <article>
      <title>PAC learnability versus VC dimension: a footnote to a basic result of
  statistical learning</title>
      <author>Vladimir Pestov</author>
      <date>2011-04-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A fundamental result of statistical learnig theory states that a concept class is PAC learnable if and only if it is a uniform Glivenko-Cantelli class if and only if the VC dimension of the class is finite. However, the theorem is only valid under special assumptions of measurability of the class, in which case the PAC learnability even becomes consistent. Otherwise, there is a classical example, constructed under the Continuum Hypothesis by Dudley and Durst and further adapted by Blumer, Ehrenfeucht, Haussler, and Warmuth, of a concept class of VC dimension one which is neither uniform Glivenko-Cantelli nor consistently PAC learnable. We show that, rather surprisingly, under an additional set-theoretic hypothesis which is much milder than the Continuum Hypothesis (Martin's Axiom), PAC learnability is equivalent to finite VC dimension for every concept class.</abstract>
   </article>
   <article>
      <title>Temporal Second Difference Traces</title>
      <author>Mitchell Keith Bloch</author>
      <date>2011-04-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Q-learning is a reliable but inefficient off-policy temporal-difference method, backing up reward only one step at a time. Replacing traces, using a recency heuristic, are more efficient but less reliable. In this work, we introduce model-free, off-policy temporal difference methods that make better use of experience than Watkins' Q(\lambda). We introduce both Optimistic Q(\lambda) and the temporal second difference trace (TSDT). TSDT is particularly powerful in deterministic domains. TSDT uses neither recency nor frequency heuristics, storing (s,a,r,s',\delta) so that off-policy updates can be performed after apparently suboptimal actions have been taken. There are additional advantages when using state abstraction, as in MAXQ. We demonstrate that TSDT does significantly better than both Q-learning and Watkins' Q(\lambda) in a deterministic cliff-walking domain. Results in a noisy cliff-walking domain are less advantageous for TSDT, but demonstrate the efficacy of Optimistic Q(\lambda), a replacing trace with some of the advantages of TSDT.</abstract>
   </article>
   <article>
      <title>Reducing Commitment to Tasks with Off-Policy Hierarchical Reinforcement
  Learning</title>
      <author>Mitchell Keith Bloch</author>
      <date>2011-04-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In experimenting with off-policy temporal difference (TD) methods in hierarchical <term>reinforcement learning</term> (HRL) systems, we have observed unwanted on-policy learning under reproducible conditions. Here we present modifications to several TD methods that prevent unintentional on-policy learning from occurring. These modifications create a tension between exploration and learning. Traditional TD methods require commitment to finishing subtasks without exploration in order to update Q-values for early actions with high probability. One-step intra-option learning and temporal second difference traces (TSDT) do not suffer from this limitation. We demonstrate that our HRL system is efficient without commitment to completion of subtasks in a cliff-walking domain, contrary to a widespread claim in the literature that it is critical for efficiency of learning. Furthermore, decreasing commitment as exploration progresses is shown to improve both online performance and the resultant policy in the taxicab domain, opening a new avenue for research into when it is more beneficial to continue with the current subtask or to replan.</abstract>
   </article>
   <article>
      <title>Attacking and Defending Covert Channels and Behavioral Models</title>
      <author>Valentino Crespi, George Cybenko, Annarita Giani</author>
      <date>2011-04-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we present methods for attacking and defending $k$-gram statistical analysis techniques that are used, for example, in network traffic analysis and covert channel detection. The main new result is our demonstration of how to use a behavior's or process' $k$-order statistics to build a stochastic process that has those same $k$-order stationary statistics but possesses different, deliberately designed, $(k+1)$-order statistics if desired. Such a model realizes a "complexification" of the process or behavior which a defender can use to monitor whether an attacker is shaping the behavior. By deliberately introducing designed $(k+1)$-order behaviors, the defender can check to see if those behaviors are present in the data. We also develop constructs for source codes that respect the $k$-order statistics of a process while encoding covert information. One fundamental consequence of these results is that certain types of behavior analyses techniques come down to an {\em arms race} in the sense that the advantage goes to the party that has more computing resources applied to the problem.</abstract>
   </article>
   <article>
      <title>Suboptimal Solution Path Algorithm for Support Vector Machine</title>
      <author>Masayuki Karasuyama, Ichiro Takeuchi</author>
      <date>2011-05-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a suboptimal solution path algorithm for the Support Vector Machine. The solution path algorithm is an effective tool for solving a sequence of a parametrized optimization problems in machine learning. The path of the solutions provided by this algorithm are very accurate and they satisfy the optimality conditions more strictly than other SVM optimization algorithms. In many machine learning application, however, this strict optimality is often unnecessary, and it adversely affects the computational efficiency. Our algorithm can generate the path of suboptimal solutions within an arbitrary user-specified tolerance level. It allows us to control the trade-off between the accuracy of the solution and the computational cost. Moreover, We also show that our suboptimal solutions can be interpreted as the solution of a \emph{perturbed optimization problem} from the original one. We provide some theoretical analyses of our algorithm based on this novel interpretation. The experimental results also demonstrate the effectiveness of our algorithm.</abstract>
   </article>
   <article>
      <title>Domain Adaptation: Overfitting and Small Sample Statistics</title>
      <author>Dean Foster, Sham Kakade, Ruslan Salakhutdinov</author>
      <date>2011-05-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the prevalent problem when a test distribution differs from the training distribution. We consider a setting where our training set consists of a small number of sample domains, but where we have many samples in each domain. Our goal is to generalize to a new domain. For example, we may want to learn a similarity function using only certain classes of objects, but we desire that this similarity function be applicable to object classes not present in our training sample (e.g. we might seek to learn that "dogs are similar to dogs" even though images of dogs were absent from our training set). Our theoretical analysis shows that we can select many more features than domains while avoiding overfitting by utilizing data-dependent variance properties. We present a greedy feature selection algorithm based on using T-statistics. Our experiments validate this theory showing that our T-statistic based greedy feature selection is more robust at avoiding overfitting than the classical greedy procedure.</abstract>
   </article>
   <article>
      <title>Adaptively Learning the Crowd Kernel</title>
      <author>Omer Tamuz, Ce Liu, Serge Belongie, Ohad Shamir, Adam Tauman Kalai</author>
      <date>2011-05-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce an algorithm that, given n objects, learns a similarity matrix over all n^2 pairs, from crowdsourced data alone. The algorithm samples responses to adaptively chosen triplet-based relative-similarity queries. Each query has the form "is object 'a' more similar to 'b' or to 'c'?" and is chosen to be maximally informative given the preceding responses. The output is an embedding of the objects into Euclidean space (like MDS); we refer to this as the "crowd kernel." SVMs reveal that the crowd kernel captures prominent and subtle features across a number of domains, such as "is striped" among neckties and "vowel vs. consonant" among letters.</abstract>
   </article>
   <article>
      <title>A Maximal Large Deviation Inequality for Sub-Gaussian Variables</title>
      <author>Dotan Di Castro, Claudio Gentile, Shie Mannor</author>
      <date>2011-05-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this short note we prove a maximal concentration lemma for sub-Gaussian random variables stating that for independent sub-Gaussian random variables we have \[P&lt;(\max_{1\le i\le N}S_{i}&gt;\epsilon&gt;) \le\exp&lt;(-\frac{1}{N^2}\sum_{i=1}^{N}\frac{\epsilon^{2}}{2\sigma_{i}^{2}}&gt;), \] where $S_i$ is the sum of $i$ zero mean independent sub-Gaussian random variables and $\sigma_i$ is the variance of the $i$th random variable.</abstract>
   </article>
   <article>
      <title>Calibration with Changing Checking Rules and Its Application to
  Short-Term Trading</title>
      <author>Vladimir Trunov, Vladimir V'yugin</author>
      <date>2011-05-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We provide a natural learning process in which a financial trader without a risk receives a gain in case when Stock Market is inefficient. In this process, the trader rationally choose his gambles using a prediction made by a randomized calibrated algorithm. Our strategy is based on Dawid's notion of calibration with more general changing checking rules and on some modification of Kakade and Foster's randomized algorithm for computing calibrated forecasts.</abstract>
   </article>
   <article>
      <title>Bounding the Fat Shattering Dimension of a Composition Function Class
  Built Using a Continuous Logic Connective</title>
      <author>Hubert Haoyang Duan</author>
      <date>2011-05-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We begin this report by describing the Probably Approximately Correct (PAC) model for learning a concept class, consisting of subsets of a domain, and a function class, consisting of functions from the domain to the unit interval. Two combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its generalization, the Fat Shattering dimension of scale e, are explained and a few examples of their calculations are given with proofs. We then explain Sauer's Lemma, which involves the VC dimension and is used to prove the equivalence of a concept class being distribution-free PAC learnable and it having finite VC dimension.   As the main new result of our research, we explore the construction of a new function class, obtained by forming compositions with a continuous logic connective, a uniformly continuous function from the unit hypercube to the unit interval, from a collection of function classes. Vidyasagar had proved that such a composition function class has finite Fat Shattering dimension of all scales if the classes in the original collection do; however, no estimates of the dimension were known. Using results by Mendelson-Vershynin and Talagrand, we bound the Fat Shattering dimension of scale e of this new function class in terms of the Fat Shattering dimensions of the collection's classes.   We conclude this report by providing a few open questions and future research topics involving the PAC learning model.</abstract>
   </article>
   <article>
      <title>Online Learning, Stability, and Stochastic Gradient Descent</title>
      <author>Tomaso Poggio, Stephen Voinea, Lorenzo Rosasco</author>
      <date>2011-05-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In batch learning, stability together with existence and uniqueness of the solution corresponds to well-posedness of Empirical Risk Minimization (ERM) methods; recently, it was proved that CV_loo stability is necessary and sufficient for generalization and consistency of ERM. In this note, we introduce CV_on stability, which plays a similar note in online learning. We show that stochastic <term>gradient descent</term> (SDG) with the usual hypotheses is CVon stable and we then discuss the implications of CV_on stability for convergence of SGD.</abstract>
   </article>
   <article>
      <title>Large-Scale Music Annotation and Retrieval: Learning to Rank in Joint
  Semantic Spaces</title>
      <author>Jason Weston, Samy Bengio, Philippe Hamel</author>
      <date>2011-05-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Music prediction tasks range from predicting tags given a song or clip of audio, predicting the name of the artist, or predicting related songs given a song, clip, artist name or tag. That is, we are interested in every semantic relationship between the different musical concepts in our database. In realistically sized databases, the number of songs is measured in the hundreds of thousands or more, and the number of artists in the tens of thousands or more, providing a considerable challenge to standard machine learning techniques. In this work, we propose a method that scales to such datasets which attempts to capture the semantic similarities between the database items by modeling audio, artist names, and tags in a single low-dimensional semantic space. This choice of space is learnt by optimizing the set of prediction tasks of interest jointly using multi-task learning. Our method both outperforms baseline methods and, in comparison to them, is faster and consumes less memory. We then demonstrate how our method learns an interpretable model, where the semantic space captures well the similarities of interest.</abstract>
   </article>
   <article>
      <title>Kernel Belief Propagation</title>
      <author>Le Song, Arthur Gretton, Danny Bickson, Yucheng Low, Carlos Guestrin</author>
      <date>2011-05-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a nonparametric generalization of belief propagation, Kernel Belief Propagation (KBP), for pairwise Markov random fields. Messages are represented as functions in a reproducing kernel Hilbert space (RKHS), and message updates are simple linear operations in the RKHS. KBP makes none of the assumptions commonly required in classical BP algorithms: the variables need not arise from a finite domain or a Gaussian distribution, nor must their relations take any particular parametric form. Rather, the relations between variables are represented implicitly, and are learned nonparametrically from training data. KBP has the advantage that it may be used on any domain where kernels are defined (Rd, strings, groups), even where explicit parametric models are not known, or closed form expressions for the BP updates do not exist. The computational cost of message updates in KBP is polynomial in the training data size. We also propose a constant time approximate message update procedure by representing messages using a small number of basis functions. In experiments, we apply KBP to image denoising, depth prediction from still images, and protein configuration prediction: KBP is faster than competing classical and nonparametric approaches (by orders of magnitude, in some cases), while providing significantly more accurate results.</abstract>
   </article>
   <article>
      <title>The Perceptron with Dynamic Margin</title>
      <author>Constantinos Panagiotakopoulos, Petroula Tsampouka</author>
      <date>2011-05-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The classical perceptron rule provides a varying upper bound on the maximum margin, namely the length of the current weight vector divided by the total number of updates up to that time. Requiring that the perceptron updates its internal state whenever the normalized margin of a pattern is found not to exceed a certain fraction of this dynamic upper bound we construct a new approximate maximum margin classifier called the perceptron with dynamic margin (PDM). We demonstrate that PDM converges in a finite number of steps and derive an upper bound on them. We also compare experimentally PDM with other perceptron-like algorithms and <term>support vector machine</term>s on hard margin tasks involving linear kernels which are equivalent to 2-norm soft margin.</abstract>
   </article>
   <article>
      <title>A Unified Framework for Approximating and Clustering Data</title>
      <author>Dan Feldman, Michael Langberg</author>
      <date>2011-06-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Given a set $F$ of $n$ positive functions over a ground set $X$, we consider the problem of computing $x^*$ that minimizes the expression $\sum_{f\in F}f(x)$, over $x\in X$. A typical application is \emph{shape fitting}, where we wish to approximate a set $P$ of $n$ elements (say, points) by a shape $x$ from a (possibly infinite) family $X$ of shapes. Here, each point $p\in P$ corresponds to a function $f$ such that $f(x)$ is the distance from $p$ to $x$, and we seek a shape $x$ that minimizes the sum of distances from each point in $P$. In the $k$-clustering variant, each $x\in X$ is a tuple of $k$ shapes, and $f(x)$ is the distance from $p$ to its closest shape in $x$.   Our main result is a unified framework for constructing {\em coresets} and {\em approximate clustering} for such general sets of functions. To achieve our results, we forge a link between the classic and well defined notion of $\varepsilon$-approximations from the theory of PAC Learning and VC dimension, to the relatively new (and not so consistent) paradigm of coresets, which are some kind of "compressed representation" of the input set $F$. Using traditional techniques, a coreset usually implies an LTAS (linear time approximation scheme) for the corresponding optimization problem, which can be computed in parallel, via one pass over the data, and using only polylogarithmic space (i.e, in the streaming model).   We show how to generalize the results of our framework for squared distances (as in $k$-mean), distances to the $q$th power, and deterministic constructions.</abstract>
   </article>
   <article>
      <title>Max-Margin Stacking and Sparse Regularization for Linear Classifier
  Combination and Selection</title>
      <author>Mehmet Umut Sen, Hakan Erdogan</author>
      <date>2011-06-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The main principle of stacked generalization (or Stacking) is using a second-level generalizer to combine the outputs of base classifiers in an ensemble. In this paper, we investigate different combination types under the stacking framework; namely weighted sum (WS), class-dependent weighted sum (CWS) and linear stacked generalization (LSG). For learning the weights, we propose using regularized empirical risk minimization with the hinge loss. In addition, we propose using group sparsity for regularization to facilitate classifier selection. We performed experiments using two different ensemble setups with differing diversities on 8 real-world datasets. Results show the power of regularized learning with the hinge loss function. Using sparse regularization, we are able to reduce the number of selected classifiers of the diverse ensemble without sacrificing accuracy. With the non-diverse ensembles, we even gain accuracy on average by using sparse regularization.</abstract>
   </article>
   <article>
      <title>Reinforcement learning based sensing policy optimization for energy
  efficient cognitive radio networks</title>
      <author>Jan Oksanen, Jarmo Lundén, Visa Koivunen</author>
      <date>2011-06-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper introduces a machine learning based collaborative multi-band spectrum sensing policy for cognitive radios. The proposed sensing policy guides secondary users to focus the search of unused radio spectrum to those frequencies that persistently provide them high data rate. The proposed policy is based on machine learning, which makes it adaptive with the temporally and spatially varying radio spectrum. Furthermore, there is no need for dynamic modeling of the primary activity since it is implicitly learned over time. Energy efficiency is achieved by minimizing the number of assigned sensors per each subband under a constraint on miss detection probability. It is important to control the missed detections because they cause collisions with primary transmissions and lead to retransmissions at both the primary and secondary user. Simulations show that the proposed machine learning based sensing policy improves the overall throughput of the secondary network and improves the energy efficiency while controlling the miss detection probability.</abstract>
   </article>
   <article>
      <title>Learning the Dependence Graph of Time Series with Latent Factors</title>
      <author>Ali Jalali, Sujay Sanghavi</author>
      <date>2011-06-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper considers the problem of learning, from samples, the dependency structure of a system of linear stochastic differential equations, when some of the variables are latent. In particular, we observe the time evolution of some variables, and never observe other variables; from this, we would like to find the dependency structure between the observed variables - separating out the spurious interactions caused by the (marginalizing out of the) latent variables' time series. We develop a new method, based on convex optimization, to do so in the case when the number of latent variables is smaller than the number of observed ones. For the case when the dependency structure between the observed variables is sparse, we theoretically establish a high-dimensional scaling result for structure recovery. We verify our theoretical result with both synthetic and real data (from the stock market).</abstract>
   </article>
   <article>
      <title>On epsilon-optimality of the pursuit learning algorithm</title>
      <author>Ryan Martin, Omkar Tilak</author>
      <date>2011-06-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Estimator algorithms in learning automata are useful tools for adaptive, real-time optimization in computer science and engineering applications. This paper investigates theoretical convergence properties for a special case of estimator algorithms: the pursuit learning algorithm. In this note, we identify and fill a gap in existing proofs of probabilistic convergence for pursuit learning. It is tradition to take the pursuit learning tuning parameter to be fixed in practical applications, but our proof sheds light on the importance of a vanishing sequence of tuning parameters in a theoretical convergence analysis.</abstract>
   </article>
   <article>
      <title>Decoding finger movements from ECoG signals using switching linear
  models</title>
      <author>Rémi Flamary, Alain Rakotomamonjy</author>
      <date>2011-06-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>One of the major challenges of ECoG-based Brain-Machine Interfaces is the movement prediction of a human subject. Several methods exist to predict an arm 2-D trajectory. The fourth BCI Competition gives a dataset in which the aim is to predict individual finger movements (5-D trajectory). The difficulty lies in the fact that there is no simple relation between ECoG signals and finger movement. We propose in this paper to decode finger flexions using switching models. This method permits to simplify the system as it is now described as an ensemble of linear models depending on an internal state. We show that an interesting accuracy prediction can be obtained by such a model.</abstract>
   </article>
   <article>
      <title>Large margin filtering for signal sequence labeling</title>
      <author>Rémi Flamary, Benjamin Labbé, Alain Rakotomamonjy</author>
      <date>2011-06-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Signal Sequence Labeling consists in predicting a sequence of labels given an observed sequence of samples. A naive way is to filter the signal in order to reduce the noise and to apply a classification algorithm on the filtered samples. We propose in this paper to jointly learn the filter with the classifier leading to a large margin filtering for classification. This method allows to learn the optimal cutoff frequency and phase of the filter that may be different from zero. Two methods are proposed and tested on a toy dataset and on a real life BCI dataset from BCI Competition III.</abstract>
   </article>
   <article>
      <title>Handling uncertainties in SVM classification</title>
      <author>Emilie Niaf, Rémi Flamary, Carole Lartizien, Stéphane Canu</author>
      <date>2011-06-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper addresses the pattern classification problem arising when available target data include some uncertainty information. Target data considered here is either qualitative (a class label) or quantitative (an estimation of the posterior probability). Our main contribution is a SVM inspired formulation of this problem allowing to take into account class label through a hinge loss as well as probability estimates using epsilon-insensitive cost function together with a minimum norm (maximum margin) objective. This formulation shows a dual form leading to a quadratic problem and allows the use of a representer theorem and associated kernel. The solution provided can be used for both decision and posterior probability estimation. Based on empirical evidence our method outperforms regular SVM in terms of probability predictions and classification performances.</abstract>
   </article>
   <article>
      <title>Algorithmic Programming Language Identification</title>
      <author>David Klein, Kyle Murray, Simon Weber</author>
      <date>2011-06-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Motivated by the amount of code that goes unidentified on the web, we introduce a practical method for algorithmically identifying the programming language of source code. Our work is based on supervised learning and intelligent statistical features. We also explored, but abandoned, a grammatical approach. In testing, our implementation greatly outperforms that of an existing tool that relies on a Bayesian classifier. Code is written in Python and available under an MIT license.</abstract>
   </article>
   <article>
      <title>Better Mini-Batch Algorithms via Accelerated Gradient Methods</title>
      <author>Andrew Cotter, Ohad Shamir, Nathan Srebro, Karthik Sridharan</author>
      <date>2011-06-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Mini-batch algorithms have been proposed as a way to speed-up stochastic convex optimization problems. We study how such algorithms can be improved using accelerated gradient methods. We provide a novel analysis, which shows how standard gradient methods may sometimes be insufficient to obtain a significant speed-up and propose a novel accelerated gradient algorithm, which deals with this deficiency, enjoys a uniformly superior guarantee and works well in practice.</abstract>
   </article>
   <article>
      <title>Potential-Based Shaping and Q-Value Initialization are Equivalent</title>
      <author>E. Wiewiora</author>
      <date>2011-06-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Shaping has proven to be a powerful but precarious means of improving <term>reinforcement learning</term> performance. Ng, Harada, and Russell (1999) proposed the potential-based shaping algorithm for adding shaping rewards in a way that guarantees the learner will learn optimal behavior. In this note, we prove certain similarities between this shaping algorithm and the initialization step required for several <term>reinforcement learning</term> algorithms. More specifically, we prove that a reinforcement learner with initial Q-values based on the shaping algorithm's potential function make the same updates throughout learning as a learner receiving potential-based shaping rewards. We further prove that under a broad category of policies, the behavior of these two learners are indistinguishable. The comparison provides intuition on the theoretical properties of the shaping algorithm as well as a suggestion for a simpler method for capturing the algorithm's benefit. In addition, the equivalence raises previously unaddressed issues concerning the efficiency of learning with potential-based shaping.</abstract>
   </article>
   <article>
      <title>IBSEAD: - A Self-Evolving Self-Obsessed Learning Algorithm for Machine
  Learning</title>
      <author>Jitesh Dundas, David Chik</author>
      <date>2011-06-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present IBSEAD or distributed autonomous entity systems based Interaction - a learning algorithm for the computer to self-evolve in a self-obsessed manner. This learning algorithm will present the computer to look at the internal and external environment in series of independent entities, which will interact with each other, with and/or without knowledge of the computer's brain. When a learning algorithm interacts, it does so by detecting and understanding the entities in the human algorithm. However, the problem with this approach is that the algorithm does not consider the interaction of the third party or unknown entities, which may be interacting with each other. These unknown entities in their interaction with the non-computer entities make an effect in the environment that influences the information and the behaviour of the computer brain. Such details and the ability to process the dynamic and unsettling nature of these interactions are absent in the current learning algorithm such as the decision tree learning algorithm. IBSEAD is able to evaluate and consider such algorithms and thus give us a better accuracy in simulation of the highly evolved nature of the human brain. Processes such as dreams, imagination and novelty, that exist in humans are not fully simulated by the existing learning algorithms. Also, Hidden Markov models (HMM) are useful in finding "hidden" entities, which may be known or unknown. However, this model fails to consider the case of unknown entities which maybe unclear or unknown. IBSEAD is better because it considers three types of entities- known, unknown and invisible. We present our case with a comparison of existing algorithms in known environments and cases and present the results of the experiments using dry run of the simulated runs of the existing machine learning algorithms versus IBSEAD.</abstract>
   </article>
   <article>
      <title>A Note on Improved Loss Bounds for Multiple Kernel Learning</title>
      <author>Zakria Hussain, John Shawe-Taylor, Mario Marchand</author>
      <date>2011-06-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we correct an upper bound, presented in~\cite{hs-11}, on the generalisation error of classifiers learned through multiple kernel learning. The bound in~\cite{hs-11} uses Rademacher complexity and has an\emph{additive} dependence on the logarithm of the number of kernels and the margin achieved by the classifier. However, there are some errors in parts of the proof which are corrected in this paper. Unfortunately, the final result turns out to be a risk bound which has a \emph{multiplicative} dependence on the logarithm of the number of kernels and the margin achieved by the classifier.</abstract>
   </article>
   <article>
      <title>GraphLab: A Distributed Framework for Machine Learning in the Cloud</title>
      <author>Yucheng Low, Joseph Gonzalez, Aapo Kyrola, Danny Bickson, Carlos Guestrin</author>
      <date>2011-07-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Machine Learning (ML) techniques are indispensable in a wide range of fields. Unfortunately, the exponential increase of dataset sizes are rapidly extending the runtime of sequential algorithms and threatening to slow future progress in ML. With the promise of affordable large-scale parallel computing, Cloud systems offer a viable platform to resolve the computational challenges in ML. However, designing and implementing efficient, provably correct distributed ML algorithms is often prohibitively challenging. To enable ML researchers to easily and efficiently use parallel systems, we introduced the GraphLab abstraction which is designed to represent the computational patterns in ML algorithms while permitting efficient parallel and distributed implementations. In this paper we provide a formal description of the GraphLab parallel abstraction and present an efficient distributed implementation. We conduct a comprehensive evaluation of GraphLab on three state-of-the-art ML algorithms using real large-scale data and a 64 node EC2 cluster of 512 processors. We find that GraphLab achieves orders of magnitude performance gains over Hadoop while performing comparably or superior to hand-tuned MPI implementations.</abstract>
   </article>
   <article>
      <title>Towards Optimal One Pass Large Scale Learning with Averaged Stochastic
  Gradient Descent</title>
      <author>Wei Xu</author>
      <date>2011-07-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>For large scale learning problems, it is desirable if we can obtain the optimal model parameters by going through the data in only one pass. Polyak and Juditsky (1992) showed that asymptotically the test performance of the simple average of the parameters obtained by stochastic <term>gradient descent</term> (SGD) is as good as that of the parameters which minimize the empirical cost. However, to our knowledge, despite its optimal asymptotic convergence rate, averaged SGD (ASGD) received little attention in recent research on large scale learning. One possible reason is that it may take a prohibitively large number of training samples for ASGD to reach its asymptotic region for most real problems. In this paper, we present a finite sample analysis for the method of Polyak and Juditsky (1992). Our analysis shows that it indeed usually takes a huge number of samples for ASGD to reach its asymptotic region for improperly chosen learning rate. More importantly, based on our analysis, we propose a simple way to properly set learning rate so that it takes a reasonable amount of data for ASGD to reach its asymptotic region. We compare ASGD using our proposed learning rate with other well known algorithms for training large scale linear classifiers. The experiments clearly show the superiority of ASGD.</abstract>
   </article>
   <article>
      <title>Discovering Knowledge using a Constraint-based Language</title>
      <author>Patrice Boizumault, Bruno Crémilleux, Mehdi Khiari, Samir Loudni, Jean-Philippe Métivier</author>
      <date>2011-07-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Discovering pattern sets or global patterns is an attractive issue from the pattern mining community in order to provide useful information. By combining local patterns satisfying a joint meaning, this approach produces patterns of higher level and thus more useful for the data analyst than the usual local patterns, while reducing the number of patterns. In parallel, recent works investigating relationships between data mining and constraint programming (CP) show that the CP paradigm is a nice framework to model and mine such patterns in a declarative and generic way. We present a constraint-based language which enables us to define queries addressing patterns sets and global patterns. The usefulness of such a declarative approach is highlighted by several examples coming from the clustering based on associations. This language has been implemented in the CP framework.</abstract>
   </article>
   <article>
      <title>On the Universality of Online Mirror Descent</title>
      <author>Nathan Srebro, Karthik Sridharan, Ambuj Tewari</author>
      <date>2011-07-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We show that for a general class of convex online learning problems, Mirror Descent can always achieve a (nearly) optimal regret guarantee.</abstract>
   </article>
   <article>
      <title>The Divergence of Reinforcement Learning Algorithms with Value-Iteration
  and Function Approximation</title>
      <author>Michael Fairbank, Eduardo Alonso</author>
      <date>2011-07-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper gives specific divergence examples of value-iteration for several major Reinforcement Learning and Adaptive Dynamic Programming algorithms, when using a function approximator for the value function. These divergence examples differ from previous divergence examples in the literature, in that they are applicable for a greedy policy, i.e. in a "value iteration" scenario. Perhaps surprisingly, with a greedy policy, it is also possible to get divergence for the algorithms TD(1) and Sarsa(1). In addition to these divergences, we also achieve divergence for the Adaptive Dynamic Programming algorithms HDP, DHP and GDHP.</abstract>
   </article>
   <article>
      <title>Axioms for Rational Reinforcement Learning</title>
      <author>Peter Sunehag, Marcus Hutter</author>
      <date>2011-07-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We provide a formal, simple and intuitive theory of rational decision making including sequential decisions that affect the environment. The theory has a geometric flavor, which makes the arguments easy to visualize and understand. Our theory is for complete decision makers, which means that they have a complete set of preferences. Our main result shows that a complete rational decision maker implicitly has a probabilistic model of the environment. We have a countable version of this result that brings light on the issue of countable vs finite additivity by showing how it depends on the geometry of the space which we have preferences over. This is achieved through fruitfully connecting rationality with the Hahn-Banach Theorem. The theory presented here can be viewed as a formalization and extension of the betting odds approach to probability of Ramsey and De Finetti.</abstract>
   </article>
   <article>
      <title>Automatic Network Reconstruction using ASP</title>
      <author>Max Ostrowski, Torsten Schaub, Markus Durzinsky, Wolfgang Marwan, Annegret Wagler</author>
      <date>2011-07-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Building biological models by inferring functional dependencies from experimental data is an im- portant issue in Molecular Biology. To relieve the biologist from this traditionally manual process, various approaches have been proposed to increase the degree of automation. However, available ap- proaches often yield a single model only, rely on specific assumptions, and/or use dedicated, heuris- tic algorithms that are intolerant to changing circumstances or requirements in the view of the rapid progress made in Biotechnology. Our aim is to provide a declarative solution to the problem by ap- peal to Answer Set Programming (ASP) overcoming these difficulties. We build upon an existing approach to Automatic Network Reconstruction proposed by part of the authors. This approach has firm mathematical foundations and is well suited for ASP due to its combinatorial flavor providing a characterization of all models explaining a set of experiments. The usage of ASP has several ben- efits over the existing heuristic algorithms. First, it is declarative and thus transparent for biological experts. Second, it is elaboration tolerant and thus allows for an easy exploration and incorporation of biological constraints. Third, it allows for exploring the entire space of possible models. Finally, our approach offers an excellent performance, matching existing, special-purpose systems.</abstract>
   </article>
   <article>
      <title>Feature Extraction for Change-Point Detection using Stationary Subspace
  Analysis</title>
      <author>Duncan Blythe, Paul von Bünau, Frank Meinecke, Klaus-Robert Müller</author>
      <date>2011-08-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Detecting changes in high-dimensional time series is difficult because it involves the comparison of probability densities that need to be estimated from finite samples. In this paper, we present the first feature extraction method tailored to change point detection, which is based on an extended version of Stationary Subspace Analysis. We reduce the dimensionality of the data to the most non-stationary directions, which are most informative for detecting state changes in the time series. In extensive simulations on synthetic data we show that the accuracy of three change point detection algorithms is significantly increased by a prior feature extraction step. These findings are confirmed in an application to industrial fault monitoring.</abstract>
   </article>
   <article>
      <title>Optimal Algorithms for Ridge and Lasso Regression with Partially
  Observed Attributes</title>
      <author>Elad Hazan, Tomer Koren</author>
      <date>2011-08-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the most common variants of linear regression, including Ridge, Lasso and Support-vector regression, in a setting where the learner is allowed to observe only a fixed number of attributes of each example at training time. We present simple and efficient algorithms for these problems: for Lasso and Ridge regression they need the same total number of attributes (up to constants) as do full-information algorithms, for reaching a certain accuracy. For Support-vector regression, we require exponentially less attributes compared to the state of the art. By that, we resolve an open problem recently posed by Cesa-Bianchi et al. (2010). Experiments show the theoretical bounds to be justified by superior performance compared to the state of the art.</abstract>
   </article>
   <article>
      <title>Non-trivial two-armed partial-monitoring games are bandits</title>
      <author>András Antos, Gábor Bartók, Csaba Szepesvári</author>
      <date>2011-08-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider online learning in partial-monitoring games against an oblivious adversary. We show that when the number of actions available to the learner is two and the game is nontrivial then it is reducible to a bandit-like game and thus the minimax regret is $\Theta(\sqrt{T})$.</abstract>
   </article>
   <article>
      <title>Local Component Analysis</title>
      <author>Nicolas Le Roux, Francis Bach</author>
      <date>2011-09-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Kernel density estimation, a.k.a. Parzen windows, is a popular density estimation method, which can be used for outlier detection or clustering. With multivariate data, its performance is heavily reliant on the metric used within the kernel. Most earlier work has focused on learning only the bandwidth of the kernel (i.e., a scalar multiplicative factor). In this paper, we propose to learn a full Euclidean metric through an expectation-minimization (EM) procedure, which can be seen as an unsupervised counterpart to neighbourhood component analysis (NCA). In order to avoid overfitting with a fully nonparametric density estimator in high dimensions, we also consider a semi-parametric Gaussian-Parzen density model, where some of the variables are modelled through a jointly Gaussian density, while others are modelled through Parzen windows. For these two models, EM leads to simple closed-form updates based on matrix inversions and eigenvalue decompositions. We show empirically that our method leads to density estimators with higher test-likelihoods than natural competing methods, and that the metrics may be used within most <term>unsupervised learning</term> techniques that rely on such metrics, such as spectral clustering or manifold learning methods. Finally, we present a stochastic approximation scheme which allows for the use of this method in a large-scale setting.</abstract>
   </article>
   <article>
      <title>Weighted Clustering</title>
      <author>Margareta Ackerman, Shai Ben-David, Simina Brânzei, David Loker</author>
      <date>2011-09-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>One of the most prominent challenges in clustering is "the user's dilemma," which is the problem of selecting an appropriate clustering algorithm for a specific task. A formal approach for addressing this problem relies on the identification of succinct, user-friendly properties that formally capture when certain clustering methods are preferred over others.   Until now these properties focused on advantages of classical Linkage-Based algorithms, failing to identify when other clustering paradigms, such as popular center-based methods, are preferable. We present surprisingly simple new properties that delineate the differences between common clustering paradigms, which clearly and formally demonstrates advantages of center-based approaches for some applications. These properties address how sensitive algorithms are to changes in element frequencies, which we capture in a generalized setting where every element is associated with a real-valued weight.</abstract>
   </article>
   <article>
      <title>Learning From Labeled And Unlabeled Data: An Empirical Study Across
  Techniques And Domains</title>
      <author>N. V. Chawla, Grigoris Karakoulas</author>
      <date>2011-09-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>There has been increased interest in devising learning techniques that combine unlabeled data with labeled data ? i.e. semi-supervised learning. However, to the best of our knowledge, no study has been performed across various techniques and different types and amounts of labeled and unlabeled data. Moreover, most of the published work on semi-supervised learning techniques assumes that the labeled and unlabeled data come from the same distribution. It is possible for the labeling process to be associated with a selection bias such that the distributions of data points in the labeled and unlabeled sets are different. Not correcting for such bias can result in biased function approximation with potentially poor performance. In this paper, we present an empirical study of various semi-supervised learning techniques on a variety of datasets. We attempt to answer various questions such as the effect of independence or relevance amongst features, the effect of the size of the labeled and unlabeled sets and the effect of noise. We also investigate the impact of sample-selection bias on the semi-supervised learning techniques under study and implement a bivariate probit technique particularly designed to correct for such bias.</abstract>
   </article>
   <article>
      <title>Efficiency versus Convergence of Boolean Kernels for On-Line Learning
  Algorithms</title>
      <author>R. Khardon, D. Roth, R. A. Servedio</author>
      <date>2011-09-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The paper studies machine learning problems where each example is described using a set of Boolean features and where hypotheses are represented by linear threshold elements. One method of increasing the expressiveness of learned hypotheses in this context is to expand the feature set to include conjunctions of basic features. This can be done explicitly or where possible by using a kernel function. Focusing on the well known Perceptron and Winnow algorithms, the paper demonstrates a tradeoff between the computational efficiency with which the algorithm can be run over the expanded feature space and the generalization ability of the corresponding learning algorithm. We first describe several kernel functions which capture either limited forms of conjunctions or all conjunctions. We show that these kernels can be used to efficiently run the Perceptron algorithm over a feature space of exponentially many conjunctions; however we also show that using such kernels, the Perceptron algorithm can provably make an exponential number of mistakes even when learning simple functions. We then consider the question of whether kernel functions can analogously be used to run the multiplicative-update Winnow algorithm over an expanded feature space of exponentially many conjunctions. Known upper bounds imply that the Winnow algorithm can learn Disjunctive Normal Form (DNF) formulae with a polynomial mistake bound in this setting. However, we prove that it is computationally hard to simulate Winnows behavior for learning DNF over such a feature set. This implies that the kernel functions which correspond to running Winnow for this problem are not efficiently computable, and that there is no general construction that can run Winnow with kernels.</abstract>
   </article>
   <article>
      <title>Risk-Sensitive Reinforcement Learning Applied to Control under
  Constraints</title>
      <author>P. Geibel, F. Wysotzki</author>
      <date>2011-09-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we consider Markov Decision Processes (MDPs) with error states. Error states are those states entering which is undesirable or dangerous. We define the risk with respect to a policy as the probability of entering such a state when the policy is pursued. We consider the problem of finding good policies whose risk is smaller than some user-specified threshold, and formalize it as a constrained MDP with two criteria. The first criterion corresponds to the value function originally given. We will show that the risk can be formulated as a second criterion function based on a cumulative return, whose definition is independent of the original value function. We present a model free, heuristic <term>reinforcement learning</term> algorithm that aims at finding good deterministic policies. It is based on weighting the original value function and the risk. The weight parameter is adapted in order to find a feasible solution for the constrained problem that has a good performance with respect to the value function. The algorithm was successfully applied to the control of a feed tank with stochastic inflows that lies upstream of a distillation column. This control task was originally formulated as an optimal control problem with chance constraints, and it was solved under certain assumptions on the model to obtain an optimal solution. The power of our learning algorithm is that it can be used even when some of these restrictive assumptions are relaxed.</abstract>
   </article>
   <article>
      <title>Bandits with an Edge</title>
      <author>Dotan Di Castro, Claudio Gentile, Shie Mannor</author>
      <date>2011-09-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a bandit problem over a graph where the rewards are not directly observed. Instead, the decision maker can compare two nodes and receive (stochastic) information pertaining to the difference in their value. The graph structure describes the set of possible comparisons. Consequently, comparing between two nodes that are relatively far requires estimating the difference between every pair of nodes on the path between them. We analyze this problem from the perspective of sample complexity: How many queries are needed to find an approximately optimal node with probability more than $1-\delta$ in the PAC setup? We show that the topology of the graph plays a crucial in defining the sample complexity: graphs with a low diameter have a much better sample complexity.</abstract>
   </article>
   <article>
      <title>Distributed User Profiling via Spectral Methods</title>
      <author>Dan-Cristian Tomozei, Laurent Massoulié</author>
      <date>2011-09-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>User profiling is a useful primitive for constructing personalised services, such as content recommendation. In the present paper we investigate the feasibility of user profiling in a distributed setting, with no central authority and only local information exchanges between users. We compute a profile vector for each user (i.e., a low-dimensional vector that characterises her taste) via spectral transformation of observed user-produced ratings for items. Our two main contributions follow: i) We consider a low-rank probabilistic model of user taste. More specifically, we consider that users and items are partitioned in a constant number of classes, such that users and items within the same class are statistically identical. We prove that without prior knowledge of the compositions of the classes, based solely on few random observed ratings (namely $O(N\log N)$ such ratings for $N$ users), we can predict user preference with high probability for unrated items by running a local vote among users with similar profile vectors. In addition, we provide empirical evaluations characterising the way in which spectral profiling performance depends on the dimension of the profile space. Such evaluations are performed on a data set of real user ratings provided by Netflix. ii) We develop distributed algorithms which provably achieve an embedding of users into a low-dimensional space, based on spectral transformation. These involve simple message passing among users, and provably converge to the desired embedding. Our method essentially relies on a novel combination of gossiping and the algorithm proposed by Oja and Karhunen.</abstract>
   </article>
   <article>
      <title>Learning Topic Models by Belief Propagation</title>
      <author>Jia Zeng, William K. Cheung, Jiming Liu</author>
      <date>2011-09-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model for probabilistic topic modeling, which attracts worldwide interests and touches on many important applications in text mining, computer vision and computational biology. This paper represents LDA as a factor graph within the Markov random field (MRF) framework, which enables the classic loopy belief propagation (BP) algorithm for approximate inference and parameter estimation. Although two commonly-used approximate inference methods, such as variational Bayes (VB) and collapsed Gibbs sampling (GS), have gained great successes in learning LDA, the proposed BP is competitive in both speed and accuracy as validated by encouraging experimental results on four large-scale document data sets. Furthermore, the BP algorithm has the potential to become a generic learning scheme for variants of LDA-based topic models. To this end, we show how to learn two typical variants of LDA-based topic models, such as author-topic models (ATM) and relational topic models (RTM), using BP based on the factor graph representation.</abstract>
   </article>
   <article>
      <title>Application of distances between terms for flat and hierarchical data</title>
      <author>Jorge-Alonso Bedoya-Puerta, Jose Hernandez-Orallo</author>
      <date>2011-09-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In machine learning, distance-based algorithms, and other approaches, use information that is represented by propositional data. However, this kind of representation can be quite restrictive and, in many cases, it requires more complex structures in order to represent data in a more natural way. Terms are the basis for functional and logic programming representation. Distances between terms are a useful tool not only to compare terms, but also to determine the search space in many of these applications. This dissertation applies distances between terms, exploiting the features of each distance and the possibility to compare from propositional data types to hierarchical representations. The distances between terms are applied through the k-NN (k-nearest neighbor) classification algorithm using XML as a common language representation. To be able to represent these data in an XML structure and to take advantage of the benefits of distance between terms, it is necessary to apply some transformations. These transformations allow the conversion of flat data into hierarchical data represented in XML, using some techniques based on intuitive associations between the names and values of variables and associations based on attribute similarity.   Several experiments with the distances between terms of Nienhuys-Cheng and Estruch et al. were performed. In the case of originally propositional data, these distances are compared to the Euclidean distance. In all cases, the experiments were performed with the distance-weighted k-nearest neighbor algorithm, using several exponents for the attraction function (weighted distance). It can be seen that in some cases, the term distances can significantly improve the results on approaches applied to flat representations.</abstract>
   </article>
   <article>
      <title>Noise Tolerance under Risk Minimization</title>
      <author>Naresh Manwani, P. S. Sastry</author>
      <date>2011-09-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we explore noise tolerant learning of classifiers. We formulate the problem as follows. We assume that there is an ${\bf unobservable}$ training set which is noise-free. The actual training set given to the learning algorithm is obtained from this ideal data set by corrupting the class label of each example. The probability that the class label of an example is corrupted is a function of the feature vector of the example. This would account for most kinds of noisy data one encounters in practice. We say that a learning method is noise tolerant if the classifiers learnt with the ideal noise-free data and with noisy data, both have the same classification accuracy on the noise-free data. In this paper we analyze the noise tolerance properties of risk minimization (under different loss functions), which is a generic method for learning classifiers. We show that risk minimization under 0-1 loss function has impressive noise tolerance properties and that under squared error loss is tolerant only to uniform noise; risk minimization under other loss functions is not noise tolerant. We conclude the paper with some discussion on implications of these theoretical results.</abstract>
   </article>
   <article>
      <title>Active Learning with Multiple Views</title>
      <author>C. A. Knoblock, S. Minton, I. Muslea</author>
      <date>2011-10-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Active learners alleviate the burden of labeling large amounts of data by detecting and asking the user to label only the most informative examples in the domain. We focus here on active learning for multi-view domains, in which there are several disjoint subsets of features (views), each of which is sufficient to learn the target concept. In this paper we make several contributions. First, we introduce Co-Testing, which is the first approach to multi-view active learning. Second, we extend the multi-view learning framework by also exploiting weak views, which are adequate only for learning a concept that is more general/specific than the target concept. Finally, we empirically show that Co-Testing outperforms existing active learners on a variety of real world domains such as wrapper induction, Web page classification, advertisement removal, and discourse tree parsing.</abstract>
   </article>
   <article>
      <title>The Augmented Complex Kernel LMS</title>
      <author>Pantelis Bouboulis, Sergios Theodoridis, Michael Mavroforakis</author>
      <date>2011-10-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently, a unified framework for adaptive kernel based signal processing of complex data was presented by the authors, which, besides offering techniques to map the input data to complex Reproducing Kernel Hilbert Spaces, developed a suitable Wirtinger-like Calculus for general Hilbert Spaces. In this short paper, the extended Wirtinger's calculus is adopted to derive complex kernel-based widely-linear estimation filters. Furthermore, we illuminate several important characteristics of the widely linear filters. We show that, although in many cases the gains from adopting widely linear estimation filters, as alternatives to ordinary linear ones, are rudimentary, for the case of kernel based widely linear filters significant performance improvements can be obtained.</abstract>
   </article>
   <article>
      <title>Dynamic Matrix Factorization: A State Space Approach</title>
      <author>John Z. Sun, Kush R. Varshney, Karthik Subbian</author>
      <date>2011-10-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Matrix factorization from a small number of observed entries has recently garnered much attention as the key ingredient of successful recommendation systems. One unresolved problem in this area is how to adapt current methods to handle changing user preferences over time. Recent proposals to address this issue are heuristic in nature and do not fully exploit the time-dependent structure of the problem. As a principled and general temporal formulation, we propose a dynamical state space model of matrix factorization. Our proposal builds upon probabilistic matrix factorization, a Bayesian model with Gaussian priors. We utilize results in state tracking, such as the Kalman filter, to provide accurate recommendations in the presence of both process and measurement noise. We show how system parameters can be learned via expectation-maximization and provide comparisons to current published techniques.</abstract>
   </article>
   <article>
      <title>Active Learning Using Smooth Relative Regret Approximations with
  Applications</title>
      <author>Nir Ailon, Ron Begleiter, Esther Ezra</author>
      <date>2011-10-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The disagreement coefficient of Hanneke has become a central data independent invariant in proving active learning rates. It has been shown in various ways that a concept class with low complexity together with a bound on the disagreement coefficient at an optimal solution allows active learning rates that are superior to passive learning ones.   We present a different tool for pool based active learning which follows from the existence of a certain uniform version of low disagreement coefficient, but is not equivalent to it. In fact, we present two fundamental active learning problems of significant interest for which our approach allows nontrivial active learning bounds. However, any general purpose method relying on the disagreement coefficient bounds only fails to guarantee any useful bounds for these problems.   The tool we use is based on the learner's ability to compute an estimator of the difference between the loss of any hypotheses and some fixed "pivotal" hypothesis to within an absolute error of at most $\eps$ times the</abstract>
   </article>
   <article>
      <title>Supervised learning of short and high-dimensional temporal sequences for
  life science measurements</title>
      <author>F. -M. Schleif, A. Gisbrecht, B. Hammer</author>
      <date>2011-10-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The analysis of physiological processes over time are often given by spectrometric or gene expression profiles over time with only few time points but a large number of measured variables. The analysis of such temporal sequences is challenging and only few methods have been proposed. The information can be encoded time independent, by means of classical expression differences for a single time point or in expression profiles over time. Available methods are limited to unsupervised and semi-supervised settings. The predictive variables can be identified only by means of wrapper or post-processing techniques. This is complicated due to the small number of samples for such studies. Here, we present a supervised learning approach, termed Supervised Topographic Mapping Through Time (SGTM-TT). It learns a supervised mapping of the temporal sequences onto a low dimensional grid. We utilize a hidden markov model (HMM) to account for the time domain and relevance learning to identify the relevant feature dimensions most predictive over time. The learned mapping can be used to visualize the temporal sequences and to predict the class of a new sequence. The relevance learning permits the identification of discriminating masses or gen expressions and prunes dimensions which are unnecessary for the classification task or encode mainly noise. In this way we obtain a very efficient learning system for temporal sequences. The results indicate that using simultaneous supervised learning and metric adaptation significantly improves the prediction accuracy for synthetically and real life data in comparison to the standard techniques. The discriminating features, identified by relevance learning, compare favorably with the results of alternative methods. Our method permits the visualization of the data on a low dimensional grid, highlighting the observed temporal structure.</abstract>
   </article>
   <article>
      <title>Dynamic Batch Bayesian Optimization</title>
      <author>Javad Azimi, Ali Jalali, Xiaoli Fern</author>
      <date>2011-10-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Bayesian optimization (BO) algorithms try to optimize an unknown function that is expensive to evaluate using minimum number of evaluations/experiments. Most of the proposed algorithms in BO are sequential, where only one experiment is selected at each iteration. This method can be time inefficient when each experiment takes a long time and more than one experiment can be ran concurrently. On the other hand, requesting a fix-sized batch of experiments at each iteration causes performance inefficiency in BO compared to the sequential policies. In this paper, we present an algorithm that asks a batch of experiments at each time step t where the batch size p_t is dynamically determined in each step. Our algorithm is based on the observation that the sequence of experiments selected by the sequential policy can sometimes be almost independent from each other. Our algorithm identifies such scenarios and request those experiments at the same time without degrading the performance. We evaluate our proposed method using the Expected Improvement policy and the results show substantial speedup with little impact on the performance in eight real and synthetic benchmarks.</abstract>
   </article>
   <article>
      <title>Injecting External Solutions Into CMA-ES</title>
      <author>Nikolaus Hansen</author>
      <date>2011-10-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This report considers how to inject external candidate solutions into the CMA-ES algorithm. The injected solutions might stem from a gradient or a Newton step, a surrogate model optimizer or any other oracle or search mechanism. They can also be the result of a repair mechanism, for example to render infeasible solutions feasible. Only small modifications to the CMA-ES are necessary to turn injection into a reliable and effective method: too long steps need to be tightly renormalized. The main objective of this report is to reveal this simple mechanism. Depending on the source of the injected solutions, interesting variants of CMA-ES arise. When the best-ever solution is always (re-)injected, an elitist variant of CMA-ES with weighted multi-recombination arises. When \emph{all} solutions are injected from an \emph{external} source, the resulting algorithm might be viewed as \emph{adaptive encoding} with step-size control. In first experiments, injected solutions of very good quality lead to a convergence speed twice as fast as on the (simple) sphere function without injection. This means that we observe an impressive speed-up on otherwise difficult to solve functions. Single bad injected solutions on the other hand do no significant harm.</abstract>
   </article>
   <article>
      <title>Data-dependent kernels in nearly-linear time</title>
      <author>Guy Lever, Tom Diethe, John Shawe-Taylor</author>
      <date>2011-10-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a method to efficiently construct data-dependent kernels which can make use of large quantities of (unlabeled) data. Our construction makes an approximation in the standard construction of semi-supervised kernels in Sindhwani et al. 2005. In typical cases these kernels can be computed in nearly-linear time (in the amount of data), improving on the cubic time of the standard construction, enabling large scale semi-supervised learning in a variety of contexts. The methods are validated on semi-supervised and unsupervised problems on data sets containing upto 64,000 sample points.</abstract>
   </article>
   <article>
      <title>Learning Hierarchical and Topographic Dictionaries with Structured
  Sparsity</title>
      <author>Julien Mairal, Rodolphe Jenatton, Guillaume Obozinski, Francis Bach</author>
      <date>2011-10-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recent work in signal processing and statistics have focused on defining new regularization functions, which not only induce sparsity of the solution, but also take into account the structure of the problem. We present in this paper a class of convex penalties introduced in the machine learning community, which take the form of a sum of l_2 and l_infinity-norms over groups of variables. They extend the classical group-sparsity regularization in the sense that the groups possibly overlap, allowing more flexibility in the group design. We review efficient optimization methods to deal with the corresponding inverse problems, and their application to the problem of learning dictionaries of natural image patches: On the one hand, dictionary learning has indeed proven effective for various signal processing tasks. On the other hand, structured sparsity provides a natural framework for modeling dependencies between dictionary elements. We thus consider a structured sparse regularization to learn dictionaries embedded in a particular structure, for instance a tree or a two-dimensional grid. In the latter case, the results we obtain are similar to the dictionaries produced by topographic independent component analysis.</abstract>
   </article>
   <article>
      <title>Wikipedia Edit Number Prediction based on Temporal Dynamics Only</title>
      <author>Dell Zhang</author>
      <date>2011-10-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we describe our approach to the Wikipedia Participation Challenge which aims to predict the number of edits a Wikipedia editor will make in the next 5 months. The best submission from our team, "zeditor", achieved 41.7% improvement over WMF's baseline predictive model and the final rank of 3rd place among 96 teams. An interesting characteristic of our approach is that only temporal dynamics features (i.e., how the number of edits changes in recent periods, etc.) are used in a self-supervised learning framework, which makes it easy to be generalised to other application domains.</abstract>
   </article>
   <article>
      <title>Deciding of HMM parameters based on number of critical points for
  gesture recognition from motion capture data</title>
      <author>Michał Cholewa, Przemysław Głomb</author>
      <date>2011-10-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a method of choosing number of states of a HMM based on number of critical points of the motion capture data. The choice of Hidden Markov Models(HMM) parameters is crucial for recognizer's performance as it is the first step of the training and cannot be corrected automatically within HMM. In this article we define predictor of number of states based on number of critical points of the sequence and test its effectiveness against sample data.</abstract>
   </article>
   <article>
      <title>PAC-Bayes-Bernstein Inequality for Martingales and its Application to
  Multiarmed Bandits</title>
      <author>Yevgeny Seldin, Nicolò Cesa-Bianchi, Peter Auer, François Laviolette, John Shawe-Taylor</author>
      <date>2011-10-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We develop a new tool for data-dependent analysis of the exploration-exploitation trade-off in learning under limited feedback. Our tool is based on two main ingredients. The first ingredient is a new concentration inequality that makes it possible to control the concentration of weighted averages of multiple (possibly uncountably many) simultaneously evolving and interdependent martingales. The second ingredient is an application of this inequality to the exploration-exploitation trade-off via importance weighted sampling. We apply the new tool to the stochastic multiarmed bandit problem, however, the main importance of this paper is the development and understanding of the new tool rather than improvement of existing algorithms for stochastic multiarmed bandits. In the follow-up work we demonstrate that the new tool can improve over state-of-the-art in structurally richer problems, such as stochastic multiarmed bandits with side information (Seldin et al., 2011a).</abstract>
   </article>
   <article>
      <title>Confidence Estimation in Structured Prediction</title>
      <author>Avihai Mejer, Koby Crammer</author>
      <date>2011-11-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Structured classification tasks such as sequence labeling and dependency parsing have seen much interest by the Natural Language Processing and the machine learning communities. Several online learning algorithms were adapted for structured tasks such as Perceptron, Passive- Aggressive and the recently introduced Confidence-Weighted learning . These online algorithms are easy to implement, fast to train and yield state-of-the-art performance. However, unlike probabilistic models like Hidden Markov Model and Conditional random fields, these methods generate models that output merely a prediction with no additional information regarding confidence in the correctness of the output. In this work we fill the gap proposing few alternatives to compute the confidence in the output of non-probabilistic algorithms.We show how to compute confidence estimates in the prediction such that the confidence reflects the probability that the word is labeled correctly. We then show how to use our methods to detect mislabeled words, trade recall for precision and active learning. We evaluate our methods on four noun-phrase chunking and named entity recognition sequence labeling tasks, and on dependency parsing for 14 languages.</abstract>
   </article>
   <article>
      <title>Robust Interactive Learning</title>
      <author>Maria-Florina Balcan, Steve Hanneke</author>
      <date>2011-11-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we propose and study a generalization of the standard active-learning model where a more general type of query, class conditional query, is allowed. Such queries have been quite useful in applications, but have been lacking theoretical understanding. In this work, we characterize the power of such queries under two well-known noise models. We give nearly tight upper and lower bounds on the number of queries needed to learn both for the general agnostic setting and for the bounded noise model. We further show that our methods can be made adaptive to the (unknown) noise rate, with only negligible loss in query complexity.</abstract>
   </article>
   <article>
      <title>Parametrized Stochastic Multi-armed Bandits with Binary Rewards</title>
      <author>Chong Jiang, R. Srikant</author>
      <date>2011-11-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we consider the problem of multi-armed bandits with a large, possibly infinite number of correlated arms. We assume that the arms have Bernoulli distributed rewards, independent across time, where the probabilities of success are parametrized by known attribute vectors for each arm, as well as an unknown preference vector, each of dimension $n$. For this model, we seek an algorithm with a total regret that is sub-linear in time and independent of the number of arms. We present such an algorithm, which we call the Two-Phase Algorithm, and analyze its performance. We show upper bounds on the total regret which applies uniformly in time, for both the finite and infinite arm cases. The asymptotics of the finite arm bound show that for any $f \in \omega(\log(T))$, the total regret can be made to be $O(n \cdot f(T))$. In the infinite arm case, the total regret is $O(\sqrt{n^3 T})$.</abstract>
   </article>
   <article>
      <title>Efficient Regression in Metric Spaces via Approximate Lipschitz
  Extension</title>
      <author>Lee-Ad Gottlieb, Aryeh Kontorovich, Robert Krauthgamer</author>
      <date>2011-11-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a framework for performing efficient regression in general metric spaces. Roughly speaking, our regressor predicts the value at a new point by computing a Lipschitz extension --- the smoothest function consistent with the observed data --- after performing structural risk minimization to avoid overfitting. We obtain finite-sample risk bounds with minimal structural and noise assumptions, and a natural speed-precision tradeoff. The offline (learning) and online (prediction) stages can be solved by convex programming, but this naive approach has runtime complexity $O(n^3)$, which is prohibitive for large datasets. We design instead a regression algorithm whose speed and generalization performance depend on the intrinsic dimension of the data, to which the algorithm adapts. While our main innovation is algorithmic, the statistical results may also be of independent interest.</abstract>
   </article>
   <article>
      <title>Large Scale Spectral Clustering Using Approximate Commute Time Embedding</title>
      <author>Nguyen Lu Dang Khoa, Sanjay Chawla</author>
      <date>2011-11-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Spectral clustering is a novel clustering method which can detect complex shapes of data clusters. However, it requires the eigen decomposition of the graph Laplacian matrix, which is proportion to $O(n^3)$ and thus is not suitable for large scale systems. Recently, many methods have been proposed to accelerate the computational time of spectral clustering. These approximate methods usually involve sampling techniques by which a lot information of the original data may be lost. In this work, we propose a fast and accurate spectral clustering approach using an approximate commute time embedding, which is similar to the spectral embedding. The method does not require using any sampling technique and computing any eigenvector at all. Instead it uses random projection and a linear time solver to find the approximate embedding. The experiments in several synthetic and real datasets show that the proposed approach has better clustering quality and is faster than the state-of-the-art approximate spectral clustering methods.</abstract>
   </article>
   <article>
      <title>Trading Regret for Efficiency: Online Convex Optimization with Long Term
  Constraints</title>
      <author>Mehrdad Mahdavi, Rong Jin, Tianbao Yang</author>
      <date>2011-11-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we propose a framework for solving constrained online convex optimization problem. Our motivation stems from the observation that most algorithms proposed for online convex optimization require a projection onto the convex set $\mathcal{K}$ from which the decisions are made. While for simple shapes (e.g. Euclidean ball) the projection is straightforward, for arbitrary complex sets this is the main computational challenge and may be inefficient in practice. In this paper, we consider an alternative online convex optimization problem. Instead of requiring decisions belong to $\mathcal{K}$ for all rounds, we only require that the constraints which define the set $\mathcal{K}$ be satisfied in the long run. We show that our framework can be utilized to solve a relaxed version of online learning with side constraints addressed in \cite{DBLP:conf/colt/MannorT06} and \cite{DBLP:conf/aaai/KvetonYTM08}. By turning the problem into an online convex-concave optimization problem, we propose an efficient algorithm which achieves $\tilde{\mathcal{O}}(\sqrt{T})$ regret bound and $\tilde{\mathcal{O}}(T^{3/4})$ bound for the violation of constraints. Then we modify the algorithm in order to guarantee that the constraints are satisfied in the long run. This gain is achieved at the price of getting $\tilde{\mathcal{O}}(T^{3/4})$ regret bound. Our second algorithm is based on the Mirror Prox method \citep{nemirovski-2005-prox} to solve variational inequalities which achieves $\tilde{\mathcal{\mathcal{O}}}(T^{2/3})$ bound for both regret and the violation of constraints when the domain $\K$ can be described by a finite number of linear constraints. Finally, we extend the result to the setting where we only have partial access to the convex set $\mathcal{K}$ and propose a multipoint bandit feedback algorithm with the same bounds in expectation as our first algorithm.</abstract>
   </article>
   <article>
      <title>Regret Bound by Variation for Online Convex Optimization</title>
      <author>Tianbao Yang, Mehrdad Mahdavi, Rong Jin, Shenghuo Zhu</author>
      <date>2011-11-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In citep{Hazan-2008-extract}, the authors showed that the regret of online linear optimization can be bounded by the total variation of the cost vectors. In this paper, we extend this result to general online convex optimization. We first analyze the limitations of the algorithm in \citep{Hazan-2008-extract} when applied it to online convex optimization. We then present two algorithms for online convex optimization whose regrets are bounded by the variation of cost functions. We finally consider the bandit setting, and present a randomized algorithm for online bandit convex optimization with a variation-based regret bound. We show that the regret bound for online bandit convex optimization is optimal when the variation of cost functions is independent of the number of trials.</abstract>
   </article>
   <article>
      <title>Learning in embodied action-perception loops through exploration</title>
      <author>Daniel Y. Little, Friedrich T. Sommer</author>
      <date>2011-12-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Although exploratory behaviors are ubiquitous in the animal kingdom, their computational underpinnings are still largely unknown. Behavioral Psychology has identified learning as a primary drive underlying many exploratory behaviors. Exploration is seen as a means for an animal to gather sensory data useful for reducing its ignorance about the environment. While related problems have been addressed in Data Mining and Reinforcement Learning, the computational modeling of learning-driven exploration by embodied agents is largely unrepresented.   Here, we propose a computational theory for learning-driven exploration based on the concept of missing information that allows an agent to identify informative actions using Bayesian inference. We demonstrate that when embodiment constraints are high, agents must actively coordinate their actions to learn efficiently. Compared to earlier approaches, our exploration policy yields more efficient learning across a range of worlds with diverse structures. The improved learning in turn affords greater success in general tasks including navigation and reward gathering. We conclude by discussing how the proposed theory relates to previous information-theoretic objectives of behavior, such as predictive information and the free energy principle, and how it might contribute to a general theory of exploratory behavior.</abstract>
   </article>
   <article>
      <title>An Identity for Kernel Ridge Regression</title>
      <author>Fedor Zhdanov, Yuri Kalnishkan</author>
      <date>2011-12-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper derives an identity connecting the square loss of ridge regression in on-line mode with the loss of the retrospectively best regressor. Some corollaries about the properties of the cumulative loss of on-line ridge regression are also obtained.</abstract>
   </article>
   <article>
      <title>Bipartite ranking algorithm for classification and survival analysis</title>
      <author>Marina Sapir</author>
      <date>2011-12-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Unsupervised aggregation of independently built univariate predictors is explored as an alternative regularization approach for noisy, sparse datasets. Bipartite ranking algorithm Smooth Rank implementing this approach is introduced. The advantages of this algorithm are demonstrated on two types of problems. First, Smooth Rank is applied to two-class problems from bio-medical field, where ranking is often preferable to classification. In comparison against SVMs with radial and linear kernels, Smooth Rank had the best performance on 8 out of 12 benchmark benchmarks. The second area of application is survival analysis, which is reduced here to bipartite ranking in a way which allows one to use commonly accepted measures of methods performance. In comparison of Smooth Rank with Cox PH regression and CoxPath methods, Smooth Rank proved to be the best on 9 out of 10 benchmark datasets.</abstract>
   </article>
   <article>
      <title>Analysis and Extension of Arc-Cosine Kernels for Large Margin
  Classification</title>
      <author>Youngmin Cho, Lawrence K. Saul</author>
      <date>2011-12-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We investigate a recently proposed family of positive-definite kernels that mimic the computation in large <term>neural network</term>s. We examine the properties of these kernels using tools from differential geometry; specifically, we analyze the geometry of surfaces in Hilbert space that are induced by these kernels. When this geometry is described by a Riemannian manifold, we derive results for the metric, curvature, and volume element. Interestingly, though, we find that the simplest kernel in this family does not admit such an interpretation. We explore two variations of these kernels that mimic computation in <term>neural network</term>s with different activation functions. We experiment with these new kernels on several data sets and highlight their general trends in performance for classification.</abstract>
   </article>
   <article>
      <title>Nonnegative Matrix Factorization for Semi-supervised Dimensionality
  Reduction</title>
      <author>Youngmin Cho, Lawrence K. Saul</author>
      <date>2011-12-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We show how to incorporate information from labeled examples into nonnegative matrix factorization (NMF), a popular <term>unsupervised learning</term> algorithm for dimensionality reduction. In addition to mapping the data into a space of lower dimensionality, our approach aims to preserve the nonnegative components of the data that are important for classification. We identify these components from the support vectors of large-margin classifiers and derive iterative updates to preserve them in a semi-supervised version of NMF. These updates have a simple multiplicative form like their unsupervised counterparts; they are also guaranteed at each iteration to decrease their loss function---a weighted sum of I-divergences that captures the trade-off between unsupervised and supervised learning. We evaluate these updates for dimensionality reduction when they are used as a precursor to linear classification. In this role, we find that they yield much better performance than their unsupervised counterparts. We also find one unexpected benefit of the low dimensional representations discovered by our approach: often they yield more accurate classifiers than both ordinary and transductive SVMs trained in the original input space.</abstract>
   </article>
   <article>
      <title>Clustering and Latent Semantic Indexing Aspects of the Nonnegative
  Matrix Factorization</title>
      <author>Andri Mirzal</author>
      <date>2011-12-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper provides a theoretical support for clustering aspect of the nonnegative matrix factorization (NMF). By utilizing the Karush-Kuhn-Tucker optimality conditions, we show that NMF objective is equivalent to graph clustering objective, so clustering aspect of the NMF has a solid justification. Different from previous approaches which usually discard the nonnegativity constraints, our approach guarantees the stationary point being used in deriving the equivalence is located on the feasible region in the nonnegative orthant. Additionally, since clustering capability of a matrix decomposition technique can sometimes imply its latent semantic indexing (LSI) aspect, we will also evaluate LSI aspect of the NMF by showing its capability in solving the synonymy and polysemy problems in synthetic datasets. And more extensive evaluation will be conducted by comparing LSI performances of the NMF and the singular value decomposition (SVD), the standard LSI method, using some standard datasets.</abstract>
   </article>
   <article>
      <title>Evaluation of Performance Measures for Classifiers Comparison</title>
      <author>Vincent Labatut, Hocine Cherifi</author>
      <date>2011-12-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The selection of the best classification algorithm for a given dataset is a very widespread problem, occuring each time one has to choose a classifier to solve a real-world problem. It is also a complex task with many important methodological decisions to make. Among those, one of the most crucial is the choice of an appropriate measure in order to properly assess the classification performance and rank the algorithms. In this article, we focus on this specific task. We present the most popular measures and compare their behavior through discrimination plots. We then discuss their properties from a more theoretical perspective. It turns out several of them are equivalent for classifiers comparison purposes. Futhermore. they can also lead to interpretation problems. Among the numerous measures proposed over the years, it appears that the classical overall success rate and marginal rates are the more suitable for classifier comparison task.</abstract>
   </article>
   <article>
      <title>Modeling transition dynamics in MDPs with RKHS embeddings of conditional
  distributions</title>
      <author>Steffen Grünewälder, Luca Baldassarre, Massimiliano Pontil, Arthur Gretton, Guy Lever</author>
      <date>2011-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a new, nonparametric approach to estimating the value function in <term>reinforcement learning</term>. This approach makes use of a recently developed representation of conditional distributions as functions in a reproducing kernel Hilbert space. Such representations bypass the need for estimating transition probabilities, and apply to any domain on which kernels can be defined. Our approach avoids the need to approximate intractable integrals since expectations are represented as RKHS inner products whose computation has linear complexity in the sample size. Thus, we can efficiently perform value function estimation in a wide variety of settings, including finite state spaces, continuous states spaces, and partially observable tasks where only sensor measurements are available. A second advantage of the approach is that we learn the conditional distribution representation from a training sample, and do not require an exhaustive exploration of the state space. We prove convergence of our approach either to the optimal policy, or to the closest projection of the optimal policy in our model class, under reasonable assumptions. In experiments, we demonstrate the performance of our algorithm on a learning task in a continuous state space (the under-actuated pendulum), and on a navigation problem where only images from a sensor are observed. We compare with least-squares policy iteration where a Gaussian process is used for value function estimation. Our algorithm achieves better performance in both tasks.</abstract>
   </article>
   <article>
      <title>Combining One-Class Classifiers via Meta-Learning</title>
      <author>Eitan Menahem, Lior Rokach, Yuval Elovici</author>
      <date>2011-12-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Selecting the best classifier among the available ones is a difficult task, especially when only instances of one class exist. In this work we examine the notion of combining one-class classifiers as an alternative for selecting the best classifier. In particular, we propose two new one-class classification performance measures to weigh classifiers and show that a simple ensemble that implements these measures can outperform the most popular one-class ensembles. Furthermore, we propose a new one-class ensemble scheme, TUPSO, which uses meta-learning to combine one-class classifiers. Our experiments demonstrate the superiority of TUPSO over all other tested ensembles and show that the TUPSO performance is statistically indistinguishable from that of the hypothetical best classifier.</abstract>
   </article>
   <article>
      <title>Building high-level features using large scale unsupervised learning</title>
      <author>Quoc V. Le, Marc'Aurelio Ranzato, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado, Jeff Dean, Andrew Y. Ng</author>
      <date>2011-12-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art.</abstract>
   </article>
   <article>
      <title>Two-Manifold Problems</title>
      <author>Byron Boots, Geoffrey J. Gordon</author>
      <date>2011-12-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently, there has been much interest in spectral approaches to learning manifolds---so-called kernel eigenmap methods. These methods have had some successes, but their applicability is limited because they are not robust to noise. To address this limitation, we look at two-manifold problems, in which we simultaneously reconstruct two related manifolds, each representing a different view of the same data. By solving these interconnected learning problems together and allowing information to flow between them, two-manifold algorithms are able to succeed where a non-integrated approach would fail: each view allows us to suppress noise in the other, reducing bias in the same way that an instrumental variable allows us to remove bias in a {linear} dimensionality reduction problem. We propose a class of algorithms for two-manifold problems, based on spectral decomposition of cross-covariance operators in Hilbert space. Finally, we discuss situations where two-manifold problems are useful, and demonstrate that solving a two-manifold problem can aid in learning a nonlinear dynamical system from limited data.</abstract>
   </article>
   <article>
      <title>T-Learning</title>
      <author>Vincent Graziano, Faustino Gomez, Mark Ring, Juergen Schmidhuber</author>
      <date>2011-12-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Traditional Reinforcement Learning (RL) has focused on problems involving many states and few actions, such as simple grid worlds. Most real world problems, however, are of the opposite type, Involving Few relevant states and many actions. For example, to return home from a conference, humans identify only few subgoal states such as lobby, taxi, airport etc. Each valid behavior connecting two such states can be viewed as an action, and there are trillions of them. Assuming the subgoal identification problem is already solved, the quality of any RL method---in real-world settings---depends less on how well it scales with the number of states than on how well it scales with the number of actions. This is where our new method T-Learning excels, by evaluating the relatively few possible transits from one state to another in a policy-independent way, rather than a huge number of state-action pairs, or states in traditional policy-dependent ways. Illustrative experiments demonstrate that performance improvements of T-Learning over Q-learning can be arbitrarily large.</abstract>
   </article>
   <article>
      <title>A Topic Modeling Toolbox Using Belief Propagation</title>
      <author>Jia Zeng</author>
      <date>2012-01-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Latent Dirichlet allocation (LDA) is an important hierarchical Bayesian model for probabilistic topic modeling, which attracts worldwide interests and touches on many important applications in text mining, computer vision and computational biology. This paper introduces a topic modeling toolbox (TMBP) based on the belief propagation (BP) algorithms. TMBP toolbox is implemented by MEX C++/Matlab/Octave for either Windows 7 or Linux. Compared with existing topic modeling packages, the novelty of this toolbox lies in the BP algorithms for learning LDA-based topic models. The current version includes BP algorithms for latent Dirichlet allocation (LDA), author-topic models (ATM), relational topic models (RTM), and labeled LDA (LaLDA). This toolbox is an ongoing project and more BP-based algorithms for various topic models will be added in the near future. Interested users may also extend BP algorithms for learning more complicated topic models. The source codes are freely available under the GNU General Public Licence, Version 1.0 at https://mloss.org/software/view/399/.</abstract>
   </article>
   <article>
      <title>Customers Behavior Modeling by Semi-Supervised Learning in Customer
  Relationship Management</title>
      <author>Siavash Emtiyaz, MohammadReza Keyvanpour</author>
      <date>2012-01-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Leveraging the power of increasing amounts of data to analyze customer base for attracting and retaining the most valuable customers is a major problem facing companies in this information age. Data mining technologies extract hidden information and knowledge from large data stored in databases or data warehouses, thereby supporting the corporate decision making process. CRM uses data mining (one of the elements of CRM) techniques to interact with customers. This study investigates the use of a technique, semi-supervised learning, for the management and analysis of customer-related data warehouse and information. The idea of semi-supervised learning is to learn not only from the labeled training data, but to exploit also the structural information in additionally available unlabeled data. The proposed semi-supervised method is a model by means of a feed-forward <term>neural network</term> trained by a back propagation algorithm (multi-layer perceptron) in order to predict the category of an unknown customer (potential customers). In addition, this technique can be used with Rapid Miner tools for both labeled and unlabeled data.</abstract>
   </article>
   <article>
      <title>Automatic Detection of Diabetes Diagnosis using Feature Weighted Support
  Vector Machines based on Mutual Information and Modified Cuckoo Search</title>
      <author>Davar Giveki, Hamid Salimi, GholamReza Bahmanyar, Younes Khademian</author>
      <date>2012-01-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Diabetes is a major health problem in both developing and developed countries and its incidence is rising dramatically. In this study, we investigate a novel automatic approach to diagnose Diabetes disease based on Feature Weighted Support Vector Machines (FW-SVMs) and Modified Cuckoo Search (MCS). The proposed model consists of three stages: Firstly, PCA is applied to select an optimal subset of features out of set of all the features. Secondly, Mutual Information is employed to construct the FWSVM by weighting different features based on their degree of importance. Finally, since parameter selection plays a vital role in classification accuracy of SVMs, MCS is applied to select the best parameter values. The proposed MI-MCS-FWSVM method obtains 93.58% accuracy on UCI dataset. The experimental results demonstrate that our method outperforms the previous methods by not only giving more accurate results but also significantly speeding up the classification procedure.</abstract>
   </article>
   <article>
      <title>Stochastic Low-Rank Kernel Learning for Regression</title>
      <author>Pierre Machart, Thomas Peel, Liva Ralaivola, Sandrine Anthoine, Hervé Glotin</author>
      <date>2012-01-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a novel approach to learn a kernel-based regression function. It is based on the useof conical combinations of data-based parameterized kernels and on a new stochastic convex optimization procedure of which we establish convergence guarantees. The overall learning procedure has the nice properties that a) the learned conical combination is automatically designed to perform the regression task at hand and b) the updates implicated by the optimization procedure are quite inexpensive. In order to shed light on the appositeness of our learning strategy, we present empirical results from experiments conducted on various benchmark datasets.</abstract>
   </article>
   <article>
      <title>Acoustical Quality Assessment of the Classroom Environment</title>
      <author>Marian George, Moustafa Youssef</author>
      <date>2012-01-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Teaching is one of the most important factors affecting any education system. Many research efforts have been conducted to facilitate the presentation modes used by instructors in classrooms as well as provide means for students to review lectures through web browsers. Other studies have been made to provide acoustical design recommendations for classrooms like room size and reverberation times. However, using acoustical features of classrooms as a way to provide education systems with feedback about the learning process was not thoroughly investigated in any of these studies. We propose a system that extracts different sound features of students and instructors, and then uses machine learning techniques to evaluate the acoustical quality of any learning environment. We infer conclusions about the students' satisfaction with the quality of lectures. Using classifiers instead of surveys and other subjective ways of measures can facilitate and speed such experiments which enables us to perform them continuously. We believe our system enables education systems to continuously review and improve their teaching strategies and acoustical quality of classrooms.</abstract>
   </article>
   <article>
      <title>An Efficient Primal-Dual Prox Method for Non-Smooth Optimization</title>
      <author>Tianbao Yang, Mehrdad Mahdavi, Rong Jin, Shenghuo Zhu</author>
      <date>2012-01-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the non-smooth optimization problems in machine learning, where both the loss function and the regularizer are non-smooth functions. Previous studies on efficient empirical loss minimization assume either a smooth loss function or a strongly convex regularizer, making them unsuitable for non-smooth optimization. We develop a simple yet efficient method for a family of non-smooth optimization problems where the dual form of the loss function is bilinear in primal and dual variables. We cast a non-smooth optimization problem into a minimax optimization problem, and develop a primal dual prox method that solves the minimax optimization problem at a rate of $O(1/T)$ {assuming that the proximal step can be efficiently solved}, significantly faster than a standard sub<term>gradient descent</term> method that has an $O(1/\sqrt{T})$ convergence rate. Our empirical study verifies the efficiency of the proposed method for various non-smooth optimization problems that arise ubiquitously in machine learning by comparing it to the state-of-the-art first order methods.</abstract>
   </article>
   <article>
      <title>A Comparison Between Data Mining Prediction Algorithms for Fault
  Detection(Case study: Ahanpishegan co.)</title>
      <author>Golriz Amooee, Behrouz Minaei-Bidgoli, Malihe Bagheri-Dehnavi</author>
      <date>2012-01-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In the current competitive world, industrial companies seek to manufacture products of higher quality which can be achieved by increasing reliability, maintainability and thus the availability of products. On the other hand, improvement in products lifecycle is necessary for achieving high reliability. Typically, maintenance activities are aimed to reduce failures of industrial machinery and minimize the consequences of such failures. So the industrial companies try to improve their efficiency by using different fault detection techniques. One strategy is to process and analyze previous generated data to predict future failures. The purpose of this paper is to detect wasted parts using different data mining algorithms and compare the accuracy of these algorithms. A combination of thermal and physical characteristics has been used and the algorithms were implemented on Ahanpishegan's current data to estimate the availability of its produced parts.   Keywords: Data Mining, Fault Detection, Availability, Prediction Algorithms.</abstract>
   </article>
   <article>
      <title>Active Learning of Custering with Side Information Using $\eps$-Smooth
  Relative Regret Approximations</title>
      <author>Nir Ailon, Ron Begleiter</author>
      <date>2012-01-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Clustering is considered a non-supervised learning setting, in which the goal is to partition a collection of data points into disjoint clusters. Often a bound $k$ on the number of clusters is given or assumed by the practitioner. Many versions of this problem have been defined, most notably $k$-means and $k$-median.   An underlying problem with the unsupervised nature of clustering it that of determining a similarity function. One approach for alleviating this difficulty is known as clustering with side information, alternatively, semi-supervised clustering. Here, the practitioner incorporates side information in the form of "must be clustered" or "must be separated" labels for data point pairs. Each such piece of information comes at a "query cost" (often involving human response solicitation). The collection of labels is then incorporated in the usual clustering algorithm as either strict or as soft constraints, possibly adding a pairwise constraint penalty function to the chosen clustering objective.   Our work is mostly related to clustering with side information. We ask how to choose the pairs of data points. Our analysis gives rise to a method provably better than simply choosing them uniformly at random. Roughly speaking, we show that the distribution must be biased so as more weight is placed on pairs incident to elements in smaller clusters in some optimal solution. Of course we do not know the optimal solution, hence we don't know the bias. Using the recently introduced method of $\eps$-smooth relative regret approximations of Ailon, Begleiter and Ezra, we can show an iterative process that improves both the clustering and the bias in tandem. The process provably converges to the optimal solution faster (in terms of query cost) than an algorithm selecting pairs uniformly.</abstract>
   </article>
   <article>
      <title>Contextual Bandit Learning with Predictable Rewards</title>
      <author>Alekh Agarwal, Miroslav Dudík, Satyen Kale, John Langford, Robert E. Schapire</author>
      <date>2012-02-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Contextual bandit learning is a <term>reinforcement learning</term> problem where the learner repeatedly receives a set of features (context), takes an action and receives a reward based on the action and context. We consider this problem under a realizability assumption: there exists a function in a (known) function class, always capable of predicting the expected reward, given the action and context. Under this assumption, we show three things. We present a new algorithm---Regressor Elimination--- with a regret similar to the agnostic setting (i.e. in the absence of realizability assumption). We prove a new lower bound showing no algorithm can achieve superior performance in the worst case even with the realizability assumption. However, we do show that for any set of policies (mapping contexts to actions), there is a distribution over rewards (given context) such that our new algorithm has constant regret unlike the previous approaches.</abstract>
   </article>
   <article>
      <title>On the Performance of Maximum Likelihood Inverse Reinforcement Learning</title>
      <author>Héctor Ratia, Luis Montesano, Ruben Martinez-Cantin</author>
      <date>2012-02-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Inverse <term>reinforcement learning</term> (IRL) addresses the problem of recovering a task description given a demonstration of the optimal policy used to solve such a task. The optimal policy is usually provided by an expert or teacher, making IRL specially suitable for the problem of apprenticeship learning. The task description is encoded in the form of a reward function of a Markov decision process (MDP). Several algorithms have been proposed to find the reward function corresponding to a set of demonstrations. One of the algorithms that has provided best results in different applications is a gradient method to optimize a policy squared error criterion. On a parallel line of research, other authors have presented recently a gradient approximation of the maximum likelihood estimate of the reward signal. In general, both approaches approximate the gradient estimate and the criteria at different stages to make the algorithm tractable and efficient. In this work, we provide a detailed description of the different methods to highlight differences in terms of reward estimation, policy similarity and computational costs. We also provide experimental results to evaluate the differences in performance of the methods.</abstract>
   </article>
   <article>
      <title>PAC Bounds for Discounted MDPs</title>
      <author>Tor Lattimore, Marcus Hutter</author>
      <date>2012-02-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study upper and lower bounds on the sample-complexity of learning near-optimal behaviour in finite-state discounted Markov Decision Processes (MDPs). For the upper bound we make the assumption that each action leads to at most two possible next-states and prove a new bound for a UCRL-style algorithm on the number of time-steps when it is not Probably Approximately Correct (PAC). The new lower bound strengthens previous work by being both more general (it applies to all policies) and tighter. The upper and lower bounds match up to logarithmic factors.</abstract>
   </article>
   <article>
      <title>Confusion Matrix Stability Bounds for Multiclass Classification</title>
      <author>Pierre Machart, Liva Ralaivola</author>
      <date>2012-02-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we provide new theoretical results on the generalization properties of learning algorithms for multiclass classification problems. The originality of our work is that we propose to use the confusion matrix of a classifier as a measure of its quality; our contribution is in the line of work which attempts to set up and study the statistical properties of new evaluation measures such as, e.g. ROC curves. In the confusion-based learning framework we propose, we claim that a targetted objective is to minimize the size of the confusion matrix C, measured through its operator norm ||C||. We derive generalization bounds on the (size of the) confusion matrix in an extended framework of uniform stability, adapted to the case of matrix valued loss. Pivotal to our study is a very recent matrix concentration inequality that generalizes McDiarmid's inequality. As an illustration of the relevance of our theoretical results, we show how two SVM learning procedures can be proved to be confusion-friendly. To the best of our knowledge, the present paper is the first that focuses on the confusion matrix from a theoretical point of view.</abstract>
   </article>
   <article>
      <title>Application of Gist SVM in Cancer Detection</title>
      <author>S. Aruna, S. P. Rajagopalan, L. V. Nandakishore</author>
      <date>2012-03-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we study the application of GIST SVM in disease prediction (detection of cancer). Pattern classification problems can be effectively solved by Support vector machines. Here we propose a classifier which can differentiate patients having benign and malignant cancer cells. To improve the accuracy of classification, we propose to determine the optimal size of the training set and perform feature selection. To find the optimal size of the training set, different sizes of training sets are experimented and the one with highest classification rate is selected. The optimal features are selected through their F-Scores.</abstract>
   </article>
   <article>
      <title>On the Necessity of Irrelevant Variables</title>
      <author>David P. Helmbold, Philip M. Long</author>
      <date>2012-03-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work explores the effects of relevant and irrelevant boolean variables on the accuracy of classifiers. The analysis uses the assumption that the variables are conditionally independent given the class, and focuses on a natural family of learning algorithms for such sources when the relevant variables have a small advantage over random guessing. The main result is that algorithms relying predominately on irrelevant variables have error probabilities that quickly go to 0 in situations where algorithms that limit the use of irrelevant variables have errors bounded below by a positive constant. We also show that accurate learning is possible even when there are so few examples that one cannot determine with high confidence whether or not any individual variable is relevant.</abstract>
   </article>
   <article>
      <title>Data Mining: A Prediction for Performance Improvement of Engineering
  Students using Classification</title>
      <author>Surjeet Kumar Yadav, Saurabh Pal</author>
      <date>2012-03-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Now-a-days the amount of data stored in educational database increasing rapidly. These databases contain hidden information for improvement of students' performance. Educational data mining is used to study the data available in the educational field and bring out the hidden knowledge from it. Classification methods like decision trees, Bayesian network etc can be applied on the educational data for predicting the student's performance in examination. This prediction will help to identify the weak students and help them to score better marks. The C4.5, ID3 and CART decision tree algorithms are applied on engineering student's data to predict their performance in the final exam. The outcome of the decision tree predicted the number of students who are likely to pass, fail or promoted to next year. The results provide steps to improve the performance of the students who were predicted to fail or promoted. After the declaration of the results in the final examination the marks obtained by the students are fed into the system and the results were analyzed for the next session. The comparative analysis of the results states that the prediction has helped the weaker students to improve and brought out betterment in the result.</abstract>
   </article>
   <article>
      <title>Adaptive Mixture Methods Based on Bregman Divergences</title>
      <author>Mehmet A. Donmez, Huseyin A. Inan, Suleyman S. Kozat</author>
      <date>2012-03-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We investigate adaptive mixture methods that linearly combine outputs of $m$ constituent filters running in parallel to model a desired signal. We use "Bregman divergences" and obtain certain multiplicative updates to train the linear combination weights under an affine constraint or without any constraints. We use unnormalized relative entropy and relative entropy to define two different Bregman divergences that produce an unnormalized exponentiated gradient update and a normalized exponentiated gradient update on the mixture weights, respectively. We then carry out the mean and the mean-square transient analysis of these adaptive algorithms when they are used to combine outputs of $m$ constituent filters. We illustrate the accuracy of our results and demonstrate the effectiveness of these updates for sparse mixture systems.</abstract>
   </article>
   <article>
      <title>Very Short Literature Survey From Supervised Learning To Surrogate
  Modeling</title>
      <author>Altay Brusan</author>
      <date>2012-03-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The past century was era of linear systems. Either systems (especially industrial ones) were simple (quasi)linear or linear approximations were accurate enough. In addition, just at the ending decades of the century profusion of computing devices were available, before then due to lack of computational resources it was not easy to evaluate available nonlinear system studies. At the moment both these two conditions changed, systems are highly complex and also pervasive amount of computation strength is cheap and easy to achieve. For recent era, a new branch of supervised learning well known as surrogate modeling (meta-modeling, surface modeling) has been devised which aimed at answering new needs of modeling realm. This short literature survey is on to introduce surrogate modeling to whom is familiar with the concepts of supervised learning. Necessity, challenges and visions of the topic are considered.</abstract>
   </article>
   <article>
      <title>Credal Classification based on AODE and compression coefficients</title>
      <author>Giorgio Corani, Alessandro Antonucci</author>
      <date>2012-03-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Bayesian model averaging (BMA) is an approach to average over alternative models; yet, it usually gets excessively concentrated around the single most probable model, therefore achieving only sub-optimal classification performance. The compression-based approach (Boulle, 2007) overcomes this problem, averaging over the different models by applying a logarithmic smoothing over the models' posterior probabilities. This approach has shown excellent performances when applied to ensembles of naive Bayes classifiers. AODE is another ensemble of models with high performance (Webb, 2005), based on a collection of non-naive classifiers (called SPODE) whose probabilistic predictions are aggregated by simple arithmetic mean. Aggregating the SPODEs via BMA rather than by arithmetic mean deteriorates the performance; instead, we aggregate the SPODEs via the compression coefficients and we show that the resulting classifier obtains a slight but consistent improvement over AODE. However, an important issue in any Bayesian ensemble of models is the arbitrariness in the choice of the prior over the models. We address this problem by the paradigm of credal classification, namely by substituting the unique prior with a set of priors. Credal classifier automatically recognize the prior-dependent instances, namely the instances whose most probable class varies, when different priors are considered; in these cases, credal classifiers remain reliable by returning a set of classes rather than a single class. We thus develop the credal version of both the BMA-based and the compression-based ensemble of SPODEs, substituting the single prior over the models by a set of priors. Experiments show that both credal classifiers provide higher classification reliability than their determinate counterparts; moreover the compression-based credal classifier compares favorably to previous credal classifiers.</abstract>
   </article>
   <article>
      <title>Minimax Classifier for Uncertain Costs</title>
      <author>Rui Wang, Ke Tang</author>
      <date>2012-05-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many studies on the cost-sensitive learning assumed that a unique cost matrix is known for a problem. However, this assumption may not hold for many real-world problems. For example, a classifier might need to be applied in several circumstances, each of which associates with a different cost matrix. Or, different human experts have different opinions about the costs for a given problem. Motivated by these facts, this study aims to seek the minimax classifier over multiple cost matrices. In summary, we theoretically proved that, no matter how many cost matrices are involved, the minimax problem can be tackled by solving a number of standard cost-sensitive problems and sub-problems that involve only two cost matrices. As a result, a general framework for achieving minimax classifier over multiple cost matrices is suggested and justified by preliminary empirical studies.</abstract>
   </article>
   <article>
      <title>Greedy Multiple Instance Learning via Codebook Learning and Nearest
  Neighbor Voting</title>
      <author>Gang Chen, Jason Corso</author>
      <date>2012-05-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multiple instance learning (MIL) has attracted great attention recently in machine learning community. However, most MIL algorithms are very slow and cannot be applied to large datasets. In this paper, we propose a greedy strategy to speed up the multiple instance learning process. Our contribution is two fold. First, we propose a density ratio model, and show that maximizing a density ratio function is the low bound of the DD model under certain conditions. Secondly, we make use of a histogram ratio between positive bags and negative bags to represent the density ratio function and find codebooks separately for positive bags and negative bags by a greedy strategy. For testing, we make use of a nearest neighbor strategy to classify new bags. We test our method on both small benchmark datasets and the large TRECVID MED11 dataset. The experimental results show that our method yields comparable accuracy to the current state of the art, while being up to at least one order of magnitude faster.</abstract>
   </article>
   <article>
      <title>A Converged Algorithm for Tikhonov Regularized Nonnegative Matrix
  Factorization with Automatic Regularization Parameters Determination</title>
      <author>Andri Mirzal</author>
      <date>2012-05-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a converged algorithm for Tikhonov regularized nonnegative matrix factorization (NMF). We specially choose this regularization because it is known that Tikhonov regularized least square (LS) is the more preferable form in solving linear inverse problems than the conventional LS. Because an NMF problem can be decomposed into LS subproblems, it can be expected that Tikhonov regularized NMF will be the more appropriate approach in solving NMF problems. The algorithm is derived using additive update rules which have been shown to have convergence guarantee. We equip the algorithm with a mechanism to automatically determine the regularization parameters based on the L-curve, a well-known concept in the inverse problems community, but is rather unknown in the NMF research. The introduction of this algorithm thus solves two inherent problems in Tikhonov regularized NMF algorithm research, i.e., convergence guarantee and regularization parameters determination.</abstract>
   </article>
   <article>
      <title>Efficient Constrained Regret Minimization</title>
      <author>Mehrdad Mahdavi, Tianbao Yang, Rong Jin</author>
      <date>2012-05-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Online learning constitutes a mathematical and compelling framework to analyze sequential decision making problems in adversarial environments. The learner repeatedly chooses an action, the environment responds with an outcome, and then the learner receives a reward for the played action. The goal of the learner is to maximize his total reward. However, there are situations in which, in addition to maximizing the cumulative reward, there are some additional constraints on the sequence of decisions that must be satisfied on average by the learner. In this paper we study an extension to the online learning where the learner aims to maximize the total reward given that some additional constraints need to be satisfied. By leveraging on the theory of Lagrangian method in constrained optimization, we propose Lagrangian exponentially weighted average (LEWA) algorithm, which is a primal-dual variant of the well known exponentially weighted average algorithm, to efficiently solve constrained online decision making problems. Using novel theoretical analysis, we establish the regret and the violation of the constraint bounds in full information and bandit feedback models.</abstract>
   </article>
   <article>
      <title>A Uniqueness Theorem for Clustering</title>
      <author>Reza Bosagh Zadeh, Shai Ben-David</author>
      <date>2012-05-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Despite the widespread use of Clustering, there is distressingly little general theory of clustering available. Questions like "What distinguishes a clustering of data from other data partitioning?", "Are there any principles governing all clustering paradigms?", "How should a user choose an appropriate clustering algorithm for a particular task?", etc. are almost completely unanswered by the existing body of clustering literature. We consider an axiomatic approach to the theory of Clustering. We adopt the framework of Kleinberg, [Kle03]. By relaxing one of Kleinberg's clustering axioms, we sidestep his impossibility result and arrive at a consistent set of axioms. We suggest to extend these axioms, aiming to provide an axiomatic taxonomy of clustering paradigms. Such a taxonomy should provide users some guidance concerning the choice of the appropriate clustering paradigm for a given task. The main result of this paper is a set of abstract properties that characterize the Single-Linkage clustering function. This characterization result provides new insight into the properties of desired data groupings that make Single-Linkage the appropriate choice. We conclude by considering a taxonomy of clustering functions based on abstract properties that each satisfies.</abstract>
   </article>
   <article>
      <title>The Entire Quantile Path of a Risk-Agnostic SVM Classifier</title>
      <author>Jin Yu, S. V. N. Vishwanatan, Jian Zhang</author>
      <date>2012-05-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A quantile binary classifier uses the rule: Classify x as +1 if P(Y = 1|X = x) &gt;= t, and as -1 otherwise, for a fixed quantile parameter t {[0, 1]. It has been shown that Support Vector Machines (SVMs) in the limit are quantile classifiers with t = 1/2 . In this paper, we show that by using asymmetric cost of misclassification SVMs can be appropriately extended to recover, in the limit, the quantile binary classifier for any t. We then present a principled algorithm to solve the extended SVM classifier for all values of t simultaneously. This has two implications: First, one can recover the entire conditional distribution P(Y = 1|X = x) = t for t {[0, 1]. Second, we can build a risk-agnostic SVM classifier where the cost of misclassification need not be known apriori. Preliminary numerical experiments show the effectiveness of the proposed algorithm.</abstract>
   </article>
   <article>
      <title>Probabilistic Structured Predictors</title>
      <author>Shankar Vembu, Thomas Gartner, Mario Boley</author>
      <date>2012-05-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider MAP estimators for structured prediction with exponential family models. In particular, we concentrate on the case that efficient algorithms for uniform sampling from the output space exist. We show that under this assumption (i) exact computation of the partition function remains a hard problem, and (ii) the partition function and the gradient of the log partition function can be approximated efficiently. Our main result is an approximation scheme for the partition function based on Markov Chain Monte Carlo theory. We also show that the efficient uniform sampling assumption holds in several application settings that are of importance in machine learning.</abstract>
   </article>
   <article>
      <title>REGAL: A Regularization based Algorithm for Reinforcement Learning in
  Weakly Communicating MDPs</title>
      <author>Peter L. Bartlett, Ambuj Tewari</author>
      <date>2012-05-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We provide an algorithm that achieves the optimal regret rate in an unknown weakly communicating Markov Decision Process (MDP). The algorithm proceeds in episodes where, in each episode, it picks a policy using regularization based on the span of the optimal bias vector. For an MDP with S states and A actions whose optimal bias vector has span bounded by H, we show a regret bound of ~O(HSpAT). We also relate the span to various diameter-like quantities associated with the MDP, demonstrating how our results improve on previous regret bounds.</abstract>
   </article>
   <article>
      <title>A Bayesian Sampling Approach to Exploration in Reinforcement Learning</title>
      <author>John Asmuth, Lihong Li, Michael L. Littman, Ali Nouri, David Wingate</author>
      <date>2012-05-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a modular approach to <term>reinforcement learning</term> that uses a Bayesian representation of the uncertainty over models. The approach, BOSS (Best of Sampled Set), drives exploration by sampling multiple models from the posterior and selecting actions optimistically. It extends previous work by providing a rule for deciding when to resample and how to combine the models. We show that our algorithm achieves nearoptimal reward with high probability with a sample complexity that is low relative to the speed at which the posterior distribution converges during learning. We demonstrate that BOSS performs quite favorably compared to state-of-the-art reinforcement-learning approaches and illustrate its flexibility by pairing it with a non-parametric model that generalizes across states.</abstract>
   </article>
   <article>
      <title>Decoupling Exploration and Exploitation in Multi-Armed Bandits</title>
      <author>Orly Avner, Shie Mannor, Ohad Shamir</author>
      <date>2012-05-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a multi-armed bandit problem where the decision maker can explore and exploit different arms at every round. The exploited arm adds to the decision maker's cumulative reward (without necessarily observing the reward) while the explored arm reveals its value. We devise algorithms for this setup and show that the dependence on the number of arms, k, can be much better than the standard square root of k dependence, depending on the behavior of the arms' reward sequences. For the important case of piecewise stationary stochastic bandits, we show a significant improvement over existing algorithms. Our algorithms are based on a non-uniform sampling policy, which we show is essential to the success of any algorithm in the adversarial setup. Finally, we show some simulation results on an ultra-wide band channel selection inspired setting indicating the applicability of our algorithms.</abstract>
   </article>
   <article>
      <title>Normalized Maximum Likelihood Coding for Exponential Family with Its
  Applications to Optimal Clustering</title>
      <author>So Hirai, Kenji Yamanishi</author>
      <date>2012-05-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We are concerned with the issue of how to calculate the normalized maximum likelihood (NML) code-length. There is a problem that the normalization term of the NML code-length may diverge when it is continuous and unbounded and a straightforward computation of it is highly expensive when the data domain is finite . In previous works it has been investigated how to calculate the NML code-length for specific types of distributions. We first propose a general method for computing the NML code-length for the exponential family. Then we specifically focus on Gaussian mixture model (GMM), and propose a new efficient method for computing the NML to them. We develop it by generalizing Rissanen's re-normalizing technique. Then we apply this method to the clustering issue, in which a clustering structure is modeled using a GMM, and the main task is to estimate the optimal number of clusters on the basis of the NML code-length. We demonstrate using artificial data sets the superiority of the NML-based clustering over other criteria such as AIC, BIC in terms of the data size required for high accuracy rate to be achieved.</abstract>
   </article>
   <article>
      <title>Visualization of features of a series of measurements with
  one-dimensional cellular structure</title>
      <author>D. V. Lande</author>
      <date>2012-05-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper describes the method of visualization of periodic constituents and instability areas in series of measurements, being based on the algorithm of smoothing out and concept of one-dimensional cellular automata. A method can be used at the analysis of temporal series, related to the volumes of thematic publications in web-space.</abstract>
   </article>
   <article>
      <title>The Role of Weight Shrinking in Large Margin Perceptron Learning</title>
      <author>Constantinos Panagiotakopoulos, Petroula Tsampouka</author>
      <date>2012-05-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce into the classical perceptron algorithm with margin a mechanism that shrinks the current weight vector as a first step of the update. If the shrinking factor is constant the resulting algorithm may be regarded as a margin-error-driven version of NORMA with constant learning rate. In this case we show that the allowed strength of shrinking depends on the value of the maximum margin. We also consider variable shrinking factors for which there is no such dependence. In both cases we obtain new generalizations of the perceptron with margin able to provably attain in a finite number of steps any desirable approximation of the maximal margin hyperplane. The new approximate maximum margin classifiers appear experimentally to be very competitive in 2-norm soft margin tasks involving linear kernels.</abstract>
   </article>
   <article>
      <title>Safe Exploration in Markov Decision Processes</title>
      <author>Teodor Mihai Moldovan, Pieter Abbeel</author>
      <date>2012-05-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In environments with uncertain dynamics exploration is necessary to learn how to perform well. Existing <term>reinforcement learning</term> algorithms provide strong exploration guarantees, but they tend to rely on an ergodicity assumption. The essence of ergodicity is that any state is eventually reachable from any other state by following a suitable policy. This assumption allows for exploration algorithms that operate by simply favoring states that have rarely been visited before. For most physical systems this assumption is impractical as the systems would break before any reasonable exploration has taken place, i.e., most physical systems don't satisfy the ergodicity assumption. In this paper we address the need for safe exploration methods in Markov decision processes. We first propose a general formulation of safety through ergodicity. We show that imposing safety by restricting attention to the resulting set of guaranteed safe policies is NP-hard. We then present an efficient algorithm for guaranteed safe, but potentially suboptimal, exploration. At the core is an optimization formulation in which the constraints restrict attention to a subset of the guaranteed safe policies and the objective favors exploration policies. Our framework is compatible with the majority of previously proposed exploration methods, which rely on an exploration bonus. Our experiments, which include a Martian terrain exploration problem, show that our method is able to explore better than classical exploration methods.</abstract>
   </article>
   <article>
      <title>Off-Policy Actor-Critic</title>
      <author>Thomas Degris, Martha White, Richard S. Sutton</author>
      <date>2012-05-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents the first actor-critic algorithm for off-policy <term>reinforcement learning</term>. Our algorithm is online and incremental, and its per-time-step complexity scales linearly with the number of learned weights. Previous work on actor-critic algorithms is limited to the on-policy setting and does not take advantage of the recent advances in off-policy gradient temporal-difference learning. Off-policy techniques, such as Greedy-GQ, enable a target policy to be learned while following and obtaining data from another (behavior) policy. For many problems, however, actor-critic methods are more practical than action value methods (like Greedy-GQ) because they explicitly represent the policy; consequently, the policy can be stochastic and utilize a large action space. In this paper, we illustrate how to practically combine the generality and learning potential of off-policy learning with the flexibility in action selection given by actor-critic methods. We derive an incremental, linear time and space complexity algorithm that includes eligibility traces, prove convergence under assumptions similar to previous off-policy algorithms, and empirically show better or comparable performance to existing algorithms on standard reinforcement-learning benchmark problems.</abstract>
   </article>
   <article>
      <title>Multiclass Learning Approaches: A Theoretical Comparison with
  Implications</title>
      <author>Amit Daniely, Sivan Sabato, Shai Shalev Shwartz</author>
      <date>2012-05-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We theoretically analyze and compare the following five popular multiclass classification methods: One vs. All, All Pairs, Tree-based classifiers, Error Correcting Output Codes (ECOC) with randomly generated code matrices, and Multiclass SVM. In the first four methods, the classification is based on a reduction to binary classification. We consider the case where the binary classifier comes from a class of VC dimension $d$, and in particular from the class of halfspaces over $\reals^d$. We analyze both the estimation error and the approximation error of these methods. Our analysis reveals interesting conclusions of practical relevance, regarding the success of the different approaches under various conditions. Our proof technique employs tools from VC theory to analyze the \emph{approximation error} of hypothesis classes. This is in sharp contrast to most, if not all, previous uses of VC theory, which only deal with estimation error.</abstract>
   </article>
   <article>
      <title>An Optimization Framework for Semi-Supervised and Transfer Learning
  using Multiple Classifiers and Clusterers</title>
      <author>Ayan Acharya, Eduardo R. Hruschka, Joydeep Ghosh, Sreangsu Acharyya</author>
      <date>2012-04-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Unsupervised models can provide supplementary soft constraints to help classify new, "target" data since similar instances in the target set are more likely to share the same class label. Such models can also help detect possible differences between training and target distributions, which is useful in applications where concept drift may take place, as in transfer learning settings. This paper describes a general optimization framework that takes as input class membership estimates from existing classifiers learnt on previously encountered "source" data, as well as a similarity matrix from a cluster ensemble operating solely on the target data to be classified, and yields a consensus labeling of the target data. This framework admits a wide range of loss functions and classification/clustering methods. It exploits properties of Bregman divergences in conjunction with Legendre duality to yield a principled and scalable approach. A variety of experiments show that the proposed framework can yield results substantially superior to those provided by popular transductive learning techniques or by naively applying classifiers learnt on the original task to the target data.</abstract>
   </article>
   <article>
      <title>Comparison of the C4.5 and a Naive Bayes Classifier for the Prediction
  of Lung Cancer Survivability</title>
      <author>George Dimitoglou, James A. Adams, Carol M. Jim</author>
      <date>2012-06-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Numerous data mining techniques have been developed to extract information and identify patterns and predict trends from large data sets. In this study, two classification techniques, the J48 implementation of the C4.5 algorithm and a Naive Bayes classifier are applied to predict lung cancer survivability from an extensive data set with fifteen years of patient records. The purpose of the project is to verify the predictive effectiveness of the two techniques on real, historical data. Besides the performance outcome that renders J48 marginally better than the Naive Bayes technique, there is a detailed description of the data and the required pre-processing activities. The performance results confirm expectations while some of the issues that appeared during experimentation, underscore the value of having domain-specific understanding to leverage any domain-specific characteristics inherent in the data.</abstract>
   </article>
   <article>
      <title>Cumulative Step-size Adaptation on Linear Functions: Technical Report</title>
      <author>Alexandre Adrien Chotard, Anne Auger, Nikolaus Hansen</author>
      <date>2012-06-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The CSA-ES is an Evolution Strategy with Cumulative Step size Adaptation, where the step size is adapted measuring the length of a so-called cumulative path. The cumulative path is a combination of the previous steps realized by the algorithm, where the importance of each step decreases with time. This article studies the CSA-ES on composites of strictly increasing with affine linear functions through the investigation of its underlying Markov chains. Rigorous results on the change and the variation of the step size are derived with and without cumulation. The step-size diverges geometrically fast in most cases. Furthermore, the influence of the cumulation parameter is studied.</abstract>
   </article>
   <article>
      <title>Communication-Efficient Parallel Belief Propagation for Latent Dirichlet
  Allocation</title>
      <author>Jian-feng Yan, Zhi-Qiang Liu, Yang Gao, Jia Zeng</author>
      <date>2012-06-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a novel communication-efficient parallel belief propagation (CE-PBP) algorithm for training latent Dirichlet allocation (LDA). Based on the synchronous belief propagation (BP) algorithm, we first develop a parallel belief propagation (PBP) algorithm on the parallel architecture. Because the extensive communication delay often causes a low efficiency of parallel topic modeling, we further use Zipf's law to reduce the total communication cost in PBP. Extensive experiments on different data sets demonstrate that CE-PBP achieves a higher topic modeling accuracy and reduces more than 80% communication cost than the state-of-the-art parallel Gibbs sampling (PGS) algorithm.</abstract>
   </article>
   <article>
      <title>Clustered Bandits</title>
      <author>Loc Bui, Ramesh Johari, Shie Mannor</author>
      <date>2012-06-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a multi-armed bandit setting that is inspired by real-world applications in e-commerce. In our setting, there are a few types of users, each with a specific response to the different arms. When a user enters the system, his type is unknown to the decision maker. The decision maker can either treat each user separately ignoring the previously observed users, or can attempt to take advantage of knowing that only few types exist and cluster the users according to their response to the arms. We devise algorithms that combine the usual exploration-exploitation tradeoff with clustering of users and demonstrate the value of clustering. In the process of developing algorithms for the clustered setting, we propose and analyze simple algorithms for the setup where a decision maker knows that a user belongs to one of few types, but does not know which one.</abstract>
   </article>
   <article>
      <title>Exact Soft Confidence-Weighted Learning</title>
      <author>Jialei Wang, Peilin Zhao, Steven C. H. Hoi</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose a new Soft Confidence-Weighted (SCW) online learning scheme, which enables the conventional confidence-weighted learning method to handle non-separable cases. Unlike the previous confidence-weighted learning algorithms, the proposed soft confidence-weighted learning method enjoys all the four salient properties: (i) large margin training, (ii) confidence weighting, (iii) capability to handle non-separable data, and (iv) adaptive margin. Our experimental results show that the proposed SCW algorithms significantly outperform the original CW algorithm. When comparing with a variety of state-of-the-art algorithms (including AROW, NAROW and NHERD), we found that SCW generally achieves better or at least comparable predictive accuracy, but enjoys significant advantage of computational efficiency (i.e., smaller number of updates and lower time cost).</abstract>
   </article>
   <article>
      <title>Inductive Kernel Low-rank Decomposition with Priors: A Generalized
  Nystrom Method</title>
      <author>Kai Zhang, Liang Lan, Jun Liu, andreas Rauber, Fabian Moerchen</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Low-rank matrix decomposition has gained great popularity recently in scaling up kernel methods to large amounts of data. However, some limitations could prevent them from working effectively in certain domains. For example, many existing approaches are intrinsically unsupervised, which does not incorporate side information (e.g., class labels) to produce task specific decompositions; also, they typically work "transductively", i.e., the factorization does not generalize to new samples, so the complete factorization needs to be recomputed when new samples become available. To solve these problems, in this paper we propose an"inductive"-flavored method for low-rank kernel decomposition with priors. We achieve this by generalizing the Nystr\"om method in a novel way. On the one hand, our approach employs a highly flexible, nonparametric structure that allows us to generalize the low-rank factors to arbitrarily new samples; on the other hand, it has linear time and space complexities, which can be orders of magnitudes faster than existing approaches and renders great efficiency in learning a low-rank kernel decomposition. Empirical results demonstrate the efficacy and efficiency of the proposed method.</abstract>
   </article>
   <article>
      <title>Path Integral Policy Improvement with Covariance Matrix Adaptation</title>
      <author>Freek Stulp, Olivier Sigaud</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>There has been a recent focus in <term>reinforcement learning</term> on addressing continuous state and action problems by optimizing parameterized policies. PI2 is a recent example of this approach. It combines a derivation from first principles of stochastic optimal control with tools from statistical estimation theory. In this paper, we consider PI2 as a member of the wider family of methods which share the concept of probability-weighted averaging to iteratively update parameters to optimize a cost function. We compare PI2 to other members of the same family - Cross-Entropy Methods and CMAES - at the conceptual level and in terms of performance. The comparison suggests the derivation of a novel algorithm which we call PI2-CMA for "Path Integral Policy Improvement with Covariance Matrix Adaptation". PI2-CMA's main advantage is that it determines the magnitude of the exploration noise automatically.</abstract>
   </article>
   <article>
      <title>Optimizing F-measure: A Tale of Two Approaches</title>
      <author>Ye Nan, Kian Ming Chai, Wee Sun Lee, Hai Leong Chieu</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>F-measures are popular performance metrics, particularly for tasks with imbalanced data sets. Algorithms for learning to maximize F-measures follow two approaches: the empirical utility maximization (EUM) approach learns a classifier having optimal performance on training data, while the decision-theoretic approach learns a probabilistic model and then predicts labels with maximum expected F-measure. In this paper, we investigate the theoretical justifications and connections for these two approaches, and we study the conditions under which one approach is preferable to the other using synthetic and real datasets. Given accurate models, our results suggest that the two approaches are asymptotically equivalent given large training and test sets. Nevertheless, empirically, the EUM approach appears to be more robust against model misspecification, and given a good model, the decision-theoretic approach appears to be better for handling rare classes and a common domain adaptation scenario.</abstract>
   </article>
   <article>
      <title>Multiple Kernel Learning from Noisy Labels by Stochastic Programming</title>
      <author>Tianbao Yang, Mehrdad Mahdavi, Rong Jin, Lijun Zhang, Yang Zhou</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the problem of multiple kernel learning from noisy labels. This is in contrast to most of the previous studies on multiple kernel learning that mainly focus on developing efficient algorithms and assume perfectly labeled training examples. Directly applying the existing multiple kernel learning algorithms to noisily labeled examples often leads to suboptimal performance due to the incorrect class assignments. We address this challenge by casting multiple kernel learning from noisy labels into a stochastic programming problem, and presenting a minimax formulation. We develop an efficient algorithm for solving the related convex-concave optimization problem with a fast convergence rate of $O(1/T)$ where $T$ is the number of iterations. Empirical studies on UCI data sets verify both the effectiveness of the proposed framework and the efficiency of the proposed optimization algorithm.</abstract>
   </article>
   <article>
      <title>Efficient Decomposed Learning for Structured Prediction</title>
      <author>Rajhans Samdani, Dan Roth</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Structured prediction is the cornerstone of several machine learning applications. Unfortunately, in structured prediction settings with expressive inter-variable interactions, exact inference-based learning algorithms, e.g. Structural SVM, are often intractable. We present a new way, Decomposed Learning (DecL), which performs efficient learning by restricting the inference step to a limited part of the structured spaces. We provide characterizations based on the structure, target parameters, and gold labels, under which DecL is equivalent to exact learning. We then show that in real world settings, where our theoretical assumptions may not completely hold, DecL-based algorithms are significantly more efficient and as accurate as exact learning.</abstract>
   </article>
   <article>
      <title>Two-Manifold Problems with Applications to Nonlinear System
  Identification</title>
      <author>Byron Boots, Geoff Gordon</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently, there has been much interest in spectral approaches to learning manifolds---so-called kernel eigenmap methods. These methods have had some successes, but their applicability is limited because they are not robust to noise. To address this limitation, we look at two-manifold problems, in which we simultaneously reconstruct two related manifolds, each representing a different view of the same data. By solving these interconnected learning problems together, two-manifold algorithms are able to succeed where a non-integrated approach would fail: each view allows us to suppress noise in the other, reducing bias. We propose a class of algorithms for two-manifold problems, based on spectral decomposition of cross-covariance operators in Hilbert space, and discuss when two-manifold problems are useful. Finally, we demonstrate that solving a two-manifold problem can aid in learning a nonlinear dynamical system from limited data.</abstract>
   </article>
   <article>
      <title>Modelling transition dynamics in MDPs with RKHS embeddings</title>
      <author>Steffen Grunewalder, Guy Lever, Luca Baldassarre, Massi Pontil, Arthur Gretton</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a new, nonparametric approach to learning and representing transition dynamics in Markov decision processes (MDPs), which can be combined easily with dynamic programming methods for policy optimisation and value estimation. This approach makes use of a recently developed representation of conditional distributions as \emph{embeddings} in a reproducing kernel Hilbert space (RKHS). Such representations bypass the need for estimating transition probabilities or densities, and apply to any domain on which kernels can be defined. This avoids the need to calculate intractable integrals, since expectations are represented as RKHS inner products whose computation has linear complexity in the number of points used to represent the embedding. We provide guarantees for the proposed applications in MDPs: in the context of a value iteration algorithm, we prove convergence to either the optimal policy, or to the closest projection of the optimal policy in our model class (an RKHS), under reasonable assumptions. In experiments, we investigate a learning task in a typical classical control setting (the under-actuated pendulum), and on a navigation problem where only images from a sensor are observed. For policy optimisation we compare with least-squares policy iteration where a Gaussian process is used for value function estimation. For value estimation we also compare to the NPDP method. Our approach achieves better performance in all experiments.</abstract>
   </article>
   <article>
      <title>Learning with Augmented Features for Heterogeneous Domain Adaptation</title>
      <author>Lixin Duan, Dong Xu, Ivor Tsang</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a new learning method for heterogeneous domain adaptation (HDA), in which the data from the source domain and the target domain are represented by heterogeneous features with different dimensions. Using two different projection matrices, we first transform the data from two domains into a common subspace in order to measure the similarity between the data from two domains. We then propose two new feature mapping functions to augment the transformed data with their original features and zeros. The existing learning methods (e.g., SVM and SVR) can be readily incorporated with our newly proposed augmented feature representations to effectively utilize the data from both domains for HDA. Using the hinge loss function in SVM as an example, we introduce the detailed objective function in our method called Heterogeneous Feature Augmentation (HFA) for a linear case and also describe its kernelization in order to efficiently cope with the data with very high dimensions. Moreover, we also develop an alternating optimization algorithm to effectively solve the nontrivial optimization problem in our HFA method. Comprehensive experiments on two benchmark datasets clearly demonstrate that HFA outperforms the existing HDA methods.</abstract>
   </article>
   <article>
      <title>Marginalized Denoising Autoencoders for Domain Adaptation</title>
      <author>Minmin Chen, Zhixiang Xu, Kilian Weinberger, Fei Sha</author>
      <date>2012-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stacked denoising autoencoders (SDAs) have been successfully used to learn new representations for domain adaptation. Recently, they have attained record accuracy on standard benchmark tasks of sentiment analysis across different text domains. SDAs learn robust data representations by reconstruction, recovering original features from data that are artificially corrupted with noise. In this paper, we propose marginalized SDA (mSDA) that addresses two crucial limitations of SDAs: high computational cost and lack of scalability to high-dimensional features. In contrast to SDAs, our approach of mSDA marginalizes noise and thus does not require stochastic <term>gradient descent</term> or other optimization algorithms to learn parameters ? in fact, they are computed in closed-form. Consequently, mSDA, which can be implemented in only 20 lines of MATLAB^{TM}, significantly speeds up SDAs by two orders of magnitude. Furthermore, the representations learnt by mSDA are as effective as the traditional SDAs, attaining almost identical accuracies in benchmark tasks.</abstract>
   </article>
   <article>
      <title>Dynamic Pricing under Finite Space Demand Uncertainty: A Multi-Armed
  Bandit with Dependent Arms</title>
      <author>Pouya Tehrani, Yixuan Zhai, Qing Zhao</author>
      <date>2012-06-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a dynamic pricing problem under unknown demand models. In this problem a seller offers prices to a stream of customers and observes either success or failure in each sale attempt. The underlying demand model is unknown to the seller and can take one of N possible forms. In this paper, we show that this problem can be formulated as a multi-armed bandit with dependent arms. We propose a dynamic pricing policy based on the likelihood ratio test. We show that the proposed policy achieves complete learning, i.e., it offers a bounded regret where regret is defined as the revenue loss with respect to the case with a known demand model. This is in sharp contrast with the logarithmic growing regret in multi-armed bandit with independent arms.</abstract>
   </article>
   <article>
      <title>Practical recommendations for gradient-based training of deep
  architectures</title>
      <author>Yoshua Bengio</author>
      <date>2012-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Learning algorithms related to artificial <term>neural network</term>s and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters. This chapter is meant as a practical guide with recommendations for some of the most commonly used hyper-parameters, in particular in the context of learning algorithms based on back-propagated gradient and gradient-based optimization. It also discusses how to deal with the fact that more interesting results can be obtained when allowing one to adjust many hyper-parameters. Overall, it describes elements of the practice used to successfully and efficiently train and debug large-scale and often deep multi-layer <term>neural network</term>s. It closes with open questions about the training difficulties observed with deeper architectures.</abstract>
   </article>
   <article>
      <title>Representation Learning: A Review and New Perspectives</title>
      <author>Yoshua Bengio, Aaron Courville, Pascal Vincent</author>
      <date>2012-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and <term>deep learning</term>, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.</abstract>
   </article>
   <article>
      <title>Graph Based Classification Methods Using Inaccurate External Classifier
  Information</title>
      <author>Sundararajan Sellamanickam, Sathiya Keerthi Selvaraj</author>
      <date>2012-06-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we consider the problem of collectively classifying entities where relational information is available across the entities. In practice inaccurate class distribution for each entity is often available from another (external) classifier. For example this distribution could come from a classifier built using content features or a simple dictionary. Given the relational and inaccurate external classifier information, we consider two graph based settings in which the problem of collective classification can be solved. In the first setting the class distribution is used to fix labels to a subset of nodes and the labels for the remaining nodes are obtained like in a transductive setting. In the other setting the class distributions of all nodes are used to define the fitting function part of a graph regularized objective function. We define a generalized objective function that handles both the settings. Methods like harmonic Gaussian field and local-global consistency (LGC) reported in the literature can be seen as special cases. We extend the LGC and weighted vote relational neighbor classification (WvRN) methods to support usage of external classifier information. We also propose an efficient least squares regularization (LSR) based method and relate it to information regularization methods. All the methods are evaluated on several benchmark and real world datasets. Considering together speed, robustness and accuracy, experimental results indicate that the LSR and WvRN-extension methods perform better than other methods.</abstract>
   </article>
   <article>
      <title>Learning Neighborhoods for Metric Learning</title>
      <author>Jun Wang, Adam Woznica, Alexandros Kalousis</author>
      <date>2012-06-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Metric learning methods have been shown to perform well on different learning tasks. Many of them rely on target neighborhood relationships that are computed in the original feature space and remain fixed throughout learning. As a result, the learned metric reflects the original neighborhood relations. We propose a novel formulation of the metric learning problem in which, in addition to the metric, the target neighborhood relations are also learned in a two-step iterative approach. The new formulation can be seen as a generalization of many existing metric learning methods. The formulation includes a target neighbor assignment rule that assigns different numbers of neighbors to instances according to their quality; `high quality' instances get more neighbors. We experiment with two of its instantiations that correspond to the metric learning algorithms LMNN and MCML and compare it to other metric learning methods on a number of datasets. The experimental results show state-of-the-art performance and provide evidence that learning the neighborhood relations does improve predictive performance.</abstract>
   </article>
   <article>
      <title>On Multilabel Classification and Ranking with Partial Feedback</title>
      <author>Claudio Gentile, Francesco Orabona</author>
      <date>2012-06-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-confidence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T^{1/2} log T) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-confidence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance.</abstract>
   </article>
   <article>
      <title>Hybrid Template Update System for Unimodal Biometric Systems</title>
      <author>Romain Giot, Christophe Rosenberger, Bernadette Dorizzi</author>
      <date>2012-07-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Semi-supervised template update systems allow to automatically take into account the intra-class variability of the biometric data over time. Such systems can be inefficient by including too many impostor's samples or skipping too many genuine's samples. In the first case, the biometric reference drifts from the real biometric data and attracts more often impostors. In the second case, the biometric reference does not evolve quickly enough and also progressively drifts from the real biometric data. We propose a hybrid system using several biometric sub-references in order to increase per- formance of self-update systems by reducing the previously cited errors. The proposition is validated for a keystroke- dynamics authentication system (this modality suffers of high variability over time) on two consequent datasets from the state of the art.</abstract>
   </article>
   <article>
      <title>Web-Based Benchmark for Keystroke Dynamics Biometric Systems: A
  Statistical Analysis</title>
      <author>Romain Giot, Mohamad El-Abed, Christophe Rosenberger</author>
      <date>2012-07-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Most keystroke dynamics studies have been evaluated using a specific kind of dataset in which users type an imposed login and password. Moreover, these studies are optimistics since most of them use different acquisition protocols, private datasets, controlled environment, etc. In order to enhance the accuracy of keystroke dynamics' performance, the main contribution of this paper is twofold. First, we provide a new kind of dataset in which users have typed both an imposed and a chosen pairs of logins and passwords. In addition, the keystroke dynamics samples are collected in a web-based uncontrolled environment (OS, keyboards, browser, etc.). Such kind of dataset is important since it provides us more realistic results of keystroke dynamics' performance in comparison to the literature (controlled environment, etc.). Second, we present a statistical analysis of well known assertions such as the relationship between performance and password size, impact of fusion schemes on system overall performance, and others such as the relationship between performance and entropy. We put into obviousness in this paper some new results on keystroke dynamics in realistic conditions.</abstract>
   </article>
   <article>
      <title>Accuracy Measures for the Comparison of Classifiers</title>
      <author>Vincent Labatut, Hocine Cherifi</author>
      <date>2012-07-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The selection of the best classification algorithm for a given dataset is a very widespread problem. It is also a complex one, in the sense it requires to make several important methodological choices. Among them, in this work we focus on the measure used to assess the classification performance and rank the algorithms. We present the most popular measures and discuss their properties. Despite the numerous measures proposed over the years, many of them turn out to be equivalent in this specific case, to have interpretation problems, or to be unsuitable for our purpose. Consequently, classic overall success rate or marginal rates should be preferred for this specific task.</abstract>
   </article>
   <article>
      <title>Better Mixing via Deep Representations</title>
      <author>Yoshua Bengio, Grégoire Mesnil, Yann Dauphin, Salah Rifai</author>
      <date>2012-07-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It has previously been hypothesized, and supported with some experimental evidence, that deeper representations, when well trained, tend to do a better job at disentangling the underlying factors of variation. We study the following related conjecture: better representations, in the sense of better disentangling, can be exploited to produce faster-mixing Markov chains. Consequently, mixing would be more efficient at higher levels of representation. To better understand why and how this is happening, we propose a secondary conjecture: the higher-level samples fill more uniformly the space they occupy and the high-density manifolds tend to unfold when represented at higher levels. The paper discusses these hypotheses and tests them experimentally through visualization and measurements of mixing and interpolating between samples.</abstract>
   </article>
   <article>
      <title>Supervised Laplacian Eigenmaps with Applications in Clinical Diagnostics
  for Pediatric Cardiology</title>
      <author>Thomas Perry, Hongyuan Zha, Patricio Frias, Dadan Zeng, Mark Braunstein</author>
      <date>2012-07-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Electronic health records contain rich textual data which possess critical predictive information for machine-learning based diagnostic aids. However many traditional machine learning methods fail to simultaneously integrate both vector space data and text. We present a supervised method using Laplacian eigenmaps to augment existing machine-learning methods with low-dimensional representations of textual predictors which preserve the local similarities. The proposed implementation performs alternating optimization using <term>gradient descent</term>. For the evaluation we applied our method to over 2,000 patient records from a large single-center pediatric cardiology practice to predict if patients were diagnosed with cardiac disease. Our method was compared with latent semantic indexing, latent Dirichlet allocation, and local Fisher discriminant analysis. The results were assessed using AUC, MCC, specificity, and sensitivity. Results indicate supervised Laplacian eigenmaps was the highest performing method in our study, achieving 0.782 and 0.374 for AUC and MCC respectively. SLE showed an increase in 8.16% in AUC and 20.6% in MCC over the baseline which excluded textual data and a 2.69% and 5.35% increase in AUC and MCC respectively over unsupervised Laplacian eigenmaps. This method allows many existing machine learning predictors to effectively and efficiently utilize the potential of textual predictors.</abstract>
   </article>
   <article>
      <title>APRIL: Active Preference-learning based Reinforcement Learning</title>
      <author>Riad Akrour, Marc Schoenauer, Michèle Sebag</author>
      <date>2012-08-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper focuses on <term>reinforcement learning</term> (RL) with limited prior knowledge. In the domain of swarm robotics for instance, the expert can hardly design a reward function or demonstrate the target behavior, forbidding the use of both standard RL and inverse <term>reinforcement learning</term>. Although with a limited expertise, the human expert is still often able to emit preferences and rank the agent demonstrations. Earlier work has presented an iterative preference-based RL framework: expert preferences are exploited to learn an approximate policy return, thus enabling the agent to achieve direct policy search. Iteratively, the agent selects a new candidate policy and demonstrates it; the expert ranks the new demonstration comparatively to the previous best one; the expert's ranking feedback enables the agent to refine the approximate policy return, and the process is iterated. In this paper, preference-based <term>reinforcement learning</term> is combined with active ranking in order to decrease the number of ranking queries to the expert needed to yield a satisfactory policy. Experiments on the mountain car and the cancer treatment testbeds witness that a couple of dozen rankings enable to learn a competent policy.</abstract>
   </article>
   <article>
      <title>Data Selection for Semi-Supervised Learning</title>
      <author>Shafigh Parsazad, Ehsan Saboori, Amin Allahyar</author>
      <date>2012-08-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The real challenge in pattern recognition task and machine learning process is to train a discriminator using labeled data and use it to distinguish between future data as accurate as possible. However, most of the problems in the real world have numerous data, which labeling them is a cumbersome or even an impossible matter. Semi-supervised learning is one approach to overcome these types of problems. It uses only a small set of labeled with the company of huge remain and unlabeled data to train the discriminator. In semi-supervised learning, it is very essential that which data is labeled and depend on position of data it effectiveness changes. In this paper, we proposed an evolutionary approach called Artificial Immune System (AIS) to determine which data is better to be labeled to get the high quality data. The experimental results represent the effectiveness of this algorithm in finding these data points.</abstract>
   </article>
   <article>
      <title>Guess Who Rated This Movie: Identifying Users Through Subspace
  Clustering</title>
      <author>Amy Zhang, Nadia Fawaz, Stratis Ioannidis, Andrea Montanari</author>
      <date>2012-08-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It is often the case that, within an online recommender system, multiple users share a common account. Can such shared accounts be identified solely on the basis of the user- provided ratings? Once a shared account is identified, can the different users sharing it be identified as well? Whenever such user identification is feasible, it opens the way to possible improvements in personalized recommendations, but also raises privacy concerns. We develop a model for composite accounts based on unions of linear subspaces, and use subspace clustering for carrying out the identification task. We show that a significant fraction of such accounts is identifiable in a reliable manner, and illustrate potential uses for personalized recommendation.</abstract>
   </article>
   <article>
      <title>Metric Learning across Heterogeneous Domains by Respectively Aligning
  Both Priors and Posteriors</title>
      <author>Qiang Qian, Songcan Chen</author>
      <date>2012-08-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we attempts to learn a single metric across two heterogeneous domains where source domain is fully labeled and has many samples while target domain has only a few labeled samples but abundant unlabeled samples. To the best of our knowledge, this task is seldom touched. The proposed learning model has a simple underlying motivation: all the samples in both the source and the target domains are mapped into a common space, where both their priors P(sample)s and their posteriors P(label|sample)s are forced to be respectively aligned as much as possible. We show that the two mappings, from both the source domain and the target domain to the common space, can be reparameterized into a single positive semi-definite(PSD) matrix. Then we develop an efficient Bregman Projection algorithm to optimize the PDS matrix over which a LogDet function is used to regularize. Furthermore, we also show that this model can be easily kernelized and verify its effectiveness in crosslanguage retrieval task and cross-domain object recognition task.</abstract>
   </article>
   <article>
      <title>Margin Distribution Controlled Boosting</title>
      <author>Guangxu Guo, Songcan Chen</author>
      <date>2012-08-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Schapire's margin theory provides a theoretical explanation to the success of boosting-type methods and manifests that a good margin distribution (MD) of training samples is essential for generalization. However the statement that a MD is good is vague, consequently, many recently developed algorithms try to generate a MD in their goodness senses for boosting generalization. Unlike their indirect control over MD, in this paper, we propose an alternative boosting algorithm termed Margin distribution Controlled Boosting (MCBoost) which directly controls the MD by introducing and optimizing a key adjustable margin parameter. MCBoost's optimization implementation adopts the column generation technique to ensure fast convergence and small number of weak classifiers involved in the final MCBooster. We empirically demonstrate: 1) AdaBoost is actually also a MD controlled algorithm and its iteration number acts as a parameter controlling the distribution and 2) the generalization performance of MCBoost evaluated on UCI benchmark datasets is validated better than those of AdaBoost, L2Boost, LPBoost, AdaBoost-CG and MDBoost.</abstract>
   </article>
   <article>
      <title>Inverse Reinforcement Learning with Gaussian Process</title>
      <author>Qifeng Qiao, Peter A. Beling</author>
      <date>2012-08-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present new algorithms for inverse <term>reinforcement learning</term> (IRL, or inverse optimal control) in convex optimization settings. We argue that finite-space IRL can be posed as a convex quadratic program under a Bayesian inference framework with the objective of maximum a posterior estimation. To deal with problems in large or even infinite state space, we propose a Gaussian process model and use preference graphs to represent observations of decision trajectories. Our method is distinguished from other approaches to IRL in that it makes no assumptions about the form of the reward function and yet it retains the promise of computationally manageable implementations for potential real-world applications. In comparison with an establish algorithm on small-scale numerical problems, our method demonstrated better accuracy in apprenticeship learning and a more robust dependence on the number of observations.</abstract>
   </article>
   <article>
      <title>Efficient Active Learning of Halfspaces: an Aggressive Approach</title>
      <author>Alon Gonen, Sivan Sabato, Shai Shalev-Shwartz</author>
      <date>2012-08-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study pool-based active learning of half-spaces. We revisit the aggressive approach for active learning in the realizable case, and show that it can be made efficient and practical, while also having theoretical guarantees under reasonable assumptions. We further show, both theoretically and experimentally, that it can be preferable to mellow approaches. Our efficient aggressive active learner of half-spaces has formal approximation guarantees that hold when the pool is separable with a margin. While our analysis is focused on the realizable setting, we show that a simple heuristic allows using the same algorithm successfully for pools with low error as well. We further compare the aggressive approach to the mellow approach, and prove that there are cases in which the aggressive approach results in significantly better label complexity compared to the mellow approach. We demonstrate experimentally that substantial improvements in label complexity can be achieved using the aggressive approach, for both realizable and low-error settings.</abstract>
   </article>
   <article>
      <title>Auto-WEKA: Combined Selection and Hyperparameter Optimization of
  Classification Algorithms</title>
      <author>Chris Thornton, Frank Hutter, Holger H. Hoos, Kevin Leyton-Brown</author>
      <date>2012-08-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many different machine learning algorithms exist; taking into account each algorithm's hyperparameters, there is a staggeringly large number of possible alternatives overall. We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters, going beyond previous work that addresses these issues in isolation. We show that this problem can be addressed by a fully automated approach, leveraging recent innovations in Bayesian optimization. Specifically, we consider a wide range of feature selection techniques (combining 3 search and 8 evaluator methods) and all classification approaches implemented in WEKA, spanning 2 ensemble methods, 10 meta-methods, 27 base classifiers, and hyperparameter settings for each classifier. On each of 21 popular datasets from the UCI repository, the KDD Cup 09, variants of the MNIST dataset and CIFAR-10, we show classification performance often much better than using standard selection/hyperparameter optimization methods. We hope that our approach will help non-expert users to more effectively identify machine learning algorithms and hyperparameter settings appropriate to their applications, and hence to achieve improved performance.</abstract>
   </article>
   <article>
      <title>Vector Field k-Means: Clustering Trajectories by Fitting Multiple Vector
  Fields</title>
      <author>Nivan Ferreira, James T. Klosowski, Carlos Scheidegger, Claudio Silva</author>
      <date>2012-08-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Scientists study trajectory data to understand trends in movement patterns, such as human mobility for traffic analysis and urban planning. There is a pressing need for scalable and efficient techniques for analyzing this data and discovering the underlying patterns. In this paper, we introduce a novel technique which we call vector-field $k$-means.   The central idea of our approach is to use vector fields to induce a similarity notion between trajectories. Other clustering algorithms seek a representative trajectory that best describes each cluster, much like $k$-means identifies a representative "center" for each cluster. Vector-field $k$-means, on the other hand, recognizes that in all but the simplest examples, no single trajectory adequately describes a cluster. Our approach is based on the premise that movement trends in trajectory data can be modeled as flows within multiple vector fields, and the vector field itself is what defines each of the clusters. We also show how vector-field $k$-means connects techniques for scalar field design on meshes and $k$-means clustering.   We present an algorithm that finds a locally optimal clustering of trajectories into vector fields, and demonstrate how vector-field $k$-means can be used to mine patterns from trajectory data. We present experimental evidence of its effectiveness and efficiency using several datasets, including historical hurricane data, GPS tracks of people and vehicles, and anonymous call records from a large phone company. We compare our results to previous trajectory clustering techniques, and find that our algorithm performs faster in practice than the current state-of-the-art in trajectory clustering, in some examples by a large margin.</abstract>
   </article>
   <article>
      <title>Link Prediction via Generalized Coupled Tensor Factorisation</title>
      <author>Beyza Ermiş, Evrim Acar, A. Taylan Cemgil</author>
      <date>2012-08-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This study deals with the missing link prediction problem: the problem of predicting the existence of missing connections between entities of interest. We address link prediction using coupled analysis of relational datasets represented as heterogeneous data, i.e., datasets in the form of matrices and higher-order tensors. We propose to use an approach based on probabilistic interpretation of tensor factorisation models, i.e., Generalised Coupled Tensor Factorisation, which can simultaneously fit a large class of tensor models to higher-order tensors/matrices with com- mon latent factors using different loss functions. Numerical experiments demonstrate that joint analysis of data from multiple sources via coupled factorisation improves the link prediction performance and the selection of right loss function and tensor model is crucial for accurately predicting missing links.</abstract>
   </article>
   <article>
      <title>Improving the K-means algorithm using improved downhill simplex search</title>
      <author>Ehsan Saboori, Shafigh Parsazad, Anoosheh Sadeghi</author>
      <date>2012-09-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The k-means algorithm is one of the well-known and most popular clustering algorithms. K-means seeks an optimal partition of the data by minimizing the sum of squared error with an iterative optimization procedure, which belongs to the category of hill climbing algorithms. As we know hill climbing searches are famous for converging to local optimums. Since k-means can converge to a local optimum, different initial points generally lead to different convergence cancroids, which makes it important to start with a reasonable initial partition in order to achieve high quality clustering solutions. However, in theory, there exist no efficient and universal methods for determining such initial partitions. In this paper we tried to find an optimum initial partitioning for k-means algorithm. To achieve this goal we proposed a new improved version of downhill simplex search, and then we used it in order to find an optimal result for clustering approach and then compare this algorithm with Genetic Algorithm base (GA), Genetic K-Means (GKM), Improved Genetic K-Means (IGKM) and k-means algorithms.</abstract>
   </article>
   <article>
      <title>Structuring Relevant Feature Sets with Multiple Model Learning</title>
      <author>Jun Wang, Alexandros Kalousis</author>
      <date>2012-09-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Feature selection is one of the most prominent learning tasks, especially in high-dimensional datasets in which the goal is to understand the mechanisms that underly the learning dataset. However most of them typically deliver just a flat set of relevant features and provide no further information on what kind of structures, e.g. feature groupings, might underly the set of relevant features. In this paper we propose a new learning paradigm in which our goal is to uncover the structures that underly the set of relevant features for a given learning problem. We uncover two types of features sets, non-replaceable features that contain important information about the target variable and cannot be replaced by other features, and functionally similar features sets that can be used interchangeably in learned models, given the presence of the non-replaceable features, with no change in the predictive performance. To do so we propose a new learning algorithm that learns a number of disjoint models using a model disjointness regularization constraint together with a constraint on the predictive agreement of the disjoint models. We explore the behavior of our approach on a number of high-dimensional datasets, and show that, as expected by their construction, these satisfy a number of properties. Namely, model disjointness, a high predictive agreement, and a similar predictive performance to models learned on the full set of relevant features. The ability to structure the set of relevant features in such a manner can become a valuable tool in different applications of scientific knowledge discovery.</abstract>
   </article>
   <article>
      <title>An Empirical Study of MAUC in Multi-class Problems with Uncertain Cost
  Matrices</title>
      <author>Rui Wang, Ke Tang</author>
      <date>2012-09-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Cost-sensitive learning relies on the availability of a known and fixed cost matrix. However, in some scenarios, the cost matrix is uncertain during training, and re-train a classifier after the cost matrix is specified would not be an option. For binary classification, this issue can be successfully addressed by methods maximizing the Area Under the ROC Curve (AUC) metric. Since the AUC can measure performance of base classifiers independent of cost during training, and a larger AUC is more likely to lead to a smaller total cost in testing using the threshold moving method. As an extension of AUC to multi-class problems, MAUC has attracted lots of attentions and been widely used. Although MAUC also measures performance of base classifiers independent of cost, it is unclear whether a larger MAUC of classifiers is more likely to lead to a smaller total cost. In fact, it is also unclear what kinds of post-processing methods should be used in multi-class problems to convert base classifiers into discrete classifiers such that the total cost is as small as possible. In the paper, we empirically explore the relationship between MAUC and the total cost of classifiers by applying two categories of post-processing methods. Our results suggest that a larger MAUC is also beneficial. Interestingly, simple calibration methods that convert the output matrix into posterior probabilities perform better than existing sophisticated post re-optimization methods.</abstract>
   </article>
   <article>
      <title>Performance Evaluation of Predictive Classifiers For Knowledge Discovery
  From Engineering Materials Data Sets</title>
      <author>Hemanth K. S Doreswamy</author>
      <date>2012-09-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, naive Bayesian and C4.5 Decision Tree Classifiers(DTC) are successively applied on materials informatics to classify the engineering materials into different classes for the selection of materials that suit the input design specifications. Here, the classifiers are analyzed individually and their performance evaluation is analyzed with confusion matrix predictive parameters and standard measures, the classification results are analyzed on different class of materials. Comparison of classifiers has found that naive Bayesian classifier is more accurate and better than the C4.5 DTC. The knowledge discovered by the naive bayesian classifier can be employed for decision making in materials selection in manufacturing industries.</abstract>
   </article>
   <article>
      <title>Conditional validity of inductive conformal predictors</title>
      <author>Vladimir Vovk</author>
      <date>2012-09-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Conformal predictors are set predictors that are automatically valid in the sense of having coverage probability equal to or exceeding a given confidence level. Inductive conformal predictors are a computationally efficient version of conformal predictors satisfying the same property of validity. However, inductive conformal predictors have been only known to control unconditional coverage probability. This paper explores various versions of conditional validity and various ways to achieve them using inductive conformal predictors and their modifications.</abstract>
   </article>
   <article>
      <title>Improving Energy Efficiency in Femtocell Networks: A Hierarchical
  Reinforcement Learning Framework</title>
      <author>Xianfu Chen, Honggang Zhang, Tao Chen, Mika Lasanen</author>
      <date>2012-09-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper investigates energy efficiency for two-tier femtocell networks through combining game theory and stochastic learning. With the Stackelberg game formulation, a hierarchical <term>reinforcement learning</term> framework is applied to study the joint average utility maximization of macrocells and femtocells subject to the minimum signal-to-interference-plus-noise-ratio requirements. The macrocells behave as the leaders and the femtocells are followers during the learning procedure. At each time step, the leaders commit to dynamic strategies based on the best responses of the followers, while the followers compete against each other with no further information but the leaders' strategy information. In this paper, we propose two learning algorithms to schedule each cell's stochastic power levels, leading by the macrocells. Numerical experiments are presented to validate the proposed studies and show that the two learning algorithms substantially improve the energy efficiency of the femtocell networks.</abstract>
   </article>
   <article>
      <title>Parametric Local Metric Learning for Nearest Neighbor Classification</title>
      <author>Jun Wang, Adam Woznica, Alexandros Kalousis</author>
      <date>2012-09-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the problem of learning local metrics for nearest neighbor classification. Most previous works on local metric learning learn a number of local unrelated metrics. While this "independence" approach delivers an increased flexibility its downside is the considerable risk of overfitting. We present a new parametric local metric learning method in which we learn a smooth metric matrix function over the data manifold. Using an approximation error bound of the metric matrix function we learn local metrics as linear combinations of basis metrics defined on anchor points over different regions of the instance space. We constrain the metric matrix function by imposing on the linear combinations manifold regularization which makes the learned metric matrix function vary smoothly along the geodesics of the data manifold. Our metric learning method has excellent performance both in terms of predictive power and scalability. We experimented with several large-scale classification problems, tens of thousands of instances, and compared it with several state of the art metric learning methods, both global and local, as well as to SVM with automatic kernel selection, all of which it outperforms in a significant manner.</abstract>
   </article>
   <article>
      <title>Fast Randomized Model Generation for Shapelet-Based Time Series
  Classification</title>
      <author>Daniel Gordon, Danny Hendler, Lior Rokach</author>
      <date>2012-09-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Time series classification is a field which has drawn much attention over the past decade. A new approach for classification of time series uses classification trees based on shapelets. A shapelet is a subsequence extracted from one of the time series in the dataset. A disadvantage of this approach is the time required for building the shapelet-based classification tree. The search for the best shapelet requires examining all subsequences of all lengths from all time series in the training set.   A key goal of this work was to find an evaluation order of the shapelets space which enables fast convergence to an accurate model. The comparative analysis we conducted clearly indicates that a random evaluation order yields the best results. Our empirical analysis of the distribution of high-quality shapelets within the shapelets space provides insights into why randomized shapelets sampling is superior to alternative evaluation orders.   We present an algorithm for randomized model generation for shapelet-based classification that converges extremely quickly to a model with surprisingly high accuracy after evaluating only an exceedingly small fraction of the shapelets space.</abstract>
   </article>
   <article>
      <title>Towards Ultrahigh Dimensional Feature Selection for Big Data</title>
      <author>Mingkui Tan, Ivor W. Tsang, Li Wang</author>
      <date>2012-09-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we present a new adaptive feature scaling scheme for ultrahigh-dimensional feature selection on Big Data. To solve this problem effectively, we first reformulate it as a convex semi-infinite programming (SIP) problem and then propose an efficient \emph{feature generating paradigm}. In contrast with traditional gradient-based approaches that conduct optimization on all input features, the proposed method iteratively activates a group of features and solves a sequence of multiple kernel learning (MKL) subproblems of much reduced scale. To further speed up the training, we propose to solve the MKL subproblems in their primal forms through a modified accelerated proximal gradient approach. Due to such an optimization scheme, some efficient cache techniques are also developed. The feature generating paradigm can guarantee that the solution converges globally under mild conditions and achieve lower feature selection bias. Moreover, the proposed method can tackle two challenging tasks in feature selection: 1) group-based feature selection with complex structures and 2) nonlinear feature selection with explicit feature mappings. Comprehensive experiments on a wide range of synthetic and real-world datasets containing tens of million data points with $O(10^{14})$ features demonstrate the competitive performance of the proposed method over state-of-the-art feature selection methods in terms of generalization performance and training efficiency.</abstract>
   </article>
   <article>
      <title>BPRS: Belief Propagation Based Iterative Recommender System</title>
      <author>Erman Ayday, Arash Einolghozati, Faramarz Fekri</author>
      <date>2012-09-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we introduce the first application of the Belief Propagation (BP) algorithm in the design of recommender systems. We formulate the recommendation problem as an inference problem and aim to compute the marginal probability distributions of the variables which represent the ratings to be predicted. However, computing these marginal probability functions is computationally prohibitive for large-scale systems. Therefore, we utilize the BP algorithm to efficiently compute these functions. Recommendations for each active user are then iteratively computed by probabilistic message passing. As opposed to the previous recommender algorithms, BPRS does not require solving the recommendation problem for all the users if it wishes to update the recommendations for only a single active. Further, BPRS computes the recommendations for each user with linear complexity and without requiring a training period. Via computer simulations (using the 100K MovieLens dataset), we verify that BPRS iteratively reduces the error in the predicted ratings of the users until it converges. Finally, we confirm that BPRS is comparable to the state of art methods such as Correlation-based neighborhood model (CorNgbr) and Singular Value Decomposition (SVD) in terms of rating and precision accuracy. Therefore, we believe that the BP-based recommendation algorithm is a new promising approach which offers a significant advantage on scalability while providing competitive accuracy for the recommender systems.</abstract>
   </article>
   <article>
      <title>More Is Better: Large Scale Partially-supervised Sentiment
  Classification - Appendix</title>
      <author>Yoav Haimovitch, Koby Crammer, Shie Mannor</author>
      <date>2012-09-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We describe a bootstrapping algorithm to learn from partially labeled data, and the results of an empirical study for using it to improve performance of sentiment classification using up to 15 million unlabeled Amazon product reviews. Our experiments cover semi-supervised learning, domain adaptation and weakly supervised learning. In some cases our methods were able to reduce test error by more than half using such large amount of data.   NOTICE: This is only the supplementary material.</abstract>
   </article>
   <article>
      <title>A Deterministic Analysis of an Online Convex Mixture of Expert
  Algorithms</title>
      <author>Mehmet A. Donmez, Sait Tunc, Suleyman S. Kozat</author>
      <date>2012-09-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We analyze an online learning algorithm that adaptively combines outputs of two constituent algorithms (or the experts) running in parallel to model an unknown desired signal. This online learning algorithm is shown to achieve (and in some cases outperform) the mean-square error (MSE) performance of the best constituent algorithm in the mixture in the steady-state. However, the MSE analysis of this algorithm in the literature uses approximations and relies on statistical models on the underlying signals and systems. Hence, such an analysis may not be useful or valid for signals generated by various real life systems that show high degrees of nonstationarity, limit cycles and, in many cases, that are even chaotic. In this paper, we produce results in an individual sequence manner. In particular, we relate the time-accumulated squared estimation error of this online algorithm at any time over any interval to the time accumulated squared estimation error of the optimal convex mixture of the constituent algorithms directly tuned to the underlying signal in a deterministic sense without any statistical assumptions. In this sense, our analysis provides the transient, steady-state and tracking behavior of this algorithm in a strong sense without any approximations in the derivations or statistical assumptions on the underlying signals such that our results are guaranteed to hold. We illustrate the introduced results through examples.</abstract>
   </article>
   <article>
      <title>Extension of TSVM to Multi-Class and Hierarchical Text Classification
  Problems With General Losses</title>
      <author>Sathiya Keerthi Selvaraj, Sundararajan Sellamanickam, Shirish Shevade</author>
      <date>2012-11-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Transductive SVM (TSVM) is a well known semi-supervised large margin learning method for binary text classification. In this paper we extend this method to multi-class and hierarchical classification problems. We point out that the determination of labels of unlabeled examples with fixed classifier weights is a linear programming problem. We devise an efficient technique for solving it. The method is applicable to general loss functions. We demonstrate the value of the new method using large margin loss on a number of multi-class and hierarchical classification datasets. For maxent loss we show empirically that our method is better than expectation regularization/constraint and posterior regularization methods, and competitive with the version of entropy regularization method which uses label constraints.</abstract>
   </article>
   <article>
      <title>K-Plane Regression</title>
      <author>Naresh Manwani, P. S. Sastry</author>
      <date>2012-11-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we present a novel algorithm for piecewise linear regression which can learn continuous as well as discontinuous piecewise linear functions. The main idea is to repeatedly partition the data and learn a liner model in in each partition. While a simple algorithm incorporating this idea does not work well, an interesting modification results in a good algorithm. The proposed algorithm is similar in spirit to $k$-means clustering algorithm. We show that our algorithm can also be viewed as an EM algorithm for maximum likelihood estimation of parameters under a reasonable probability model. We empirically demonstrate the effectiveness of our approach by comparing its performance with the state of art regression learning algorithms on some real world datasets.</abstract>
   </article>
   <article>
      <title>Algorithm for Missing Values Imputation in Categorical Data with Use of
  Association Rules</title>
      <author>Jiří Kaiser</author>
      <date>2012-11-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents algorithm for missing values imputation in categorical data. The algorithm is based on using association rules and is presented in three variants. Experimental shows better accuracy of missing values imputation using the algorithm then using most common attribute value.</abstract>
   </article>
   <article>
      <title>No-Regret Algorithms for Unconstrained Online Convex Optimization</title>
      <author>Matthew Streeter, H. Brendan McMahan</author>
      <date>2012-11-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Some of the most compelling applications of online convex optimization, including online prediction and classification, are unconstrained: the natural feasible set is R^n. Existing algorithms fail to achieve sub-linear regret in this setting unless constraints on the comparator point x^* are known in advance. We present algorithms that, without such prior knowledge, offer near-optimal regret bounds with respect to any choice of x^*. In particular, regret with respect to x^* = 0 is constant. We then prove lower bounds showing that our guarantees are near-optimal in this setting.</abstract>
   </article>
   <article>
      <title>Recovering the Optimal Solution by Dual Random Projection</title>
      <author>Lijun Zhang, Mehrdad Mahdavi, Rong Jin, Tianbao Yang, Shenghuo Zhu</author>
      <date>2012-11-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Random projection has been widely used in data classification. It maps high-dimensional data into a low-dimensional subspace in order to reduce the computational cost in solving the related optimization problem. While previous studies are focused on analyzing the classification performance of using random projection, in this work, we consider the recovery problem, i.e., how to accurately recover the optimal solution to the original optimization problem in the high-dimensional space based on the solution learned from the subspace spanned by random projections. We present a simple algorithm, termed Dual Random Projection, that uses the dual solution of the low-dimensional optimization problem to recover the optimal solution to the original problem. Our theoretical analysis shows that with a high probability, the proposed algorithm is able to accurately recover the optimal solution to the original problem, provided that the data matrix is of low rank or can be well approximated by a low rank matrix.</abstract>
   </article>
   <article>
      <title>On the difficulty of training Recurrent Neural Networks</title>
      <author>Razvan Pascanu, Tomas Mikolov, Yoshua Bengio</author>
      <date>2012-11-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>There are two widely known issues with properly training Recurrent Neural Networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.</abstract>
   </article>
   <article>
      <title>An Approach of Improving Students Academic Performance by using k means
  clustering algorithm and Decision tree</title>
      <author>Md. Hedayetul Islam Shovon, Mahfuza Haque</author>
      <date>2012-11-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Improving students academic performance is not an easy task for the academic community of higher learning. The academic performance of engineering and science students during their first year at university is a turning point in their educational path and usually encroaches on their General Point Average,GPA in a decisive manner. The students evaluation factors like class quizzes mid and final exam assignment lab work are studied. It is recommended that all these correlated information should be conveyed to the class teacher before the conduction of final exam. This study will help the teachers to reduce the drop out ratio to a significant level and improve the performance of students. In this paper, we present a hybrid procedure based on Decision Tree of Data mining method and Data Clustering that enables academicians to predict students GPA and based on that instructor can take necessary step to improve student academic performance.</abstract>
   </article>
   <article>
      <title>Multi-Target Regression via Input Space Expansion: Treating Targets as
  Inputs</title>
      <author>Eleftherios Spyromitros-Xioufis, Grigorios Tsoumakas, William Groves, Ioannis Vlahavas</author>
      <date>2012-11-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In many practical applications of supervised learning the task involves the prediction of multiple target variables from a common set of input variables. When the prediction targets are binary the task is called multi-label classification, while when the targets are continuous the task is called multi-target regression. In both tasks, target variables often exhibit statistical dependencies and exploiting them in order to improve predictive accuracy is a core challenge. A family of multi-label classification methods address this challenge by building a separate model for each target on an expanded input space where other targets are treated as additional input variables. Despite the success of these methods in the multi-label classification domain, their applicability and effectiveness in multi-target regression has not been studied until now. In this paper, we introduce two new methods for multi-target regression, called Stacked Single-Target and Ensemble of Regressor Chains, by adapting two popular multi-label classification methods of this family. Furthermore, we highlight an inherent problem of these methods - a discrepancy of the values of the additional input variables between training and prediction - and develop extensions that use out-of-sample estimates of the target variables during training in order to tackle this problem. The results of an extensive experimental evaluation carried out on a large and diverse collection of datasets show that, when the discrepancy is appropriately mitigated, the proposed methods attain consistent improvements over the independent regressions baseline. Moreover, two versions of Ensemble of Regression Chains perform significantly better than four state-of-the-art methods including regularization-based multi-task learning methods and a multi-objective <term>random forest</term> approach.</abstract>
   </article>
   <article>
      <title>Advances in Optimizing Recurrent Networks</title>
      <author>Yoshua Bengio, Nicolas Boulanger-Lewandowski, Razvan Pascanu</author>
      <date>2012-12-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>After a more than decade-long period of relatively little research activity in the area of recurrent <term>neural network</term>s, several new developments will be reviewed here that have allowed substantial progress both in understanding and in technical solutions towards more efficient training of recurrent networks. These advances have been motivated by and related to the optimization issues surrounding <term>deep learning</term>. Although recurrent networks are extremely powerful in what they can in principle represent in terms of modelling sequences,their training is plagued by two aspects of the same issue regarding the learning of long-term dependencies. Experiments reported here evaluate the use of clipping gradients, spanning longer time ranges with leaky integration, advanced momentum techniques, using more powerful output probability models, and encouraging sparser gradients to help symmetry breaking and credit assignment. The experiments are performed on text and music data and show off the combined effects of these techniques in generally improving both training and test error.</abstract>
   </article>
   <article>
      <title>High-dimensional sequence transduction</title>
      <author>Nicolas Boulanger-Lewandowski, Yoshua Bengio, Pascal Vincent</author>
      <date>2012-12-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We investigate the problem of transforming an input sequence into a high-dimensional output sequence in order to transcribe polyphonic audio music into symbolic notation. We introduce a probabilistic model based on a recurrent <term>neural network</term> that is able to learn realistic output distributions given the input and we devise an efficient algorithm to search for the global mode of that distribution. The resulting method produces musically plausible transcriptions even under high levels of noise and drastically outperforms previous state-of-the-art approaches on five datasets of synthesized sounds and real recordings, approximately halving the test error rate.</abstract>
   </article>
   <article>
      <title>Cost-Sensitive Feature Selection of Data with Errors</title>
      <author>Hong Zhao, Fan Min, William Zhu</author>
      <date>2012-12-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In data mining applications, feature selection is an essential process since it reduces a model's complexity. The cost of obtaining the feature values must be taken into consideration in many domains. In this paper, we study the cost-sensitive feature selection problem on numerical data with measurement errors, test costs and misclassification costs. The major contributions of this paper are four-fold. First, a new data model is built to address test costs and misclassification costs as well as error boundaries. Second, a covering-based rough set with measurement errors is constructed. Given a confidence interval, the neighborhood is an ellipse in a two-dimension space, or an ellipsoidal in a three-dimension space, etc. Third, a new cost-sensitive feature selection problem is defined on this covering-based rough set. Fourth, both backtracking and heuristic algorithms are proposed to deal with this new problem. The algorithms are tested on six UCI (University of California - Irvine) data sets. Experimental results show that (1) the pruning techniques of the backtracking algorithm help reducing the number of operations significantly, and (2) the heuristic algorithm usually obtains optimal results. This study is a step toward realistic applications of cost-sensitive learning.</abstract>
   </article>
   <article>
      <title>Learning efficient sparse and low rank models</title>
      <author>Pablo Sprechmann, Alex M. Bronstein, Guillermo Sapiro</author>
      <date>2012-12-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Parsimony, including sparsity and low rank, has been shown to successfully model data in numerous machine learning and signal processing tasks. Traditionally, such modeling approaches rely on an iterative algorithm that minimizes an objective function with parsimony-promoting terms. The inherently sequential structure and data-dependent complexity and latency of iterative optimization constitute a major limitation in many applications requiring real-time performance or involving large-scale data. Another limitation encountered by these modeling techniques is the difficulty of their inclusion in discriminative learning scenarios. In this work, we propose to move the emphasis from the model to the pursuit algorithm, and develop a process-centric view of parsimonious modeling, in which a learned deterministic fixed-complexity pursuit process is used in lieu of iterative optimization. We show a principled way to construct learnable pursuit process architectures for structured sparse and robust low rank models, derived from the iteration of proximal descent algorithms. These architectures learn to approximate the exact parsimonious representation at a fraction of the complexity of the standard optimization methods. We also show that appropriate training regimes allow to naturally extend parsimonious models to discriminative settings. State-of-the-art results are demonstrated on several challenging problems in image and audio processing with several orders of magnitude speedup compared to the exact optimization algorithms.</abstract>
   </article>
   <article>
      <title>Analysis of Large-scale Traffic Dynamics using Non-negative Tensor
  Factorization</title>
      <author>Yufei Han, Fabien Moutarde</author>
      <date>2012-12-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we present our work on clustering and prediction of temporal dynamics of global congestion configurations in large-scale road networks. Instead of looking into temporal traffic state variation of individual links, or of small areas, we focus on spatial congestion configurations of the whole network. In our work, we aim at describing the typical temporal dynamic patterns of this network-level traffic state and achieving long-term prediction of the large-scale traffic dynamics, in a unified data-mining framework. To this end, we formulate this joint task using Non-negative Tensor Factorization (NTF), which has been shown to be a useful decomposition tools for multivariate data sequences. Clustering and prediction are performed based on the compact tensor factorization results. Experiments on large-scale simulated data illustrate the interest of our method with promising results for long-term forecast of traffic evolution.</abstract>
   </article>
   <article>
      <title>Hybrid Fuzzy-ART based K-Means Clustering Methodology to Cellular
  Manufacturing Using Operational Time</title>
      <author>Sourav Sengupta, Tamal Ghosh, Pranab K Dan, Manojit Chattopadhyay</author>
      <date>2012-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a new hybrid Fuzzy-ART based K-Means Clustering technique to solve the part machine grouping problem in cellular manufacturing systems considering operational time. The performance of the proposed technique is tested with problems from open literature and the results are compared to the existing clustering models such as simple K-means algorithm and modified ART1 algorithm using an efficient modified performance measure known as modified grouping efficiency (MGE) as found in the literature. The results support the better performance of the proposed algorithm. The Novelty of this study lies in the simple and efficient methodology to produce quick solutions for shop floor managers with least computational efforts and time.</abstract>
   </article>
   <article>
      <title>ADADELTA: An Adaptive Learning Rate Method</title>
      <author>Matthew D. Zeiler</author>
      <date>2012-12-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a novel per-dimension learning rate method for <term>gradient descent</term> called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic <term>gradient descent</term>. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.</abstract>
   </article>
   <article>
      <title>Tangent Bundle Manifold Learning via Grassmann&amp;Stiefel Eigenmaps</title>
      <author>Alexander V. Bernstein, Alexander P. Kuleshov</author>
      <date>2012-12-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>One of the ultimate goals of Manifold Learning (ML) is to reconstruct an unknown nonlinear low-dimensional manifold embedded in a high-dimensional observation space by a given set of data points from the manifold. We derive a local lower bound for the maximum reconstruction error in a small neighborhood of an arbitrary point. The lower bound is defined in terms of the distance between tangent spaces to the original manifold and the estimated manifold at the considered point and reconstructed point, respectively. We propose an amplification of the ML, called Tangent Bundle ML, in which the proximity not only between the original manifold and its estimator but also between their tangent spaces is required. We present a new algorithm that solves this problem and gives a new solution for the ML also.</abstract>
   </article>
   <article>
      <title>A Novel Design Specification Distance(DSD) Based K-Mean Clustering
  Performace Evluation on Engineering Materials Database</title>
      <author>Doreswamy, K. S. Hemanth</author>
      <date>2013-01-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Organizing data into semantically more meaningful is one of the fundamental modes of understanding and learning. Cluster analysis is a formal study of methods for understanding and algorithm for learning. K-mean clustering algorithm is one of the most fundamental and simple clustering algorithms. When there is no prior knowledge about the distribution of data sets, K-mean is the first choice for clustering with an initial number of clusters. In this paper a novel distance metric called Design Specification (DS) distance measure function is integrated with K-mean clustering algorithm to improve cluster accuracy. The K-means algorithm with proposed distance measure maximizes the cluster accuracy to 99.98% at P = 1.525, which is determined through the iterative procedure. The performance of Design Specification (DS) distance measure function with K - mean algorithm is compared with the performances of other standard distance functions such as Euclidian, squared Euclidean, City Block, and Chebshew similarity measures deployed with K-mean algorithm.The proposed method is evaluated on the engineering materials database. The experiments on cluster analysis and the outlier profiling show that these is an excellent improvement in the performance of the proposed method.</abstract>
   </article>
   <article>
      <title>Risk-Aversion in Multi-armed Bandits</title>
      <author>Amir Sani, Alessandro Lazaric, Rémi Munos</author>
      <date>2013-01-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic multi-armed bandits solve the Exploration-Exploitation dilemma and ultimately maximize the expected reward. Nonetheless, in many practical problems, maximizing the expected reward is not the most desirable objective. In this paper, we introduce a novel setting based on the principle of risk-aversion where the objective is to compete against the arm with the best risk-return trade-off. This setting proves to be intrinsically more difficult than the standard multi-arm bandit setting due in part to an exploration risk which introduces a regret associated to the variability of an algorithm. Using variance as a measure of risk, we introduce two new algorithms, investigate their theoretical guarantees, and report preliminary empirical results.</abstract>
   </article>
   <article>
      <title>Error Correction in Learning using SVMs</title>
      <author>Srivatsan Laxman, Sushil Mittal, Ramarathnam Venkatesan</author>
      <date>2013-01-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper is concerned with learning binary classifiers under adversarial label-noise. We introduce the problem of error-correction in learning where the goal is to recover the original clean data from a label-manipulated version of it, given (i) no constraints on the adversary other than an upper-bound on the number of errors, and (ii) some regularity properties for the original data. We present a simple and practical error-correction algorithm called SubSVMs that learns individual SVMs on several small-size (log-size), class-balanced, random subsets of the data and then reclassifies the training points using a majority vote. Our analysis reveals the need for the two main ingredients of SubSVMs, namely class-balanced sampling and subsampled bagging. Experimental results on synthetic as well as benchmark UCI data demonstrate the effectiveness of our approach. In addition to noise-tolerance, log-size subsampled bagging also yields significant run-time benefits over standard SVMs.</abstract>
   </article>
   <article>
      <title>Learning to Optimize Via Posterior Sampling</title>
      <author>Daniel Russo, Benjamin Van Roy</author>
      <date>2013-01-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper considers the use of a simple posterior sampling algorithm to balance between exploration and exploitation when learning to optimize actions such as in multi-armed bandit problems. The algorithm, also known as Thompson Sampling, offers significant advantages over the popular upper confidence bound (UCB) approach, and can be applied to problems with finite or infinite action spaces and complicated relationships among action rewards. We make two theoretical contributions. The first establishes a connection between posterior sampling and UCB algorithms. This result lets us convert regret bounds developed for UCB algorithms into Bayesian regret bounds for posterior sampling. Our second theoretical contribution is a Bayesian regret bound for posterior sampling that applies broadly and can be specialized to many model classes. This bound depends on a new notion we refer to as the eluder dimension, which measures the degree of dependence among action rewards. Compared to UCB algorithm Bayesian regret bounds for specific model classes, our general bound matches the best available for linear models and is stronger than the best available for generalized linear models. Further, our analysis provides insight into performance advantages of posterior sampling, which are highlighted through simulation results that demonstrate performance surpassing recently proposed UCB algorithms.</abstract>
   </article>
   <article>
      <title>Efficient Learning of Domain-invariant Image Representations</title>
      <author>Judy Hoffman, Erik Rodner, Jeff Donahue, Trevor Darrell, Kate Saenko</author>
      <date>2013-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present an algorithm that learns representations which explicitly compensate for domain mismatch and which can be efficiently realized as linear classifiers. Specifically, we form a linear transformation that maps features from the target (test) domain to the source (training) domain as part of training the classifier. We optimize both the transformation and classifier parameters jointly, and introduce an efficient cost function based on misclassification loss. Our method combines several features previously unavailable in a single algorithm: multi-class adaptation through representation learning, ability to map across heterogeneous feature spaces, and scalability to large datasets. We present experiments on several image datasets that demonstrate improved accuracy and computational advantages compared to previous approaches.</abstract>
   </article>
   <article>
      <title>Feature grouping from spatially constrained multiplicative interaction</title>
      <author>Felix Bauer, Roland Memisevic</author>
      <date>2013-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a feature learning model that learns to encode relationships between images. The model is defined as a Gated Boltzmann Machine, which is constrained such that hidden units that are nearby in space can gate each other's connections. We show how frequency/orientation "columns" as well as topographic filter maps follow naturally from training the model on image pairs. The model also helps explain why square-pooling models yield feature groups with similar grouping properties. Experimental results on synthetic image transformations show that spatially constrained gating is an effective way to reduce the number of parameters and thereby to regularize a transformation-learning model.</abstract>
   </article>
   <article>
      <title>A Semantic Matching Energy Function for Learning with Multi-relational
  Data</title>
      <author>Xavier Glorot, Antoine Bordes, Jason Weston, Yoshua Bengio</author>
      <date>2013-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Large-scale relational learning becomes crucial for handling the huge amounts of structured data generated daily in many application domains ranging from computational biology or information retrieval, to natural language processing. In this paper, we present a new <term>neural network</term> architecture designed to embed multi-relational graphs into a flexible continuous vector space in which the original data is kept and enhanced. The network is trained to encode the semantics of these graphs in order to assign high probabilities to plausible components. We empirically show that it reaches competitive performance in link prediction on standard datasets from the literature.</abstract>
   </article>
   <article>
      <title>How good is the Electricity benchmark for evaluating concept drift
  adaptation</title>
      <author>Indre Zliobaite</author>
      <date>2013-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this correspondence, we will point out a problem with testing adaptive classifiers on autocorrelated data. In such a case random change alarms may boost the accuracy figures. Hence, we cannot be sure if the adaptation is working well.</abstract>
   </article>
   <article>
      <title>Learning Features with Structure-Adapting Multi-view Exponential Family
  Harmoniums</title>
      <author>Yoonseop Kang, Seungjin Choi</author>
      <date>2013-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We proposea graphical model for multi-view feature extraction that automatically adapts its structure to achieve better representation of data distribution. The proposed model, structure-adapting multi-view harmonium (SA-MVH) has switch parameters that control the connection between hidden nodes and input views, and learn the switch parameter while training. Numerical experiments on synthetic and a real-world dataset demonstrate the useful behavior of the SA-MVH, compared to existing multi-view feature extraction methods.</abstract>
   </article>
   <article>
      <title>Saturating Auto-Encoders</title>
      <author>Rostislav Goroshin, Yann LeCun</author>
      <date>2013-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a simple new regularizer for auto-encoders whose hidden-unit activation functions contain at least one zero-gradient (saturated) region. This regularizer explicitly encourages activations in the saturated region(s) of the corresponding activation function. We call these Saturating Auto-Encoders (SATAE). We show that the saturation regularizer explicitly limits the SATAE's ability to reconstruct inputs which are not near the data manifold. Furthermore, we show that a wide variety of features can be learned when different activation functions are used. Finally, connections are established with the Contractive and Sparse Auto-Encoders.</abstract>
   </article>
   <article>
      <title>Behavior Pattern Recognition using A New Representation Model</title>
      <author>Qifeng Qiao, Peter A. Beling</author>
      <date>2013-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the use of inverse <term>reinforcement learning</term> (IRL) as a tool for the recognition of agents' behavior on the basis of observation of their sequential decision behavior interacting with the environment. We model the problem faced by the agents as a Markov decision process (MDP) and model the observed behavior of the agents in terms of forward planning for the MDP. We use IRL to learn reward functions and then use these reward functions as the basis for clustering or classification models. Experimental studies with GridWorld, a navigation problem, and the secretary problem, an optimal stopping problem, suggest reward vectors found from IRL can be a good basis for behavior pattern recognition problems. Empirical comparisons of our method with several existing IRL algorithms and with direct methods that use feature statistics observed in state-action space suggest it may be superior for recognition problems.</abstract>
   </article>
   <article>
      <title>Switched linear encoding with rectified linear autoencoders</title>
      <author>Leif Johnson, Craig Corcoran</author>
      <date>2013-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Several recent results in machine learning have established formal connections between autoencoders---artificial <term>neural network</term> models that attempt to reproduce their inputs---and other coding models like sparse coding and K-means. This paper explores in depth an autoencoder model that is constructed using rectified linear activations on its hidden units. Our analysis builds on recent results to further unify the world of sparse linear coding models. We provide an intuitive interpretation of the behavior of these coding models and demonstrate this intuition using small, artificial datasets with known distributions.</abstract>
   </article>
   <article>
      <title>Learning Output Kernels for Multi-Task Problems</title>
      <author>Francesco Dinuzzo</author>
      <date>2013-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Simultaneously solving multiple related learning tasks is beneficial under a variety of circumstances, but the prior knowledge necessary to correctly model task relationships is rarely available in practice. In this paper, we develop a novel kernel-based multi-task learning technique that automatically reveals structural inter-task relationships. Building over the framework of output kernel learning (OKL), we introduce a method that jointly learns multiple functions and a low-rank multi-task kernel by solving a non-convex regularization problem. Optimization is carried out via a block coordinate descent strategy, where each subproblem is solved using suitable conjugate gradient (CG) type iterative methods for linear operator equations. The effectiveness of the proposed approach is demonstrated on pharmacological and collaborative filtering data.</abstract>
   </article>
   <article>
      <title>See the Tree Through the Lines: The Shazoo Algorithm -- Full Version --</title>
      <author>Fabio Vitale, Nicolo Cesa-Bianchi, Claudio Gentile, Giovanni Zappella</author>
      <date>2013-01-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Predicting the nodes of a given graph is a fascinating theoretical problem with applications in several domains. Since graph sparsification via spanning trees retains enough information while making the task much easier, trees are an important special case of this problem. Although it is known how to predict the nodes of an unweighted tree in a nearly optimal way, in the weighted case a fully satisfactory algorithm is not available yet. We fill this hole and introduce an efficient node predictor, Shazoo, which is nearly optimal on any weighted tree. Moreover, we show that Shazoo can be viewed as a common nontrivial generalization of both previous approaches for unweighted trees and weighted lines. Experiments on real-world datasets confirm that Shazoo performs well in that it fully exploits the structure of the input tree, and gets very close to (and sometimes better than) less scalable energy minimization methods.</abstract>
   </article>
   <article>
      <title>Weighted Last-Step Min-Max Algorithm with Improved Sub-Logarithmic
  Regret</title>
      <author>Edward Moroshko, Koby Crammer</author>
      <date>2013-01-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In online learning the performance of an algorithm is typically compared to the performance of a fixed function from some class, with a quantity called regret. Forster proposed a last-step min-max algorithm which was somewhat simpler than the algorithm of Vovk, yet with the same regret. In fact the algorithm he analyzed assumed that the choices of the adversary are bounded, yielding artificially only the two extreme cases. We fix this problem by weighing the examples in such a way that the min-max problem will be well defined, and provide analysis with logarithmic regret that may have better multiplicative factor than both bounds of Forster and Vovk. We also derive a new bound that may be sub-logarithmic, as a recent bound of Orabona et.al, but may have better multiplicative factor. Finally, we analyze the algorithm in a weak-type of non-stationary setting, and show a bound that is sub-linear if the non-stationarity is sub-linear as well.</abstract>
   </article>
   <article>
      <title>Hierarchical Data Representation Model - Multi-layer NMF</title>
      <author>Hyun Ah Song, Soo-Young Lee</author>
      <date>2013-01-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose a data representation model that demonstrates hierarchical feature learning using nsNMF. We extend unit algorithm into several layers. Experiments with document and image data successfully discovered feature hierarchies. We also prove that proposed method results in much better classification and reconstruction performance, especially for small number of features. feature hierarchies.</abstract>
   </article>
   <article>
      <title>Clustering-Based Matrix Factorization</title>
      <author>Nima Mirbakhsh, Charles X. Ling</author>
      <date>2013-01-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recommender systems are emerging technologies that nowadays can be found in many applications such as Amazon, Netflix, and so on. These systems help users to find relevant information, recommendations, and their preferred items. Slightly improvement of the accuracy of these recommenders can highly affect the quality of recommendations. Matrix Factorization is a popular method in Recommendation Systems showing promising results in accuracy and complexity. In this paper we propose an extension of matrix factorization which adds general neighborhood information on the recommendation model. Users and items are clustered into different categories to see how these categories share preferences. We then employ these shared interests of categories in a fusion by Biased Matrix Factorization to achieve more accurate recommendations. This is a complement for the current neighborhood aware matrix factorization models which rely on using direct neighborhood information of users and items. The proposed model is tested on two well-known recommendation system datasets: Movielens100k and Netflix. Our experiment shows applying the general latent features of categories into factorized recommender models improves the accuracy of recommendations. The current neighborhood-aware models need a great number of neighbors to acheive good accuracies. To the best of our knowledge, the proposed model is better than or comparable with the current neighborhood-aware models when they consider fewer number of neighbors.</abstract>
   </article>
   <article>
      <title>A game-theoretic framework for classifier ensembles using weighted
  majority voting with local accuracy estimates</title>
      <author>Harris V. Georgiou, Michael E. Mavroforakis</author>
      <date>2013-02-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, a novel approach for the optimal combination of binary classifiers is proposed. The classifier combination problem is approached from a Game Theory perspective. The proposed framework of adapted weighted majority rules (WMR) is tested against common rank-based, Bayesian and simple majority models, as well as two soft-output averaging rules. Experiments with ensembles of Support Vector Machines (SVM), Ordinary Binary Tree Classifiers (OBTC) and weighted k-nearest-neighbor (w/k-NN) models on benchmark datasets indicate that this new adaptive WMR model, employing local accuracy estimators and the analytically computed optimal weights outperform all the other simple combination rules.</abstract>
   </article>
   <article>
      <title>RandomBoost: Simplified Multi-class Boosting through Randomization</title>
      <author>Sakrapee Paisitkriangkrai, Chunhua Shen, Qinfeng Shi, Anton van den Hengel</author>
      <date>2013-02-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a novel boosting approach to multi-class classification problems, in which multiple classes are distinguished by a set of random projection matrices in essence. The approach uses random projections to alleviate the proliferation of binary classifiers typically required to perform multi-class classification. The result is a multi-class classifier with a single vector-valued parameter, irrespective of the number of classes involved. Two variants of this approach are proposed. The first method randomly projects the original data into new spaces, while the second method randomly projects the outputs of learned weak classifiers. These methods are not only conceptually simple but also effective and easy to implement. A series of experiments on synthetic, machine learning and visual recognition data sets demonstrate that our proposed methods compare favorably to existing multi-class boosting algorithms in terms of both the convergence rate and classification accuracy.</abstract>
   </article>
   <article>
      <title>A Comparison of Relaxations of Multiset Cannonical Correlation Analysis
  and Applications</title>
      <author>Jan Rupnik, Primoz Skraba, John Shawe-Taylor, Sabrina Guettes</author>
      <date>2013-02-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Canonical correlation analysis is a statistical technique that is used to find relations between two sets of variables. An important extension in pattern analysis is to consider more than two sets of variables. This problem can be expressed as a quadratically constrained quadratic program (QCQP), commonly referred to Multi-set Canonical Correlation Analysis (MCCA). This is a non-convex problem and so greedy algorithms converge to local optima without any guarantees on global optimality. In this paper, we show that despite being highly structured, finding the optimal solution is NP-Hard. This motivates our relaxation of the QCQP to a semidefinite program (SDP). The SDP is convex, can be solved reasonably efficiently and comes with both absolute and output-sensitive approximation quality. In addition to theoretical guarantees, we do an extensive comparison of the QCQP method and the SDP relaxation on a variety of synthetic and real world data. Finally, we present two useful extensions: we incorporate kernel methods and computing multiple sets of canonical vectors.</abstract>
   </article>
   <article>
      <title>The price of bandit information in multiclass online classification</title>
      <author>Amit Daniely, Tom Helbertal</author>
      <date>2013-02-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider two scenarios of multiclass online learning of a hypothesis class $H\subseteq Y^X$. In the {\em full information} scenario, the learner is exposed to instances together with their labels. In the {\em bandit} scenario, the true label is not exposed, but rather an indication whether the learner's prediction is correct or not. We show that the ratio between the error rates in the two scenarios is at most $8\cdot|Y|\cdot \log(|Y|)$ in the realizable case, and $\tilde{O}(\sqrt{|Y|})$ in the agnostic case. The results are tight up to a logarithmic factor and essentially answer an open question from (Daniely et. al. - Multiclass learnability and the erm principle).   We apply these results to the class of $\gamma$-margin multiclass linear classifiers in $\reals^d$. We show that the bandit error rate of this class is $\tilde{\Theta}(\frac{|Y|}{\gamma^2})$ in the realizable case and $\tilde{\Theta}(\frac{1}{\gamma}\sqrt{|Y|T})$ in the agnostic case. This resolves an open question from (Kakade et. al. - Efficient bandit algorithms for online multiclass prediction).</abstract>
   </article>
   <article>
      <title>Passive Learning with Target Risk</title>
      <author>Mehrdad Mahdavi, Rong Jin</author>
      <date>2013-02-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we consider learning in passive setting but with a slight modification. We assume that the target expected loss, also referred to as target risk, is provided in advance for learner as prior knowledge. Unlike most studies in the learning theory that only incorporate the prior knowledge into the generalization bounds, we are able to explicitly utilize the target risk in the learning process. Our analysis reveals a surprising result on the sample complexity of learning: by exploiting the target risk in the learning algorithm, we show that when the loss function is both strongly convex and smooth, the sample complexity reduces to $\O(\log (\frac{1}{\epsilon}))$, an exponential improvement compared to the sample complexity $\O(\frac{1}{\epsilon})$ for learning with strongly convex loss functions. Furthermore, our proof is constructive and is based on a computationally efficient stochastic optimization algorithm for such settings which demonstrate that the proposed algorithm is practically useful.</abstract>
   </article>
   <article>
      <title>Minimax Optimal Algorithms for Unconstrained Linear Optimization</title>
      <author>H. Brendan McMahan</author>
      <date>2013-02-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We design and analyze minimax-optimal algorithms for online linear optimization games where the player's choice is unconstrained. The player strives to minimize regret, the difference between his loss and the loss of a post-hoc benchmark strategy. The standard benchmark is the loss of the best strategy chosen from a bounded comparator set. When the the comparison set and the adversary's gradients satisfy L_infinity bounds, we give the value of the game in closed form and prove it approaches sqrt(2T/pi) as T -&gt; infinity.   Interesting algorithms result when we consider soft constraints on the comparator, rather than restricting it to a bounded set. As a warmup, we analyze the game with a quadratic penalty. The value of this game is exactly T/2, and this value is achieved by perhaps the simplest online algorithm of all: unprojected <term>gradient descent</term> with a constant learning rate.   We then derive a minimax-optimal algorithm for a much softer penalty function. This algorithm achieves good bounds under the standard notion of regret for any comparator point, without needing to specify the comparator set in advance. The value of this game converges to sqrt{e} as T -&gt;infinity; we give a closed-form for the exact value as a function of T. The resulting algorithm is natural in unconstrained investment or betting scenarios, since it guarantees at worst constant loss, while allowing for exponential reward against an "easy" adversary.</abstract>
   </article>
   <article>
      <title>A Time Series Forest for Classification and Feature Extraction</title>
      <author>Houtao Deng, George Runger, Eugene Tuv, Martyanov Vladimir</author>
      <date>2013-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a tree ensemble method, referred to as time series forest (TSF), for time series classification. TSF employs a combination of the entropy gain and a distance measure, referred to as the Entrance (entropy and distance) gain, for evaluating the splits. Experimental studies show that the Entrance gain criterion improves the accuracy of TSF. TSF randomly samples features at each tree node and has a computational complexity linear in the length of a time series and can be built using parallel computing techniques such as multi-core computing used here. The temporal importance curve is also proposed to capture the important temporal characteristics useful for classification. Experimental studies show that TSF using simple features such as mean, deviation and slope outperforms strong competitors such as one-nearest-neighbor classifiers with dynamic time warping, is computationally efficient, and can provide insights into the temporal characteristics.</abstract>
   </article>
   <article>
      <title>Extracting useful rules through improved decision tree induction using
  information entropy</title>
      <author>Mohd Mahmood Ali, Mohd S Qaseem, Lakshmi Rajamani, A Govardhan</author>
      <date>2013-02-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Classification is widely used technique in the data mining domain, where scalability and efficiency are the immediate problems in classification algorithms for large databases. We suggest improvements to the existing C4.5 decision tree algorithm. In this paper attribute oriented induction (AOI) and relevance analysis are incorporated with concept hierarchys knowledge and HeightBalancePriority algorithm for construction of decision tree along with Multi level mining. The assignment of priorities to attributes is done by evaluating information entropy, at different levels of abstraction for building decision tree using HeightBalancePriority algorithm. Modified DMQL queries are used to understand and explore the shortcomings of the decision trees generated by C4.5 classifier for education dataset and the results are compared with the proposed approach.</abstract>
   </article>
   <article>
      <title>Online Regret Bounds for Undiscounted Continuous Reinforcement Learning</title>
      <author>Ronald Ortner, Daniil Ryabko</author>
      <date>2013-02-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We derive sublinear regret bounds for undiscounted <term>reinforcement learning</term> in continuous state space. The proposed algorithm combines state aggregation with the use of upper confidence bounds for implementing optimism in the face of uncertainty. Beside the existence of an optimal policy which satisfies the Poisson equation, the only assumptions made are Holder continuity of rewards and transition probabilities.</abstract>
   </article>
   <article>
      <title>Selecting the State-Representation in Reinforcement Learning</title>
      <author>Odalric-Ambrym Maillard, Rémi Munos, Daniil Ryabko</author>
      <date>2013-02-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The problem of selecting the right state-representation in a <term>reinforcement learning</term> problem is considered. Several models (functions mapping past observations to a finite set) of the observations are given, and it is known that for at least one of these models the resulting state dynamics are indeed Markovian. Without knowing neither which of the models is the correct one, nor what are the probabilistic characteristics of the resulting MDP, it is required to obtain as much reward as the optimal policy for the correct model (or for the best of the correct models, if there are several). We propose an algorithm that achieves that, with a regret of order T^{2/3} where T is the horizon time.</abstract>
   </article>
   <article>
      <title>Optimal Regret Bounds for Selecting the State Representation in
  Reinforcement Learning</title>
      <author>Odalric-Ambrym Maillard, Phuong Nguyen, Ronald Ortner, Daniil Ryabko</author>
      <date>2013-02-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider an agent interacting with an environment in a single stream of actions, observations, and rewards, with no reset. This process is not assumed to be a Markov Decision Process (MDP). Rather, the agent has several representations (mapping histories of past interactions to a discrete state space) of the environment with unknown dynamics, only some of which result in an MDP. The goal is to minimize the average regret criterion against an agent who knows an MDP representation giving the highest optimal reward, and acts optimally in it. Recent regret bounds for this setting are of order $O(T^{2/3})$ with an additive term constant yet exponential in some characteristics of the optimal MDP. We propose an algorithm whose regret after $T$ time steps is $O(\sqrt{T})$, with all constants reasonably small. This is optimal in $T$ since $O(\sqrt{T})$ is the optimal regret in the setting of learning in a (single discrete) MDP.</abstract>
   </article>
   <article>
      <title>An Efficient Dual Approach to Distance Metric Learning</title>
      <author>Chunhua Shen, Junae Kim, Fayao Liu, Lei Wang, Anton van den Hengel</author>
      <date>2013-02-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Distance metric learning is of fundamental interest in machine learning because the distance metric employed can significantly affect the performance of many learning methods. Quadratic Mahalanobis metric learning is a popular approach to the problem, but typically requires solving a semidefinite programming (SDP) problem, which is computationally expensive. Standard interior-point SDP solvers typically have a complexity of $O(D^{6.5})$ (with $D$ the dimension of input data), and can thus only practically solve problems exhibiting less than a few thousand variables. Since the number of variables is $D (D+1) / 2 $, this implies a limit upon the size of problem that can practically be solved of around a few hundred dimensions. The complexity of the popular quadratic Mahalanobis metric learning approach thus limits the size of problem to which metric learning can be applied. Here we propose a significantly more efficient approach to the metric learning problem based on the Lagrange dual formulation of the problem. The proposed formulation is much simpler to implement, and therefore allows much larger Mahalanobis metric learning problems to be solved. The time complexity of the proposed method is $O (D ^ 3) $, which is significantly lower than that of the SDP approach. Experiments on a variety of datasets demonstrate that the proposed method achieves an accuracy comparable to the state-of-the-art, but is applicable to significantly larger problems. We also show that the proposed method can be applied to solve more general Frobenius-norm regularized SDP problems approximately.</abstract>
   </article>
   <article>
      <title>Adaptive Crowdsourcing Algorithms for the Bandit Survey Problem</title>
      <author>Ittai Abraham, Omar Alonso, Vasilis Kandylas, Aleksandrs Slivkins</author>
      <date>2013-02-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Very recently crowdsourcing has become the de facto platform for distributing and collecting human computation for a wide range of tasks and applications such as information retrieval, natural language processing and machine learning. Current crowdsourcing platforms have some limitations in the area of quality control. Most of the effort to ensure good quality has to be done by the experimenter who has to manage the number of workers needed to reach good results.   We propose a simple model for adaptive quality control in crowdsourced multiple-choice tasks which we call the \emph{bandit survey problem}. This model is related to, but technically different from the well-known multi-armed bandit problem. We present several algorithms for this problem, and support them with analysis and simulations. Our approach is based in our experience conducting relevance evaluation for a large commercial search engine.</abstract>
   </article>
   <article>
      <title>StructBoost: Boosting Methods for Predicting Structured Output Variables</title>
      <author>Chunhua Shen, Guosheng Lin, Anton van den Hengel</author>
      <date>2013-02-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Boosting is a method for learning a single accurate predictor by linearly combining a set of less accurate weak learners. Recently, structured learning has found many applications in computer vision. Inspired by structured <term>support vector machine</term>s (SSVM), here we propose a new boosting algorithm for structured output prediction, which we refer to as StructBoost. StructBoost supports nonlinear structured learning by combining a set of weak structured learners. As SSVM generalizes SVM, our StructBoost generalizes standard boosting approaches such as AdaBoost, or LPBoost to structured learning. The resulting optimization problem of StructBoost is more challenging than SSVM in the sense that it may involve exponentially many variables and constraints. In contrast, for SSVM one usually has an exponential number of constraints and a cutting-plane method is used. In order to efficiently solve StructBoost, we formulate an equivalent $ 1 $-slack formulation and solve it using a combination of cutting planes and column generation. We show the versatility and usefulness of StructBoost on a range of problems such as optimizing the tree loss for hierarchical multi-class classification, optimizing the Pascal overlap criterion for robust visual tracking and learning conditional random field parameters for image segmentation.</abstract>
   </article>
   <article>
      <title>Thompson Sampling in Switching Environments with Bayesian Online Change
  Point Detection</title>
      <author>Joseph Mellor, Jonathan Shapiro</author>
      <date>2013-02-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Thompson Sampling has recently been shown to be optimal in the Bernoulli Multi-Armed Bandit setting[Kaufmann et al., 2012]. This bandit problem assumes stationary distributions for the rewards. It is often unrealistic to model the real world as a stationary distribution. In this paper we derive and evaluate algorithms using Thompson Sampling for a Switching Multi-Armed Bandit Problem. We propose a Thompson Sampling strategy equipped with a Bayesian change point mechanism to tackle this problem. We develop algorithms for a variety of cases with constant switching rate: when switching occurs all arms change (Global Switching), switching occurs independently for each arm (Per-Arm Switching), when the switching rate is known and when it must be inferred from data. This leads to a family of algorithms we collectively term Change-Point Thompson Sampling (CTS). We show empirical results of the algorithm in 4 artificial environments, and 2 derived from real world data; news click-through[Yahoo!, 2011] and foreign exchange data[Dukascopy, 2012], comparing them to some other bandit algorithms. In real world data CTS is the most effective.</abstract>
   </article>
   <article>
      <title>Graph-based Generalization Bounds for Learning Binary Relations</title>
      <author>Ben London, Bert Huang, Lise Getoor</author>
      <date>2013-02-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We investigate the generalizability of learned binary relations: functions that map pairs of instances to a logical indicator. This problem has application in numerous areas of machine learning, such as ranking, entity resolution and link prediction. Our learning framework incorporates an example labeler that, given a sequence $X$ of $n$ instances and a desired training size $m$, subsamples $m$ pairs from $X \times X$ without replacement. The challenge in analyzing this learning scenario is that pairwise combinations of random variables are inherently dependent, which prevents us from using traditional learning-theoretic arguments. We present a unified, graph-based analysis, which allows us to analyze this dependence using well-known graph identities. We are then able to bound the generalization error of learned binary relations using Rademacher complexity and algorithmic stability. The rate of uniform convergence is partially determined by the labeler's subsampling process. We thus examine how various assumptions about subsampling affect generalization; under a natural random subsampling process, our bounds guarantee $\tilde{O}(1/\sqrt{n})$ uniform convergence.</abstract>
   </article>
   <article>
      <title>The Importance of Clipping in Neurocontrol by Direct Gradient Descent on
  the Cost-to-Go Function and in Adaptive Dynamic Programming</title>
      <author>Michael Fairbank</author>
      <date>2013-02-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In adaptive dynamic programming, neurocontrol and <term>reinforcement learning</term>, the objective is for an agent to learn to choose actions so as to minimise a total cost function. In this paper we show that when discretized time is used to model the motion of the agent, it can be very important to do "clipping" on the motion of the agent in the final time step of the trajectory. By clipping we mean that the final time step of the trajectory is to be truncated such that the agent stops exactly at the first terminal state reached, and no distance further. We demonstrate that when clipping is omitted, learning performance can fail to reach the optimum; and when clipping is done properly, learning performance can improve significantly.   The clipping problem we describe affects algorithms which use explicit derivatives of the model functions of the environment to calculate a learning gradient. These include Backpropagation Through Time for Control, and methods based on Dual Heuristic Dynamic Programming. However the clipping problem does not significantly affect methods based on Heuristic Dynamic Programming, Temporal Differences or Policy Gradient Learning algorithms. Similarly, the clipping problem does not affect fixed-length finite-horizon problems.</abstract>
   </article>
   <article>
      <title>Prediction by Random-Walk Perturbation</title>
      <author>Luc Devroye, Gábor Lugosi, Gergely Neu</author>
      <date>2013-02-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a version of the follow-the-perturbed-leader online prediction algorithm in which the cumulative losses are perturbed by independent symmetric random walks. The forecaster is shown to achieve an expected regret of the optimal order O(sqrt(n log N)) where n is the time horizon and N is the number of experts. More importantly, it is shown that the forecaster changes its prediction at most O(sqrt(n log N)) times, in expectation. We also extend the analysis to online combinatorial optimization and show that even in this more general setting, the forecaster rarely switches between experts while having a regret of near-optimal order.</abstract>
   </article>
   <article>
      <title>Sparse Frequency Analysis with Sparse-Derivative Instantaneous Amplitude
  and Phase Functions</title>
      <author>Yin Ding, Ivan W. Selesnick</author>
      <date>2013-02-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper addresses the problem of expressing a signal as a sum of frequency components (sinusoids) wherein each sinusoid may exhibit abrupt changes in its amplitude and/or phase. The Fourier transform of a narrow-band signal, with a discontinuous amplitude and/or phase function, exhibits spectral and temporal spreading. The proposed method aims to avoid such spreading by explicitly modeling the signal of interest as a sum of sinusoids with time-varying amplitudes. So as to accommodate abrupt changes, it is further assumed that the amplitude/phase functions are approximately piecewise constant (i.e., their time-derivatives are sparse). The proposed method is based on a convex variational (optimization) approach wherein the total variation (TV) of the amplitude functions are regularized subject to a perfect (or approximate) reconstruction constraint. A computationally efficient algorithm is derived based on convex optimization techniques. The proposed technique can be used to perform band-pass filtering that is relatively insensitive to narrow-band amplitude/phase jumps present in data, which normally pose a challenge (due to transients, leakage, etc.). The method is illustrated using both synthetic signals and human EEG data for the purpose of band-pass filtering and the estimation of phase synchrony indexes.</abstract>
   </article>
   <article>
      <title>Online Learning for Time Series Prediction</title>
      <author>Oren Anava, Elad Hazan, Shie Mannor, Ohad Shamir</author>
      <date>2013-02-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we address the problem of predicting a time series using the ARMA (autoregressive moving average) model, under minimal assumptions on the noise terms. Using regret minimization techniques, we develop effective online learning algorithms for the prediction problem, without assuming that the noise terms are Gaussian, identically distributed or even independent. Furthermore, we show that our algorithm's performances asymptotically approaches the performance of the best ARMA model in hindsight.</abstract>
   </article>
   <article>
      <title>Online Convex Optimization Against Adversaries with Memory and
  Application to Statistical Arbitrage</title>
      <author>Oren Anava, Elad Hazan, Shie Mannor</author>
      <date>2013-02-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The framework of online learning with memory naturally captures learning problems with temporal constraints, and was previously studied for the experts setting. In this work we extend the notion of learning with memory to the general Online Convex Optimization (OCO) framework, and present two algorithms that attain low regret. The first algorithm applies to Lipschitz continuous loss functions, obtaining optimal regret bounds for both convex and strongly convex losses. The second algorithm attains the optimal regret bounds and applies more broadly to convex losses without requiring Lipschitz continuity, yet is more complicated to implement. We complement our theoretic results with an application to statistical arbitrage in finance: we devise algorithms for constructing mean-reverting portfolios.</abstract>
   </article>
   <article>
      <title>Online Similarity Prediction of Networked Data from Known and Unknown
  Graphs</title>
      <author>Claudio Gentile, Mark Herbster, Stephen Pasteris</author>
      <date>2013-02-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider online similarity prediction problems over networked data. We begin by relating this task to the more standard class prediction problem, showing that, given an arbitrary algorithm for class prediction, we can construct an algorithm for similarity prediction with "nearly" the same mistake bound, and vice versa. After noticing that this general construction is computationally infeasible, we target our study to {\em feasible} similarity prediction algorithms on networked data. We initially assume that the network structure is {\em known} to the learner. Here we observe that Matrix Winnow \cite{w07} has a near-optimal mistake guarantee, at the price of cubic prediction time per round. This motivates our effort for an efficient implementation of a Perceptron algorithm with a weaker mistake guarantee but with only poly-logarithmic prediction time. Our focus then turns to the challenging case of networks whose structure is initially {\em unknown} to the learner. In this novel setting, where the network structure is only incrementally revealed, we obtain a mistake-bounded algorithm with a quadratic prediction time per round.</abstract>
   </article>
   <article>
      <title>Learning Hash Functions Using Column Generation</title>
      <author>Xi Li, Guosheng Lin, Chunhua Shen, Anton van den Hengel, Anthony Dick</author>
      <date>2013-03-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Fast nearest neighbor searching is becoming an increasingly important tool in solving many large-scale problems. Recently a number of approaches to learning data-dependent hash functions have been developed. In this work, we propose a column generation based method for learning data-dependent hash functions on the basis of proximity comparison information. Given a set of triplets that encode the pairwise proximity comparison information, our method learns hash functions that preserve the relative comparison relationships in the data as well as possible within the large-margin learning framework. The learning procedure is implemented using column generation and hence is named CGHash. At each iteration of the column generation procedure, the best hash function is selected. Unlike most other hashing methods, our method generalizes to new data points naturally; and has a training objective which is convex, thus ensuring that the global optimum can be identified. Experiments demonstrate that the proposed method learns compact binary codes and that its retrieval performance compares favorably with state-of-the-art methods when tested on a few benchmark datasets.</abstract>
   </article>
   <article>
      <title>Inductive Sparse Subspace Clustering</title>
      <author>Xi Peng, Lei Zhang, Zhang Yi</author>
      <date>2013-03-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Sparse Subspace Clustering (SSC) has achieved state-of-the-art clustering quality by performing spectral clustering over a $\ell^{1}$-norm based similarity graph. However, SSC is a transductive method which does not handle with the data not used to construct the graph (out-of-sample data). For each new datum, SSC requires solving $n$ optimization problems in O(n) variables for performing the algorithm over the whole data set, where $n$ is the number of data points. Therefore, it is inefficient to apply SSC in fast online clustering and scalable graphing. In this letter, we propose an inductive spectral clustering algorithm, called inductive Sparse Subspace Clustering (iSSC), which makes SSC feasible to cluster out-of-sample data. iSSC adopts the assumption that high-dimensional data actually lie on the low-dimensional manifold such that out-of-sample data could be grouped in the embedding space learned from in-sample data. Experimental results show that iSSC is promising in clustering out-of-sample data.</abstract>
   </article>
   <article>
      <title>Convex and Scalable Weakly Labeled SVMs</title>
      <author>Yu-Feng Li, Ivor W. Tsang, James T. Kwok, Zhi-Hua Zhou</author>
      <date>2013-03-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we study the problem of learning from weakly labeled data, where labels of the training examples are incomplete. This includes, for example, (i) semi-supervised learning where labels are partially known; (ii) multi-instance learning where labels are implicitly known; and (iii) clustering where labels are completely unknown. Unlike supervised learning, learning with weak labels involves a difficult Mixed-Integer Programming (MIP) problem. Therefore, it can suffer from poor scalability and may also get stuck in local minimum. In this paper, we focus on SVMs and propose the WellSVM via a novel label generation strategy. This leads to a convex relaxation of the original MIP, which is at least as tight as existing convex Semi-Definite Programming (SDP) relaxations. Moreover, the WellSVM can be solved via a sequence of SVM subproblems that are much more scalable than previous convex SDP relaxations. Experiments on three weakly labeled learning tasks, namely, (i) semi-supervised learning; (ii) multi-instance learning for locating regions of interest in content-based information retrieval; and (iii) clustering, clearly demonstrate improved performance, and WellSVM is also readily applicable on large data sets.</abstract>
   </article>
   <article>
      <title>Multi-relational Learning Using Weighted Tensor Decomposition with
  Modular Loss</title>
      <author>Ben London, Theodoros Rekatsinas, Bert Huang, Lise Getoor</author>
      <date>2013-03-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a modular framework for multi-relational learning via tensor decomposition. In our learning setting, the training data contains multiple types of relationships among a set of objects, which we represent by a sparse three-mode tensor. The goal is to predict the values of the missing entries. To do so, we model each relationship as a function of a linear combination of latent factors. We learn this latent representation by computing a low-rank tensor decomposition, using quasi-Newton optimization of a weighted objective function. Sparsity in the observed data is captured by the weighted objective, leading to improved accuracy when training data is limited. Exploiting sparsity also improves efficiency, potentially up to an order of magnitude over unweighted approaches. In addition, our framework accommodates arbitrary combinations of smooth, task-specific loss functions, making it better suited for learning different types of relations. For the typical cases of real-valued functions and binary relations, we propose several loss functions and derive the associated parameter gradients. We evaluate our method on synthetic and real data, showing significant improvements in both accuracy and scalability over related factorization techniques.</abstract>
   </article>
   <article>
      <title>Transfer Learning for Voice Activity Detection: A Denoising Deep Neural
  Network Perspective</title>
      <author>Xiao-Lei Zhang, Ji Wu</author>
      <date>2013-03-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Mismatching problem between the source and target noisy corpora severely hinder the practical use of the machine-learning-based voice activity detection (VAD). In this paper, we try to address this problem in the transfer learning prospective. Transfer learning tries to find a common learning machine or a common feature subspace that is shared by both the source corpus and the target corpus. The denoising deep <term>neural network</term> is used as the learning machine. Three transfer techniques, which aim to learn common feature representations, are used for analysis. Experimental results demonstrate the effectiveness of the transfer learning schemes on the mismatch problem.</abstract>
   </article>
   <article>
      <title>Convex Discriminative Multitask Clustering</title>
      <author>Xiao-Lei Zhang</author>
      <date>2013-03-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multitask clustering tries to improve the clustering performance of multiple tasks simultaneously by taking their relationship into account. Most existing multitask clustering algorithms fall into the type of generative clustering, and none are formulated as convex optimization problems. In this paper, we propose two convex Discriminative Multitask Clustering (DMTC) algorithms to address the problems. Specifically, we first propose a Bayesian DMTC framework. Then, we propose two convex DMTC objectives within the framework. The first one, which can be seen as a technical combination of the convex multitask feature learning and the convex Multiclass Maximum Margin Clustering (M3C), aims to learn a shared feature representation. The second one, which can be seen as a combination of the convex multitask relationship learning and M3C, aims to learn the task relationship. The two objectives are solved in a uniform procedure by the efficient cutting-plane algorithm. Experimental results on a toy problem and two benchmark datasets demonstrate the effectiveness of the proposed algorithms.</abstract>
   </article>
   <article>
      <title>Heuristic Ternary Error-Correcting Output Codes Via Weight Optimization
  and Layered Clustering-Based Approach</title>
      <author>Xiao-Lei Zhang</author>
      <date>2013-03-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>One important classifier ensemble for multiclass classification problems is Error-Correcting Output Codes (ECOCs). It bridges multiclass problems and binary-class classifiers by decomposing multiclass problems to a serial binary-class problems. In this paper, we present a heuristic ternary code, named Weight Optimization and Layered Clustering-based ECOC (WOLC-ECOC). It starts with an arbitrary valid ECOC and iterates the following two steps until the training risk converges. The first step, named Layered Clustering based ECOC (LC-ECOC), constructs multiple strong classifiers on the most confusing binary-class problem. The second step adds the new classifiers to ECOC by a novel Optimized Weighted (OW) decoding algorithm, where the optimization problem of the decoding is solved by the cutting plane algorithm. Technically, LC-ECOC makes the heuristic training process not blocked by some difficult binary-class problem. OW decoding guarantees the non-increase of the training risk for ensuring a small code length. Results on 14 UCI datasets and a music genre classification problem demonstrate the effectiveness of WOLC-ECOC.</abstract>
   </article>
   <article>
      <title>A Last-Step Regression Algorithm for Non-Stationary Online Learning</title>
      <author>Edward Moroshko, Koby Crammer</author>
      <date>2013-03-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The goal of a learner in standard online learning is to maintain an average loss close to the loss of the best-performing single function in some class. In many real-world problems, such as rating or ranking items, there is no single best target function during the runtime of the algorithm, instead the best (local) target function is drifting over time. We develop a novel last-step minmax optimal algorithm in context of a drift. We analyze the algorithm in the worst-case regret framework and show that it maintains an average loss close to that of the best slowly changing sequence of linear functions, as long as the total of drift is sublinear. In some situations, our bound improves over existing bounds, and additionally the algorithm suffers logarithmic regret when there is no drift. We also build on the H_infinity filter and its bound, and develop and analyze a second algorithm for drifting setting. Synthetic simulations demonstrate the advantages of our algorithms in a worst-case constant drift setting.</abstract>
   </article>
   <article>
      <title>A Quorum Sensing Inspired Algorithm for Dynamic Clustering</title>
      <author>Feng Tan, Jean-Jacques Slotine</author>
      <date>2013-03-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Quorum sensing is a decentralized biological process, through which a community of cells with no global awareness coordinate their functional behaviors based solely on cell-medium interactions and local decisions. This paper draws inspirations from quorum sensing and colony competition to derive a new algorithm for data clustering. The algorithm treats each data as a single cell, and uses knowledge of local connectivity to cluster cells into multiple colonies simultaneously. It simulates auto-inducers secretion in quorum sensing to tune the influence radius for each cell. At the same time, sparsely distributed core cells spread their influences to form colonies, and interactions between colonies eventually determine each cell's identity. The algorithm has the flexibility to analyze not only static but also time-varying data, which surpasses the capacity of many existing algorithms. Its stability and convergence properties are established. The algorithm is tested on several applications, including both synthetic and real benchmarks data sets, alleles clustering, community detection, image segmentation. In particular, the algorithm's distinctive capability to deal with time-varying data allows us to experiment it on novel applications such as robotic swarms grouping and switching model identification. We believe that the algorithm's promising performance would stimulate many more exciting applications.</abstract>
   </article>
   <article>
      <title>On multi-class learning through the minimization of the confusion matrix
  norm</title>
      <author>Sokol Koço, Cécile Capponi</author>
      <date>2013-03-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In imbalanced multi-class classification problems, the misclassification rate as an error measure may not be a relevant choice. Several methods have been developed where the performance measure retained richer information than the mere misclassification rate: misclassification costs, ROC-based information, etc. Following this idea of dealing with alternate measures of performance, we propose to address imbalanced classification problems by using a new measure to be optimized: the norm of the confusion matrix. Indeed, recent results show that using the norm of the confusion matrix as an error measure can be quite interesting due to the fine-grain informations contained in the matrix, especially in the case of imbalanced classes. Our first contribution then consists in showing that optimizing criterion based on the confusion matrix gives rise to a common background for cost-sensitive methods aimed at dealing with imbalanced classes learning problems. As our second contribution, we propose an extension of a recent multi-class boosting method --- namely AdaBoost.MM --- to the imbalanced class problem, by greedily minimizing the empirical norm of the confusion matrix. A theoretical analysis of the properties of the proposed method is presented, while experimental results illustrate the behavior of the algorithm and show the relevancy of the approach compared to other methods.</abstract>
   </article>
   <article>
      <title>Markov Chain Monte Carlo for Arrangement of Hyperplanes in
  Locality-Sensitive Hashing</title>
      <author>Yui Noma, Makiko Konoshima</author>
      <date>2013-03-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Since Hamming distances can be calculated by bitwise computations, they can be calculated with less computational load than L2 distances. Similarity searches can therefore be performed faster in Hamming distance space. The elements of Hamming distance space are bit strings. On the other hand, the arrangement of hyperplanes induce the transformation from the feature vectors into feature bit strings. This transformation method is a type of locality-sensitive hashing that has been attracting attention as a way of performing approximate similarity searches at high speed. Supervised learning of hyperplane arrangements allows us to obtain a method that transforms them into feature bit strings reflecting the information of labels applied to higher-dimensional feature vectors. In this p aper, we propose a supervised learning method for hyperplane arrangements in feature space that uses a Markov chain Monte Carlo (MCMC) method. We consider the probability density functions used during learning, and evaluate their performance. We also consider the sampling method for learning data pairs needed in learning, and we evaluate its performance. We confirm that the accuracy of this learning method when using a suitable probability density function and sampling method is greater than the accuracy of existing learning methods.</abstract>
   </article>
   <article>
      <title>Large-Scale Learning with Less RAM via Randomization</title>
      <author>Daniel Golovin, D. Sculley, H. Brendan McMahan, Michael Young</author>
      <date>2013-03-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We reduce the memory footprint of popular large-scale online learning methods by projecting our weight vector onto a coarse discrete set using randomized rounding. Compared to standard 32-bit float encodings, this reduces RAM usage by more than 50% during training and by up to 95% when making predictions from a fixed model, with almost no loss in accuracy. We also show that randomized counting can be used to implement per-coordinate learning rates, improving model quality with little additional RAM. We prove these memory-saving methods achieve regret guarantees similar to their exact variants. Empirical evaluation confirms excellent performance, dominating standard approaches across memory versus accuracy tradeoffs.</abstract>
   </article>
   <article>
      <title>A Note on k-support Norm Regularized Risk Minimization</title>
      <author>Matthew Blaschko</author>
      <date>2013-03-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The k-support norm has been recently introduced to perform correlated sparsity regularization. Although Argyriou et al. only reported experiments using squared loss, here we apply it to several other commonly used settings resulting in novel machine learning algorithms with interesting and familiar limit cases. Source code for the algorithms described here is available.</abstract>
   </article>
   <article>
      <title>Inductive Hashing on Manifolds</title>
      <author>Fumin Shen, Chunhua Shen, Qinfeng Shi, Anton van den Hengel, Zhenmin Tang</author>
      <date>2013-03-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Learning based hashing methods have attracted considerable attention due to their ability to greatly increase the scale at which existing algorithms may operate. Most of these methods are designed to generate binary codes that preserve the Euclidean distance in the original space. Manifold learning techniques, in contrast, are better able to model the intrinsic structure embedded in the original high-dimensional data. The complexity of these models, and the problems with out-of-sample data, have previously rendered them unsuitable for application to large-scale embedding, however. In this work, we consider how to learn compact binary embeddings on their intrinsic manifolds. In order to address the above-mentioned difficulties, we describe an efficient, inductive solution to the out-of-sample data problem, and a process by which non-parametric manifold learning may be used as the basis of a hashing method. Our proposed approach thus allows the development of a range of new hashing techniques exploiting the flexibility of the wide variety of manifold learning approaches available. We particularly show that hashing on the basis of t-SNE .</abstract>
   </article>
   <article>
      <title>O(logT) Projections for Stochastic Optimization of Smooth and Strongly
  Convex Functions</title>
      <author>Lijun Zhang, Tianbao Yang, Rong Jin, Xiaofei He</author>
      <date>2013-04-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Traditional algorithms for stochastic optimization require projecting the solution at each iteration into a given domain to ensure its feasibility. When facing complex domains, such as positive semi-definite cones, the projection operation can be expensive, leading to a high computational cost per iteration. In this paper, we present a novel algorithm that aims to reduce the number of projections for stochastic optimization. The proposed algorithm combines the strength of several recent developments in stochastic optimization, including mini-batch, extra-gradient, and epoch <term>gradient descent</term>, in order to effectively explore the smoothness and strong convexity. We show, both in expectation and with a high probability, that when the objective function is both smooth and strongly convex, the proposed algorithm achieves the optimal $O(1/T)$ rate of convergence with only $O(\log T)$ projections. Our empirical study verifies the theoretical result.</abstract>
   </article>
   <article>
      <title>Efficient Distance Metric Learning by Adaptive Sampling and Mini-Batch
  Stochastic Gradient Descent (SGD)</title>
      <author>Qi Qian, Rong Jin, Jinfeng Yi, Lijun Zhang, Shenghuo Zhu</author>
      <date>2013-04-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Distance metric learning (DML) is an important task that has found applications in many domains. The high computational cost of DML arises from the large number of variables to be determined and the constraint that a distance metric has to be a positive semi-definite (PSD) matrix. Although stochastic <term>gradient descent</term> (SGD) has been successfully applied to improve the efficiency of DML, it can still be computationally expensive because in order to ensure that the solution is a PSD matrix, it has to, at every iteration, project the updated distance metric onto the PSD cone, an expensive operation. We address this challenge by developing two strategies within SGD, i.e. mini-batch and adaptive sampling, to effectively reduce the number of updates (i.e., projections onto the PSD cone) in SGD. We also develop hybrid approaches that combine the strength of adaptive sampling with that of mini-batch online learning techniques to further improve the computational efficiency of SGD for DML. We prove the theoretical guarantees for both adaptive sampling and mini-batch based approaches for DML. We also conduct an extensive empirical study to verify the effectiveness of the proposed algorithms for DML.</abstract>
   </article>
   <article>
      <title>Fast SVM training using approximate extreme points</title>
      <author>Manu Nandan, Pramod P. Khargonekar, Sachin S. Talathi</author>
      <date>2013-04-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Applications of non-linear kernel Support Vector Machines (SVMs) to large datasets is seriously hampered by its excessive training time. We propose a modification, called the approximate extreme points <term>support vector machine</term> (AESVM), that is aimed at overcoming this burden. Our approach relies on conducting the SVM optimization over a carefully selected subset, called the representative set, of the training dataset. We present analytical results that indicate the similarity of AESVM and SVM solutions. A linear time algorithm based on convex hulls and extreme points is used to compute the representative set in kernel space. Extensive computational experiments on nine datasets compared AESVM to LIBSVM \citep{LIBSVM}, CVM \citep{Tsang05}, BVM \citep{Tsang07}, LASVM \citep{Bordes05}, $\text{SVM}^{\text{perf}}$ \citep{Joachims09}, and the random features method \citep{rahimi07}. Our AESVM implementation was found to train much faster than the other methods, while its classification accuracy was similar to that of LIBSVM in all cases. In particular, for a seizure detection dataset, AESVM training was almost $10^3$ times faster than LIBSVM and LASVM and more than forty times faster than CVM and BVM. Additionally, AESVM also gave competitively fast classification times.</abstract>
   </article>
   <article>
      <title>A Generalized Online Mirror Descent with Applications to Classification
  and Regression</title>
      <author>Francesco Orabona, Koby Crammer, Nicolò Cesa-Bianchi</author>
      <date>2013-04-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Online learning algorithms are fast, memory-efficient, easy to implement, and applicable to many prediction problems, including classification, regression, and ranking. Several online algorithms were proposed in the past few decades, some based on additive updates, like the Perceptron, and some on multiplicative updates, like Winnow. A unifying perspective on the design and the analysis of online algorithms is provided by online mirror descent, a general prediction strategy from which most first-order algorithms can be obtained as special cases. We generalize online mirror descent to time-varying regularizers with generic updates. Unlike standard mirror descent, our more general formulation also captures second order algorithms, algorithms for composite losses and algorithms for adaptive filtering. Moreover, we recover, and sometimes improve, known regret bounds as special cases of our analysis using specific regularizers. Finally, we show the power of our approach by deriving a new second order algorithm with a regret bound invariant with respect to arbitrary rescalings of individual features.</abstract>
   </article>
   <article>
      <title>A New Homogeneity Inter-Clusters Measure in SemiSupervised Clustering</title>
      <author>Badreddine Meftahi, Ourida Ben Boubaker Saidi</author>
      <date>2013-04-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many studies in data mining have proposed a new learning called semi-Supervised. Such type of learning combines unlabeled and labeled data which are hard to obtain. However, in unsupervised methods, the only unlabeled data are used. The problem of significance and the effectiveness of semi-supervised clustering results is becoming of main importance. This paper pursues the thesis that muchgreater accuracy can be achieved in such clustering by improving the similarity computing. Hence, we introduce a new approach of semisupervised clustering using an innovative new homogeneity measure of generated clusters. Our experimental results demonstrate significantly improved accuracy as a result.</abstract>
   </article>
   <article>
      <title>A Survey on Multi-view Learning</title>
      <author>Chang Xu, Dacheng Tao, Chao Xu</author>
      <date>2013-04-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In recent years, a great many methods of learning from multi-view data by considering the diversity of different views have been proposed. These views may be obtained from multiple sources or different feature subsets. In trying to organize and highlight similarities and differences between the variety of multi-view learning approaches, we review a number of representative multi-view learning algorithms in different areas and classify them into three groups: 1) co-training, 2) multiple kernel learning, and 3) subspace learning. Notably, co-training style algorithms train alternately to maximize the mutual agreement on two distinct views of the data; multiple kernel learning algorithms exploit kernels that naturally correspond to different views and combine kernels either linearly or non-linearly to improve learning performance; and subspace learning algorithms aim to obtain a latent subspace shared by multiple views by assuming that the input views are generated from this latent subspace. Though there is significant variance in the approaches to integrating multiple views to improve learning performance, they mainly exploit either the consensus principle or the complementary principle to ensure the success of multi-view learning. Since accessing multiple views is the fundament of multi-view learning, with the exception of study on learning a model from multiple views, it is also valuable to study how to construct multiple views and how to evaluate these views. Overall, by exploring the consistency and complementary properties of different views, multi-view learning is rendered more effective, more promising, and has better generalization ability than single-view learning.</abstract>
   </article>
   <article>
      <title>Continuum armed bandit problem of few variables in high dimensions</title>
      <author>Hemant Tyagi, Bernd Gärtner</author>
      <date>2013-04-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the stochastic and adversarial settings of continuum armed bandits where the arms are indexed by [0,1]^d. The reward functions r:[0,1]^d -&gt; R are assumed to intrinsically depend on at most k coordinate variables implying r(x_1,..,x_d) = g(x_{i_1},..,x_{i_k}) for distinct and unknown i_1,..,i_k from {1,..,d} and some locally Holder continuous g:[0,1]^k -&gt; R with exponent 0 &lt; alpha &lt;= 1. Firstly, assuming (i_1,..,i_k) to be fixed across time, we propose a simple modification of the CAB1 algorithm where we construct the discrete set of sampling points to obtain a bound of O(n^((alpha+k)/(2*alpha+k)) (log n)^((alpha)/(2*alpha+k)) C(k,d)) on the regret, with C(k,d) depending at most polynomially in k and sub-logarithmically in d. The construction is based on creating partitions of {1,..,d} into k disjoint subsets and is probabilistic, hence our result holds with high probability. Secondly we extend our results to also handle the more general case where (i_1,...,i_k) can change over time and derive regret bounds for the same.</abstract>
   </article>
   <article>
      <title>Irreflexive and Hierarchical Relations as Translations</title>
      <author>Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko</author>
      <date>2013-04-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of embedding entities and relations of knowledge bases in low-dimensional vector spaces. Unlike most existing approaches, which are primarily efficient for modeling equivalence relations, our approach is designed to explicitly model irreflexive relations, such as hierarchies, by interpreting them as translations operating on the low-dimensional embeddings of the entities. Preliminary experiments show that, despite its simplicity and a smaller number of parameters than previous approaches, our approach achieves state-of-the-art performance according to standard evaluation protocols on data from WordNet and Freebase.</abstract>
   </article>
   <article>
      <title>Fractal structures in Adversarial Prediction</title>
      <author>Rina Panigrahy, Preyas Popat</author>
      <date>2013-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Fractals are self-similar recursive structures that have been used in modeling several real world processes. In this work we study how "fractal-like" processes arise in a prediction game where an adversary is generating a sequence of bits and an algorithm is trying to predict them. We will see that under a certain formalization of the predictive payoff for the algorithm it is most optimal for the adversary to produce a fractal-like sequence to minimize the algorithm's ability to predict. Indeed it has been suggested before that financial markets exhibit a fractal-like behavior. We prove that a fractal-like distribution arises naturally out of an optimization from the adversary's perspective.   In addition, we give optimal trade-offs between predictability and expected deviation (i.e. sum of bits) for our formalization of predictive payoff. This result is motivated by the observation that several time series data exhibit higher deviations than expected for a completely random walk.</abstract>
   </article>
   <article>
      <title>Clustering Unclustered Data: Unsupervised Binary Labeling of Two
  Datasets Having Different Class Balances</title>
      <author>Marthinus Christoffel du Plessis, Masashi Sugiyama</author>
      <date>2013-05-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the <term>unsupervised learning</term> problem of assigning labels to unlabeled data. A naive approach is to use clustering methods, but this works well only when data is properly clustered and each cluster corresponds to an underlying class. In this paper, we first show that this unsupervised labeling problem in balanced binary cases can be solved if two unlabeled datasets having different class balances are available. More specifically, estimation of the sign of the difference between probability densities of two unlabeled datasets gives the solution. We then introduce a new method to directly estimate the sign of the density difference without density estimation. Finally, we demonstrate the usefulness of the proposed method against several clustering methods on various toy problems and real-world datasets.</abstract>
   </article>
   <article>
      <title>Perceptron Mistake Bounds</title>
      <author>Mehryar Mohri, Afshin Rostamizadeh</author>
      <date>2013-05-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a brief survey of existing mistake bounds and introduce novel bounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds generalize beyond standard margin-loss type bounds, allow for any convex and Lipschitz loss function, and admit a very simple proof.</abstract>
   </article>
   <article>
      <title>Deep Learning of Representations: Looking Forward</title>
      <author>Yoshua Bengio</author>
      <date>2013-05-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of <term>deep learning</term> has already led to impressive theoretical results, learning algorithms and breakthrough experiments, several challenges lie ahead. This paper proposes to examine some of these challenges, centering on the questions of scaling <term>deep learning</term> algorithms to much larger models and datasets, reducing optimization difficulties due to ill-conditioning or local minima, designing more efficient and powerful inference and sampling procedures, and learning to disentangle the factors of variation underlying the observed data. It also proposes a few forward-looking research directions aimed at overcoming these challenges.</abstract>
   </article>
   <article>
      <title>Spectral Classification Using Restricted Boltzmann Machine</title>
      <author>Fuqiang Chen, Yan Wu, Yude Bu, Guodong Zhao</author>
      <date>2013-05-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this study, a novel machine learning algorithm, restricted Boltzmann machine (RBM), is introduced. The algorithm is applied for the spectral classification in astronomy. RBM is a bipartite generative graphical model with two separate layers (one visible layer and one hidden layer), which can extract higher level features to represent the original data. Despite generative, RBM can be used for classification when modified with a free energy and a soft-max function. Before spectral classification, the original data is binarized according to some rule. Then we resort to the binary RBM to classify cataclysmic variables (CVs) and non-CVs (one half of all the given data for training and the other half for testing). The experiment result shows state-of-the-art accuracy of 100%, which indicates the efficiency of the binary RBM algorithm.</abstract>
   </article>
   <article>
      <title>Learning from Imprecise and Fuzzy Observations: Data Disambiguation
  through Generalized Loss Minimization</title>
      <author>Eyke Hüllermeier</author>
      <date>2013-05-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Methods for analyzing or learning from "fuzzy data" have attracted increasing attention in recent years. In many cases, however, existing methods (for precise, non-fuzzy data) are extended to the fuzzy case in an ad-hoc manner, and without carefully considering the interpretation of a fuzzy set when being used for modeling data. Distinguishing between an ontic and an epistemic interpretation of fuzzy set-valued data, and focusing on the latter, we argue that a "fuzzification" of learning algorithms based on an application of the generic extension principle is not appropriate. In fact, the extension principle fails to properly exploit the inductive bias underlying statistical and machine learning methods, although this bias, at least in principle, offers a means for "disambiguating" the fuzzy data. Alternatively, we therefore propose a method which is based on the generalization of loss functions in empirical risk minimization, and which performs model identification and data disambiguation simultaneously. Elaborating on the fuzzification of specific types of losses, we establish connections to well-known loss functions in regression and classification. We compare our approach with related methods and illustrate its use in logistic regression for binary classification.</abstract>
   </article>
   <article>
      <title>Simple Deep Random Model Ensemble</title>
      <author>Xiao-Lei Zhang, Ji Wu</author>
      <date>2013-05-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Representation learning and <term>unsupervised learning</term> are two central topics of machine learning and signal processing. Deep learning is one of the most effective unsupervised representation learning approach. The main contributions of this paper to the topics are as follows. (i) We propose to view the representative <term>deep learning</term> approaches as special cases of the knowledge reuse framework of clustering ensemble. (ii) We propose to view sparse coding when used as a feature encoder as the consensus function of clustering ensemble, and view dictionary learning as the training process of the base clusterings of clustering ensemble. (ii) Based on the above two views, we propose a very simple <term>deep learning</term> algorithm, named deep random model ensemble (DRME). It is a stack of random model ensembles. Each random model ensemble is a special k-means ensemble that discards the expectation-maximization optimization of each base k-means but only preserves the default initialization method of the base k-means. (iv) We propose to select the most powerful representation among the layers by applying DRME to clustering where the single-linkage is used as the clustering algorithm. Moreover, the DRME based clustering can also detect the number of the natural clusters accurately. Extensive experimental comparisons with 5 representation learning methods on 19 benchmark data sets demonstrate the effectiveness of DRME.</abstract>
   </article>
   <article>
      <title>A Differential Equations Approach to Optimizing Regret Trade-offs</title>
      <author>Alexandr Andoni, Rina Panigrahy</author>
      <date>2013-05-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the classical question of predicting binary sequences and study the {\em optimal} algorithms for obtaining the best possible regret and payoff functions for this problem. The question turns out to be also equivalent to the problem of optimal trade-offs between the regrets of two experts in an "experts problem", studied before by \cite{kearns-regret}. While, say, a regret of $\Theta(\sqrt{T})$ is known, we argue that it important to ask what is the provably optimal algorithm for this problem --- both because it leads to natural algorithms, as well as because regret is in fact often comparable in magnitude to the final payoffs and hence is a non-negligible term.   In the basic setting, the result essentially follows from a classical result of Cover from '65. Here instead, we focus on another standard setting, of time-discounted payoffs, where the final "stopping time" is not specified. We exhibit an explicit characterization of the optimal regret for this setting.   To obtain our main result, we show that the optimal payoff functions have to satisfy the Hermite differential equation, and hence are given by the solutions to this equation. It turns out that characterization of the payoff function is qualitatively different from the classical (non-discounted) setting, and, namely, there's essentially a unique optimal solution.</abstract>
   </article>
   <article>
      <title>One-Pass AUC Optimization</title>
      <author>Wei Gao, Rong Jin, Shenghuo Zhu, Zhi-Hua Zhou</author>
      <date>2013-05-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>AUC is an important performance measure and many algorithms have been devoted to AUC optimization, mostly by minimizing a surrogate convex loss on a training data set. In this work, we focus on one-pass AUC optimization that requires only going through the training data once without storing the entire training dataset, where conventional online learning algorithms cannot be applied directly because AUC is measured by a sum of losses defined over pairs of instances from different classes. We develop a regression-based algorithm which only needs to maintain the first and second order statistics of training data in memory, resulting a storage requirement independent from the size of training data. To efficiently handle high dimensional data, we develop a randomized algorithm that approximates the covariance matrices by low rank matrices. We verify, both theoretically and empirically, the effectiveness of the proposed algorithm.</abstract>
   </article>
   <article>
      <title>Class Imbalance Problem in Data Mining Review</title>
      <author>Rushi Longadge, Snehalata Dongre</author>
      <date>2013-05-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In last few years there are major changes and evolution has been done on classification of data. As the application area of technology is increases the size of data also increases. Classification of data becomes difficult because of unbounded size and imbalance nature of data. Class imbalance problem become greatest issue in data mining. Imbalance problem occur where one of the two classes having more sample than other classes. The most of algorithm are more focusing on classification of major sample while ignoring or misclassifying minority sample. The minority samples are those that rarely occur but very important. There are different methods available for classification of imbalance data set which is divided into three main categories, the algorithmic approach, data-preprocessing approach and feature selection approach. Each of this technique has their own advantages and disadvantages. In this paper systematic study of each approach is define which gives the right direction for research in class imbalance problem.</abstract>
   </article>
   <article>
      <title>Stochastic Collapsed Variational Bayesian Inference for Latent Dirichlet
  Allocation</title>
      <author>James Foulds, Levi Boyles, Christopher Dubois, Padhraic Smyth, Max Welling</author>
      <date>2013-05-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In the internet era there has been an explosion in the amount of digital text information available, leading to difficulties of scale for traditional inference algorithms for topic models. Recent advances in stochastic variational inference algorithms for latent Dirichlet allocation (LDA) have made it feasible to learn topic models on large-scale corpora, but these methods do not currently take full advantage of the collapsed representation of the model. We propose a stochastic algorithm for collapsed variational Bayesian inference for LDA, which is simpler and more efficient than the state of the art method. We show connections between collapsed variational Bayesian inference and MAP estimation for LDA, and leverage these connections to prove convergence properties of the proposed algorithm. In experiments on large-scale text corpora, the algorithm was found to converge faster and often to a better solution than the previous method. Human-subject experiments also demonstrated that the method can learn coherent topics in seconds on small corpora, facilitating the use of topic models in interactive document analysis software.</abstract>
   </article>
   <article>
      <title>An efficient algorithm for learning with semi-bandit feedback</title>
      <author>Gergely Neu, Gábor Bartók</author>
      <date>2013-05-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of online combinatorial optimization under semi-bandit feedback. The goal of the learner is to sequentially select its actions from a combinatorial decision set so as to minimize its cumulative loss. We propose a learning algorithm for this problem based on combining the Follow-the-Perturbed-Leader (FPL) prediction method with a novel loss estimation procedure called Geometric Resampling (GR). Contrary to previous solutions, the resulting algorithm can be efficiently implemented for any decision set where efficient offline combinatorial optimization is possible at all. Assuming that the elements of the decision set can be described with d-dimensional binary vectors with at most m non-zero entries, we show that the expected regret of our algorithm after T rounds is O(m sqrt(dT log d)). As a side result, we also improve the best known regret bounds for FPL in the full information setting to O(m^(3/2) sqrt(T log d)), gaining a factor of sqrt(d/m) over previous bounds for this algorithm.</abstract>
   </article>
   <article>
      <title>Estimating or Propagating Gradients Through Stochastic Neurons</title>
      <author>Yoshua Bengio</author>
      <date>2013-05-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic neurons can be useful for a number of reasons in <term>deep learning</term> models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic neurons, i.e., can we "back-propagate" through these stochastic neurons? We examine this question, existing approaches, and present two novel families of solutions, applicable in different settings. In particular, it is demonstrated that a simple biologically plausible formula gives rise to an an unbiased (but noisy) estimator of the gradient with respect to a binary stochastic neuron firing probability. Unlike other estimators which view the noise as a small perturbation in order to estimate gradients by finite differences, this estimator is unbiased even without assuming that the stochastic perturbation is small. This estimator is also interesting because it can be applied in very general settings which do not allow gradient back-propagation, including the estimation of the gradient with respect to future rewards, as required in <term>reinforcement learning</term> setups. We also propose an approach to approximating this unbiased but high-variance estimator by learning to predict it using a biased estimator. The second approach we propose assumes that an estimator of the gradient can be back-propagated and it provides an unbiased estimator of the gradient, but can only work with non-linearities unlike the hard threshold, but like the rectifier, that are not flat for all of their range. This is similar to traditional sigmoidal units but has the advantage that for many inputs, a hard decision (e.g., a 0 output) can be produced, which would be convenient for conditional computation and achieving sparse representations and sparse gradients.</abstract>
   </article>
   <article>
      <title>Contractive De-noising Auto-encoder</title>
      <author>Fu-qiang Chen, Yan Wu, Guo-dong Zhao, Jun-ming Zhang, Ming Zhu, Jing Bai</author>
      <date>2013-05-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Auto-encoder is a special kind of <term>neural network</term> based on reconstruction. De-noising auto-encoder (DAE) is an improved auto-encoder which is robust to the input by corrupting the original data first and then reconstructing the original input by minimizing the reconstruction error function. And contractive auto-encoder (CAE) is another kind of improved auto-encoder to learn robust feature by introducing the Frobenius norm of the Jacobean matrix of the learned feature with respect to the original input. In this paper, we combine de-noising auto-encoder and contractive auto- encoder, and propose another improved auto-encoder, contractive de-noising auto- encoder (CDAE), which is robust to both the original input and the learned feature. We stack CDAE to extract more abstract features and apply SVM for classification. The experiment result on benchmark dataset MNIST shows that our proposed CDAE performed better than both DAE and CAE, proving the effective of our method.</abstract>
   </article>
   <article>
      <title>Ensembles of Classifiers based on Dimensionality Reduction</title>
      <author>Alon Schclar, Lior Rokach, Amir Amit</author>
      <date>2013-05-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a novel approach for the construction of ensemble classifiers based on dimensionality reduction. Dimensionality reduction methods represent datasets using a small number of attributes while preserving the information conveyed by the original dataset. The ensemble members are trained based on dimension-reduced versions of the training set. These versions are obtained by applying dimensionality reduction to the original training set using different values of the input parameters. This construction meets both the diversity and accuracy criteria which are required to construct an ensemble classifier where the former criterion is obtained by the various input parameter values and the latter is achieved due to the decorrelation and noise reduction properties of dimensionality reduction. In order to classify a test sample, it is first embedded into the dimension reduced space of each individual classifier by using an out-of-sample extension algorithm. Each classifier is then applied to the embedded sample and the classification is obtained via a voting scheme. We present three variations of the proposed approach based on the Random Projections, the Diffusion Maps and the Random Subspaces dimensionality reduction algorithms. We also present a multi-strategy ensemble which combines AdaBoost and Diffusion Maps. A comparison is made with the Bagging, AdaBoost, Rotation Forest ensemble classifiers and also with the base classifier which does not incorporate dimensionality reduction. Our experiments used seventeen benchmark datasets from the UCI repository. The results obtained by the proposed algorithms were superior in many cases to other algorithms.</abstract>
   </article>
   <article>
      <title>Generalized Denoising Auto-Encoders as Generative Models</title>
      <author>Yoshua Bengio, Li Yao, Guillaume Alain, Pascal Vincent</author>
      <date>2013-05-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recent work has shown how denoising and contractive autoencoders implicitly capture the structure of the data-generating density, in the case where the corruption noise is Gaussian, the reconstruction error is the squared error, and the data is continuous-valued. This has led to various proposals for sampling from this implicitly learned density function, using Langevin and Metropolis-Hastings MCMC. However, it remained unclear how to connect the training procedure of regularized auto-encoders to the implicit estimation of the underlying data-generating distribution when the data are discrete, or using other forms of corruption process and reconstruction errors. Another issue is the mathematical justification which is only valid in the limit of small corruption noise. We propose here a different attack on the problem, which deals with all these issues: arbitrary (but noisy enough) corruption, arbitrary reconstruction loss (seen as a log-likelihood), handling both discrete and continuous-valued variables, and removing the bias due to non-infinitesimal corruption noise (or non-infinitesimal contractive penalty).</abstract>
   </article>
   <article>
      <title>Test cost and misclassification cost trade-off using reframing</title>
      <author>Celestine Periale Maguedong-Djoumessi, José Hernández-Orallo</author>
      <date>2013-05-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many solutions to cost-sensitive classification (and regression) rely on some or all of the following assumptions: we have complete knowledge about the cost context at training time, we can easily re-train whenever the cost context changes, and we have technique-specific methods (such as cost-sensitive decision trees) that can take advantage of that information. In this paper we address the problem of selecting models and minimising joint cost (integrating both misclassification cost and test costs) without any of the above assumptions. We introduce methods and plots (such as the so-called JROC plots) that can work with any off-the-shelf predictive technique, including ensembles, such that we reframe the model to use the appropriate subset of attributes (the feature configuration) during deployment time. In other words, models are trained with the available attributes (once and for all) and then deployed by setting missing values on the attributes that are deemed ineffective for reducing the joint cost. As the number of feature configuration combinations grows exponentially with the number of features we introduce quadratic methods that are able to approximate the optimal configuration and model choices, as shown by the experimental results.</abstract>
   </article>
   <article>
      <title>Understanding ACT-R - an Outsider's Perspective</title>
      <author>Jacob Whitehill</author>
      <date>2013-06-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The ACT-R theory of cognition developed by John Anderson and colleagues endeavors to explain how humans recall chunks of information and how they solve problems. ACT-R also serves as a theoretical basis for "cognitive tutors", i.e., automatic tutoring systems that help students learn mathematics, computer programming, and other subjects. The official ACT-R definition is distributed across a large body of literature spanning many articles and monographs, and hence it is difficult for an "outsider" to learn the most important aspects of the theory. This paper aims to provide a tutorial to the core components of the ACT-R theory.</abstract>
   </article>
   <article>
      <title>Guided Random Forest in the RRF Package</title>
      <author>Houtao Deng</author>
      <date>2013-06-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Random Forest (RF) is a powerful supervised learner and has been popularly used in many applications such as bioinformatics.   In this work we propose the guided <term>random forest</term> (GRF) for feature selection. Similar to a feature selection method called guided regularized <term>random forest</term> (GRRF), GRF is built using the importance scores from an ordinary RF. However, the trees in GRRF are built sequentially, are highly correlated and do not allow for parallel computing, while the trees in GRF are built independently and can be implemented in parallel. Experiments on 10 high-dimensional gene data sets show that, with a fixed parameter value (without tuning the parameter), RF applied to features selected by GRF outperforms RF applied to all features on 9 data sets and 7 of them have significant differences at the 0.05 level. Therefore, both accuracy and interpretability are significantly improved. GRF selects more features than GRRF, however, leads to better classification accuracy. Note in this work the guided <term>random forest</term> is guided by the importance scores from an ordinary <term>random forest</term>, however, it can also be guided by other methods such as human insights (by specifying $\lambda_i$). GRF can be used in "RRF" v1.4 (and later versions), a package that also includes the regularized <term>random forest</term> methods.</abstract>
   </article>
   <article>
      <title>Deep Generative Stochastic Networks Trainable by Backprop</title>
      <author>Yoshua Bengio, Éric Thibodeau-Laufer, Guillaume Alain, Jason Yosinski</author>
      <date>2013-06-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution of the Markov chain is conditional on the previous state, generally involving a small move, so this conditional distribution has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn because it is easier to approximate its partition function, more like learning to perform supervised function approximation, with gradients that can be obtained by backprop. We provide theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood, along with a definition of an appropriate joint distribution and sampling mechanism even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. We validate these theoretical results with experiments on two image datasets using an architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with simple backprop, without the need for layerwise pretraining.</abstract>
   </article>
   <article>
      <title>Performance analysis of unsupervised feature selection methods</title>
      <author>A. Nisthana Parveen, H. Hannah Inbarani, E. N. Sathishkumar</author>
      <date>2013-06-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Feature selection (FS) is a process which attempts to select more informative features. In some cases, too many redundant or irrelevant features may overpower main features for classification. Feature selection can remedy this problem and therefore improve the prediction accuracy and reduce the computational overhead of classification algorithms. The main aim of feature selection is to determine a minimal feature subset from a problem domain while retaining a suitably high accuracy in representing the original features. In this paper, Principal Component Analysis (PCA), Rough PCA, Unsupervised Quick Reduct (USQR) algorithm and Empirical Distribution Ranking (EDR) approaches are applied to discover discriminative features that will be the most adequate ones for classification. Efficiency of the approaches is evaluated using standard classification metrics.</abstract>
   </article>
   <article>
      <title>Auditing: Active Learning with Outcome-Dependent Query Costs</title>
      <author>Sivan Sabato, Anand D. Sarwate, Nathan Srebro</author>
      <date>2013-06-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a learning setting in which unlabeled data is free, and the cost of a label depends on its value, which is not known in advance. We study binary classification in an extreme case, where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection, in which investigating an honest transaction should be avoided if possible. We term the setting auditing, and consider the auditing complexity of an algorithm: the number of negative labels the algorithm requires in order to learn a hypothesis with low relative error. We design auditing algorithms for simple hypothesis classes (thresholds and rectangles), and show that with these algorithms, the auditing complexity can be significantly lower than the active label complexity. We also discuss a general competitive approach for auditing and possible modifications to the framework.</abstract>
   </article>
   <article>
      <title>Guaranteed Classification via Regularized Similarity Learning</title>
      <author>Zheng-Chu Guo, Yiming Ying</author>
      <date>2013-06-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Learning an appropriate (dis)similarity function from the available data is a central problem in machine learning, since the success of many machine learning algorithms critically depends on the choice of a similarity function to compare examples. Despite many approaches for similarity metric learning have been proposed, there is little theoretical study on the links between similarity met- ric learning and the classification performance of the result classifier. In this paper, we propose a regularized similarity learning formulation associated with general matrix-norms, and establish their generalization bounds. We show that the generalization error of the resulting linear separator can be bounded by the derived generalization bound of similarity learning. This shows that a good gen- eralization of the learnt similarity function guarantees a good classification of the resulting linear classifier. Our results extend and improve those obtained by Bellet at al. [3]. Due to the techniques dependent on the notion of uniform stability [6], the bound obtained there holds true only for the Frobenius matrix- norm regularization. Our techniques using the Rademacher complexity [5] and its related Khinchin-type inequality enable us to establish bounds for regularized similarity learning formulations associated with general matrix-norms including sparse L 1 -norm and mixed (2,1)-norm.</abstract>
   </article>
   <article>
      <title>On-line PCA with Optimal Regrets</title>
      <author>Jiazhong Nie, Wojciech Kotlowski, Manfred K. Warmuth</author>
      <date>2013-06-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We carefully investigate the on-line version of PCA, where in each trial a learning algorithm plays a k-dimensional subspace, and suffers the compression loss on the next instance when projected into the chosen subspace. In this setting, we analyze two popular on-line algorithms, Gradient Descent (GD) and Exponentiated Gradient (EG). We show that both algorithms are essentially optimal in the worst-case. This comes as a surprise, since EG is known to perform sub-optimally when the instances are sparse. This different behavior of EG for PCA is mainly related to the non-negativity of the loss in this case, which makes the PCA setting qualitatively different from other settings studied in the literature. Furthermore, we show that when considering regret bounds as function of a loss budget, EG remains optimal and strictly outperforms GD. Next, we study the extension of the PCA setting, in which the Nature is allowed to play with dense instances, which are positive matrices with bounded largest eigenvalue. Again we can show that EG is optimal and strictly better than GD in this setting.</abstract>
   </article>
   <article>
      <title>Multiarmed Bandits With Limited Expert Advice</title>
      <author>Satyen Kale</author>
      <date>2013-06-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We solve the COLT 2013 open problem of \citet{SCB} on minimizing regret in the setting of advice-efficient multiarmed bandits with expert advice. We give an algorithm for the setting of K arms and N experts out of which we are allowed to query and use only M experts' advices in each round, which has a regret bound of \tilde{O}\bigP{\sqrt{\frac{\min\{K, M\} N}{M} T}} after T rounds. We also prove that any algorithm for this problem must have expected regret at least \tilde{\Omega}\bigP{\sqrt{\frac{\min\{K, M\} N}{M}T}}, thus showing that our upper bound is nearly tight.</abstract>
   </article>
   <article>
      <title>Machine Teaching for Bayesian Learners in the Exponential Family</title>
      <author>Xiaojin Zhu</author>
      <date>2013-06-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>What if there is a teacher who knows the learning goal and wants to design good training data for a machine learner? We propose an optimal teaching framework aimed at learners who employ Bayesian models. Our framework is expressed as an optimization problem over teaching examples that balance the future loss of the learner and the effort of the teacher. This optimization problem is in general hard. In the case where the learner employs conjugate exponential family models, we present an approximate algorithm for finding the optimal teaching set. Our algorithm optimizes the aggregate sufficient statistics, then unpacks them into actual teaching examples. We give several examples to illustrate our framework.</abstract>
   </article>
   <article>
      <title>Song-based Classification techniques for Endangered Bird Conservation</title>
      <author>Erick Stattner, Wilfried Segretier, Martine Collard, Philippe Hunel, Nicolas Vidot</author>
      <date>2013-06-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The work presented in this paper is part of a global framework which long term goal is to design a wireless sensor network able to support the observation of a population of endangered birds. We present the first stage for which we have conducted a knowledge discovery approach on a sample of acoustical data. We use MFCC features extracted from bird songs and we exploit two knowledge discovery techniques. One that relies on clustering-based approaches, that highlights the homogeneity in the songs of the species. The other, based on predictive modeling, that demonstrates the good performances of various machine learning techniques for the identification process. The knowledge elicited provides promising results to consider a widespread study and to elicit guidelines for designing a first version of the automatic approach for data collection based on acoustic sensors.</abstract>
   </article>
   <article>
      <title>Model Reframing by Feature Context Change</title>
      <author>Celestine-Periale Maguedong-Djoumessi</author>
      <date>2013-06-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The feature space (including both input and output variables) characterises a data mining problem. In predictive (supervised) problems, the quality and availability of features determines the predictability of the dependent variable, and the performance of data mining models in terms of misclassification or regression error. Good features, however, are usually difficult to obtain. It is usual that many instances come with missing values, either because the actual value for a given attribute was not available or because it was too expensive. This is usually interpreted as a utility or cost-sensitive learning dilemma, in this case between misclassification (or regression error) costs and attribute tests costs. Both misclassification cost (MC) and test cost (TC) can be integrated into a single measure, known as joint cost (JC). We introduce methods and plots (such as the so-called JROC plots) that can work with any of-the-shelf predictive technique, including ensembles, such that we re-frame the model to use the appropriate subset of attributes (the feature configuration) during deployment time. In other words, models are trained with the available attributes (once and for all) and then deployed by setting missing values on the attributes that are deemed ineffective for reducing the joint cost. As the number of feature configuration combinations grows exponentially with the number of features we introduce quadratic methods that are able to approximate the optimal configuration and model choices, as shown by the experimental results.</abstract>
   </article>
   <article>
      <title>Exploratory Learning</title>
      <author>Bhavana Dalvi, William W. Cohen, Jamie Callan</author>
      <date>2013-07-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In multiclass semi-supervised learning (SSL), it is sometimes the case that the number of classes present in the data is not known, and hence no labeled examples are provided for some classes. In this paper we present variants of well-known semi-supervised multiclass learning methods that are robust when the data contains an unknown number of classes. In particular, we present an "exploratory" extension of expectation-maximization (EM) that explores different numbers of classes while learning. "Exploratory" SSL greatly improves performance on three datasets in terms of F1 on the classes with seed examples i.e., the classes which are expected to be in the data. Our Exploratory EM algorithm also outperforms a SSL method based non-parametric Bayesian clustering.</abstract>
   </article>
   <article>
      <title>A PAC-Bayesian Tutorial with A Dropout Bound</title>
      <author>David McAllester</author>
      <date>2013-07-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This tutorial gives a concise overview of existing PAC-Bayesian theory focusing on three generalization bounds. The first is an Occam bound which handles rules with finite precision parameters and which states that generalization loss is near training loss when the number of bits needed to write the rule is small compared to the sample size. The second is a PAC-Bayesian bound providing a generalization guarantee for posterior distributions rather than for individual rules. The PAC-Bayesian bound naturally handles infinite precision rule parameters, $L_2$ regularization, {\em provides a bound for dropout training}, and defines a natural notion of a single distinguished PAC-Bayesian posterior distribution. The third bound is a training-variance bound --- a kind of bias-variance analysis but with bias replaced by expected training loss. The training-variance bound dominates the other bounds but is more difficult to interpret. It seems to suggest variance reduction methods such as bagging and may ultimately provide a more meaningful analysis of dropouts.</abstract>
   </article>
   <article>
      <title>Minimum Error Rate Training and the Convex Hull Semiring</title>
      <author>Chris Dyer</author>
      <date>2013-07-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We describe the line search used in the minimum error rate training algorithm MERT as the "inside score" of a weighted proof forest under a semiring defined in terms of well-understood operations from computational geometry. This conception leads to a straightforward complexity analysis of the dynamic programming MERT algorithms of Macherey et al. (2008) and Kumar et al. (2009) and practical approaches to implementation.</abstract>
   </article>
   <article>
      <title>Large-scale Multi-label Learning with Missing Labels</title>
      <author>Hsiang-Fu Yu, Prateek Jain, Purushottam Kar, Inderjit S. Dhillon</author>
      <date>2013-07-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The multi-label classification problem has generated significant interest in recent years. However, existing approaches do not adequately address two key challenges: (a) the ability to tackle problems with a large number (say millions) of labels, and (b) the ability to handle data with missing labels. In this paper, we directly address both these problems by studying the multi-label problem in a generic empirical risk minimization (ERM) framework. Our framework, despite being simple, is surprisingly able to encompass several recent label-compression based methods which can be derived as special cases of our method. To optimize the ERM problem, we develop techniques that exploit the structure of specific loss functions - such as the squared loss function - to offer efficient algorithms. We further show that our learning framework admits formal excess risk bounds even in the presence of missing labels. Our risk bounds are tight and demonstrate better generalization performance for low-rank promoting trace-norm regularization when compared to (rank insensitive) Frobenius norm regularization. Finally, we present extensive empirical results on a variety of benchmark datasets and show that our methods perform significantly better than existing label compression based methods and can scale up to very large datasets such as the Wikipedia dataset.</abstract>
   </article>
   <article>
      <title>Towards Distribution-Free Multi-Armed Bandits with Combinatorial
  Strategies</title>
      <author>Xiang-yang Li, Shaojie Tang, Yaqin Zhou</author>
      <date>2013-07-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we study a generalized version of classical multi-armed bandits (MABs) problem by allowing for arbitrary constraints on constituent bandits at each decision point. The motivation of this study comes from many situations that involve repeatedly making choices subject to arbitrary constraints in an uncertain environment: for instance, regularly deciding which advertisements to display online in order to gain high click-through-rate without knowing user preferences, or what route to drive home each day under uncertain weather and traffic conditions. Assume that there are $K$ unknown random variables (RVs), i.e., arms, each evolving as an \emph{i.i.d} stochastic process over time. At each decision epoch, we select a strategy, i.e., a subset of RVs, subject to arbitrary constraints on constituent RVs.   We then gain a reward that is a linear combination of observations on selected RVs.   The performance of prior results for this problem heavily depends on the distribution of strategies generated by corresponding learning policy. For example, if the reward-difference between the best and second best strategy approaches zero, prior result may lead to arbitrarily large regret.   Meanwhile, when there are exponential number of possible strategies at each decision point, naive extension of a prior distribution-free policy would cause poor performance in terms of regret, computation and space complexity.   To this end, we propose an efficient Distribution-Free Learning (DFL) policy that achieves zero regret, regardless of the probability distribution of the resultant strategies.   Our learning policy has both $O(K)$ time complexity and $O(K)$ space complexity. In successive generations, we show that even if finding the optimal strategy at each decision point is NP-hard, our policy still allows for approximated solutions while retaining near zero-regret.</abstract>
   </article>
   <article>
      <title>A scalable stage-wise approach to large-margin multi-class loss based
  boosting</title>
      <author>Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel</author>
      <date>2013-07-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a scalable and effective classification model to train multi-class boosting for multi-class classification problems. Shen and Hao introduced a direct formulation of multi- class boosting in the sense that it directly maximizes the multi- class margin [C. Shen and Z. Hao, "A direct formulation for totally-corrective multi- class boosting", in Proc. IEEE Conf. Comp. Vis. Patt. Recogn., 2011]. The major problem of their approach is its high computational complexity for training, which hampers its application on real-world problems. In this work, we propose a scalable and simple stage-wise multi-class boosting method, which also directly maximizes the multi-class margin. Our approach of- fers a few advantages: 1) it is simple and computationally efficient to train. The approach can speed up the training time by more than two orders of magnitude without sacrificing the classification accuracy. 2) Like traditional AdaBoost, it is less sensitive to the choice of parameters and empirically demonstrates excellent generalization performance. Experimental results on challenging multi-class machine learning and vision tasks demonstrate that the proposed approach substantially improves the convergence rate and accuracy of the final visual detector at no additional computational cost compared to existing multi-class boosting.</abstract>
   </article>
   <article>
      <title>A New Strategy of Cost-Free Learning in the Class Imbalance Problem</title>
      <author>Xiaowan Zhang, Bao-Gang Hu</author>
      <date>2013-07-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this work, we define cost-free learning (CFL) formally in comparison with cost-sensitive learning (CSL). The main difference between them is that a CFL approach seeks optimal classification results without requiring any cost information, even in the class imbalance problem. In fact, several CFL approaches exist in the related studies, such as sampling and some criteria-based pproaches. However, to our best knowledge, none of the existing CFL and CSL approaches are able to process the abstaining classifications properly when no information is given about errors and rejects. Based on information theory, we propose a novel CFL which seeks to maximize normalized mutual information of the targets and the decision outputs of classifiers. Using the strategy, we can deal with binary/multi-class classifications with/without abstaining. Significant features are observed from the new strategy. While the degree of class imbalance is changing, the proposed strategy is able to balance the errors and rejects accordingly and automatically. Another advantage of the strategy is its ability of deriving optimal rejection thresholds for abstaining classifications and the "equivalent" costs in binary classifications. The connection between rejection thresholds and ROC curve is explored. Empirical investigation is made on several benchmark data sets in comparison with other existing approaches. The classification results demonstrate a promising perspective of the strategy in machine learning.</abstract>
   </article>
   <article>
      <title>A Propound Method for the Improvement of Cluster Quality</title>
      <author>Shveta Kundra Bhatia, V. S. Dixit</author>
      <date>2013-07-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper Knockout Refinement Algorithm (KRA) is proposed to refine original clusters obtained by applying SOM and K-Means clustering algorithms. KRA Algorithm is based on Contingency Table concepts. Metrics are computed for the Original and Refined Clusters. Quality of Original and Refined Clusters are compared in terms of metrics. The proposed algorithm (KRA) is tested in the educational domain and results show that it generates better quality clusters in terms of improved metric values.</abstract>
   </article>
   <article>
      <title>Towards Minimax Online Learning with Unknown Time Horizon</title>
      <author>Haipeng Luo, Robert E. Schapire</author>
      <date>2013-07-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider online learning when the time horizon is unknown. We apply a minimax analysis, beginning with the fixed horizon case, and then moving on to two unknown-horizon settings, one that assumes the horizon is chosen randomly according to some known distribution, and the other which allows the adversary full control over the horizon. For the random horizon setting with restricted losses, we derive a fully optimal minimax algorithm. And for the adversarial horizon setting, we prove a nontrivial lower bound which shows that the adversary obtains strictly more power than when the horizon is fixed and known. Based on the minimax solution of the random horizon setting, we then propose a new adaptive algorithm which "pretends" that the horizon is drawn from a distribution from a special family, but no matter how the actual horizon is chosen, the worst-case regret is of the optimal rate. Furthermore, our algorithm can be combined and applied in many ways, for instance, to online convex optimization, follow the perturbed leader, exponential weights algorithm and first order bounds. Experiments show that our algorithm outperforms many other existing algorithms in an online linear optimization setting.</abstract>
   </article>
   <article>
      <title>The Planning-ahead SMO Algorithm</title>
      <author>Tobias Glasmachers</author>
      <date>2013-07-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The sequential minimal optimization (SMO) algorithm and variants thereof are the de facto standard method for solving large quadratic programs for <term>support vector machine</term> (SVM) training. In this paper we propose a simple yet powerful modification. The main emphasis is on an algorithm improving the SMO step size by planning-ahead. The theoretical analysis ensures its convergence to the optimum. Experiments involving a large number of datasets were carried out to demonstrate the superiority of the new algorithm.</abstract>
   </article>
   <article>
      <title>Multiclass learnability and the ERM principle</title>
      <author>Amit Daniely, Sivan Sabato, Shai Ben-David, Shai Shalev-Shwartz</author>
      <date>2013-08-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the sample complexity of multiclass prediction in several learning settings. For the PAC setting our analysis reveals a surprising phenomenon: In sharp contrast to binary classification, we show that there exist multiclass hypothesis classes for which some Empirical Risk Minimizers (ERM learners) have lower sample complexity than others. Furthermore, there are classes that are learnable by some ERM learners, while other ERM learners will fail to learn them. We propose a principle for designing good ERM learners, and use this principle to prove tight bounds on the sample complexity of learning {\em symmetric} multiclass hypothesis classes---classes that are invariant under permutations of label names. We further provide a characterization of mistake and regret bounds for multiclass learning in the online setting and the bandit setting, using new generalizations of Littlestone's dimension.</abstract>
   </article>
   <article>
      <title>Estimating or Propagating Gradients Through Stochastic Neurons for
  Conditional Computation</title>
      <author>Yoshua Bengio, Nicholas Léonard, Aaron Courville</author>
      <date>2013-08-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic neurons and hard non-linearities can be useful for a number of reasons in <term>deep learning</term> models, but in many cases they pose a challenging problem: how to estimate the gradient of a loss function with respect to the input of such stochastic or non-smooth neurons? I.e., can we "back-propagate" through these stochastic neurons? We examine this question, existing approaches, and compare four families of solutions, applicable in different settings. One of them is the minimum variance unbiased gradient estimator for stochatic binary neurons (a special case of the REINFORCE algorithm). A second approach, introduced here, decomposes the operation of a binary stochastic neuron into a stochastic binary part and a smooth differentiable part, which approximates the expected effect of the pure stochatic binary neuron to first order. A third approach involves the injection of additive or multiplicative noise in a computational graph that is otherwise differentiable. A fourth approach heuristically copies the gradient with respect to the stochastic output directly as an estimator of the gradient with respect to the sigmoid argument (we call this the straight-through estimator). To explore a context where these estimators are useful, we consider a small-scale version of {\em conditional computation}, where sparse stochastic units form a distributed representation of gaters that can turn off in combinatorially many ways large chunks of the computation performed in the rest of the <term>neural network</term>. In this case, it is important that the gating units produce an actual 0 most of the time. The resulting sparsity can be potentially be exploited to greatly reduce the computational cost of large deep networks for which conditional computation would be useful.</abstract>
   </article>
   <article>
      <title>Stochastic Optimization for Machine Learning</title>
      <author>Andrew Cotter</author>
      <date>2013-08-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It has been found that stochastic algorithms often find good solutions much more rapidly than inherently-batch approaches. Indeed, a very useful rule of thumb is that often, when solving a machine learning problem, an iterative technique which relies on performing a very large number of relatively-inexpensive updates will often outperform one which performs a smaller number of much "smarter" but computationally-expensive updates.   In this thesis, we will consider the application of stochastic algorithms to two of the most important machine learning problems. Part i is concerned with the supervised problem of binary classification using kernelized linear classifiers, for which the data have labels belonging to exactly two classes (e.g. "has cancer" or "doesn't have cancer"), and the learning problem is to find a linear classifier which is best at predicting the label. In Part ii, we will consider the unsupervised problem of Principal Component Analysis, for which the learning task is to find the directions which contain most of the variance of the data distribution.   Our goal is to present stochastic algorithms for both problems which are, above all, practical--they work well on real-world data, in some cases better than all known competing algorithms. A secondary, but still very important, goal is to derive theoretical bounds on the performance of these algorithms which are at least competitive with, and often better than, those known for other approaches.</abstract>
   </article>
   <article>
      <title>Knapsack Constrained Contextual Submodular List Prediction with
  Application to Multi-document Summarization</title>
      <author>Jiaji Zhou, Stephane Ross, Yisong Yue, Debadeepta Dey, J. Andrew Bagnell</author>
      <date>2013-08-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the problem of predicting a set or list of options under knapsack constraint. The quality of such lists are evaluated by a submodular reward function that measures both quality and diversity. Similar to DAgger (Ross et al., 2010), by a reduction to online learning, we show how to adapt two sequence prediction models to imitate greedy maximization under knapsack constraint problems: CONSEQOPT (Dey et al., 2012) and SCP (Ross et al., 2013). Experiments on extractive multi-document summarization show that our approach outperforms existing state-of-the-art methods.</abstract>
   </article>
   <article>
      <title>Comment on "robustness and regularization of support vector machines" by
  H. Xu, et al., (Journal of Machine Learning Research, vol. 10, pp. 1485-1510,
  2009, arXiv:0803.3490)</title>
      <author>Yahya Forghani, Hadi Sadoghi Yazdi</author>
      <date>2013-08-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper comments on the published work dealing with robustness and regularization of <term>support vector machine</term>s (Journal of Machine Learning Research, vol. 10, pp. 1485-1510, 2009) [arXiv:0803.3490] by H. Xu, etc. They proposed a theorem to show that it is possible to relate robustness in the feature space and robustness in the sample space directly. In this paper, we propose a counter example that rejects their theorem.</abstract>
   </article>
   <article>
      <title>The Sample-Complexity of General Reinforcement Learning</title>
      <author>Tor Lattimore, Marcus Hutter, Peter Sunehag</author>
      <date>2013-08-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a new algorithm for general <term>reinforcement learning</term> where the true environment is known to belong to a finite class of N arbitrary models. The algorithm is shown to be near-optimal for all but O(N log^2 N) time-steps with high probability. Infinite classes are also considered where we show that compactness is a key criterion for determining the existence of uniform sample-complexity bounds. A matching lower bound is given for the finite case.</abstract>
   </article>
   <article>
      <title>Ensemble of Distributed Learners for Online Classification of Dynamic
  Data Streams</title>
      <author>Luca Canzian, Yu Zhang, Mihaela van der Schaar</author>
      <date>2013-08-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present an efficient distributed online learning scheme to classify data captured from distributed, heterogeneous, and dynamic data sources. Our scheme consists of multiple distributed local learners, that analyze different streams of data that are correlated to a common event that needs to be classified. Each learner uses a local classifier to make a local prediction. The local predictions are then collected by each learner and combined using a weighted majority rule to output the final prediction. We propose a novel online ensemble learning algorithm to update the aggregation rule in order to adapt to the underlying data dynamics. We rigorously determine a bound for the worst case misclassification probability of our algorithm which depends on the misclassification probabilities of the best static aggregation rule, and of the best local classifier. Importantly, the worst case misclassification probability of our algorithm tends asymptotically to 0 if the misclassification probability of the best static aggregation rule or the misclassification probability of the best local classifier tend to 0. Then we extend our algorithm to address challenges specific to the distributed implementation and we prove new bounds that apply to these settings. Finally, we test our scheme by performing an evaluation study on several data sets. When applied to data sets widely used by the literature dealing with dynamic data streams and concept drift, our scheme exhibits performance gains ranging from 34% to 71% with respect to state of the art solutions.</abstract>
   </article>
   <article>
      <title>Prediction of breast cancer recurrence using Classification Restricted
  Boltzmann Machine with Dropping</title>
      <author>Jakub M. Tomczak</author>
      <date>2013-08-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we apply Classification Restricted Boltzmann Machine (ClassRBM) to the problem of predicting breast cancer recurrence. According to the Polish National Cancer Registry, in 2010 only, the breast cancer caused almost 25% of all diagnosed cases of cancer in Poland. We propose how to use ClassRBM for predicting breast cancer return and discovering relevant inputs (symptoms) in illness reappearance. Next, we outline a general probabilistic framework for learning Boltzmann machines with masks, which we refer to as Dropping. The fashion of generating masks leads to different learning methods, i.e., DropOut, DropConnect. We propose a new method called DropPart which is a generalization of DropConnect. In DropPart the Beta distribution instead of Bernoulli distribution in DropConnect is used. At the end, we carry out an experiment using real-life dataset consisting of 949 cases, provided by the Institute of Oncology Ljubljana.</abstract>
   </article>
   <article>
      <title>Relative Comparison Kernel Learning with Auxiliary Kernels</title>
      <author>Eric Heim, Hamed Valizadegan, Milos Hauskrecht</author>
      <date>2013-09-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this work we consider the problem of learning a positive semidefinite kernel matrix from relative comparisons of the form: "object A is more similar to object B than it is to C", where comparisons are given by humans. Existing solutions to this problem assume many comparisons are provided to learn a high quality kernel. However, this can be considered unrealistic for many real-world tasks since relative assessments require human input, which is often costly or difficult to obtain. Because of this, only a limited number of these comparisons may be provided. In this work, we explore methods for aiding the process of learning a kernel with the help of auxiliary kernels built from more easily extractable information regarding the relationships among objects. We propose a new kernel learning approach in which the target kernel is defined as a conic combination of auxiliary kernels and a kernel whose elements are learned directly. We formulate a convex optimization to solve for this target kernel that adds only minor overhead to methods that use no auxiliary information. Empirical results show that in the presence of few training relative comparisons, our method can learn kernels that generalize to more out-of-sample comparisons than methods that do not utilize auxiliary information, as well as similar methods that learn metrics over objects.</abstract>
   </article>
   <article>
      <title>Group Learning and Opinion Diffusion in a Broadcast Network</title>
      <author>Yang Liu, Mingyan Liu</author>
      <date>2013-09-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We analyze the following group learning problem in the context of opinion diffusion: Consider a network with $M$ users, each facing $N$ options. In a discrete time setting, at each time step, each user chooses $K$ out of the $N$ options, and receive randomly generated rewards, whose statistics depend on the options chosen as well as the user itself, and are unknown to the users. Each user aims to maximize their expected total rewards over a certain time horizon through an online learning process, i.e., a sequence of exploration (sampling the return of each option) and exploitation (selecting empirically good options) steps.   Within this context we consider two group learning scenarios, (1) users with uniform preferences and (2) users with diverse preferences, and examine how a user should construct its learning process to best extract information from other's decisions and experiences so as to maximize its own reward. Performance is measured in {\em weak regret}, the difference between the user's total reward and the reward from a user-specific best single-action policy (i.e., always selecting the set of options generating the highest mean rewards for this user). Within each scenario we also consider two cases: (i) when users exchange full information, meaning they share the actual rewards they obtained from their choices, and (ii) when users exchange limited information, e.g., only their choices but not rewards obtained from these choices.</abstract>
   </article>
   <article>
      <title>A Metric-learning based framework for Support Vector Machines and
  Multiple Kernel Learning</title>
      <author>Huyen Do, Alexandros Kalousis</author>
      <date>2013-09-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Most metric learning algorithms, as well as Fisher's Discriminant Analysis (FDA), optimize some cost function of different measures of within-and between-class distances. On the other hand, Support Vector Machines(SVMs) and several Multiple Kernel Learning (MKL) algorithms are based on the SVM large margin theory. Recently, SVMs have been analyzed from SVM and metric learning, and to develop new algorithms that build on the strengths of each. Inspired by the metric learning interpretation of SVM, we develop here a new metric-learning based SVM framework in which we incorporate metric learning concepts within SVM. We extend the optimization problem of SVM to include some measure of the within-class distance and along the way we develop a new within-class distance measure which is appropriate for SVM. In addition, we adopt the same approach for MKL and show that it can be also formulated as a Mahalanobis metric learning problem. Our end result is a number of SVM/MKL algorithms that incorporate metric learning concepts. We experiment with them on a set of benchmark datasets and observe important predictive performance improvements.</abstract>
   </article>
   <article>
      <title>Stochastic Bound Majorization</title>
      <author>Anna Choromanska, Tony Jebara</author>
      <date>2013-09-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently a majorization method for optimizing partition functions of log-linear models was proposed alongside a novel quadratic variational upper-bound. In the batch setting, it outperformed state-of-the-art first- and second-order optimization methods on various learning tasks. We propose a stochastic version of this bound majorization method as well as a low-rank modification for high-dimensional data-sets. The resulting stochastic second-order method outperforms stochastic <term>gradient descent</term> (across variations and various tunings) both in terms of the number of iterations and computation time till convergence while finding a better quality parameter setting. The proposed method bridges first- and second-order stochastic optimization methods by maintaining a computational complexity that is linear in the data dimension and while exploiting second order information about the pseudo-global curvature of the objective function (as opposed to the local curvature in the Hessian).</abstract>
   </article>
   <article>
      <title>A Kernel Classification Framework for Metric Learning</title>
      <author>Faqiang Wang, Wangmeng Zuo, Lei Zhang, Deyu Meng, David Zhang</author>
      <date>2013-09-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Learning a distance metric from the given training samples plays a crucial role in many machine learning tasks, and various models and optimization algorithms have been proposed in the past decade. In this paper, we generalize several state-of-the-art metric learning methods, such as large margin nearest neighbor (LMNN) and information theoretic metric learning (ITML), into a kernel classification framework. First, doublets and triplets are constructed from the training samples, and a family of degree-2 polynomial kernel functions are proposed for pairs of doublets or triplets. Then, a kernel classification framework is established, which can not only generalize many popular metric learning methods such as LMNN and ITML, but also suggest new metric learning methods, which can be efficiently implemented, interestingly, by using the standard <term>support vector machine</term> (SVM) solvers. Two novel metric learning methods, namely doublet-SVM and triplet-SVM, are then developed under the proposed framework. Experimental results show that doublet-SVM and triplet-SVM achieve competitive classification accuracies with state-of-the-art metric learning methods such as ITML and LMNN but with significantly less training time.</abstract>
   </article>
   <article>
      <title>Fenchel Duals for Drifting Adversaries</title>
      <author>Suman K Bera, Anamitra R Choudhury, Syamantak Das, Sambuddha Roy, Jayram S. Thatchachar</author>
      <date>2013-09-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We describe a primal-dual framework for the design and analysis of online convex optimization algorithms for {\em drifting regret}. Existing literature shows (nearly) optimal drifting regret bounds only for the $\ell_2$ and the $\ell_1$-norms. Our work provides a connection between these algorithms and the Online Mirror Descent ($\omd$) updates; one key insight that results from our work is that in order for these algorithms to succeed, it suffices to have the gradient of the regularizer to be bounded (in an appropriate norm). For situations (like for the $\ell_1$ norm) where the vanilla regularizer does not have this property, we have to {\em shift} the regularizer to ensure this. Thus, this helps explain the various updates presented in \cite{bansal10, buchbinder12}. We also consider the online variant of the problem with 1-lookahead, and with movement costs in the $\ell_2$-norm. Our primal dual approach yields nearly optimal competitive ratios for this problem.</abstract>
   </article>
   <article>
      <title>On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori
  Perturbations</title>
      <author>Tamir Hazan, Subhransu Maji, Tommi Jaakkola</author>
      <date>2013-09-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we describe how MAP inference can be used to sample efficiently from Gibbs distributions. Specifically, we provide means for drawing either approximate or unbiased samples from Gibbs' distributions by introducing low dimensional perturbations and solving the corresponding MAP assignments. Our approach also leads to new ways to derive lower bounds on partition functions. We demonstrate empirically that our method excels in the typical "high signal - high coupling" regime. The setting results in ragged energy landscapes that are challenging for alternative approaches to sampling and/or lower bounds.</abstract>
   </article>
   <article>
      <title>An Extensive Experimental Study on the Cluster-based Reference Set
  Reduction for speeding-up the k-NN Classifier</title>
      <author>Stefanos Ougiaroglou, Georgios Evangelidis, Dimitris A. Dervos</author>
      <date>2013-09-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The k-Nearest Neighbor (k-NN) classification algorithm is one of the most widely-used lazy classifiers because of its simplicity and ease of implementation. It is considered to be an effective classifier and has many applications. However, its major drawback is that when sequential search is used to find the neighbors, it involves high computational cost. Speeding-up k-NN search is still an active research field. Hwang and Cho have recently proposed an adaptive cluster-based method for fast Nearest Neighbor searching. The effectiveness of this method is based on the adjustment of three parameters. However, the authors evaluated their method by setting specific parameter values and using only one dataset. In this paper, an extensive experimental study of this method is presented. The results, which are based on five real life datasets, illustrate that if the parameters of the method are carefully defined, one can achieve even better classification performance.</abstract>
   </article>
   <article>
      <title>On the Feature Discovery for App Usage Prediction in Smartphones</title>
      <author>Zhung-Xun Liao, Shou-Chung Li, Wen-Chih Peng, Philip S Yu</author>
      <date>2013-09-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>With the increasing number of mobile Apps developed, they are now closely integrated into daily life. In this paper, we develop a framework to predict mobile Apps that are most likely to be used regarding the current device status of a smartphone. Such an Apps usage prediction framework is a crucial prerequisite for fast App launching, intelligent user experience, and power management of smartphones. By analyzing real App usage log data, we discover two kinds of features: The Explicit Feature (EF) from sensing readings of built-in sensors, and the Implicit Feature (IF) from App usage relations. The IF feature is derived by constructing the proposed App Usage Graph (abbreviated as AUG) that models App usage transitions. In light of AUG, we are able to discover usage relations among Apps. Since users may have different usage behaviors on their smartphones, we further propose one personalized feature selection algorithm. We explore minimum description length (MDL) from the training data and select those features which need less length to describe the training data. The personalized feature selection can successfully reduce the log size and the prediction time. Finally, we adopt the kNN classification model to predict Apps usage. Note that through the features selected by the proposed personalized feature selection algorithm, we only need to keep these features, which in turn reduces the prediction time and avoids the curse of dimensionality when using the kNN classifier. We conduct a comprehensive experimental study based on a real mobile App usage dataset. The results demonstrate the effectiveness of the proposed framework and show the predictive capability for App usage prediction.</abstract>
   </article>
   <article>
      <title>Clustering on Multiple Incomplete Datasets via Collective Kernel
  Learning</title>
      <author>Weixiang Shao, Xiaoxiao Shi, Philip S. Yu</author>
      <date>2013-10-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multiple datasets containing different types of features may be available for a given task. For instance, users' profiles can be used to group users for recommendation systems. In addition, a model can also use users' historical behaviors and credit history to group users. Each dataset contains different information and suffices for learning. A number of clustering algorithms on multiple datasets were proposed during the past few years. These algorithms assume that at least one dataset is complete. So far as we know, all the previous methods will not be applicable if there is no complete dataset available. However, in reality, there are many situations where no dataset is complete. As in building a recommendation system, some new users may not have a profile or historical behaviors, while some may not have a credit history. Hence, no available dataset is complete. In order to solve this problem, we propose an approach called Collective Kernel Learning to infer hidden sample similarity from multiple incomplete datasets. The idea is to collectively completes the kernel matrices of incomplete datasets by optimizing the alignment of the shared instances of the datasets. Furthermore, a clustering algorithm is proposed based on the kernel matrix. The experiments on both synthetic and real datasets demonstrate the effectiveness of the proposed approach. The proposed clustering algorithm outperforms the comparison algorithms by as much as two times in normalized mutual information.</abstract>
   </article>
   <article>
      <title>Fast Multi-Instance Multi-Label Learning</title>
      <author>Sheng-Jun Huang, Zhi-Hua Zhou</author>
      <date>2013-10-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In many real-world tasks, particularly those involving data objects with complicated semantics such as images and texts, one object can be represented by multiple instances and simultaneously be associated with multiple labels. Such tasks can be formulated as multi-instance multi-label learning (MIML) problems, and have been extensively studied during the past few years. Existing MIML approaches have been found useful in many applications; however, most of them can only handle moderate-sized data. To efficiently handle large data sets, in this paper we propose the MIMLfast approach, which first constructs a low-dimensional subspace shared by all labels, and then trains label specific linear models to optimize approximated ranking loss via stochastic <term>gradient descent</term>. Although the MIML problem is complicated, MIMLfast is able to achieve excellent performance by exploiting label relations with shared space and discovering sub-concepts for complicated labels. Experiments show that the performance of MIMLfast is highly competitive to state-of-the-art techniques, whereas its time cost is much less; particularly, on a data set with 20K bags and 180K instances, MIMLfast is more than 100 times faster than existing MIML approaches. On a larger data set where none of existing approaches can return results in 24 hours, MIMLfast takes only 12 minutes. Moreover, our approach is able to identify the most representative instance for each label, and thus providing a chance to understand the relation between input patterns and output label semantics.</abstract>
   </article>
   <article>
      <title>Localized Iterative Methods for Interpolation in Graph Structured Data</title>
      <author>Sunil K. Narang, Akshay Gadde, Eduard Sanou, Antonio Ortega</author>
      <date>2013-10-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we present two localized graph filtering based methods for interpolating graph signals defined on the vertices of arbitrary graphs from only a partial set of samples. The first method is an extension of previous work on reconstructing bandlimited graph signals from partially observed samples. The iterative graph filtering approach very closely approximates the solution proposed in the that work, while being computationally more efficient. As an alternative, we propose a regularization based framework in which we define the cost of reconstruction to be a combination of smoothness of the graph signal and the reconstruction error with respect to the known samples, and find solutions that minimize this cost. We provide both a closed form solution and a computationally efficient iterative solution of the optimization problem. The experimental results on the recommendation system datasets demonstrate effectiveness of the proposed methods.</abstract>
   </article>
   <article>
      <title>Scaling Graph-based Semi Supervised Learning to Large Number of Labels
  Using Count-Min Sketch</title>
      <author>Partha Pratim Talukdar, William Cohen</author>
      <date>2013-10-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Graph-based Semi-supervised learning (SSL) algorithms have been successfully used in a large number of applications. These methods classify initially unlabeled nodes by propagating label information over the structure of graph starting from seed nodes. Graph-based SSL algorithms usually scale linearly with the number of distinct labels (m), and require O(m) space on each node. Unfortunately, there exist many applications of practical significance with very large m over large graphs, demanding better space and time complexity. In this paper, we propose MAD-SKETCH, a novel graph-based SSL algorithm which compactly stores label distribution on each node using Count-min Sketch, a randomized data structure. We present theoretical analysis showing that under mild conditions, MAD-SKETCH can reduce space complexity at each node from O(m) to O(log m), and achieve similar savings in time complexity as well. We support our analysis through experiments on multiple real world datasets. We observe that MAD-SKETCH achieves similar performance as existing state-of-the-art graph- based SSL algorithms, while requiring smaller memory footprint and at the same time achieving up to 10x speedup. We find that MAD-SKETCH is able to scale to datasets with one million labels, which is beyond the scope of existing graph- based SSL algorithms.</abstract>
   </article>
   <article>
      <title>Learning Tensors in Reproducing Kernel Hilbert Spaces with Multilinear
  Spectral Penalties</title>
      <author>Marco Signoretto, Lieven De Lathauwer, Johan A. K. Suykens</author>
      <date>2013-10-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a general framework to learn functions in tensor product reproducing kernel Hilbert spaces (TP-RKHSs). The methodology is based on a novel representer theorem suitable for existing as well as new spectral penalties for tensors. When the functions in the TP-RKHS are defined on the Cartesian product of finite discrete sets, in particular, our main problem formulation admits as a special case existing tensor completion problems. Other special cases include transfer learning with multimodal side information and multilinear multitask learning. For the latter case, our kernel-based view is instrumental to derive nonlinear extensions of existing model classes. We give a novel algorithm and show in experiments the usefulness of the proposed extensions.</abstract>
   </article>
   <article>
      <title>Thompson Sampling in Dynamic Systems for Contextual Bandit Problems</title>
      <author>Tianbing Xu, Yaming Yu, John Turner, Amelia Regan</author>
      <date>2013-10-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the multiarm bandit problems in the timevarying dynamic system for rich structural features. For the nonlinear dynamic model, we propose the approximate inference for the posterior distributions based on Laplace Approximation. For the context bandit problems, Thompson Sampling is adopted based on the underlying posterior distributions of the parameters. More specifically, we introduce the discount decays on the previous samples impact and analyze the different decay rates with the underlying sample dynamics. Consequently, the exploration and exploitation is adaptively tradeoff according to the dynamics in the system.</abstract>
   </article>
   <article>
      <title>Graph-Based Approaches to Clustering Network-Constrained Trajectory Data</title>
      <author>Mohamed Khalil El Mahrsi, Fabrice Rossi</author>
      <date>2013-10-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Clustering trajectory data attracted considerable attention in the last few years. Most of prior work assumed that moving objects can move freely in an euclidean space and did not consider the eventual presence of an underlying road network and its influence on evaluating the similarity between trajectories. In this paper, we present an approach to clustering such network-constrained trajectory data. More precisely we aim at discovering groups of road segments that are often travelled by the same trajectories. To achieve this end, we model the interactions between segments w.r.t. their similarity as a weighted graph to which we apply a community detection algorithm to discover meaningful clusters. We showcase our proposition through experimental results obtained on synthetic datasets.</abstract>
   </article>
   <article>
      <title>Multi-Task Regularization with Covariance Dictionary for Linear
  Classifiers</title>
      <author>Fanyi Xiao, Ruikun Luo, Zhiding Yu</author>
      <date>2013-10-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we propose a multi-task linear classifier learning problem called D-SVM (Dictionary SVM). D-SVM uses a dictionary of parameter covariance shared by all tasks to do multi-task knowledge transfer among different tasks. We formally define the learning problem of D-SVM and show two interpretations of this problem, from both the probabilistic and kernel perspectives. From the probabilistic perspective, we show that our learning formulation is actually a MAP estimation on all optimization variables. We also show its equivalence to a multiple kernel learning problem in which one is trying to find a re-weighting kernel for features from a dictionary of basis (despite the fact that only linear classifiers are learned). Finally, we describe an alternative optimization scheme to minimize the objective function and present empirical studies to valid our algorithm.</abstract>
   </article>
   <article>
      <title>Learning Theory and Algorithms for Revenue Optimization in Second-Price
  Auctions with Reserve</title>
      <author>Mehryar Mohri, Andres Muñoz Medina</author>
      <date>2013-10-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Second-price auctions with reserve play a critical role for modern search engine and popular online sites since the revenue of these companies often directly de- pends on the outcome of such auctions. The choice of the reserve price is the main mechanism through which the auction revenue can be influenced in these electronic markets. We cast the problem of selecting the reserve price to optimize revenue as a learning problem and present a full theoretical analysis dealing with the complex properties of the corresponding loss function. We further give novel algorithms for solving this problem and report the results of several experiments in both synthetic and real data demonstrating their effectiveness.</abstract>
   </article>
   <article>
      <title>Relative Deviation Learning Bounds and Generalization with Unbounded
  Loss Functions</title>
      <author>Corinna Cortes, Spencer Greenberg, Mehryar Mohri</author>
      <date>2013-10-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present an extensive analysis of relative deviation bounds, including detailed proofs of two-sided inequalities and their implications. We also give detailed proofs of two-sided generalization bounds that hold in the general case of unbounded loss functions, under the assumption that a moment of the loss is bounded. These bounds are useful in the analysis of importance weighting and other learning tasks such as unbounded regression.</abstract>
   </article>
   <article>
      <title>Efficient Optimization for Sparse Gaussian Process Regression</title>
      <author>Yanshuai Cao, Marcus A. Brubaker, David J. Fleet, Aaron Hertzmann</author>
      <date>2013-10-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose an efficient optimization algorithm for selecting a subset of training data to induce sparsity for Gaussian process regression. The algorithm estimates an inducing set and the hyperparameters using a single objective, either the marginal likelihood or a variational free energy. The space and time complexity are linear in training set size, and the algorithm can be applied to large regression problems on discrete or continuous domains. Empirical evaluation shows state-of-art performance in discrete cases and competitive results in the continuous case.</abstract>
   </article>
   <article>
      <title>Combining Structured and Unstructured Randomness in Large Scale PCA</title>
      <author>Nikos Karampatziakis, Paul Mineiro</author>
      <date>2013-10-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Principal Component Analysis (PCA) is a ubiquitous tool with many applications in machine learning including feature construction, subspace embedding, and outlier detection. In this paper, we present an algorithm for computing the top principal components of a dataset with a large number of rows (examples) and columns (features). Our algorithm leverages both structured and unstructured random projections to retain good accuracy while being computationally efficient. We demonstrate the technique on the winning submission the KDD 2010 Cup.</abstract>
   </article>
   <article>
      <title>An Unsupervised Feature Learning Approach to Improve Automatic Incident
  Detection</title>
      <author>Jimmy SJ. Ren, Wei Wang, Jiawei Wang, Stephen Liao</author>
      <date>2013-10-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Sophisticated automatic incident detection (AID) technology plays a key role in contemporary transportation systems. Though many papers were devoted to study incident classification algorithms, few study investigated how to enhance feature representation of incidents to improve AID performance. In this paper, we propose to use an unsupervised feature learning algorithm to generate higher level features to represent incidents. We used real incident data in the experiments and found that effective feature mapping function can be learnt from the data crosses the test sites. With the enhanced features, detection rate (DR), false alarm rate (FAR) and mean time to detect (MTTD) are significantly improved in all of the three representative cases. This approach also provides an alternative way to reduce the amount of labeled data, which is expensive to obtain, required in training better incident classifiers since the feature learning is unsupervised.</abstract>
   </article>
   <article>
      <title>An efficient distributed learning algorithm based on effective local
  functional approximations</title>
      <author>Dhruv Mahajan, Nikunj Agrawal, S. Sathiya Keerthi, S. Sundararajan, Leon Bottou</author>
      <date>2013-10-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Scalable machine learning over big data is an important problem that is receiving a lot of attention in recent years. On popular distributed environments such as Hadoop running on a cluster of commodity machines, communication costs are substantial and algorithms need to be designed suitably considering those costs. In this paper we give a novel approach to the distributed training of linear classifiers (involving smooth losses and L2 regularization) that is designed to reduce the total communication costs. At each iteration, the nodes minimize locally formed approximate objective functions; then the resulting minimizers are combined to form a descent direction to move. Our approach gives a lot of freedom in the formation of the approximate objective function as well as in the choice of methods to solve them. The method is shown to have $O(log(1/\epsilon))$ time convergence. The method can be viewed as an iterative parameter mixing method. A special instantiation yields a parallel stochastic <term>gradient descent</term> method with strong convergence. When communication times between nodes are large, our method is much faster than the Terascale method (Agarwal et al., 2011), which is a state of the art distributed solver based on the statistical query model (Chuet al., 2006) that computes function and gradient values in a distributed fashion. We also evaluate against other recent distributed methods and demonstrate superior performance of our method.</abstract>
   </article>
   <article>
      <title>Multilabel Classification through Random Graph Ensembles</title>
      <author>Hongyu Su, Juho Rousu</author>
      <date>2013-10-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present new methods for multilabel classification, relying on ensemble learning on a collection of random output graphs imposed on the multilabel and a kernel-based structured output learner as the base classifier. For ensemble learning, differences among the output graphs provide the required base classifier diversity and lead to improved performance in the increasing size of the ensemble. We study different methods of forming the ensemble prediction, including majority voting and two methods that perform inferences over the graph structures before or after combining the base models into the ensemble. We compare the methods against the state-of-the-art machine learning approaches on a set of heterogeneous multilabel benchmark problems, including multilabel AdaBoost, convex multitask feature learning, as well as single target learning approaches represented by Bagging and SVM. In our experiments, the random graph ensembles are very competitive and robust, ranking first or second on most of the datasets. Overall, our results show that random graph ensembles are viable alternatives to flat multilabel and multitask learners.</abstract>
   </article>
   <article>
      <title>Stochastic Optimization of Smooth Loss</title>
      <author>Rong Jin</author>
      <date>2013-11-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we first prove a high probability bound rather than an expectation bound for stochastic optimization with smooth loss. Furthermore, the existing analysis requires the knowledge of optimal classifier for tuning the step size in order to achieve the desired bound. However, this information is usually not accessible in advanced. We also propose a strategy to address the limitation.</abstract>
   </article>
   <article>
      <title>Practical Collapsed Stochastic Variational Inference for the HDP</title>
      <author>Arnim Bleier</author>
      <date>2013-12-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recent advances have made it feasible to apply the stochastic variational paradigm to a collapsed representation of latent Dirichlet allocation (LDA). While the stochastic variational paradigm has successfully been applied to an uncollapsed representation of the hierarchical Dirichlet process (HDP), no attempts to apply this type of inference in a collapsed setting of non-parametric topic modeling have been put forward so far. In this paper we explore such a collapsed stochastic variational Bayes inference for the HDP. The proposed online algorithm is easy to implement and accounts for the inference of hyper-parameters. First experiments show a promising improvement in predictive performance.</abstract>
   </article>
   <article>
      <title>Sensing-Aware Kernel SVM</title>
      <author>Weicong Ding, Prakash Ishwar, Venkatesh Saligrama, W. Clem Karl</author>
      <date>2013-12-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a novel approach for designing kernels for <term>support vector machine</term>s (SVMs) when the class label is linked to the observation through a latent state and the likelihood function of the observation given the state (the sensing model) is available. We show that the Bayes-optimum decision boundary is a hyperplane under a mapping defined by the likelihood function. Combining this with the maximum margin principle yields kernels for SVMs that leverage knowledge of the sensing model in an optimal way. We derive the optimum kernel for the bag-of-words (BoWs) sensing model and demonstrate its superior performance over other kernels in document and image classification tasks. These results indicate that such optimum sensing-aware kernel SVMs can match the performance of rather sophisticated state-of-the-art approaches.</abstract>
   </article>
   <article>
      <title>SpeedMachines: Anytime Structured Prediction</title>
      <author>Alexander Grubb, Daniel Munoz, J. Andrew Bagnell, Martial Hebert</author>
      <date>2013-12-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Structured prediction plays a central role in machine learning applications from computational biology to computer vision. These models require significantly more computation than unstructured models, and, in many applications, algorithms may need to make predictions within a computational budget or in an anytime fashion. In this work we propose an anytime technique for learning structured prediction that, at training time, incorporates both structural elements and feature computation trade-offs that affect test-time inference. We apply our technique to the challenging problem of scene understanding in computer vision and demonstrate efficient and anytime predictions that gradually improve towards state-of-the-art classification performance as the allotted time increases.</abstract>
   </article>
   <article>
      <title>Image Representation Learning Using Graph Regularized Auto-Encoders</title>
      <author>Yiyi Liao, Yue Wang, Yong Liu</author>
      <date>2013-12-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of image representation for the tasks of <term>unsupervised learning</term> and semi-supervised learning. In those learning tasks, the raw image vectors may not provide enough representation for their intrinsic structures due to their highly dense feature space. To overcome this problem, the raw image vectors should be mapped to a proper representation space which can capture the latent structure of the original data and represent the data explicitly for further learning tasks such as clustering.   Inspired by the recent research works on deep <term>neural network</term> and representation learning, in this paper, we introduce the multiple-layer auto-encoder into image representation, we also apply the locally invariant ideal to our image representation with auto-encoders and propose a novel method, called Graph regularized Auto-Encoder (GAE). GAE can provide a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure.   Extensive experiments on image clustering show encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-word cases.</abstract>
   </article>
   <article>
      <title>Interpreting random forest classification models using a feature
  contribution method</title>
      <author>Anna Palczewska, Jan Palczewski, Richard Marchese Robinson, Daniel Neagu</author>
      <date>2013-12-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Model interpretation is one of the key aspects of the model evaluation process. The explanation of the relationship between model variables and outputs is relatively easy for statistical models, such as linear regressions, thanks to the availability of model parameters and their statistical significance. For "black box" models, such as <term>random forest</term>, this information is hidden inside the model structure. This work presents an approach for computing feature contributions for <term>random forest</term> classification models. It allows for the determination of the influence of each variable on the model prediction for an individual instance. By analysing feature contributions for a training dataset, the most significant variables can be determined and their typical contribution towards predictions made for individual classes, i.e., class-specific feature contribution "patterns", are discovered. These patterns represent a standard behaviour of the model and allow for an additional assessment of the model reliability for a new data. Interpretation of feature contributions for two UCI benchmark datasets shows the potential of the proposed methodology. The robustness of results is demonstrated through an extensive analysis of feature contributions calculated for a large number of generated <term>random forest</term> models.</abstract>
   </article>
   <article>
      <title>Bandit Online Optimization Over the Permutahedron</title>
      <author>Nir Ailon, Kohei Hatano, Eiji Takimoto</author>
      <date>2013-12-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The permutahedron is the convex polytope with vertex set consisting of the vectors $(\pi(1),\dots, \pi(n))$ for all permutations (bijections) $\pi$ over $\{1,\dots, n\}$. We study a bandit game in which, at each step $t$, an adversary chooses a hidden weight weight vector $s_t$, a player chooses a vertex $\pi_t$ of the permutahedron and suffers an observed loss of $\sum_{i=1}^n \pi(i) s_t(i)$.   A previous algorithm CombBand of Cesa-Bianchi et al (2009) guarantees a regret of $O(n\sqrt{T \log n})$ for a time horizon of $T$. Unfortunately, CombBand requires at each step an $n$-by-$n$ matrix permanent approximation to within improved accuracy as $T$ grows, resulting in a total running time that is super linear in $T$, making it impractical for large time horizons.   We provide an algorithm of regret $O(n^{3/2}\sqrt{T})$ with total time complexity $O(n^3T)$. The ideas are a combination of CombBand and a recent algorithm by Ailon (2013) for online optimization over the permutahedron in the full information setting. The technical core is a bound on the variance of the Plackett-Luce noisy sorting process's "pseudo loss". The bound is obtained by establishing positive semi-definiteness of a family of 3-by-3 matrices generated from rational functions of exponentials of 3 parameters.</abstract>
   </article>
   <article>
      <title>Curriculum Learning for Handwritten Text Line Recognition</title>
      <author>Jérôme Louradour, Christopher Kermorvant</author>
      <date>2013-12-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recurrent Neural Networks (RNN) have recently achieved the best performance in off-line Handwriting Text Recognition. At the same time, learning RNN by <term>gradient descent</term> leads to slow convergence, and training times are particularly long when the training database consists of full lines of text. In this paper, we propose an easy way to accelerate stochastic <term>gradient descent</term> in this set-up, and in the general context of learning to recognize sequences. The principle is called Curriculum Learning, or shaping. The idea is to first learn to recognize short sequences before training on all available training sequences. Experiments on three different handwritten text databases (Rimes, IAM, OpenHaRT) show that a simple implementation of this strategy can significantly speed up the training of RNN for Text Recognition, and even significantly improve performance in some cases.</abstract>
   </article>
   <article>
      <title>Understanding Deep Architectures using a Recursive Convolutional Network</title>
      <author>David Eigen, Jason Rolfe, Rob Fergus, Yann LeCun</author>
      <date>2013-12-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A key challenge in designing <term>convolutional network</term> models is sizing them appropriately. Many factors are involved in these decisions, including number of layers, feature maps, kernel sizes, etc. Complicating this further is the fact that each of these influence not only the numbers and dimensions of the activation units, but also the total number of parameters. In this paper we focus on assessing the independent contributions of three of these linked variables: The numbers of layers, feature maps, and parameters. To accomplish this, we employ a recursive <term>convolutional network</term> whose weights are tied between layers; this allows us to vary each of the three factors in a controlled setting. We find that while increasing the numbers of layers and parameters each have clear benefit, the number of feature maps (and hence dimensionality of the representation) appears ancillary, and finds most of its benefit through the introduction of more weights. Our results (i) empirically confirm the notion that adding layers alone increases computational power, within the context of convolutional layers, and (ii) suggest that precise sizing of convolutional feature map dimensions is itself of little concern; more attention should be paid to the number of parameters in these layers instead.</abstract>
   </article>
   <article>
      <title>CEAI: CCM based Email Authorship Identification Model</title>
      <author>Sarwat Nizamani, Nasrullah Memon</author>
      <date>2013-12-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we present a model for email authorship identification (EAI) by employing a Cluster-based Classification (CCM) technique. Traditionally, stylometric features have been successfully employed in various authorship analysis tasks; we extend the traditional feature-set to include some more interesting and effective features for email authorship identification (e.g. the last punctuation mark used in an email, the tendency of an author to use capitalization at the start of an email, or the punctuation after a greeting or farewell). We also included Info Gain feature selection based content features. It is observed that the use of such features in the authorship identification process has a positive impact on the accuracy of the authorship identification task. We performed experiments to justify our arguments and compared the results with other base line models. Experimental results reveal that the proposed CCM-based email authorship identification model, along with the proposed feature set, outperforms the state-of-the-art <term>support vector machine</term> (SVM)-based models, as well as the models proposed by Iqbal et al. [1, 2]. The proposed model attains an accuracy rate of 94% for 10 authors, 89% for 25 authors, and 81% for 50 authors, respectively on Enron dataset, while 89.5% accuracy has been achieved on authors' constructed real email dataset. The results on Enron dataset have been achieved on quite a large number of authors as compared to the models proposed by Iqbal et al. [1, 2].</abstract>
   </article>
   <article>
      <title>Kernel-based Distance Metric Learning in the Output Space</title>
      <author>Cong Li, Michael Georgiopoulos, Georgios C. Anagnostopoulos</author>
      <date>2013-12-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we present two related, kernel-based Distance Metric Learning (DML) methods. Their respective models non-linearly map data from their original space to an output space, and subsequent distance measurements are performed in the output space via a Mahalanobis metric. The dimensionality of the output space can be directly controlled to facilitate the learning of a low-rank metric. Both methods allow for simultaneous inference of the associated metric and the mapping to the output space, which can be used to visualize the data, when the output space is 2- or 3-dimensional. Experimental results for a collection of classification tasks illustrate the advantages of the proposed methods over other traditional and kernel-based DML approaches.</abstract>
   </article>
   <article>
      <title>Multi-Task Classification Hypothesis Space with Improved Generalization
  Bounds</title>
      <author>Cong Li, Michael Georgiopoulos, Georgios C. Anagnostopoulos</author>
      <date>2013-12-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a RKHS, in general, of vector-valued functions intended to be used as hypothesis space for multi-task classification. It extends similar hypothesis spaces that have previously considered in the literature. Assuming this space, an improved Empirical Rademacher Complexity-based generalization bound is derived. The analysis is itself extended to an MKL setting. The connection between the proposed hypothesis space and a Group-Lasso type regularizer is discussed. Finally, experimental results, with some SVM-based Multi-Task Learning problems, underline the quality of the derived bounds and validate the paper's analysis.</abstract>
   </article>
   <article>
      <title>Performance Analysis Of Regularized Linear Regression Models For
  Oxazolines And Oxazoles Derivitive Descriptor Dataset</title>
      <author>Doreswamy, Chanabasayya . M. Vastrad</author>
      <date>2013-12-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Regularized regression techniques for linear regression have been created the last few ten years to reduce the flaws of ordinary least squares regression with regard to prediction accuracy. In this paper, new methods for using regularized regression in model choice are introduced, and we distinguish the conditions in which regularized regression develops our ability to discriminate models. We applied all the five methods that use penalty-based (regularization) shrinkage to handle Oxazolines and Oxazoles derivatives descriptor dataset with far more predictors than observations. The lasso, ridge, elasticnet, lars and relaxed lasso further possess the desirable property that they simultaneously select relevant predictive descriptors and optimally estimate their effects. Here, we comparatively evaluate the performance of five regularized linear regression methods The assessment of the performance of each model by means of benchmark experiments is an established exercise. Cross-validation and resampling methods are generally used to arrive point evaluates the efficiencies which are compared to recognize methods with acceptable features. Predictive accuracy was evaluated using the root mean squared error (RMSE) and Square of usual correlation between predictors and observed mean inhibitory concentration of antitubercular activity (R square). We found that all five regularized regression models were able to produce feasible models and efficient capturing the linearity in the data. The elastic net and lars had similar accuracies as well as lasso and relaxed lasso had similar accuracies but outperformed ridge regression in terms of the RMSE and R square metrics.</abstract>
   </article>
   <article>
      <title>Active Player Modelling</title>
      <author>Julian Togelius, Noor Shaker, Georgios N. Yannakakis</author>
      <date>2013-12-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We argue for the use of active learning methods for player modelling. In active learning, the learning algorithm chooses where to sample the search space so as to optimise learning progress. We hypothesise that player modelling based on active learning could result in vastly more efficient learning, but will require big changes in how data is collected. Some example active player modelling scenarios are described. A particular form of active learning is also equivalent to an influential formalisation of (human and machine) curiosity, and games with active learning could therefore be seen as being curious about the player. We further hypothesise that this form of curiosity is symmetric, and therefore that games that explore their players based on the principles of active learning will turn out to select game configurations that are interesting to the player that is being explored.</abstract>
   </article>
   <article>
      <title>Online Bayesian Passive-Aggressive Learning</title>
      <author>Tianlin Shi, Jun Zhu</author>
      <date>2013-12-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Online Passive-Aggressive (PA) learning is an effective framework for performing max-margin online learning. But the deterministic formulation and estimated single large-margin model could limit its capability in discovering descriptive structures underlying complex data. This pa- per presents online Bayesian Passive-Aggressive (BayesPA) learning, which subsumes the online PA and extends naturally to incorporate latent variables and perform nonparametric Bayesian inference, thus providing great flexibility for explorative analysis. We apply BayesPA to topic modeling and derive efficient online learning algorithms for max-margin topic models. We further develop nonparametric methods to resolve the number of topics. Experimental results on real datasets show that our approaches significantly improve time efficiency while maintaining comparable results with the batch counterparts.</abstract>
   </article>
   <article>
      <title>Relative Upper Confidence Bound for the K-Armed Dueling Bandit Problem</title>
      <author>Masrour Zoghi, Shimon Whiteson, Remi Munos, Maarten de Rijke</author>
      <date>2013-12-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper proposes a new method for the K-armed dueling bandit problem, a variation on the regular K-armed bandit problem that offers only relative feedback about pairs of arms. Our approach extends the Upper Confidence Bound algorithm to the relative setting by using estimates of the pairwise probabilities to select a promising arm and applying Upper Confidence Bound with the winner as a benchmark. We prove a finite-time regret bound of order O(log t). In addition, our empirical results using real data from an information retrieval application show that it greatly outperforms the state of the art.</abstract>
   </article>
   <article>
      <title>Efficient Baseline-free Sampling in Parameter Exploring Policy
  Gradients: Super Symmetric PGPE</title>
      <author>Frank Sehnke</author>
      <date>2013-12-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Policy Gradient methods that explore directly in parameter space are among the most effective and robust direct policy search methods and have drawn a lot of attention lately. The basic method from this field, Policy Gradients with Parameter-based Exploration, uses two samples that are symmetric around the current hypothesis to circumvent misleading reward in \emph{asymmetrical} reward distributed problems gathered with the usual baseline approach. The exploration parameters are still updated by a baseline approach - leaving the exploration prone to asymmetric reward distributions. In this paper we will show how the exploration parameters can be sampled quasi symmetric despite having limited instead of free parameters for exploration. We give a transformation approximation to get quasi symmetric samples with respect to the exploration without changing the overall sampling distribution. Finally we will demonstrate that sampling symmetrically also for the exploration parameters is superior in needs of samples and robustness than the original sampling approach.</abstract>
   </article>
   <article>
      <title>Feature Graph Architectures</title>
      <author>Richard Davis, Sanjay Chawla, Philip Leong</author>
      <date>2013-12-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this article we propose feature graph architectures (FGA), which are <term>deep learning</term> systems employing a structured initialisation and training method based on a feature graph which facilitates improved generalisation performance compared with a standard shallow architecture. The goal is to explore alternative perspectives on the problem of deep network training. We evaluate FGA performance for deep SVMs on some experimental datasets, and show how generalisation and stability results may be derived for these models. We describe the effect of permutations on the model accuracy, and give a criterion for the optimal permutation in terms of feature correlations. The experimental results show that the algorithm produces robust and significant test set improvements over a standard shallow SVM training method for a range of datasets. These gains are achieved with a moderate increase in time complexity.</abstract>
   </article>
   <article>
      <title>Learning Factored Representations in a Deep Mixture of Experts</title>
      <author>David Eigen, Marc'Aurelio Ranzato, Ilya Sutskever</author>
      <date>2013-12-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Mixtures of Experts combine the outputs of several "expert" networks, each of which specializes in a different part of the input space. This is achieved by training a "gating" network that maps each input to a distribution over the experts. Such models show promise for building larger networks that are still cheap to compute at test time, and more parallelizable at training time. In this this work, we extend the Mixture of Experts to a stacked model, the Deep Mixture of Experts, with multiple sets of gating and experts. This exponentially increases the number of effective experts by associating each input with a combination of experts at each layer, yet maintains a modest model size. On a randomly translated version of the MNIST dataset, we find that the Deep Mixture of Experts automatically learns to develop location-dependent ("where") experts at the first layer, and class-specific ("what") experts at the second layer. In addition, we see that the different combinations are in use when the model is applied to a dataset of speech monophones. These demonstrate effective use of all expert combinations.</abstract>
   </article>
   <article>
      <title>Learning Deep Representations By Distributed Random Samplings</title>
      <author>Xiao-Lei Zhang</author>
      <date>2013-12-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose an extremely simple deep model for the unsupervised nonlinear dimensionality reduction -- deep distributed random samplings, which performs like a stack of unsupervised bootstrap aggregating. First, its network structure is novel: each layer of the network is a group of mutually independent $k$-centers clusterings. Second, its learning method is extremely simple: the $k$ centers of each clustering are only $k$ randomly selected examples from the training data; for small-scale data sets, the $k$ centers are further randomly reconstructed by a simple cyclic-shift operation. Experimental results on nonlinear dimensionality reduction show that the proposed method can learn abstract representations on both large-scale and small-scale problems, and meanwhile is much faster than deep <term>neural network</term>s on large-scale problems.</abstract>
   </article>
   <article>
      <title>Low-Rank Approximations for Conditional Feedforward Computation in Deep
  Neural Networks</title>
      <author>Andrew Davis, Itamar Arel</author>
      <date>2013-12-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Scalability properties of deep <term>neural network</term>s raise key research questions, particularly as the problems considered become larger and more challenging. This paper expands on the idea of conditional computation introduced by Bengio, et. al., where the nodes of a deep network are augmented by a set of gating units that determine when a node should be calculated. By factorizing the weight matrix into a low-rank approximation, an estimation of the sign of the pre-nonlinearity activation can be efficiently obtained. For networks using rectified-linear hidden units, this implies that the computation of a hidden unit with an estimated negative pre-nonlinearity can be ommitted altogether, as its value will become zero when nonlinearity is applied. For sparse <term>neural network</term>s, this can result in considerable speed gains. Experimental results using the MNIST and SVHN data sets with a fully-connected deep <term>neural network</term> demonstrate the performance robustness of the proposed scheme with respect to the error introduced by the conditional computation process.</abstract>
   </article>
   <article>
      <title>Evolution and Computational Learning Theory: A survey on Valiant's paper</title>
      <author>Arka Bhattacharya</author>
      <date>2013-12-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Darwin's theory of evolution is considered to be one of the greatest scientific gems in modern science. It not only gives us a description of how living things evolve, but also shows how a population evolves through time and also, why only the fittest individuals continue the generation forward. The paper basically gives a high level analysis of the works of Valiant[1]. Though, we know the mechanisms of evolution, but it seems that there does not exist any strong quantitative and mathematical theory of the evolution of certain mechanisms. What is defined exactly as the fitness of an individual, why is that only certain individuals in a population tend to mutate, how computation is done in finite time when we have exponentially many examples: there seems to be a lot of questions which need to be answered. [1] basically treats Darwinian theory as a form of computational learning theory, which calculates the net fitness of the hypotheses and thus distinguishes functions and their classes which could be evolvable using polynomial amount of resources. Evolution is considered as a function of the environment and the previous evolutionary stages that chooses the best hypothesis using learning techniques that makes mutation possible and hence, gives a quantitative idea that why only the fittest individuals tend to survive and have the power to mutate.</abstract>
   </article>
   <article>
      <title>A Comparative Evaluation of Curriculum Learning with Filtering and
  Boosting</title>
      <author>Michael R. Smith, Tony Martinez</author>
      <date>2013-12-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Not all instances in a data set are equally beneficial for inferring a model of the data. Some instances (such as outliers) are detrimental to inferring a model of the data. Several machine learning techniques treat instances in a data set differently during training such as curriculum learning, filtering, and boosting. However, an automated method for determining how beneficial an instance is for inferring a model of the data does not exist. In this paper, we present an automated method that orders the instances in a data set by complexity based on the their likelihood of being misclassified (instance hardness). The underlying assumption of this method is that instances with a high likelihood of being misclassified represent more complex concepts in a data set. Ordering the instances in a data set allows a learning algorithm to focus on the most beneficial instances and ignore the detrimental ones. We compare ordering the instances in a data set in curriculum learning, filtering and boosting. We find that ordering the instances significantly increases classification accuracy and that filtering has the largest impact on classification accuracy. On a set of 52 data sets, ordering the instances increases the average accuracy from 81% to 84%.</abstract>
   </article>
   <article>
      <title>Efficient Online Bootstrapping for Large Scale Learning</title>
      <author>Zhen Qin, Vaclav Petricek, Nikos Karampatziakis, Lihong Li, John Langford</author>
      <date>2013-12-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Bootstrapping is a useful technique for estimating the uncertainty of a predictor, for example, confidence intervals for prediction. It is typically used on small to moderate sized datasets, due to its high computation cost. This work describes a highly scalable online bootstrapping strategy, implemented inside Vowpal Wabbit, that is several times faster than traditional strategies. Our experiments indicate that, in addition to providing a black box-like method for estimating uncertainty, our implementation of online bootstrapping may also help to train models with better prediction performance due to model averaging.</abstract>
   </article>
   <article>
      <title>Large-scale Multi-label Text Classification - Revisiting Neural Networks</title>
      <author>Jinseok Nam, Jungi Kim, Eneldo Loza Mencía, Iryna Gurevych, Johannes Fürnkranz</author>
      <date>2013-12-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Neural networks have recently been proposed for multi-label classification because they are able to capture and model label dependencies in the output layer. In this work, we investigate limitations of BP-MLL, a <term>neural network</term> (NN) architecture that aims at minimizing pairwise ranking error. Instead, we propose to use a comparably simple NN approach with recently proposed learning techniques for large-scale multi-label text classification tasks. In particular, we show that BP-MLL's ranking loss minimization can be efficiently and effectively replaced with the commonly used cross entropy error function, and demonstrate that several advances in <term>neural network</term> training that have been developed in the realm of <term>deep learning</term> can be effectively employed in this setting. Our experimental results show that simple NN models equipped with advanced techniques such as rectified linear units, dropout, and AdaGrad perform as well as or even outperform state-of-the-art approaches on six large-scale textual datasets with diverse characteristics.</abstract>
   </article>
   <article>
      <title>Playing Atari with Deep Reinforcement Learning</title>
      <author>Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller</author>
      <date>2013-12-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present the first <term>deep learning</term> model to successfully learn control policies directly from high-dimensional sensory input using <term>reinforcement learning</term>. The model is a convolutional <term>neural network</term>, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.</abstract>
   </article>
   <article>
      <title>Zero-Shot Learning by Convex Combination of Semantic Embeddings</title>
      <author>Mohammad Norouzi, Tomas Mikolov, Samy Bengio, Yoram Singer, Jonathon Shlens, Andrea Frome, Greg S. Corrado, Jeffrey Dean</author>
      <date>2013-12-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional \nway{} classification framing of image understanding, particularly in terms of the promise for zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing \nway{} image classifier and a semantic word embedding model, which contains the $\n$ class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional training. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.</abstract>
   </article>
   <article>
      <title>k-Sparse Autoencoders</title>
      <author>Alireza Makhzani, Brendan Frey</author>
      <date>2013-12-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently, it has been observed that when representations are learnt in a way that encourages sparsity, improved performance is obtained on classification tasks. These methods involve combinations of activation functions, sampling steps and different kinds of penalties. To investigate the effectiveness of sparsity by itself, we propose the k-sparse autoencoder, which is an autoencoder with linear activation function, where in hidden layers only the k highest activities are kept. When applied to the MNIST and NORB datasets, we find that this method achieves better classification results than denoising autoencoders, networks trained with dropout, and RBMs. k-sparse autoencoders are simple to train and the encoding stage is very fast, making them well-suited to large problem sizes, where conventional sparse coding algorithms cannot be applied.</abstract>
   </article>
   <article>
      <title>Principled Non-Linear Feature Selection</title>
      <author>Dimitrios Athanasakis, John Shawe-Taylor, Delmiro Fernandez-Reyes</author>
      <date>2013-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recent non-linear feature selection approaches employing greedy optimisation of Centred Kernel Target Alignment(KTA) exhibit strong results in terms of generalisation accuracy and sparsity. However, they are computationally prohibitive for large datasets. We propose randSel, a randomised feature selection algorithm, with attractive scaling properties. Our theoretical analysis of randSel provides strong probabilistic guarantees for correct identification of relevant features. RandSel's characteristics make it an ideal candidate for identifying informative learned representations. We've conducted experimentation to establish the performance of this approach, and present encouraging results, including a 3rd position result in the recent ICML black box learning challenge as well as competitive results for signal peptide prediction, an important problem in bioinformatics.</abstract>
   </article>
   <article>
      <title>Adaptive Seeding for Gaussian Mixture Models</title>
      <author>Johannes Blömer, Kathrin Bujna</author>
      <date>2013-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present new initialization methods for the expectation-maximization algorithm for multivariate Gaussian mixture models. Our methods are adaptions of the well-known $K$-means++ initialization and the Gonzalez algorithm. Thereby we aim to close the gap between simple random, e.g. uniform, and complex methods, that crucially depend on the right choice of hyperparameters. Our extensive experiments indicate the usefulness of our methods compared to common techniques and methods, which e.g. apply the original $K$-means++ and Gonzalez directly, with respect to artificial as well as real-world data sets.</abstract>
   </article>
   <article>
      <title>Learning States Representations in POMDP</title>
      <author>Gabriella Contardo, Ludovic Denoyer, Thierry Artieres, Patrick Gallinari</author>
      <date>2013-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose to deal with sequential processes where only partial observations are available by learning a latent representation space on which policies may be accurately learned.</abstract>
   </article>
   <article>
      <title>Unit Tests for Stochastic Optimization</title>
      <author>Tom Schaul, Ioannis Antonoglou, David Silver</author>
      <date>2013-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Optimization by stochastic <term>gradient descent</term> is an important component of many large-scale machine learning algorithms. A wide variety of such optimization algorithms have been devised; however, it is unclear whether these algorithms are robust and widely applicable across many different optimization landscapes. In this paper we develop a collection of unit tests for stochastic optimization. Each unit test rapidly evaluates an optimization algorithm on a small-scale, isolated, and well-understood difficulty, rather than in real-world scenarios where many such issues are entangled. Passing these unit tests is not sufficient, but absolutely necessary for any algorithms with claims to generality or robustness. We give initial quantitative and qualitative results on numerous established algorithms. The testing framework is open-source, extensible, and easy to apply to new algorithms.</abstract>
   </article>
   <article>
      <title>Stopping Criteria in Contrastive Divergence: Alternatives to the
  Reconstruction Error</title>
      <author>David Buchaca, Enrique Romero, Ferran Mazzanti, Jordi Delgado</author>
      <date>2013-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Restricted Boltzmann Machines (RBMs) are general unsupervised learning devices to ascertain generative models of data distributions. RBMs are often trained using the Contrastive Divergence learning algorithm (CD), an approximation to the gradient of the data log-likelihood. A simple reconstruction error is often used to decide whether the approximation provided by the CD algorithm is good enough, though several authors (Schulz et al., 2010; Fischer &amp; Igel, 2010) have raised doubts concerning the feasibility of this procedure. However, not many alternatives to the reconstruction error have been used in the literature. In this manuscript we investigate simple alternatives to the reconstruction error in order to detect as soon as possible the decrease in the log-likelihood during learning.</abstract>
   </article>
   <article>
      <title>The return of AdaBoost.MH: multi-class Hamming trees</title>
      <author>Balázs Kégl</author>
      <date>2013-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Within the framework of AdaBoost.MH, we propose to train vector-valued decision trees to optimize the multi-class edge without reducing the multi-class problem to $K$ binary one-against-all classifications. The key element of the method is a vector-valued decision stump, factorized into an input-independent vector of length $K$ and label-independent scalar classifier. At inner tree nodes, the label-dependent vector is discarded and the binary classifier can be used for partitioning the input space into two regions. The algorithm retains the conceptual elegance, power, and computational efficiency of binary AdaBoost. In experiments it is on par with <term>support vector machine</term>s and with the best existing multi-class boosting algorithm AOSOLogitBoost, and it is significantly better than other known implementations of AdaBoost.MH.</abstract>
   </article>
   <article>
      <title>Comparison three methods of clustering: k-means, spectral clustering and
  hierarchical clustering</title>
      <author>Kamran Kowsari</author>
      <date>2013-12-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Comparison of three kind of the clustering and find cost function and loss function and calculate them. Error rate of the clustering methods and how to calculate the error percentage always be one on the important factor for evaluating the clustering methods, so this paper introduce one way to calculate the error rate of clustering methods. Clustering algorithms can be divided into several categories including partitioning clustering algorithms, hierarchical algorithms and density based algorithms. Generally speaking we should compare clustering algorithms by Scalability, Ability to work with different attribute, Clusters formed by conventional, Having minimal knowledge of the computer to recognize the input parameters, Classes for dealing with noise and extra deposition that same error rate for clustering a new data, Thus, there is no effect on the input data, different dimensions of high levels, K-means is one of the simplest approach to clustering that clustering is an unsupervised problem.</abstract>
   </article>
   <article>
      <title>Adaptive Feature Ranking for Unsupervised Transfer Learning</title>
      <author>Son N. Tran, Artur d'Avila Garcez</author>
      <date>2013-12-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Transfer Learning is concerned with the application of knowledge gained from solving a problem to a different but related problem domain. In this paper, we propose a method and efficient algorithm for ranking and selecting representations from a Restricted Boltzmann Machine trained on a source domain to be transferred onto a target domain. Experiments carried out using the MNIST, ICDAR and TiCC image datasets show that the proposed adaptive feature ranking and transfer learning method offers statistically significant improvements on the training of RBMs. Our method is general in that the knowledge chosen by the ranking function does not depend on its relation to any specific target domain, and it works with <term>unsupervised learning</term> and knowledge-based transfer.</abstract>
   </article>
   <article>
      <title>Dimension-free Concentration Bounds on Hankel Matrices for Spectral
  Learning</title>
      <author>François Denis, Mattias Gybels, Amaury Habrard</author>
      <date>2013-12-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Learning probabilistic models over strings is an important issue for many applications. Spectral methods propose elegant solutions to the problem of inferring weighted automata from finite samples of variable-length strings drawn from an unknown target distribution. These methods rely on a singular value decomposition of a matrix $H_S$, called the Hankel matrix, that records the frequencies of (some of) the observed strings. The accuracy of the learned distribution depends both on the quantity of information embedded in $H_S$ and on the distance between $H_S$ and its mean $H_r$. Existing concentration bounds seem to indicate that the concentration over $H_r$ gets looser with the size of $H_r$, suggesting to make a trade-off between the quantity of used information and the size of $H_r$. We propose new dimension-free concentration bounds for several variants of Hankel matrices. Experiments demonstrate that these bounds are tight and that they significantly improve existing bounds. These results suggest that the concentration rate of the Hankel matrix around its mean does not constitute an argument for limiting its size.</abstract>
   </article>
   <article>
      <title>Invariant Factorization Of Time-Series</title>
      <author>Josif Grabocka, Lars Schmidt-Thieme</author>
      <date>2013-12-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Time-series classification is an important domain of machine learning and a plethora of methods have been developed for the task. In comparison to existing approaches, this study presents a novel method which decomposes a time-series dataset into latent patterns and membership weights of local segments to those patterns. The process is formalized as a constrained objective function and a tailored stochastic coordinate descent optimization is applied. The time-series are projected to a new feature representation consisting of the sums of the membership weights, which captures frequencies of local patterns. Features from various sliding window sizes are concatenated in order to encapsulate the interaction of patterns from different sizes. Finally, a large-scale experimental comparison against 6 state of the art baselines and 43 real life datasets is conducted. The proposed method outperforms all the baselines with statistically significant margins in terms of prediction accuracy.</abstract>
   </article>
   <article>
      <title>Iterative Nearest Neighborhood Oversampling in Semisupervised Learning
  from Imbalanced Data</title>
      <author>Fengqi Li, Chuang Yu, Nanhai Yang, Feng Xia, Guangming Li, Fatemeh Kaveh-Yazdy</author>
      <date>2013-12-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Transductive graph-based semi-supervised learning methods usually build an undirected graph utilizing both labeled and unlabeled samples as vertices. Those methods propagate label information of labeled samples to neighbors through their edges in order to get the predicted labels of unlabeled samples. Most popular semi-supervised learning approaches are sensitive to initial label distribution happened in imbalanced labeled datasets. The class boundary will be severely skewed by the majority classes in an imbalanced classification. In this paper, we proposed a simple and effective approach to alleviate the unfavorable influence of imbalance problem by iteratively selecting a few unlabeled samples and adding them into the minority classes to form a balanced labeled dataset for the learning methods afterwards. The experiments on UCI datasets and MNIST handwritten digits dataset showed that the proposed approach outperforms other existing state-of-art methods.</abstract>
   </article>
   <article>
      <title>Rate-Distortion Auto-Encoders</title>
      <author>Luis G. Sanchez Giraldo, Jose C. Principe</author>
      <date>2013-12-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A rekindled the interest in auto-encoder algorithms has been spurred by recent work on <term>deep learning</term>. Current efforts have been directed towards effective training of auto-encoder architectures with a large number of coding units. Here, we propose a learning algorithm for auto-encoders based on a rate-distortion objective that minimizes the mutual information between the inputs and the outputs of the auto-encoder subject to a fidelity constraint. The goal is to learn a representation that is minimally committed to the input data, but that is rich enough to reconstruct the inputs up to certain level of distortion. Minimizing the mutual information acts as a regularization term whereas the fidelity constraint can be understood as a risk functional in the conventional statistical learning setting. The proposed algorithm uses a recently introduced measure of entropy based on infinitely divisible matrices that avoids the plug in estimation of densities. Experiments using over-complete bases show that the rate-distortion auto-encoders can learn a regularized input-output mapping in an implicit manner.</abstract>
   </article>
   <article>
      <title>Approximating the Bethe partition function</title>
      <author>Adrian Weller, Tony Jebara</author>
      <date>2013-12-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>When belief propagation (BP) converges, it does so to a stationary point of the Bethe free energy $F$, and is often strikingly accurate. However, it may converge only to a local optimum or may not converge at all. An algorithm was recently introduced for attractive binary pairwise MRFs which is guaranteed to return an $\epsilon$-approximation to the global minimum of $F$ in polynomial time provided the maximum degree $\Delta=O(\log n)$, where $n$ is the number of variables. Here we significantly improve this algorithm and derive several results including a new approach based on analyzing first derivatives of $F$, which leads to performance that is typically far superior and yields a fully polynomial-time approximation scheme (FPTAS) for attractive models without any degree restriction. Further, the method applies to general (non-attractive) models, though with no polynomial time guarantee in this case, leading to the important result that approximating $\log$ of the Bethe partition function, $\log Z_B=-\min F$, for a general model to additive $\epsilon$-accuracy may be reduced to a discrete MAP inference problem. We explore an application to predicting equipment failure on an urban power network and demonstrate that the Bethe approximation can perform well even when BP fails to converge.</abstract>
   </article>
   <article>
      <title>Controlled Sparsity Kernel Learning</title>
      <author>Dinesh Govindaraj, Raman Sankaran, Sreedal Menon, Chiranjib Bhattacharyya</author>
      <date>2013-12-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multiple Kernel Learning(MKL) on Support Vector Machines(SVMs) has been a popular front of research in recent times due to its success in application problems like Object Categorization. This success is due to the fact that MKL has the ability to choose from a variety of feature kernels to identify the optimal kernel combination. But the initial formulation of MKL was only able to select the best of the features and misses out many other informative kernels presented. To overcome this, the Lp norm based formulation was proposed by Kloft et. al. This formulation is capable of choosing a non-sparse set of kernels through a control parameter p. Unfortunately, the parameter p does not have a direct meaning to the number of kernels selected. We have observed that stricter control over the number of kernels selected gives us an edge over these techniques in terms of accuracy of classification and also helps us to fine tune the algorithms to the time requirements at hand. In this work, we propose a Controlled Sparsity Kernel Learning (CSKL) formulation that can strictly control the number of kernels which we wish to select. The CSKL formulation introduces a parameter t which directly corresponds to the number of kernels selected. It is important to note that a search in t space is finite and fast as compared to p. We have also provided an efficient Reduced Gradient Descent based algorithm to solve the CSKL formulation, which is proven to converge. Through our experiments on the Caltech101 Object Categorization dataset, we have also shown that one can achieve better accuracies than the previous formulations through the right choice of t.</abstract>
   </article>
   <article>
      <title>EigenGP: Gaussian Process Models with Adaptive Eigenfunctions</title>
      <author>Hao Peng, Yuan Qi</author>
      <date>2014-01-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Gaussian processes (GPs) provide a nonparametric representation of functions. However, classical GP inference suffers from high computational cost for big data. In this paper, we propose a new Bayesian approach, EigenGP, that learns both basis dictionary elements--eigenfunctions of a GP prior--and prior precisions in a sparse finite model. It is well known that, among all orthogonal basis functions, eigenfunctions can provide the most compact representation. Unlike other sparse Bayesian finite models where the basis function has a fixed form, our eigenfunctions live in a reproducing kernel Hilbert space as a finite linear combination of kernel functions. We learn the dictionary elements--eigenfunctions--and the prior precisions over these elements as well as all the other hyperparameters from data by maximizing the model marginal likelihood. We explore computational linear algebra to simplify the gradient computation significantly. Our experimental results demonstrate improved predictive performance of EigenGP over alternative sparse GP methods as well as relevance vector machine.</abstract>
   </article>
   <article>
      <title>Exploration vs Exploitation vs Safety: Risk-averse Multi-Armed Bandits</title>
      <author>Nicolas Galichet, Michèle Sebag, Olivier Teytaud</author>
      <date>2014-01-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Motivated by applications in energy management, this paper presents the Multi-Armed Risk-Aware Bandit (MARAB) algorithm. With the goal of limiting the exploration of risky arms, MARAB takes as arm quality its conditional value at risk. When the user-supplied risk level goes to 0, the arm quality tends toward the essential infimum of the arm distribution density, and MARAB tends toward the MIN multi-armed bandit algorithm, aimed at the arm with maximal minimal value. As a first contribution, this paper presents a theoretical analysis of the MIN algorithm under mild assumptions, establishing its robustness comparatively to UCB. The analysis is supported by extensive experimental validation of MIN and MARAB compared to UCB and state-of-art risk-aware MAB algorithms on artificial and real-world problems.</abstract>
   </article>
   <article>
      <title>DJ-MC: A Reinforcement-Learning Agent for Music Playlist Recommendation</title>
      <author>Elad Liebman, Maytal Saar-Tsechansky, Peter Stone</author>
      <date>2014-01-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In recent years, there has been growing focus on the study of automated recommender systems. Music recommendation systems serve as a prominent domain for such works, both from an academic and a commercial perspective. A fundamental aspect of music perception is that music is experienced in temporal context and in sequence. In this work we present DJ-MC, a novel reinforcement-learning framework for music recommendation that does not recommend songs individually but rather song sequences, or playlists, based on a model of preferences for both songs and song transitions. The model is learned online and is uniquely adapted for each listener. To reduce exploration time, DJ-MC exploits user feedback to initialize a model, which it subsequently updates by reinforcement. We evaluate our framework with human participants using both real song and playlist data. Our results indicate that DJ-MC's ability to recommend sequences of songs provides a significant improvement over more straightforward approaches, which do not take transitions into account.</abstract>
   </article>
   <article>
      <title>Clustering, Coding, and the Concept of Similarity</title>
      <author>L. Thorne McCarty</author>
      <date>2014-01-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper develops a theory of clustering and coding which combines a geometric model with a probabilistic model in a principled way. The geometric model is a Riemannian manifold with a Riemannian metric, ${g}_{ij}({\bf x})$, which we interpret as a measure of dissimilarity. The probabilistic model consists of a stochastic process with an invariant probability measure which matches the density of the sample input data. The link between the two models is a potential function, $U({\bf x})$, and its gradient, $\nabla U({\bf x})$. We use the gradient to define the dissimilarity metric, which guarantees that our measure of dissimilarity will depend on the probability measure. Finally, we use the dissimilarity metric to define a coordinate system on the embedded Riemannian manifold, which gives us a low-dimensional encoding of our original data.</abstract>
   </article>
   <article>
      <title>Latent Tree Models and Approximate Inference in Bayesian Networks</title>
      <author>Yi Wang, Nevin L. Zhang, Tao Chen</author>
      <date>2014-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a novel method for approximate inference in Bayesian networks (BNs). The idea is to sample data from a BN, learn a latent tree model (LTM) from the data offline, and when online, make inference with the LTM instead of the original BN. Because LTMs are tree-structured, inference takes linear time. In the meantime, they can represent complex relationship among leaf nodes and hence the approximation accuracy is often good. Empirical evidence shows that our method can achieve good approximation accuracy at low online computational cost.</abstract>
   </article>
   <article>
      <title>Adaptive Stochastic Resource Control: A Machine Learning Approach</title>
      <author>Balázs Csanád Csáji, László Monostori</author>
      <date>2014-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The paper investigates stochastic resource allocation problems with scarce, reusable resources and non-preemtive, time-dependent, interconnected tasks. This approach is a natural generalization of several standard resource management problems, such as scheduling and transportation problems. First, reactive solutions are considered and defined as control policies of suitably reformulated Markov decision processes (MDPs). We argue that this reformulation has several favorable properties, such as it has finite state and action spaces, it is aperiodic, hence all policies are proper and the space of control policies can be safely restricted. Next, approximate dynamic programming (ADP) methods, such as fitted Q-learning, are suggested for computing an efficient control policy. In order to compactly maintain the cost-to-go function, two representations are studied: hash tables and support vector regression (SVR), particularly, nu-SVRs. Several additional improvements, such as the application of limited-lookahead rollout algorithms in the initial phases, action space decomposition, task clustering and distributed sampling are investigated, too. Finally, experimental results on both benchmark and industry-related data are presented.</abstract>
   </article>
   <article>
      <title>Anytime Induction of Low-cost, Low-error Classifiers: a Sampling-based
  Approach</title>
      <author>Saher Esmeir, Shaul Markovitch</author>
      <date>2014-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Machine learning techniques are gaining prevalence in the production of a wide range of classifiers for complex real-world applications with nonuniform testing and misclassification costs. The increasing complexity of these applications poses a real challenge to resource management during learning and classification. In this work we introduce ACT (anytime cost-sensitive tree learner), a novel framework for operating in such complex environments. ACT is an anytime algorithm that allows learning time to be increased in return for lower classification costs. It builds a tree top-down and exploits additional time resources to obtain better estimations for the utility of the different candidate splits. Using sampling techniques, ACT approximates the cost of the subtree under each candidate split and favors the one with a minimal cost. As a stochastic algorithm, ACT is expected to be able to escape local minima, into which greedy methods may be trapped. Experiments with a variety of datasets were conducted to compare ACT to the state-of-the-art cost-sensitive tree learners. The results show that for the majority of domains ACT produces significantly less costly trees. ACT also exhibits good anytime behavior with diminishing returns.</abstract>
   </article>
   <article>
      <title>Regression Conformal Prediction with Nearest Neighbours</title>
      <author>Harris Papadopoulos, Vladimir Vovk, Alex Gammerman</author>
      <date>2014-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we apply Conformal Prediction (CP) to the k-Nearest Neighbours Regression (k-NNR) algorithm and propose ways of extending the typical nonconformity measure used for regression so far. Unlike traditional regression methods which produce point predictions, Conformal Predictors output predictive regions that satisfy a given confidence level. The regions produced by any Conformal Predictor are automatically valid, however their tightness and therefore usefulness depends on the nonconformity measure used by each CP. In effect a nonconformity measure evaluates how strange a given example is compared to a set of other examples based on some traditional machine learning algorithm. We define six novel nonconformity measures based on the k-Nearest Neighbours Regression algorithm and develop the corresponding CPs following both the original (transductive) and the inductive CP approaches. A comparison of the predictive regions produced by our measures with those of the typical regression measure suggests that a major improvement in terms of predictive region tightness is achieved by the new measures.</abstract>
   </article>
   <article>
      <title>Convex Optimization for Binary Classifier Aggregation in Multiclass
  Problems</title>
      <author>Sunho Park, TaeHyun Hwang, Seungjin Choi</author>
      <date>2014-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multiclass problems are often decomposed into multiple binary problems that are solved by individual binary classifiers whose results are integrated into a final answer. Various methods, including all-pairs (APs), one-versus-all (OVA), and error correcting output code (ECOC), have been studied, to decompose multiclass problems into binary problems. However, little study has been made to optimally aggregate binary problems to determine a final answer to the multiclass problem. In this paper we present a convex optimization method for an optimal aggregation of binary classifiers to estimate class membership probabilities in multiclass problems. We model the class membership probability as a softmax function which takes a conic combination of discrepancies induced by individual binary classifiers, as an input. With this model, we formulate the regularized maximum likelihood estimation as a convex optimization problem, which is solved by the primal-dual interior point method. Connections of our method to large margin classifiers are presented, showing that the large margin formulation can be considered as a limiting case of our convex formulation. Numerical experiments on synthetic and real-world data sets demonstrate that our method outperforms existing aggregation methods as well as direct methods, in terms of the classification accuracy and the quality of class membership probability estimates.</abstract>
   </article>
   <article>
      <title>A Unifying Framework for Typical Multi-Task Multiple Kernel Learning
  Problems</title>
      <author>Cong Li, Michael Georgiopoulos, Georgios C. Anagnostopoulos</author>
      <date>2014-01-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Over the past few years, Multi-Kernel Learning (MKL) has received significant attention among data-driven feature selection techniques in the context of kernel-based learning. MKL formulations have been devised and solved for a broad spectrum of machine learning problems, including Multi-Task Learning (MTL). Solving different MKL formulations usually involves designing algorithms that are tailored to the problem at hand, which is, typically, a non-trivial accomplishment.   In this paper we present a general Multi-Task Multi-Kernel Learning (Multi-Task MKL) framework that subsumes well-known Multi-Task MKL formulations, as well as several important MKL approaches on single-task problems. We then derive a simple algorithm that can solve the unifying framework. To demonstrate the flexibility of the proposed framework, we formulate a new learning problem, namely Partially-Shared Common Space (PSCS) Multi-Task MKL, and demonstrate its merits through experimentation.</abstract>
   </article>
   <article>
      <title>Is Extreme Learning Machine Feasible? A Theoretical Assessment (Part II)</title>
      <author>Shaobo Lin, Xia Liu, Jian Fang, Zongben Xu</author>
      <date>2014-01-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>An extreme learning machine (ELM) can be regarded as a two stage feed-forward <term>neural network</term> (FNN) learning system which randomly assigns the connections with and within hidden neurons in the first stage and tunes the connections with output neurons in the second stage. Therefore, ELM training is essentially a linear learning problem, which significantly reduces the computational burden. Numerous applications show that such a computation burden reduction does not degrade the generalization capability. It has, however, been open that whether this is true in theory. The aim of our work is to study the theoretical feasibility of ELM by analyzing the pros and cons of ELM. In the previous part on this topic, we pointed out that via appropriate selection of the activation function, ELM does not degrade the generalization capability in the expectation sense. In this paper, we launch the study in a different direction and show that the randomness of ELM also leads to certain negative consequences. On one hand, we find that the randomness causes an additional uncertainty problem of ELM, both in approximation and learning. On the other hand, we theoretically justify that there also exists an activation function such that the corresponding ELM degrades the generalization capability. In particular, we prove that the generalization capability of ELM with Gaussian kernel is essentially worse than that of FNN with Gaussian kernel. To facilitate the use of ELM, we also provide a remedy to such a degradation. We find that the well-developed coefficient regularization technique can essentially improve the generalization capability. The obtained results reveal the essential characteristic of ELM and give theoretical guidance concerning how to use ELM.</abstract>
   </article>
   <article>
      <title>Steady-state performance of non-negative least-mean-square algorithm and
  its variants</title>
      <author>Jie Chen, José Carlos M. Bermudez, Cédric Richard</author>
      <date>2014-01-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Non-negative least-mean-square (NNLMS) algorithm and its variants have been proposed for online estimation under non-negativity constraints. The transient behavior of the NNLMS, Normalized NNLMS, Exponential NNLMS and Sign-Sign NNLMS algorithms have been studied in our previous work. In this technical report, we derive closed-form expressions for the steady-state excess mean-square error (EMSE) for the four algorithms. Simulations results illustrate the accuracy of the theoretical results. This is a complementary material to our previous work.</abstract>
   </article>
   <article>
      <title>Riffled Independence for Efficient Inference with Partial Rankings</title>
      <author>Jonathan Huang, Ashish Kapoor, Carlos Guestrin</author>
      <date>2014-01-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Distributions over rankings are used to model data in a multitude of real world settings such as preference analysis and political elections. Modeling such distributions presents several computational challenges, however, due to the factorial size of the set of rankings over an item set. Some of these challenges are quite familiar to the artificial intelligence community, such as how to compactly represent a distribution over a combinatorially large space, and how to efficiently perform probabilistic inference with these representations. With respect to ranking, however, there is the additional challenge of what we refer to as human task complexity users are rarely willing to provide a full ranking over a long list of candidates, instead often preferring to provide partial ranking information. Simultaneously addressing all of these challenges i.e., designing a compactly representable model which is amenable to efficient inference and can be learned using partial ranking data is a difficult task, but is necessary if we would like to scale to problems with nontrivial size. In this paper, we show that the recently proposed riffled independence assumptions cleanly and efficiently address each of the above challenges. In particular, we establish a tight mathematical connection between the concepts of riffled independence and of partial rankings. This correspondence not only allows us to then develop efficient and exact algorithms for performing inference tasks using riffled independence based represen- tations with partial rankings, but somewhat surprisingly, also shows that efficient inference is not possible for riffle independent models (in a certain sense) with observations which do not take the form of partial rankings. Finally, using our inference algorithm, we introduce the first method for learning riffled independence based models from partially ranked data.</abstract>
   </article>
   <article>
      <title>Toward Supervised Anomaly Detection</title>
      <author>Nico Goernitz, Marius Micha Kloft, Konrad Rieck, Ulf Brefeld</author>
      <date>2014-01-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Anomaly detection is being regarded as an <term>unsupervised learning</term> task as anomalies stem from adversarial or unlikely events with unknown distributions. However, the predictive performance of purely unsupervised anomaly detection often fails to match the required detection rates in many tasks and there exists a need for labeled data to guide the model generation. Our first contribution shows that classical semi-supervised approaches, originating from a supervised classifier, are inappropriate and hardly detect new and unknown anomalies. We argue that semi-supervised anomaly detection needs to ground on the <term>unsupervised learning</term> paradigm and devise a novel algorithm that meets this requirement. Although being intrinsically non-convex, we further show that the optimization problem has a convex equivalent under relatively mild assumptions. Additionally, we propose an active learning strategy to automatically filter candidates for labeling. In an empirical study on network intrusion detection data, we observe that the proposed learning methodology requires much less labeled data than the state-of-the-art, while achieving higher detection accuracies.</abstract>
   </article>
   <article>
      <title>A Lower Bound for the Variance of Estimators for Nakagami m Distribution</title>
      <author>Rangeet Mitra, Amit Kumar Mishra, Tarun Choubisa</author>
      <date>2014-02-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently, we have proposed a maximum likelihood iterative algorithm for estimation of the parameters of the Nakagami-m distribution. This technique performs better than state of art estimation techniques for this distribution. This could be of particular use in low data or block based estimation problems. In these scenarios, the estimator should be able to give accurate estimates in the mean square sense with less amounts of data. Also, the estimates should improve with the increase in number of blocks received. In this paper, we see through our simulations, that our proposal is well designed for such requirements. Further, it is well known in the literature that an efficient estimator does not exist for Nakagami-m distribution. In this paper, we derive a theoretical expression for the variance of our proposed estimator. We find that this expression clearly fits the experimental curve for the variance of the proposed estimator. This expression is pretty close to the cramer-rao lower bound(CRLB).</abstract>
   </article>
   <article>
      <title>A Feature Subset Selection Algorithm Automatic Recommendation Method</title>
      <author>Guangtao Wang, Qinbao Song, Heli Sun, Xueying Zhang, Baowen Xu, Yuming Zhou</author>
      <date>2014-02-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many feature subset selection (FSS) algorithms have been proposed, but not all of them are appropriate for a given feature selection problem. At the same time, so far there is rarely a good way to choose appropriate FSS algorithms for the problem at hand. Thus, FSS algorithm automatic recommendation is very important and practically useful. In this paper, a meta learning based FSS algorithm automatic recommendation method is presented. The proposed method first identifies the data sets that are most similar to the one at hand by the k-nearest neighbor classification algorithm, and the distances among these data sets are calculated based on the commonly-used data set characteristics. Then, it ranks all the candidate FSS algorithms according to their performance on these similar data sets, and chooses the algorithms with best performance as the appropriate ones. The performance of the candidate FSS algorithms is evaluated by a multi-criteria metric that takes into account not only the classification accuracy over the selected features, but also the runtime of feature selection and the number of selected features. The proposed recommendation method is extensively tested on 115 real world data sets with 22 well-known and frequently-used different FSS algorithms for five representative classifiers. The results show the effectiveness of our proposed FSS algorithm recommendation method.</abstract>
   </article>
   <article>
      <title>A Survey on Latent Tree Models and Applications</title>
      <author>Raphaël Mourad, Christine Sinoquet, Nevin L. Zhang, Tengfei Liu, Philippe Leray</author>
      <date>2014-02-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In data analysis, latent variables play a central role because they help provide powerful insights into a wide variety of phenomena, ranging from biological to human sciences. The latent tree model, a particular type of probabilistic graphical models, deserves attention. Its simple structure - a tree - allows simple and efficient inference, while its latent variables capture complex relationships. In the past decade, the latent tree model has been subject to significant theoretical and methodological developments. In this review, we propose a comprehensive study of this model. First we summarize key ideas underlying the model. Second we explain how it can be efficiently learned from data. Third we illustrate its use within three types of applications: latent structure discovery, multidimensional clustering, and probabilistic inference. Finally, we conclude and give promising directions for future researches in this field.</abstract>
   </article>
   <article>
      <title>Near-Optimally Teaching the Crowd to Classify</title>
      <author>Adish Singla, Ilija Bogunovic, Gábor Bartók, Amin Karbasi, Andreas Krause</author>
      <date>2014-02-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>How should we present training examples to learners to teach them classification rules? This is a natural problem when training workers for crowdsourcing labeling tasks, and is also motivated by challenges in data-driven online education. We propose a natural stochastic model of the learners, modeling them as randomly switching among hypotheses based on observed feedback. We then develop STRICT, an efficient algorithm for selecting examples to teach to workers. Our solution greedily maximizes a submodular surrogate objective function in order to select examples to show to the learners. We prove that our strategy is competitive with the optimal teaching policy. Moreover, for the special case of linear separators, we prove that an exponential reduction in error probability can be achieved. Our experiments on simulated workers as well as three real image annotation tasks on Amazon Mechanical Turk show the effectiveness of our teaching algorithm.</abstract>
   </article>
   <article>
      <title>Indian Buffet Process Deep Generative Models for Semi-Supervised
  Classification</title>
      <author>Sotirios P. Chatzis</author>
      <date>2014-02-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Deep generative models (DGMs) have brought about a major breakthrough, as well as renewed interest, in generative latent variable models. However, DGMs do not allow for performing data-driven inference of the number of latent features needed to represent the observed data. Traditional linear formulations address this issue by resorting to tools from the field of nonparametric statistics. Indeed, linear latent variable models imposed an Indian Buffet Process (IBP) prior have been extensively studied by the machine learning community; inference for such models can been performed either via exact sampling or via approximate variational techniques. Based on this inspiration, in this paper we examine whether similar ideas from the field of Bayesian nonparametrics can be utilized in the context of modern DGMs in order to address the latent variable dimensionality inference problem. To this end, we propose a novel DGM formulation, based on the imposition of an IBP prior. We devise an efficient Black-Box Variational inference algorithm for our model, and exhibit its efficacy in a number of semi-supervised classification experiments. In all cases, we use popular benchmark datasets, and compare to state-of-the-art DGMs.</abstract>
   </article>
   <article>
      <title>Sparse Polynomial Learning and Graph Sketching</title>
      <author>Murat Kocaoglu, Karthikeyan Shanmugam, Alexandros G. Dimakis, Adam Klivans</author>
      <date>2014-02-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Let $f:\{-1,1\}^n$ be a polynomial with at most $s$ non-zero real coefficients. We give an algorithm for exactly reconstructing f given random examples from the uniform distribution on $\{-1,1\}^n$ that runs in time polynomial in $n$ and $2s$ and succeeds if the function satisfies the unique sign property: there is one output value which corresponds to a unique set of values of the participating parities. This sufficient condition is satisfied when every coefficient of f is perturbed by a small random noise, or satisfied with high probability when s parity functions are chosen randomly or when all the coefficients are positive. Learning sparse polynomials over the Boolean domain in time polynomial in $n$ and $2s$ is considered notoriously hard in the worst-case. Our result shows that the problem is tractable for almost all sparse polynomials. Then, we show an application of this result to hypergraph sketching which is the problem of learning a sparse (both in the number of hyperedges and the size of the hyperedges) hypergraph from uniformly drawn random cuts. We also provide experimental results on a real world dataset.</abstract>
   </article>
   <article>
      <title>Selective Sampling with Drift</title>
      <author>Edward Moroshko, Koby Crammer</author>
      <date>2014-02-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recently there has been much work on selective sampling, an online active learning setting, in which algorithms work in rounds. On each round an algorithm receives an input and makes a prediction. Then, it can decide whether to query a label, and if so to update its model, otherwise the input is discarded. Most of this work is focused on the stationary case, where it is assumed that there is a fixed target model, and the performance of the algorithm is compared to a fixed model. However, in many real-world applications, such as spam prediction, the best target function may drift over time, or have shifts from time to time. We develop a novel selective sampling algorithm for the drifting setting, analyze it under no assumptions on the mechanism generating the sequence of instances, and derive new mistake bounds that depend on the amount of drift in the problem. Simulations on synthetic and real-world datasets demonstrate the superiority of our algorithms as a selective sampling algorithm in the drifting setting.</abstract>
   </article>
   <article>
      <title>On the properties of $α$-unchaining single linkage hierarchical
  clustering</title>
      <author>A. Martínez-Pérez</author>
      <date>2014-02-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In the election of a hierarchical clustering method, theoretic properties may give some insight to determine which method is the most suitable to treat a clustering problem. Herein, we study some basic properties of two hierarchical clustering methods: $\alpha$-unchaining single linkage or $SL(\alpha)$ and a modified version of this one, $SL^*(\alpha)$. We compare the results with the properties satisfied by the classical linkage-based hierarchical clustering methods.</abstract>
   </article>
   <article>
      <title>Learning the Irreducible Representations of Commutative Lie Groups</title>
      <author>Taco Cohen, Max Welling</author>
      <date>2014-02-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a new probabilistic model of compact commutative Lie groups that produces invariant-equivariant and disentangled representations of data. To define the notion of disentangling, we borrow a fundamental principle from physics that is used to derive the elementary particles of a system from its symmetries. Our model employs a newfound Bayesian conjugacy relation that enables fully tractable probabilistic inference over compact commutative Lie groups -- a class that includes the groups that describe the rotation and cyclic translation of images. We train the model on pairs of transformed image patches, and show that the learned invariant representation is highly effective for classification.</abstract>
   </article>
   <article>
      <title>A Survey on Semi-Supervised Learning Techniques</title>
      <author>V. Jothi Prakash, Dr. L. M. Nithya</author>
      <date>2014-02-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Semisupervised learning is a learning standard which deals with the study of how computers and natural systems such as human beings acquire knowledge in the presence of both labeled and unlabeled data. Semisupervised learning based methods are preferred when compared to the supervised and <term>unsupervised learning</term> because of the improved performance shown by the semisupervised approaches in the presence of large volumes of data. Labels are very hard to attain while unlabeled data are surplus, therefore semisupervised learning is a noble indication to shrink human labor and improve accuracy. There has been a large spectrum of ideas on semisupervised learning. In this paper we bring out some of the key approaches for semisupervised learning.</abstract>
   </article>
   <article>
      <title>A Quasi-Newton Method for Large Scale Support Vector Machines</title>
      <author>Aryan Mokhtari, Alejandro Ribeiro</author>
      <date>2014-02-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper adapts a recently developed regularized stochastic version of the Broyden, Fletcher, Goldfarb, and Shanno (BFGS) quasi-Newton method for the solution of <term>support vector machine</term> classification problems. The proposed method is shown to converge almost surely to the optimal classifier at a rate that is linear in expectation. Numerical results show that the proposed method exhibits a convergence rate that degrades smoothly with the dimensionality of the feature vectors.</abstract>
   </article>
   <article>
      <title>To go deep or wide in learning?</title>
      <author>Gaurav Pandey, Ambedkar Dukkipati</author>
      <date>2014-02-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>To achieve acceptable performance for AI tasks, one can either use sophisticated feature extraction methods as the first layer in a two-layered supervised learning model, or learn the features directly using a deep (multi-layered) model. While the first approach is very problem-specific, the second approach has computational overheads in learning multiple layers and fine-tuning of the model. In this paper, we propose an approach called wide learning based on arc-cosine kernels, that learns a single layer of infinite width. We propose exact and inexact learning strategies for wide learning and show that wide learning with single layer outperforms single layer as well as deep architectures of finite width for some benchmark datasets.</abstract>
   </article>
   <article>
      <title>Bandits with concave rewards and convex knapsacks</title>
      <author>Shipra Agrawal, Nikhil R. Devanur</author>
      <date>2014-02-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we consider a very general model for exploration-exploitation tradeoff which allows arbitrary concave rewards and convex constraints on the decisions across time, in addition to the customary limitation on the time horizon. This model subsumes the classic multi-armed bandit (MAB) model, and the Bandits with Knapsacks (BwK) model of Badanidiyuru et al.[2013]. We also consider an extension of this model to allow linear contexts, similar to the linear contextual extension of the MAB model. We demonstrate that a natural and simple extension of the UCB family of algorithms for MAB provides a polynomial time algorithm that has near-optimal regret guarantees for this substantially more general model, and matches the bounds provided by Badanidiyuru et al.[2013] for the special case of BwK, which is quite surprising. We also provide computationally more efficient algorithms by establishing interesting connections between this problem and other well studied problems/algorithms such as the Blackwell approachability problem, online convex optimization, and the Frank-Wolfe technique for convex optimization. We give examples of several concrete applications, where this more general model of bandits allows for richer and/or more efficient formulations of the problem.</abstract>
   </article>
   <article>
      <title>Renewable Energy Prediction using Weather Forecasts for Optimal
  Scheduling in HPC Systems</title>
      <author>Ankur Sahai</author>
      <date>2014-02-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The objective of the GreenPAD project is to use green energy (wind, solar and biomass) for powering data-centers that are used to run HPC jobs. As a part of this it is important to predict the Renewable (Wind) energy for efficient scheduling (executing jobs that require higher energy when there is more green energy available and vice-versa). For predicting the wind energy we first analyze the historical data to find a statistical model that gives relation between wind energy and weather attributes. Then we use this model based on the weather forecast data to predict the green energy availability in the future. Using the green energy prediction obtained from the statistical model we are able to precompute job schedules for maximizing the green energy utilization in the future. We propose a model which uses live weather data in addition to machine learning techniques (which can predict future deviations in weather conditions based on current deviations from the forecast) to make on-the-fly changes to the precomputed schedule (based on green energy prediction).   For this we first analyze the data using histograms and simple statistical tools such as correlation. In addition we build (correlation) regression model for finding the relation between wind energy availability and weather attributes (temperature, cloud cover, air pressure, wind speed / direction, precipitation and sunshine). We also analyze different algorithms and machine learning techniques for optimizing the job schedules for maximizing the green energy utilization.</abstract>
   </article>
   <article>
      <title>Marginalizing Corrupted Features</title>
      <author>Laurens van der Maaten, Minmin Chen, Stephen Tyree, Kilian Weinberger</author>
      <date>2014-02-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The goal of machine learning is to develop predictors that generalize well to test data. Ideally, this is achieved by training on an almost infinitely large training data set that captures all variations in the data distribution. In practical learning settings, however, we do not have infinite data and our predictors may overfit. Overfitting may be combatted, for example, by adding a regularizer to the training objective or by defining a prior over the model parameters and performing Bayesian inference. In this paper, we propose a third, alternative approach to combat overfitting: we extend the training set with infinitely many artificial training examples that are obtained by corrupting the original training data. We show that this approach is practical and efficient for a range of predictors and corruption models. Our approach, called marginalized corrupted features (MCF), trains robust predictors by minimizing the expected value of the loss function under the corruption model. We show empirically on a variety of data sets that MCF classifiers can be trained efficiently, may generalize substantially better to test data, and are also more robust to feature deletion at test time.</abstract>
   </article>
   <article>
      <title>Exploiting the Statistics of Learning and Inference</title>
      <author>Max Welling</author>
      <date>2014-02-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>When dealing with datasets containing a billion instances or with simulations that require a supercomputer to execute, computational resources become part of the equation. We can improve the efficiency of learning and inference by exploiting their inherent statistical nature. We propose algorithms that exploit the redundancy of data relative to a model by subsampling data-cases for every update and reasoning about the uncertainty created in this process. In the context of learning we propose to test for the probability that a stochastically estimated gradient points more than 180 degrees in the wrong direction. In the context of MCMC sampling we use stochastic gradients to improve the efficiency of MCMC updates, and hypothesis tests based on adaptive mini-batches to decide whether to accept or reject a proposed parameter update. Finally, we argue that in the context of likelihood free MCMC one needs to store all the information revealed by all simulations, for instance in a Gaussian process. We conclude that Bayesian methods will remain to play a crucial role in the era of big data and big simulations, but only if we overcome a number of computational challenges.</abstract>
   </article>
   <article>
      <title>Sleep Analytics and Online Selective Anomaly Detection</title>
      <author>Tahereh Babaie, Sanjay Chawla, Romesh Abeysuriya</author>
      <date>2014-03-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a new problem, the Online Selective Anomaly Detection (OSAD), to model a specific scenario emerging from research in sleep science. Scientists have segmented sleep into several stages and stage two is characterized by two patterns (or anomalies) in the EEG time series recorded on sleep subjects. These two patterns are sleep spindle (SS) and K-complex. The OSAD problem was introduced to design a residual system, where all anomalies (known and unknown) are detected but the system only triggers an alarm when non-SS anomalies appear. The solution of the OSAD problem required us to combine techniques from both machine learning and control theory. Experiments on data from real subjects attest to the effectiveness of our approach.</abstract>
   </article>
   <article>
      <title>The Structurally Smoothed Graphlet Kernel</title>
      <author>Pinar Yanardag, S. V. N. Vishwanathan</author>
      <date>2014-03-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A commonly used paradigm for representing graphs is to use a vector that contains normalized frequencies of occurrence of certain motifs or sub-graphs. This vector representation can be used in a variety of applications, such as, for computing similarity between graphs. The graphlet kernel of Shervashidze et al. [32] uses induced sub-graphs of k nodes (christened as graphlets by Przulj [28]) as motifs in the vector representation, and computes the kernel via a dot product between these vectors. One can easily show that this is a valid kernel between graphs. However, such a vector representation suffers from a few drawbacks. As k becomes larger we encounter the sparsity problem; most higher order graphlets will not occur in a given graph. This leads to diagonal dominance, that is, a given graph is similar to itself but not to any other graph in the dataset. On the other hand, since lower order graphlets tend to be more numerous, using lower values of k does not provide enough discrimination ability. We propose a smoothing technique to tackle the above problems. Our method is based on a novel extension of Kneser-Ney and Pitman-Yor smoothing techniques from natural language processing to graphs. We use the relationships between lower order and higher order graphlets in order to derive our method. Consequently, our smoothing algorithm not only respects the dependency between sub-graphs but also tackles the diagonal dominance problem by distributing the probability mass across graphlets. In our experiments, the smoothed graphlet kernel outperforms graph kernels based on raw frequency counts.</abstract>
   </article>
   <article>
      <title>Unconstrained Online Linear Learning in Hilbert Spaces: Minimax
  Algorithms and Normal Approximations</title>
      <author>H. Brendan McMahan, Francesco Orabona</author>
      <date>2014-03-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study algorithms for online linear optimization in Hilbert spaces, focusing on the case where the player is unconstrained. We develop a novel characterization of a large class of minimax algorithms, recovering, and even improving, several previous results as immediate corollaries. Moreover, using our tools, we develop an algorithm that provides a regret bound of $\mathcal{O}\Big(U \sqrt{T \log(U \sqrt{T} \log^2 T +1)}\Big)$, where $U$ is the $L_2$ norm of an arbitrary comparator and both $T$ and $U$ are unknown to the player. This bound is optimal up to $\sqrt{\log \log T}$ terms. When $T$ is known, we derive an algorithm with an optimal regret bound (up to constant factors). For both the known and unknown $T$ case, a Normal approximation to the conditional value of the game proves to be the key analysis tool.</abstract>
   </article>
   <article>
      <title>Integer Programming Relaxations for Integrated Clustering and Outlier
  Detection</title>
      <author>Lionel Ott, Linsey Pang, Fabio Ramos, David Howe, Sanjay Chawla</author>
      <date>2014-03-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we present methods for exemplar based clustering with outlier selection based on the facility location formulation. Given a distance function and the number of outliers to be found, the methods automatically determine the number of clusters and outliers. We formulate the problem as an integer program to which we present relaxations that allow for solutions that scale to large data sets. The advantages of combining clustering and outlier selection include: (i) the resulting clusters tend to be compact and semantically coherent (ii) the clusters are more robust against data perturbations and (iii) the outliers are contextualised by the clusters and more interpretable, i.e. it is easier to distinguish between outliers which are the result of data errors from those that may be indicative of a new pattern emergent in the data. We present and contrast three relaxations to the integer program formulation: (i) a linear programming formulation (LP) (ii) an extension of affinity propagation to outlier detection (APOC) and (iii) a Lagrangian duality based formulation (LD). Evaluation on synthetic as well as real data shows the quality and scalability of these different methods.</abstract>
   </article>
   <article>
      <title>Predictive Overlapping Co-Clustering</title>
      <author>Chandrima Sarkar, Jaideep Srivastava</author>
      <date>2014-03-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In the past few years co-clustering has emerged as an important data mining tool for two way data analysis. Co-clustering is more advantageous over traditional one dimensional clustering in many ways such as, ability to find highly correlated sub-groups of rows and columns. However, one of the overlooked benefits of co-clustering is that, it can be used to extract meaningful knowledge for various other knowledge extraction purposes. For example, building predictive models with high dimensional data and heterogeneous population is a non-trivial task. Co-clusters extracted from such data, which shows similar pattern in both the dimension, can be used for a more accurate predictive model building. Several applications such as finding patient-disease cohorts in health care analysis, finding user-genre groups in recommendation systems and community detection problems can benefit from co-clustering technique that utilizes the predictive power of the data to generate co-clusters for improved data analysis.   In this paper, we present the novel idea of Predictive Overlapping Co-Clustering (POCC) as an optimization problem for a more effective and improved predictive analysis. Our algorithm generates optimal co-clusters by maximizing predictive power of the co-clusters subject to the constraints on the number of row and column clusters. In this paper precision, recall and f-measure have been used as evaluation measures of the resulting co-clusters. Results of our algorithm has been compared with two other well-known techniques - K-means and Spectral co-clustering, over four real data set namely, Leukemia, Internet-Ads, Ovarian cancer and MovieLens data set. The results demonstrate the effectiveness and utility of our algorithm POCC in practice.</abstract>
   </article>
   <article>
      <title>Improving Performance of a Group of Classification Algorithms Using
  Resampling and Feature Selection</title>
      <author>Mehdi Naseriparsa, Amir-masoud Bidgoli, Touraj Varaee</author>
      <date>2014-03-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In recent years the importance of finding a meaningful pattern from huge datasets has become more challenging. Data miners try to adopt innovative methods to face this problem by applying feature selection methods. In this paper we propose a new hybrid method in which we use a combination of resampling, filtering the sample domain and wrapper subset evaluation method with genetic search to reduce dimensions of Lung-Cancer dataset that we received from UCI Repository of Machine Learning databases. Finally, we apply some well- known classification algorithms (Na\"ive Bayes, Logistic, Multilayer Perceptron, Best First Decision Tree and JRIP) to the resulting dataset and compare the results and prediction rates before and after the application of our feature selection method on that dataset. The results show a substantial progress in the average performance of five classification algorithms simultaneously and the classification error for these classifiers decreases considerably. The experiments also show that this method outperforms other feature selection methods with a lower cost.</abstract>
   </article>
   <article>
      <title>Categorization Axioms for Clustering Results</title>
      <author>Jian Yu, Zongben Xu</author>
      <date>2014-03-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Cluster analysis has attracted more and more attention in the field of machine learning and data mining. Numerous clustering algorithms have been proposed and are being developed due to diverse theories and various requirements of emerging applications. Therefore, it is very worth establishing an unified axiomatic framework for data clustering. In the literature, it is an open problem and has been proved very challenging. In this paper, clustering results are axiomatized by assuming that an proper clustering result should satisfy categorization axioms. The proposed axioms not only introduce classification of clustering results and inequalities of clustering results, but also are consistent with prototype theory and exemplar theory of categorization models in cognitive science. Moreover, the proposed axioms lead to three principles of designing clustering algorithm and cluster validity index, which follow many popular clustering algorithms and cluster validity indices.</abstract>
   </article>
   <article>
      <title>A Hybrid Feature Selection Method to Improve Performance of a Group of
  Classification Algorithms</title>
      <author>Mehdi Naseriparsa, Amir-Masoud Bidgoli, Touraj Varaee</author>
      <date>2014-03-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper a hybrid feature selection method is proposed which takes advantages of wrapper subset evaluation with a lower cost and improves the performance of a group of classifiers. The method uses combination of sample domain filtering and resampling to refine the sample domain and two feature subset evaluation methods to select reliable features. This method utilizes both feature space and sample domain in two phases. The first phase filters and resamples the sample domain and the second phase adopts a hybrid procedure by information gain, wrapper subset evaluation and genetic search to find the optimal feature space. Experiments carried out on different types of datasets from UCI Repository of Machine Learning databases and the results show a rise in the average performance of five classifiers (Naive Bayes, Logistic, Multilayer Perceptron, Best First Decision Tree and JRIP) simultaneously and the classification error for these classifiers decreases considerably. The experiments also show that this method outperforms other feature selection methods with a lower cost.</abstract>
   </article>
   <article>
      <title>Cancer Prognosis Prediction Using Balanced Stratified Sampling</title>
      <author>J S Saleema, N Bhagawathi, S Monica, P Deepa Shenoy, K R Venugopal, L M Patnaik</author>
      <date>2014-03-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>High accuracy in cancer prediction is important to improve the quality of the treatment and to improve the rate of survivability of patients. As the data volume is increasing rapidly in the healthcare research, the analytical challenge exists in double. The use of effective sampling technique in classification algorithms always yields good prediction accuracy. The SEER public use cancer database provides various prominent class labels for prognosis prediction. The main objective of this paper is to find the effect of sampling techniques in classifying the prognosis variable and propose an ideal sampling method based on the outcome of the experimentation. In the first phase of this work the traditional random sampling and stratified sampling techniques have been used. At the next level the balanced stratified sampling with variations as per the choice of the prognosis class labels have been tested. Much of the initial time has been focused on performing the pre_processing of the SEER data set. The classification model for experimentation has been built using the breast cancer, respiratory cancer and mixed cancer data sets with three traditional classifiers namely Decision Tree, Naive Bayes and K-Nearest Neighbor. The three prognosis factors survival, stage and metastasis have been used as class labels for experimental comparisons. The results shows a steady increase in the prediction accuracy of balanced stratified model as the sample size increases, but the traditional approach fluctuates before the optimum results.</abstract>
   </article>
   <article>
      <title>A Survey of Algorithms and Analysis for Adaptive Online Learning</title>
      <author>H. Brendan McMahan</author>
      <date>2014-03-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present tools for the analysis of Follow-The-Regularized-Leader (FTRL), Dual Averaging, and Mirror Descent algorithms when the regularizer (equivalently, prox-function or learning rate schedule) is chosen adaptively based on the data. Adaptivity can be used to prove regret bounds that hold on every round, and also allows for data-dependent regret bounds as in AdaGrad-style algorithms (e.g., Online Gradient Descent with adaptive per-coordinate learning rates). We present results from a large number of prior works in a unified manner, using a modular and tight analysis that isolates the key arguments in easily re-usable lemmas. This approach strengthens pre-viously known FTRL analysis techniques to produce bounds as tight as those achieved by potential functions or primal-dual analysis. Further, we prove a general and exact equivalence between an arbitrary adaptive Mirror Descent algorithm and a correspond- ing FTRL update, which allows us to analyze any Mirror Descent algorithm in the same framework. The key to bridging the gap between Dual Averaging and Mirror Descent algorithms lies in an analysis of the FTRL-Proximal algorithm family. Our regret bounds are proved in the most general form, holding for arbitrary norms and non-smooth regularizers with time-varying weight.</abstract>
   </article>
   <article>
      <title>Making Risk Minimization Tolerant to Label Noise</title>
      <author>Aritra Ghosh, Naresh Manwani, P. S. Sastry</author>
      <date>2014-03-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In many applications, the training data, from which one needs to learn a classifier, is corrupted with label noise. Many standard algorithms such as SVM perform poorly in presence of label noise. In this paper we investigate the robustness of risk minimization to label noise. We prove a sufficient condition on a loss function for the risk minimization under that loss to be tolerant to uniform label noise. We show that the $0-1$ loss, sigmoid loss, ramp loss and probit loss satisfy this condition though none of the standard convex loss functions satisfy it. We also prove that, by choosing a sufficiently large value of a parameter in the loss function, the sigmoid loss, ramp loss and probit loss can be made tolerant to non-uniform label noise also if we can assume the classes to be separable under noise-free data distribution. Through extensive empirical studies, we show that risk minimization under the $0-1$ loss, the sigmoid loss and the ramp loss has much better robustness to label noise when compared to the SVM algorithm.</abstract>
   </article>
   <article>
      <title>Mixed-norm Regularization for Brain Decoding</title>
      <author>Rémi Flamary, Nisrine Jrad, Ronald Phlypo, Marco Congedo, Alain Rakotomamonjy</author>
      <date>2014-03-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work investigates the use of mixed-norm regularization for sensor selection in Event-Related Potential (ERP) based Brain-Computer Interfaces (BCI). The classification problem is cast as a discriminative optimization framework where sensor selection is induced through the use of mixed-norms. This framework is extended to the multi-task learning situation where several similar classification tasks related to different subjects are learned simultaneously. In this case, multi-task learning helps in leveraging data scarcity issue yielding to more robust classifiers. For this purpose, we have introduced a regularizer that induces both sensor selection and classifier similarities. The different regularization approaches are compared on three ERP datasets showing the interest of mixed-norm regularization in terms of sensor selection. The multi-task approaches are evaluated when a small number of learning examples are available yielding to significant performance improvements especially for subjects performing poorly.</abstract>
   </article>
   <article>
      <title>Learning Negative Mixture Models by Tensor Decompositions</title>
      <author>Guillaume Rabusseau, François Denis</author>
      <date>2014-03-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work considers the problem of estimating the parameters of negative mixture models, i.e. mixture models that possibly involve negative weights. The contributions of this paper are as follows. (i) We show that every rational probability distributions on strings, a representation which occurs naturally in spectral learning, can be computed by a negative mixture of at most two probabilistic automata (or HMMs). (ii) We propose a method to estimate the parameters of negative mixture models having a specific tensor structure in their low order observable moments. Building upon a recent paper on tensor decompositions for learning latent variable models, we extend this work to the broader setting of tensors having a symmetric decomposition with positive and negative weights. We introduce a generalization of the tensor power method for complex valued tensors, and establish theoretical convergence guarantees. (iii) We show how our approach applies to negative Gaussian mixture models, for which we provide some experiments.</abstract>
   </article>
   <article>
      <title>Spectral Clustering with Jensen-type kernels and their multi-point
  extensions</title>
      <author>Debarghya Ghoshdastidar, Ambedkar Dukkipati, Ajay P. Adsul, Aparna S. Vijayan</author>
      <date>2014-03-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Motivated by multi-distribution divergences, which originate in information theory, we propose a notion of `multi-point' kernels, and study their applications. We study a class of kernels based on Jensen type divergences and show that these can be extended to measure similarity among multiple points. We study tensor flattening methods and develop a multi-point (kernel) spectral clustering (MSC) method. We further emphasize on a special case of the proposed kernels, which is a multi-point extension of the linear (dot-product) kernel and show the existence of cubic time tensor flattening algorithm in this case. Finally, we illustrate the usefulness of our contributions using standard data sets and image segmentation tasks.</abstract>
   </article>
   <article>
      <title>Unconfused Ultraconservative Multiclass Algorithms</title>
      <author>Ugo Louche, Liva Ralaivola</author>
      <date>2014-03-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We tackle the problem of learning linear classifiers from noisy datasets in a multiclass setting. The two-class version of this problem was studied a few years ago by, e.g. Bylander (1994) and Blum et al. (1996): in these contributions, the proposed approaches to fight the noise revolve around a Perceptron learning scheme fed with peculiar examples computed through a weighted average of points from the noisy training set. We propose to build upon these approaches and we introduce a new algorithm called UMA (for Unconfused Multiclass additive Algorithm) which may be seen as a generalization to the multiclass setting of the previous approaches. In order to characterize the noise we use the confusion matrix as a multiclass extension of the classification noise studied in the aforementioned literature. Theoretically well-founded, UMA furthermore displays very good empirical noise robustness, as evidenced by numerical simulations conducted on both synthetic and real data. Keywords: Multiclass classification, Perceptron, Noisy labels, Confusion Matrix</abstract>
   </article>
   <article>
      <title>Online Local Learning via Semidefinite Programming</title>
      <author>Paul Christiano</author>
      <date>2014-03-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In many online learning problems we are interested in predicting local information about some universe of items. For example, we may want to know whether two items are in the same cluster rather than computing an assignment of items to clusters; we may want to know which of two teams will win a game rather than computing a ranking of teams. Although finding the optimal clustering or ranking is typically intractable, it may be possible to predict the relationships between items as well as if you could solve the global optimization problem exactly.   Formally, we consider an online learning problem in which a learner repeatedly guesses a pair of labels (l(x), l(y)) and receives an adversarial payoff depending on those labels. The learner's goal is to receive a payoff nearly as good as the best fixed labeling of the items. We show that a simple algorithm based on semidefinite programming can obtain asymptotically optimal regret in the case where the number of possible labels is O(1), resolving an open problem posed by Hazan, Kale, and Shalev-Schwartz. Our main technical contribution is a novel use and analysis of the log determinant regularizer, exploiting the observation that log det(A + I) upper bounds the entropy of any distribution with covariance matrix A.</abstract>
   </article>
   <article>
      <title>An Information-Theoretic Analysis of Thompson Sampling</title>
      <author>Daniel Russo, Benjamin Van Roy</author>
      <date>2014-03-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We provide an information-theoretic analysis of Thompson sampling that applies across a broad range of online optimization problems in which a decision-maker must learn from partial feedback. This analysis inherits the simplicity and elegance of information theory and leads to regret bounds that scale with the entropy of the optimal-action distribution. This strengthens preexisting results and yields new insight into how information improves performance.</abstract>
   </article>
   <article>
      <title>Learning to Optimize via Information-Directed Sampling</title>
      <author>Daniel Russo, Benjamin Van Roy</author>
      <date>2014-03-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose information-directed sampling -- a new approach to online optimization problems in which a decision-maker must balance between exploration and exploitation while learning from partial feedback. Each action is sampled in a manner that minimizes the ratio between squared expected single-period regret and a measure of information gain: the mutual information between the optimal action and the next observation. We establish an expected regret bound for information-directed sampling that applies across a very general class of models and scales with the entropy of the optimal action distribution. We illustrate through simple analytic examples how information-directed sampling accounts for kinds of information that alternative approaches do not adequately address and that this can lead to dramatic performance gains. For the widely studied Bernoulli, Gaussian, and linear bandit problems, we demonstrate state-of-the-art simulation performance.</abstract>
   </article>
   <article>
      <title>Online Learning of k-CNF Boolean Functions</title>
      <author>Joel Veness, Marcus Hutter</author>
      <date>2014-03-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper revisits the problem of learning a k-CNF Boolean function from examples in the context of online learning under the logarithmic loss. In doing so, we give a Bayesian interpretation to one of Valiant's celebrated PAC learning algorithms, which we then build upon to derive two efficient, online, probabilistic, supervised learning algorithms for predicting the output of an unknown k-CNF Boolean function. We analyze the loss of our methods, and show that the cumulative log-loss can be upper bounded, ignoring logarithmic factors, by a polynomial function of the size of each example.</abstract>
   </article>
   <article>
      <title>A study on cost behaviors of binary classification measures in
  class-imbalanced problems</title>
      <author>Bao-Gang Hu, Wei-Ming Dong</author>
      <date>2014-03-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work investigates into cost behaviors of binary classification measures in a background of class-imbalanced problems. Twelve performance measures are studied, such as F measure, G-means in terms of accuracy rates, and of recall and precision, balance error rate (BER), Matthews correlation coefficient (MCC), Kappa coefficient, etc. A new perspective is presented for those measures by revealing their cost functions with respect to the class imbalance ratio. Basically, they are described by four types of cost functions. The functions provides a theoretical understanding why some measures are suitable for dealing with class-imbalanced problems. Based on their cost functions, we are able to conclude that G-means of accuracy rates and BER are suitable measures because they show "proper" cost behaviors in terms of "a misclassification from a small class will cause a greater cost than that from a large class". On the contrary, F1 measure, G-means of recall and precision, MCC and Kappa coefficient measures do not produce such behaviors so that they are unsuitable to serve our goal in dealing with the problems properly.</abstract>
   </article>
   <article>
      <title>Approximate Decentralized Bayesian Inference</title>
      <author>Trevor Campbell, Jonathan P. How</author>
      <date>2014-03-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents an approximate method for performing Bayesian inference in models with conditional independence over a decentralized network of learning agents. The method first employs variational inference on each individual learning agent to generate a local approximate posterior, the agents transmit their local posteriors to other agents in the network, and finally each agent combines its set of received local posteriors. The key insight in this work is that, for many Bayesian models, approximate inference schemes destroy symmetry and dependencies in the model that are crucial to the correct application of Bayes' rule when combining the local posteriors. The proposed method addresses this issue by including an additional optimization step in the combination procedure that accounts for these broken dependencies. Experiments on synthetic and real data demonstrate that the decentralized method provides advantages in computational performance and predictive test likelihood over previous batch and distributed methods.</abstract>
   </article>
   <article>
      <title>Efficient Algorithms and Error Analysis for the Modified Nystrom Method</title>
      <author>Shusen Wang, Zhihua Zhang</author>
      <date>2014-04-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many kernel methods suffer from high time and space complexities and are thus prohibitive in big-data applications. To tackle the computational challenge, the Nystr\"om method has been extensively used to reduce time and space complexities by sacrificing some accuracy. The Nystr\"om method speedups computation by constructing an approximation of the kernel matrix using only a few columns of the matrix. Recently, a variant of the Nystr\"om method called the modified Nystr\"om method has demonstrated significant improvement over the standard Nystr\"om method in approximation accuracy, both theoretically and empirically.   In this paper, we propose two algorithms that make the modified Nystr\"om method practical. First, we devise a simple column selection algorithm with a provable error bound. Our algorithm is more efficient and easier to implement than and nearly as accurate as the state-of-the-art algorithm. Second, with the selected columns at hand, we propose an algorithm that computes the approximation in lower time complexity than the approach in the previous work. Furthermore, we prove that the modified Nystr\"om method is exact under certain conditions, and we establish a lower error bound for the modified Nystr\"om method.</abstract>
   </article>
   <article>
      <title>A probabilistic estimation and prediction technique for dynamic
  continuous social science models: The evolution of the attitude of the Basque
  Country population towards ETA as a case study</title>
      <author>Juan-Carlos Cortés, Francisco-J. Santonja, Ana-C. Tarazona, Rafael-J. Villanueva, Javier Villanueva-Oller</author>
      <date>2014-03-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we present a computational technique to deal with uncertainty in dynamic continuous models in Social Sciences. Considering data from surveys, the method consists of determining the probability distribution of the survey output and this allows to sample data and fit the model to the sampled data using a goodness-of-fit criterion based on the chi-square-test. Taking the fitted parameters non-rejected by the chi-square-test, substituting them into the model and computing their outputs, we build 95% confidence intervals in each time instant capturing uncertainty of the survey data (probabilistic estimation). Using the same set of obtained model parameters, we also provide a prediction over the next few years with 95% confidence intervals (probabilistic prediction). This technique is applied to a dynamic social model describing the evolution of the attitude of the Basque Country population towards the revolutionary organization ETA.</abstract>
   </article>
   <article>
      <title>The Least Wrong Model Is Not in the Data</title>
      <author>Oscar Stiffelman</author>
      <date>2014-04-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The true process that generated data cannot be determined when multiple explanations are possible. Prediction requires a model of the probability that a process, chosen randomly from the set of candidate explanations, generates some future observation. The best model includes all of the information contained in the minimal description of the data that is not contained in the data. It is closely related to the Halting Problem and is logarithmic in the size of the data. Prediction is difficult because the ideal model is not computable, and the best computable model is not "findable." However, the error from any approximation can be bounded by the size of the description using the model.</abstract>
   </article>
   <article>
      <title>Bayes and Naive Bayes Classifier</title>
      <author>Vikramkumar, Vijaykumar B, Trilochan</author>
      <date>2014-04-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The Bayesian Classification represents a supervised learning method as well as a statistical method for classification. Assumes an underlying probabilistic model and it allows us to capture uncertainty about the model in a principled way by determining probabilities of the outcomes. This Classification is named after Thomas Bayes (1702-1761), who proposed the Bayes Theorem. Bayesian classification provides practical learning algorithms and prior knowledge and observed data can be combined. Bayesian Classification provides a useful perspective for understanding and evaluating many learning algorithms. It calculates explicit probabilities for hypothesis and it is robust to noise in input data. In statistical classification the Bayes classifier minimises the probability of misclassification. That was a visual intuition for a simple case of the Bayes classifier, also called: 1)Idiot Bayes 2)Naive Bayes 3)Simple Bayes</abstract>
   </article>
   <article>
      <title>Parallel Support Vector Machines in Practice</title>
      <author>Stephen Tyree, Jacob R. Gardner, Kilian Q. Weinberger, Kunal Agrawal, John Tran</author>
      <date>2014-04-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we evaluate the performance of various parallel optimization methods for Kernel Support Vector Machines on multicore CPUs and GPUs. In particular, we provide the first comparison of algorithms with explicit and implicit parallelization. Most existing parallel implementations for multi-core or GPU architectures are based on explicit parallelization of Sequential Minimal Optimization (SMO)---the programmers identified parallelizable components and hand-parallelized them, specifically tuned for a particular architecture. We compare these approaches with each other and with implicitly parallelized algorithms---where the algorithm is expressed such that most of the work is done within few iterations with large dense linear algebra operations. These can be computed with highly-optimized libraries, that are carefully parallelized for a large variety of parallel platforms. We highlight the advantages and disadvantages of both approaches and compare them on various benchmark data sets. We find an approximate implicitly parallel algorithm which is surprisingly efficient, permits a much simpler implementation, and leads to unprecedented speedups in SVM training.</abstract>
   </article>
   <article>
      <title>Hierarchical Dirichlet Scaling Process</title>
      <author>Dongwoo Kim, Alice Oh</author>
      <date>2014-03-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present the \textit{hierarchical Dirichlet scaling process} (HDSP), a Bayesian nonparametric mixed membership model. The HDSP generalizes the hierarchical Dirichlet process (HDP) to model the correlation structure between metadata in the corpus and mixture components. We construct the HDSP based on the normalized gamma representation of the Dirichlet process, and this construction allows incorporating a scaling function that controls the membership probabilities of the mixture components. We develop two scaling methods to demonstrate that different modeling assumptions can be expressed in the HDSP. We also derive the corresponding approximate posterior inference algorithms using variational Bayes. Through experiments on datasets of newswire, medical journal articles, conference proceedings, and product reviews, we show that the HDSP results in a better predictive performance than labeled LDA, partially labeled LDA, and author topic model and a better negative review classification performance than the supervised topic model and SVM.</abstract>
   </article>
   <article>
      <title>An Efficient Feature Selection in Classification of Audio Files</title>
      <author>Jayita Mitra, Diganta Saha</author>
      <date>2014-03-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we have focused on an efficient feature selection method in classification of audio files. The main objective is feature selection and extraction. We have selected a set of features for further analysis, which represents the elements in feature vector. By extraction method we can compute a numerical representation that can be used to characterize the audio using the existing toolbox. In this study Gain Ratio (GR) is used as a feature selection measure. GR is used to select splitting attribute which will separate the tuples into different classes. The pulse clarity is considered as a subjective measure and it is used to calculate the gain of features of audio files. The splitting criterion is employed in the application to identify the class or the music genre of a specific audio file from testing database. Experimental results indicate that by using GR the application can produce a satisfactory result for music genre classification. After dimensionality reduction best three features have been selected out of various features of audio file and in this technique we will get more than 90% successful classification result.</abstract>
   </article>
   <article>
      <title>Gradient-based Laplacian Feature Selection</title>
      <author>Bo Wang, Anna Goldenberg</author>
      <date>2014-04-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Analysis of high dimensional noisy data is of essence across a variety of research fields. Feature selection techniques are designed to find the relevant feature subset that can facilitate classification or pattern detection. Traditional (supervised) feature selection methods utilize label information to guide the identification of relevant feature subsets. In this paper, however, we consider the unsupervised feature selection problem. Without the label information, it is particularly difficult to identify a small set of relevant features due to the noisy nature of real-world data which corrupts the intrinsic structure of the data. Our Gradient-based Laplacian Feature Selection (GLFS) selects important features by minimizing the variance of the Laplacian regularized least squares regression model. With $\ell_1$ relaxation, GLFS can find a sparse subset of features that is relevant to the Laplacian manifolds. Extensive experiments on simulated, three real-world object recognition and two computational biology datasets, have illustrated the power and superior performance of our approach over multiple state-of-the-art unsupervised feature selection methods. Additionally, we show that GLFS selects a sparser set of more relevant features in a supervised setting outperforming the popular elastic net methodology.</abstract>
   </article>
   <article>
      <title>Pareto-Path Multi-Task Multiple Kernel Learning</title>
      <author>Cong Li, Michael Georgiopoulos, Georgios C. Anagnostopoulos</author>
      <date>2014-04-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A traditional and intuitively appealing Multi-Task Multiple Kernel Learning (MT-MKL) method is to optimize the sum (thus, the average) of objective functions with (partially) shared kernel function, which allows information sharing amongst tasks. We point out that the obtained solution corresponds to a single point on the Pareto Front (PF) of a Multi-Objective Optimization (MOO) problem, which considers the concurrent optimization of all task objectives involved in the Multi-Task Learning (MTL) problem. Motivated by this last observation and arguing that the former approach is heuristic, we propose a novel Support Vector Machine (SVM) MT-MKL framework, that considers an implicitly-defined set of conic combinations of task objectives. We show that solving our framework produces solutions along a path on the aforementioned PF and that it subsumes the optimization of the average of objective functions as a special case. Using algorithms we derived, we demonstrate through a series of experimental results that the framework is capable of achieving better classification performance, when compared to other similar MTL approaches.</abstract>
   </article>
   <article>
      <title>Discovering and Exploiting Entailment Relationships in Multi-Label
  Learning</title>
      <author>Christina Papagiannopoulou, Grigorios Tsoumakas, Ioannis Tsamardinos</author>
      <date>2014-04-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work presents a sound probabilistic method for enforcing adherence of the marginal probabilities of a multi-label model to automatically discovered deterministic relationships among labels. In particular we focus on discovering two kinds of relationships among the labels. The first one concerns pairwise positive entailement: pairs of labels, where the presence of one implies the presence of the other in all instances of a dataset. The second concerns exclusion: sets of labels that do not coexist in the same instances of the dataset. These relationships are represented with a Bayesian network. Marginal probabilities are entered as soft evidence in the network and adjusted through probabilistic inference. Our approach offers robust improvements in mean average precision compared to the standard binary relavance approach across all 12 datasets involved in our experiments. The discovery process helps interesting implicit knowledge to emerge, which could be useful in itself.</abstract>
   </article>
   <article>
      <title>Ensemble Classifiers and Their Applications: A Review</title>
      <author>Akhlaqur Rahman, Sumaira Tasnim</author>
      <date>2014-04-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Ensemble classifier refers to a group of individual classifiers that are cooperatively trained on data set in a supervised classification problem. In this paper we present a review of commonly used ensemble classifiers in the literature. Some ensemble classifiers are also developed targeting specific applications. We also present some application driven ensemble classifiers in this paper.</abstract>
   </article>
   <article>
      <title>Representation as a Service</title>
      <author>Ouais Alsharif, Philip Bachman, Joelle Pineau</author>
      <date>2014-02-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Consider a Machine Learning Service Provider (MLSP) designed to rapidly create highly accurate learners for a never-ending stream of new tasks. The challenge is to produce task-specific learners that can be trained from few labeled samples, even if tasks are not uniquely identified, and the number of tasks and input dimensionality are large. In this paper, we argue that the MLSP should exploit knowledge from previous tasks to build a good representation of the environment it is in, and more precisely, that useful representations for such a service are ones that minimize generalization error for a new hypothesis trained on a new task. We formalize this intuition with a novel method that minimizes an empirical proxy of the intra-task small-sample generalization error. We present several empirical results showing state-of-the art performance on single-task transfer, multitask learning, and the full lifelong learning problem.</abstract>
   </article>
   <article>
      <title>Structured Stochastic Variational Inference</title>
      <author>Matthew D. Hoffman, David M. Blei</author>
      <date>2014-04-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic variational inference makes it possible to approximate posterior distributions induced by large datasets quickly using stochastic optimization. The algorithm relies on the use of fully factorized variational distributions. However, this "mean-field" independence approximation limits the fidelity of the posterior approximation, and introduces local optima. We show how to relax the mean-field approximation to allow arbitrary dependencies between global parameters and local hidden variables, producing better parameter estimates by reducing bias, sensitivity to local optima, and sensitivity to hyperparameters.</abstract>
   </article>
   <article>
      <title>Dropout Training for Support Vector Machines</title>
      <author>Ning Chen, Jun Zhu, Jianfei Chen, Bo Zhang</author>
      <date>2014-04-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Dropout and other feature noising schemes have shown promising results in controlling over-fitting by artificially corrupting the training data. Though extensive theoretical and empirical studies have been performed for generalized linear models, little work has been done for <term>support vector machine</term>s (SVMs), one of the most successful approaches for supervised learning. This paper presents dropout training for linear SVMs. To deal with the intractable expectation of the non-smooth hinge loss under corrupting distributions, we develop an iteratively re-weighted least square (IRLS) algorithm by exploring data augmentation techniques. Our algorithm iteratively minimizes the expectation of a re-weighted least square problem, where the re-weights have closed-form solutions. The similar ideas are applied to develop a new IRLS algorithm for the expected logistic loss under corrupting distributions. Our algorithms offer insights on the connection and difference between the hinge loss and logistic loss in dropout training. Empirical results on several real datasets demonstrate the effectiveness of dropout training on significantly boosting the classification accuracy of linear SVMs.</abstract>
   </article>
   <article>
      <title>Agent Behavior Prediction and Its Generalization Analysis</title>
      <author>Fei Tian, Haifang Li, Wei Chen, Tao Qin, Enhong Chen, Tie-Yan Liu</author>
      <date>2014-04-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Machine learning algorithms have been applied to predict agent behaviors in real-world dynamic systems, such as advertiser behaviors in sponsored search and worker behaviors in crowdsourcing. The behavior data in these systems are generated by live agents: once the systems change due to the adoption of the prediction models learnt from the behavior data, agents will observe and respond to these changes by changing their own behaviors accordingly. As a result, the behavior data will evolve and will not be identically and independently distributed, posing great challenges to the theoretical analysis on the machine learning algorithms for behavior prediction. To tackle this challenge, in this paper, we propose to use Markov Chain in Random Environments (MCRE) to describe the behavior data, and perform generalization analysis of the machine learning algorithms on its basis. Since the one-step transition probability matrix of MCRE depends on both previous states and the random environment, conventional techniques for generalization analysis cannot be directly applied. To address this issue, we propose a novel technique that transforms the original MCRE into a higher-dimensional time-homogeneous Markov chain. The new Markov chain involves more variables but is more regular, and thus easier to deal with. We prove the convergence of the new Markov chain when time approaches infinity. Then we prove a generalization bound for the machine learning algorithms on the behavior data generated by the new Markov chain, which depends on both the Markovian parameters and the covering number of the function class compounded by the loss function for behavior prediction and the behavior prediction model. To the best of our knowledge, this is the first work that performs the generalization analysis on data generated by complex processes in real-world dynamic systems.</abstract>
   </article>
   <article>
      <title>Multi-Target Regression via Random Linear Target Combinations</title>
      <author>Grigorios Tsoumakas, Eleftherios Spyromitros-Xioufis, Aikaterini Vrekou, Ioannis Vlahavas</author>
      <date>2014-04-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multi-target regression is concerned with the simultaneous prediction of multiple continuous target variables based on the same set of input variables. It arises in several interesting industrial and environmental application domains, such as ecological modelling and energy forecasting. This paper presents an ensemble method for multi-target regression that constructs new target variables via random linear combinations of existing targets. We discuss the connection of our approach with multi-label classification algorithms, in particular RA$k$EL, which originally inspired this work, and a family of recent multi-label classification algorithms that involve output coding. Experimental results on 12 multi-target datasets show that it performs significantly better than a strong baseline that learns a single model for each target using gradient boosting and compares favourably to multi-objective <term>random forest</term> approach, which is a state-of-the-art approach. The experiments further show that our approach improves more when stronger unconditional dependencies exist among the targets.</abstract>
   </article>
   <article>
      <title>Coactive Learning for Locally Optimal Problem Solving</title>
      <author>Robby Goetschalckx, Alan Fern, Prasad Tadepalli</author>
      <date>2014-04-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Coactive learning is an online problem solving setting where the solutions provided by a solver are interactively improved by a domain expert, which in turn drives learning. In this paper we extend the study of coactive learning to problems where obtaining a globally optimal or near-optimal solution may be intractable or where an expert can only be expected to make small, local improvements to a candidate solution. The goal of learning in this new setting is to minimize the cost as measured by the expert effort over time. We first establish theoretical bounds on the average cost of the existing coactive Perceptron algorithm. In addition, we consider new online algorithms that use cost-sensitive and Passive-Aggressive (PA) updates, showing similar or improved theoretical bounds. We provide an empirical evaluation of the learners in various domains, which show that the Perceptron based algorithms are quite effective and that unlike the case for online classification, the PA algorithms do not yield significant performance gains.</abstract>
   </article>
   <article>
      <title>Overlapping Trace Norms in Multi-View Learning</title>
      <author>Behrouz Behmardi, Cedric Archambeau, Guillaume Bouchard</author>
      <date>2014-04-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multi-view learning leverages correlations between different sources of data to make predictions in one view based on observations in another view. A popular approach is to assume that, both, the correlations between the views and the view-specific covariances have a low-rank structure, leading to inter-battery factor analysis, a model closely related to canonical correlation analysis. We propose a convex relaxation of this model using structured norm regularization. Further, we extend the convex formulation to a robust version by adding an l1-penalized matrix to our estimator, similarly to convex robust PCA. We develop and compare scalable algorithms for several convex multi-view models. We show experimentally that the view-specific correlations are improving data imputation performances, as well as labeling accuracy in real-world multi-label prediction tasks.</abstract>
   </article>
   <article>
      <title>Multitask Learning for Sequence Labeling Tasks</title>
      <author>Arvind Agarwal, Saurabh Kataria</author>
      <date>2014-04-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we present a learning method for sequence labeling tasks in which each example sequence has multiple label sequences. Our method learns multiple models, one model for each label sequence. Each model computes the joint probability of all label sequences given the example sequence. Although each model considers all label sequences, its primary focus is only one label sequence, and therefore, each model becomes a task-specific model, for the task belonging to that primary label. Such multiple models are learned {\it simultaneously} by facilitating the learning transfer among models through {\it explicit parameter sharing}. We experiment the proposed method on two applications and show that our method significantly outperforms the state-of-the-art method.</abstract>
   </article>
   <article>
      <title>A Comparison of First-order Algorithms for Machine Learning</title>
      <author>Yu Wei, Pock Thomas</author>
      <date>2014-04-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Using an optimization algorithm to solve a machine learning problem is one of mainstreams in the field of science. In this work, we demonstrate a comprehensive comparison of some state-of-the-art first-order optimization algorithms for convex optimization problems in machine learning. We concentrate on several smooth and non-smooth machine learning problems with a loss function plus a regularizer. The overall experimental results show the superiority of primal-dual algorithms in solving a machine learning problem from the perspectives of the ease to construct, running time and accuracy.</abstract>
   </article>
   <article>
      <title>Fast Approximation of Rotations and Hessians matrices</title>
      <author>Michael Mathieu, Yann LeCun</author>
      <date>2014-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A new method to represent and approximate rotation matrices is introduced. The method represents approximations of a rotation matrix $Q$ with linearithmic complexity, i.e. with $\frac{1}{2}n\lg(n)$ rotations over pairs of coordinates, arranged in an FFT-like fashion. The approximation is "learned" using <term>gradient descent</term>. It allows to represent symmetric matrices $H$ as $QDQ^T$ where $D$ is a diagonal matrix. It can be used to approximate covariance matrix of Gaussian models in order to speed up inference, or to estimate and track the inverse Hessian of an objective function by relating changes in parameters to changes in gradient along the trajectory followed by the optimization procedure. Experiments were conducted to approximate synthetic matrices, covariance matrices of real data, and Hessian matrices of objective functions involved in machine learning problems.</abstract>
   </article>
   <article>
      <title>Meteorological time series forecasting based on MLP modelling using
  heterogeneous transfer functions</title>
      <author>Cyril Voyant, Marie Laure Nivet, Christophe Paoli, Marc Muselli, Gilles Notton</author>
      <date>2014-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose to study four meteorological and seasonal time series coupled with a multi-layer perceptron (MLP) modeling. We chose to combine two transfer functions for the nodes of the hidden layer, and to use a temporal indicator (time index as input) in order to take into account the seasonal aspect of the studied time series. The results of the prediction concern two years of measurements and the learning step, eight independent years. We show that this methodology can improve the accuracy of meteorological data estimation compared to a classical MLP modelling with a homogenous transfer function.</abstract>
   </article>
   <article>
      <title>Implementing spectral methods for hidden Markov models with real-valued
  emissions</title>
      <author>Carl Mattfeld</author>
      <date>2014-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Hidden Markov models (HMMs) are widely used statistical models for modeling sequential data. The parameter estimation for HMMs from time series data is an important learning problem. The predominant methods for parameter estimation are based on local search heuristics, most notably the expectation-maximization (EM) algorithm. These methods are prone to local optima and oftentimes suffer from high computational and sample complexity. Recent years saw the emergence of spectral methods for the parameter estimation of HMMs, based on a method of moments approach. Two spectral learning algorithms as proposed by Hsu, Kakade and Zhang 2012 (arXiv:0811.4413) and Anandkumar, Hsu and Kakade 2012 (arXiv:1203.0683) are assessed in this work. Using experiments with synthetic data, the algorithms are compared with each other. Furthermore, the spectral methods are compared to the Baum-Welch algorithm, a well-established method applying the EM algorithm to HMMs. The spectral algorithms are found to have a much more favorable computational and sample complexity. Even though the algorithms readily handle high dimensional observation spaces, instability issues are encountered in this regime. In view of learning from real-world experimental data, the representation of real-valued observations for the use in spectral methods is discussed, presenting possible methods to represent data for the use in the learning algorithms.</abstract>
   </article>
   <article>
      <title>A Map of Update Constraints in Inductive Inference</title>
      <author>Timo Kötzing, Raphaela Palenta</author>
      <date>2014-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We investigate how different learning restrictions reduce learning power and how the different restrictions relate to one another. We give a complete map for nine different restrictions both for the cases of complete information learning and set-driven learning. This completes the picture for these well-studied \emph{delayable} learning restrictions. A further insight is gained by different characterizations of \emph{conservative} learning in terms of variants of \emph{cautious} learning.   Our analyses greatly benefit from general theorems we give, for example showing that learners with exclusively delayable restrictions can always be assumed total.</abstract>
   </article>
   <article>
      <title>On Exact Learning Monotone DNF from Membership Queries</title>
      <author>Hasan Abasi, Nader H. Bshouty, Hanna Mazzawi</author>
      <date>2014-05-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we study the problem of learning a monotone DNF with at most $s$ terms of size (number of variables in each term) at most $r$ ($s$ term $r$-MDNF) from membership queries. This problem is equivalent to the problem of learning a general hypergraph using hyperedge-detecting queries, a problem motivated by applications arising in chemical reactions and genome sequencing.   We first present new lower bounds for this problem and then present deterministic and randomized adaptive algorithms with query complexities that are almost optimal. All the algorithms we present in this paper run in time linear in the query complexity and the number of variables $n$. In addition, all of the algorithms we present in this paper are asymptotically tight for fixed $r$ and/or $s$.</abstract>
   </article>
   <article>
      <title>Adaptation Algorithm and Theory Based on Generalized Discrepancy</title>
      <author>Corinna Cortes, Mehryar Mohri, Andres Muñoz Medina</author>
      <date>2014-05-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a new algorithm for domain adaptation improving upon a discrepancy minimization algorithm previously shown to outperform a number of algorithms for this task. Unlike many previous algorithms for domain adaptation, our algorithm does not consist of a fixed reweighting of the losses over the training sample. We show that our algorithm benefits from a solid theoretical foundation and more favorable learning bounds than discrepancy minimization. We present a detailed description of our algorithm and give several efficient solutions for solving its optimization problem. We also report the results of several experiments showing that it outperforms discrepancy minimization.</abstract>
   </article>
   <article>
      <title>Learning Boolean Halfspaces with Small Weights from Membership Queries</title>
      <author>Hasan Abasi, Ali Z. Abdi, Nader H. Bshouty</author>
      <date>2014-05-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of proper learning a Boolean Halfspace with integer weights $\{0,1,\ldots,t\}$ from membership queries only. The best known algorithm for this problem is an adaptive algorithm that asks $n^{O(t^5)}$ membership queries where the best lower bound for the number of membership queries is $n^t$ [Learning Threshold Functions with Small Weights Using Membership Queries. COLT 1999]   In this paper we close this gap and give an adaptive proper learning algorithm with two rounds that asks $n^{O(t)}$ membership queries. We also give a non-adaptive proper learning algorithm that asks $n^{O(t^3)}$ membership queries.</abstract>
   </article>
   <article>
      <title>Optimal Learners for Multiclass Problems</title>
      <author>Amit Daniely, Shai Shalev-Shwartz</author>
      <date>2014-05-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The fundamental theorem of statistical learning states that for binary classification problems, any Empirical Risk Minimization (ERM) learning rule has close to optimal sample complexity. In this paper we seek for a generic optimal learner for multiclass prediction. We start by proving a surprising result: a generic optimal multiclass learner must be improper, namely, it must have the ability to output hypotheses which do not belong to the hypothesis class, even though it knows that all the labels are generated by some hypothesis from the class. In particular, no ERM learner is optimal. This brings back the fundmamental question of "how to learn"? We give a complete answer to this question by giving a new analysis of the one-inclusion multiclass learner of Rubinstein et al (2006) showing that its sample complexity is essentially optimal. Then, we turn to study the popular hypothesis class of generalized linear classifiers. We derive optimal learners that, unlike the one-inclusion algorithm, are computationally efficient. Furthermore, we show that the sample complexity of these learners is better than the sample complexity of the ERM rule, thus settling in negative an open question due to Collins (2005).</abstract>
   </article>
   <article>
      <title>A Canonical Semi-Deterministic Transducer</title>
      <author>Achilles Beros, Colin de la Higuera</author>
      <date>2014-05-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We prove the existence of a canonical form for semi-deterministic transducers with incomparable sets of output strings. Based on this, we develop an algorithm which learns semi-deterministic transducers given access to translation queries. We also prove that there is no learning algorithm for semi-deterministic transducers that uses only domain knowledge.</abstract>
   </article>
   <article>
      <title>Selecting Near-Optimal Approximate State Representations in
  Reinforcement Learning</title>
      <author>Ronald Ortner, Odalric-Ambrym Maillard, Daniil Ryabko</author>
      <date>2014-05-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a <term>reinforcement learning</term> setting introduced in (Maillard et al., NIPS 2011) where the learner does not have explicit access to the states of the underlying Markov decision process (MDP). Instead, she has access to several models that map histories of past interactions to states. Here we improve over known regret bounds in this setting, and more importantly generalize to the case where the models given to the learner do not contain a true model resulting in an MDP representation but only approximations of it. We also give improved error bounds for state aggregation.</abstract>
   </article>
   <article>
      <title>Clustering, Hamming Embedding, Generalized LSH and the Max Norm</title>
      <author>Behnam Neyshabur, Yury Makarychev, Nathan Srebro</author>
      <date>2014-05-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the convex relaxation of clustering and hamming embedding, focusing on the asymmetric case (co-clustering and asymmetric hamming embedding), understanding their relationship to LSH as studied by (Charikar 2002) and to the max-norm ball, and the differences between their symmetric and asymmetric versions.</abstract>
   </article>
   <article>
      <title>Reducing Dueling Bandits to Cardinal Bandits</title>
      <author>Nir Ailon, Thorsten Joachims, Zohar Karnin</author>
      <date>2014-05-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present algorithms for reducing the Dueling Bandits problem to the conventional (stochastic) Multi-Armed Bandits problem. The Dueling Bandits problem is an online model of learning with ordinal feedback of the form "A is preferred to B" (as opposed to cardinal feedback like "A has value 2.5"), giving it wide applicability in learning from implicit user feedback and revealed and stated preferences. In contrast to existing algorithms for the Dueling Bandits problem, our reductions -- named $\Doubler$, $\MultiSbm$ and $\DoubleSbm$ -- provide a generic schema for translating the extensive body of known results about conventional Multi-Armed Bandit algorithms to the Dueling Bandits setting. For $\Doubler$ and $\MultiSbm$ we prove regret upper bounds in both finite and infinite settings, and conjecture about the performance of $\DoubleSbm$ which empirically outperforms the other two as well as previous algorithms in our experiments. In addition, we provide the first almost optimal regret bound in terms of second order terms, such as the differences between the values of the arms.</abstract>
   </article>
   <article>
      <title>Logistic Regression: Tight Bounds for Stochastic and Online Optimization</title>
      <author>Elad Hazan, Tomer Koren, Kfir Y. Levy</author>
      <date>2014-05-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The logistic loss function is often advocated in machine learning and statistics as a smooth and strictly convex surrogate for the 0-1 loss. In this paper we investigate the question of whether these smoothness and convexity properties make the logistic loss preferable to other widely considered options such as the hinge loss. We show that in contrast to known asymptotic bounds, as long as the number of prediction/optimization iterations is sub exponential, the logistic loss provides no improvement over a generic non-smooth loss function such as the hinge loss. In particular we show that the convergence rate of stochastic logistic optimization is bounded from below by a polynomial in the diameter of the decision set and the number of prediction iterations, and provide a matching tight upper bound. This resolves the COLT open problem of McMahan and Streeter (2012).</abstract>
   </article>
   <article>
      <title>A two-step learning approach for solving full and almost full cold start
  problems in dyadic prediction</title>
      <author>Tapio Pahikkala, Michiel Stock, Antti Airola, Tero Aittokallio, Bernard De Baets, Willem Waegeman</author>
      <date>2014-05-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Dyadic prediction methods operate on pairs of objects (dyads), aiming to infer labels for out-of-sample dyads. We consider the full and almost full cold start problem in dyadic prediction, a setting that occurs when both objects in an out-of-sample dyad have not been observed during training, or if one of them has been observed, but very few times. A popular approach for addressing this problem is to train a model that makes predictions based on a pairwise feature representation of the dyads, or, in case of kernel methods, based on a tensor product pairwise kernel. As an alternative to such a kernel approach, we introduce a novel two-step learning algorithm that borrows ideas from the fields of pairwise learning and spectral filtering. We show theoretically that the two-step method is very closely related to the tensor product kernel approach, and experimentally that it yields a slightly better predictive performance. Moreover, unlike existing tensor product kernel methods, the two-step method allows closed-form solutions for training and parameter selection via cross-validation estimates both in the full and almost full cold start settings, making the approach much more efficient and straightforward to implement.</abstract>
   </article>
   <article>
      <title>Online Learning with Composite Loss Functions</title>
      <author>Ofer Dekel, Jian Ding, Tomer Koren, Yuval Peres</author>
      <date>2014-05-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study a new class of online learning problems where each of the online algorithm's actions is assigned an adversarial value, and the loss of the algorithm at each step is a known and deterministic function of the values assigned to its recent actions. This class includes problems where the algorithm's loss is the minimum over the recent adversarial values, the maximum over the recent values, or a linear combination of the recent values. We analyze the minimax regret of this class of problems when the algorithm receives bandit feedback, and prove that when the minimum or maximum functions are used, the minimax regret is $\tilde \Omega(T^{2/3})$ (so called hard online learning problems), and when a linear function is used, the minimax regret is $\tilde O(\sqrt{T})$ (so called easy learning problems). Previously, the only online learning problem that was known to be provably hard was the multi-armed bandit with switching costs.</abstract>
   </article>
   <article>
      <title>A Distributed Algorithm for Training Nonlinear Kernel Machines</title>
      <author>Dhruv Mahajan, S. Sathiya Keerthi, S. Sundararajan</author>
      <date>2014-05-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper concerns the distributed training of nonlinear kernel machines on Map-Reduce. We show that a re-formulation of Nystr\"om approximation based solution which is solved using gradient based techniques is well suited for this, especially when it is necessary to work with a large number of basis points. The main advantages of this approach are: avoidance of computing the pseudo-inverse of the kernel sub-matrix corresponding to the basis points; simplicity and efficiency of the distributed part of the computations; and, friendliness to stage-wise addition of basis points. We implement the method using an AllReduce tree on Hadoop and demonstrate its value on a few large benchmark datasets.</abstract>
   </article>
   <article>
      <title>A distributed block coordinate descent method for training $l_1$
  regularized linear classifiers</title>
      <author>Dhruv Mahajan, S. Sathiya Keerthi, S. Sundararajan</author>
      <date>2014-05-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Distributed training of $l_1$ regularized classifiers has received great attention recently. Most existing methods approach this problem by taking steps obtained from approximating the objective by a quadratic approximation that is decoupled at the individual variable level. These methods are designed for multicore and MPI platforms where communication costs are low. They are inefficient on systems such as Hadoop running on a cluster of commodity machines where communication costs are substantial. In this paper we design a distributed algorithm for $l_1$ regularization that is much better suited for such systems than existing algorithms. A careful cost analysis is used to support these points and motivate our method. The main idea of our algorithm is to do block optimization of many variables on the actual objective function within each computing node; this increases the computational cost per step that is matched with the communication cost, and decreases the number of outer iterations, thus yielding a faster overall method. Distributed Gauss-Seidel and Gauss-Southwell greedy schemes are used for choosing variables to update in each step. We establish global convergence theory for our algorithm, including Q-linear rate of convergence. Experiments on two benchmark problems show our method to be much faster than existing methods.</abstract>
   </article>
   <article>
      <title>Lipschitz Bandits: Regret Lower Bounds and Optimal Algorithms</title>
      <author>Stefan Magureanu, Richard Combes, Alexandre Proutiere</author>
      <date>2014-05-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider stochastic multi-armed bandit problems where the expected reward is a Lipschitz function of the arm, and where the set of arms is either discrete or continuous. For discrete Lipschitz bandits, we derive asymptotic problem specific lower bounds for the regret satisfied by any algorithm, and propose OSLB and CKL-UCB, two algorithms that efficiently exploit the Lipschitz structure of the problem. In fact, we prove that OSLB is asymptotically optimal, as its asymptotic regret matches the lower bound. The regret analysis of our algorithms relies on a new concentration inequality for weighted sums of KL divergences between the empirical distributions of rewards and their true distributions. For continuous Lipschitz bandits, we propose to first discretize the action space, and then apply OSLB or CKL-UCB, algorithms that provably exploit the structure efficiently. This approach is shown, through numerical experiments, to significantly outperform existing algorithms that directly deal with the continuous set of arms. Finally the results and algorithms are extended to contextual bandits with similarities.</abstract>
   </article>
   <article>
      <title>Online Linear Optimization via Smoothing</title>
      <author>Jacob Abernethy, Chansoo Lee, Abhinav Sinha, Ambuj Tewari</author>
      <date>2014-05-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a new optimization-theoretic approach to analyzing Follow-the-Leader style algorithms, particularly in the setting where perturbations are used as a tool for regularization. We show that adding a strongly convex penalty function to the decision rule and adding stochastic perturbations to data correspond to deterministic and stochastic smoothing operations, respectively. We establish an equivalence between "Follow the Regularized Leader" and "Follow the Perturbed Leader" up to the smoothness properties. This intuition leads to a new generic analysis framework that recovers and improves the previous known regret bounds of the class of algorithms commonly known as Follow the Perturbed Leader.</abstract>
   </article>
   <article>
      <title>Visualizing Random Forest with Self-Organising Map</title>
      <author>Piotr Płoński, Krzysztof Zaremba</author>
      <date>2014-05-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Random Forest (RF) is a powerful ensemble method for classification and regression tasks. It consists of decision trees set. Although, a single tree is well interpretable for human, the ensemble of trees is a black-box model. The popular technique to look inside the RF model is to visualize a RF proximity matrix obtained on data samples with Multidimensional Scaling (MDS) method. Herein, we present a novel method based on Self-Organising Maps (SOM) for revealing intrinsic relationships in data that lay inside the RF used for classification tasks. We propose an algorithm to learn the SOM with the proximity matrix obtained from the RF. The visualization of RF proximity matrix with MDS and SOM is compared. What is more, the SOM learned with the RF proximity matrix has better classification accuracy in comparison to SOM learned with Euclidean distance. Presented approach enables better understanding of the RF and additionally improves accuracy of the SOM.</abstract>
   </article>
   <article>
      <title>Proximal Reinforcement Learning: A New Theory of Sequential Decision
  Making in Primal-Dual Spaces</title>
      <author>Sridhar Mahadevan, Bo Liu, Philip Thomas, Will Dabney, Steve Giguere, Nicholas Jacek, Ian Gemp, Ji Liu</author>
      <date>2014-05-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we set forth a new vision of <term>reinforcement learning</term> developed by us over the past few years, one that yields mathematically rigorous solutions to longstanding important questions that have remained unresolved: (i) how to design reliable, convergent, and robust <term>reinforcement learning</term> algorithms (ii) how to guarantee that <term>reinforcement learning</term> satisfies pre-specified "safety" guarantees, and remains in a stable region of the parameter space (iii) how to design "off-policy" temporal difference learning algorithms in a reliable and stable manner, and finally (iv) how to integrate the study of <term>reinforcement learning</term> into the rich theory of stochastic optimization. In this paper, we provide detailed answers to all these questions using the powerful framework of proximal operators.   The key idea that emerges is the use of primal dual spaces connected through the use of a Legendre transform. This allows temporal difference updates to occur in dual spaces, allowing a variety of important technical advantages. The Legendre transform elegantly generalizes past algorithms for solving <term>reinforcement learning</term> problems, such as natural gradient methods, which we show relate closely to the previously unconnected framework of mirror descent methods. Equally importantly, proximal operator theory enables the systematic development of operator splitting methods that show how to safely and reliably decompose complex products of gradients that occur in recent variants of gradient-based temporal difference learning. This key technical innovation makes it possible to finally design "true" stochastic gradient methods for <term>reinforcement learning</term>. Finally, Legendre transforms enable a variety of other benefits, including modeling sparsity and domain geometry. Our work builds extensively on recent work on the convergence of saddle-point algorithms, and on the theory of monotone operators.</abstract>
   </article>
   <article>
      <title>BayesOpt: A Bayesian Optimization Library for Nonlinear Optimization,
  Experimental Design and Bandits</title>
      <author>Ruben Martinez-Cantin</author>
      <date>2014-05-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>BayesOpt is a library with state-of-the-art Bayesian optimization methods to solve nonlinear optimization, stochastic bandits or sequential experimental design problems. Bayesian optimization is sample efficient by building a posterior distribution to capture the evidence and prior knowledge for the target function. Built in standard C++, the library is extremely efficient while being portable and flexible. It includes a common interface for C, C++, Python, Matlab and Octave.</abstract>
   </article>
   <article>
      <title>Effect of Different Distance Measures on the Performance of K-Means
  Algorithm: An Experimental Study in Matlab</title>
      <author>Mr. Dibya Jyoti Bora, Dr. Anil Kumar Gupta</author>
      <date>2014-05-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>K-means algorithm is a very popular clustering algorithm which is famous for its simplicity. Distance measure plays a very important rule on the performance of this algorithm. We have different distance measure techniques available. But choosing a proper technique for distance calculation is totally dependent on the type of the data that we are going to cluster. In this paper an experimental study is done in Matlab to cluster the iris and wine data sets with different distance measures and thereby observing the variation of the performances shown.</abstract>
   </article>
   <article>
      <title>Simultaneous Feature and Expert Selection within Mixture of Experts</title>
      <author>Billy Peralta</author>
      <date>2014-05-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A useful strategy to deal with complex classification scenarios is the "divide and conquer" approach. The mixture of experts (MOE) technique makes use of this strategy by joinly training a set of classifiers, or experts, that are specialized in different regions of the input space. A global model, or gate function, complements the experts by learning a function that weights their relevance in different parts of the input space. Local feature selection appears as an attractive alternative to improve the specialization of experts and gate function, particularly, for the case of high dimensional data. Our main intuition is that particular subsets of dimensions, or subspaces, are usually more appropriate to classify instances located in different regions of the input space. Accordingly, this work contributes with a regularized variant of MoE that incorporates an embedded process for local feature selection using $L1$ regularization, with a simultaneous expert selection. The experiments are still pending.</abstract>
   </article>
   <article>
      <title>Flip-Flop Sublinear Models for Graphs: Proof of Theorem 1</title>
      <author>Brijnesh Jain</author>
      <date>2014-05-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We prove that there is no class-dual for almost all sublinear models on graphs.</abstract>
   </article>
   <article>
      <title>Holistic Measures for Evaluating Prediction Models in Smart Grids</title>
      <author>Saima Aman, Yogesh Simmhan, Viktor K. Prasanna</author>
      <date>2014-06-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The performance of prediction models is often based on "abstract metrics" that estimate the model's ability to limit residual errors between the observed and predicted values. However, meaningful evaluation and selection of prediction models for end-user domains requires holistic and application-sensitive performance measures. Inspired by energy consumption prediction models used in the emerging "big data" domain of Smart Power Grids, we propose a suite of performance measures to rationally compare models along the dimensions of scale independence, reliability, volatility and cost. We include both application independent and dependent measures, the latter parameterized to allow customization by domain experts to fit their scenario. While our measures are generalizable to other domains, we offer an empirical analysis using real energy use data for three Smart Grid applications: planning, customer education and demand response, which are relevant for energy sustainability. Our results underscore the value of the proposed measures to offer a deeper insight into models' behavior and their impact on real applications, which benefit both data mining researchers and practitioners.</abstract>
   </article>
   <article>
      <title>Learning the Information Divergence</title>
      <author>Onur Dikmen, Zhirong Yang, Erkki Oja</author>
      <date>2014-06-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Information divergence that measures the difference between two nonnegative matrices or tensors has found its use in a variety of machine learning problems. Examples are Nonnegative Matrix/Tensor Factorization, Stochastic Neighbor Embedding, topic models, and Bayesian network optimization. The success of such a learning task depends heavily on a suitable divergence. A large variety of divergences have been suggested and analyzed, but very few results are available for an objective choice of the optimal divergence for a given task. Here we present a framework that facilitates automatic selection of the best divergence among a given family, based on standard maximum likelihood estimation. We first propose an approximated Tweedie distribution for the beta-divergence family. Selecting the best beta then becomes a machine learning problem solved by maximum likelihood. Next, we reformulate alpha-divergence in terms of beta-divergence, which enables automatic selection of alpha by maximum likelihood with reuse of the learning principle for beta-divergence. Furthermore, we show the connections between gamma and beta-divergences as well as R\'enyi and alpha-divergences, such that our automatic selection framework is extended to non-separable divergences. Experiments on both synthetic and real-world data demonstrate that our method can quite accurately select information divergence across different learning problems and various divergence families.</abstract>
   </article>
   <article>
      <title>Learning to Discover Efficient Mathematical Identities</title>
      <author>Wojciech Zaremba, Karol Kurach, Rob Fergus</author>
      <date>2014-06-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we explore how machine learning techniques can be applied to the discovery of efficient mathematical identities. We introduce an attribute grammar framework for representing symbolic expressions. Given a set of grammar rules we build trees that combine different rules, looking for branches which yield compositions that are analytically equivalent to a target expression, but of lower computational complexity. However, as the size of the trees grows exponentially with the complexity of the target expression, brute force search is impractical for all but the simplest of expressions. Consequently, we introduce two novel learning approaches that are able to learn from simpler expressions to guide the tree search. The first of these is a simple n-gram model, the other being a recursive neural-network. We show how these approaches enable us to derive complex identities, beyond reach of brute-force search, or human derivation.</abstract>
   </article>
   <article>
      <title>Logarithmic Time Online Multiclass prediction</title>
      <author>Anna Choromanska, John Langford</author>
      <date>2014-06-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the problem of multiclass classification with an extremely large number of classes (k), with the goal of obtaining train and test time complexity logarithmic in the number of classes. We develop top-down tree construction approaches for constructing logarithmic depth trees. On the theoretical front, we formulate a new objective function, which is optimized at each node of the tree and creates dynamic partitions of the data which are both pure (in terms of class labels) and balanced. We demonstrate that under favorable conditions, we can construct logarithmic depth trees that have leaves with low label entropy. However, the objective function at the nodes is challenging to optimize computationally. We address the empirical problem with a new online decision tree construction procedure. Experiments demonstrate that this online algorithm quickly achieves improvement in test error compared to more common logarithmic training time approaches, which makes it a plausible method in computationally constrained large-k applications.</abstract>
   </article>
   <article>
      <title>A Credit Assignment Compiler for Joint Prediction</title>
      <author>Kai-Wei Chang, He He, Hal Daumé III, John Langford, Stephane Ross</author>
      <date>2014-06-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many machine learning applications involve jointly predicting multiple mutually dependent output variables. Learning to search is a family of methods where the complex decision problem is cast into a sequence of decisions via a search space. Although these methods have shown promise both in theory and in practice, implementing them has been burdensomely awkward. In this paper, we show the search space can be defined by an arbitrary imperative program, turning learning to search into a credit assignment compiler. Altogether with the algorithmic improvements for the compiler, we radically reduce the complexity of programming and the running time. We demonstrate the feasibility of our approach on multiple joint prediction tasks. In all cases, we obtain accuracies as high as alternative approaches, at drastically reduced execution and programming time.</abstract>
   </article>
   <article>
      <title>A Drifting-Games Analysis for Online Learning and Applications to
  Boosting</title>
      <author>Haipeng Luo, Robert E. Schapire</author>
      <date>2014-06-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We provide a general mechanism to design online learning algorithms based on a minimax analysis within a drifting-games framework. Different online learning settings (Hedge, multi-armed bandit problems and online convex optimization) are studied by converting into various kinds of drifting games. The original minimax analysis for drifting games is then used and generalized by applying a series of relaxations, starting from choosing a convex surrogate of the 0-1 loss function. With different choices of surrogates, we not only recover existing algorithms, but also propose new algorithms that are totally parameter-free and enjoy other useful properties. Moreover, our drifting-games framework naturally allows us to study high probability bounds without resorting to any concentration results, and also a generalized notion of regret that measures how good the algorithm is compared to all but the top small fraction of candidates. Finally, we translate our new Hedge algorithm into a new adaptive boosting algorithm that is computationally faster as shown in experiments, since it ignores a large number of examples on each round.</abstract>
   </article>
   <article>
      <title>Reweighted Wake-Sleep</title>
      <author>Jörg Bornschein, Yoshua Bengio</author>
      <date>2014-06-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Training deep directed graphical models with many hidden variables and performing inference remains a major challenge. Helmholtz machines and deep belief networks are such models, and the wake-sleep algorithm has been proposed to train them. The wake-sleep algorithm relies on training not just the directed generative model but also a conditional generative model (the inference network) that runs backward from visible to latent, estimating the posterior distribution of latent given visible. We propose a novel interpretation of the wake-sleep algorithm which suggests that better estimators of the gradient can be obtained by sampling latent variables multiple times from the inference network. This view is based on importance sampling as an estimator of the likelihood, with the approximate inference network as a proposal distribution. This interpretation is confirmed experimentally, showing that better likelihood can be achieved with this reweighted wake-sleep procedure. Based on this interpretation, we propose that a sigmoidal belief network is not sufficiently powerful for the layers of the inference network in order to recover a good estimator of the posterior distribution of latent variables. Our experiments show that using a more powerful layer model, such as NADE, yields substantially better generative models.</abstract>
   </article>
   <article>
      <title>Kalman Temporal Differences</title>
      <author>Matthieu Geist, Olivier Pietquin</author>
      <date>2014-01-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Because <term>reinforcement learning</term> suffers from a lack of scalability, online value (and Q-) function approximation has received increasing interest this last decade. This contribution introduces a novel approximation scheme, namely the Kalman Temporal Differences (KTD) framework, that exhibits the following features: sample-efficiency, non-linear approximation, non-stationarity handling and uncertainty management. A first KTD-based algorithm is provided for deterministic Markov Decision Processes (MDP) which produces biased estimates in the case of stochastic transitions. Than the eXtended KTD framework (XKTD), solving stochastic MDP, is described. Convergence is analyzed for special cases for both deterministic and stochastic transitions. Related algorithms are experimented on classical benchmarks. They compare favorably to the state of the art while exhibiting the announced features.</abstract>
   </article>
   <article>
      <title>Restricted Boltzmann Machine for Classification with Hierarchical
  Correlated Prior</title>
      <author>Gang Chen, Sargur H. Srihari</author>
      <date>2014-06-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Restricted Boltzmann machines (RBM) and its variants have become hot research topics recently, and widely applied to many classification problems, such as character recognition and document categorization. Often, classification RBM ignores the interclass relationship or prior knowledge of sharing information among classes. In this paper, we are interested in RBM with the hierarchical prior over classes. We assume parameters for nearby nodes are correlated in the hierarchical tree, and further the parameters at each node of the tree be orthogonal to those at its ancestors. We propose a hierarchical correlated RBM for classification problem, which generalizes the classification RBM with sharing information among different classes. In order to reduce the redundancy between node parameters in the hierarchy, we also introduce orthogonal restrictions to our objective function. We test our method on challenge datasets, and show promising results compared to competitive baselines.</abstract>
   </article>
   <article>
      <title>Evaluation of Machine Learning Techniques for Green Energy Prediction</title>
      <author>Ankur Sahai</author>
      <date>2014-06-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We evaluate the following Machine Learning techniques for Green Energy (Wind, Solar) Prediction: Bayesian Inference, Neural Networks, Support Vector Machines, Clustering techniques (PCA). Our objective is to predict green energy using weather forecasts, predict deviations from forecast green energy, find correlation amongst different weather parameters and green energy availability, recover lost or missing energy (/ weather) data. We use historical weather data and weather forecasts for the same.</abstract>
   </article>
   <article>
      <title>Optimal Resource Allocation with Semi-Bandit Feedback</title>
      <author>Tor Lattimore, Koby Crammer, Csaba Szepesvári</author>
      <date>2014-06-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study a sequential resource allocation problem involving a fixed number of recurring jobs. At each time-step the manager should distribute available resources among the jobs in order to maximise the expected number of completed jobs. Allocating more resources to a given job increases the probability that it completes, but with a cut-off. Specifically, we assume a linear model where the probability increases linearly until it equals one, after which allocating additional resources is wasteful. We assume the difficulty of each job is unknown and present the first algorithm for this problem and prove upper and lower bounds on its regret. Despite its apparent simplicity, the problem has a rich structure: we show that an appropriate optimistic algorithm can improve its learning speed dramatically beyond the results one normally expects for similar problems as the problem becomes resource-laden.</abstract>
   </article>
   <article>
      <title>A Sober Look at Spectral Learning</title>
      <author>Han Zhao, Pascal Poupart</author>
      <date>2014-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Spectral learning recently generated lots of excitement in machine learning, largely because it is the first known method to produce consistent estimates (under suitable conditions) for several latent variable models. In contrast, maximum likelihood estimates may get trapped in local optima due to the non-convex nature of the likelihood function of latent variable models. In this paper, we do an empirical evaluation of spectral learning (SL) and expectation maximization (EM), which reveals an important gap between the theory and the practice. First, SL often leads to negative probabilities. Second, EM often yields better estimates than spectral learning and it does not seem to get stuck in local optima. We discuss how the rank of the model parameters and the amount of training data can yield negative probabilities. We also question the common belief that maximum likelihood estimators are necessarily inconsistent.</abstract>
   </article>
   <article>
      <title>An Experimental Evaluation of Nearest Neighbour Time Series
  Classification</title>
      <author>Anthony Bagnall, Jason Lines</author>
      <date>2014-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Data mining research into time series classification (TSC) has focussed on alternative distance measures for nearest neighbour classifiers. It is standard practice to use 1-NN with Euclidean or dynamic time warping (DTW) distance as a straw man for comparison. As part of a wider investigation into elastic distance measures for TSC~\cite{lines14elastic}, we perform a series of experiments to test whether this standard practice is valid.   Specifically, we compare 1-NN classifiers with Euclidean and DTW distance to standard classifiers, examine whether the performance of 1-NN Euclidean approaches that of 1-NN DTW as the number of cases increases, assess whether there is any benefit of setting $k$ for $k$-NN through cross validation whether it is worth setting the warping path for DTW through cross validation and finally is it better to use a window or weighting for DTW. Based on experiments on 77 problems, we conclude that 1-NN with Euclidean distance is fairly easy to beat but 1-NN with DTW is not, if window size is set through cross validation.</abstract>
   </article>
   <article>
      <title>Learning computationally efficient dictionaries and their implementation
  as fast transforms</title>
      <author>Luc Le Magoarou, Rémi Gribonval</author>
      <date>2014-06-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Dictionary learning is a branch of signal processing and machine learning that aims at finding a frame (called dictionary) in which some training data admits a sparse representation. The sparser the representation, the better the dictionary. The resulting dictionary is in general a dense matrix, and its manipulation can be computationally costly both at the learning stage and later in the usage of this dictionary, for tasks such as sparse coding. Dictionary learning is thus limited to relatively small-scale problems. In this paper, inspired by usual fast transforms, we consider a general dictionary structure that allows cheaper manipulation, and propose an algorithm to learn such dictionaries --and their fast implementation-- over training data. The approach is demonstrated experimentally with the factorization of the Hadamard matrix and with synthetic dictionary learning experiments.</abstract>
   </article>
   <article>
      <title>From conformal to probabilistic prediction</title>
      <author>Vladimir Vovk, Ivan Petej, Valentina Fedorova</author>
      <date>2014-06-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper proposes a new method of probabilistic prediction, which is based on conformal prediction. The method is applied to the standard USPS data set and gives encouraging results.</abstract>
   </article>
   <article>
      <title>SPSD Matrix Approximation vis Column Selection: Theories, Algorithms,
  and Extensions</title>
      <author>Shusen Wang, Luo Luo, Zhihua Zhang</author>
      <date>2014-06-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Symmetric positive semidefinite (SPSD) matrix approximation is an important problem with applications in kernel methods. However, existing SPSD matrix approximation methods such as the Nystr\"om method only have weak error bounds. In this paper we conduct in-depth studies of an SPSD matrix approximation model and establish strong relative-error bounds. We call it the prototype model for it has more efficient and effective extensions, and some of its extensions have high scalability. Though the prototype model itself is not suitable for large-scale data, it is still useful to study its properties, on which the analysis of its extensions relies.   This paper offers novel theoretical analysis, efficient algorithms, and a highly accurate extension. First, we establish a lower error bound for the prototype model and improve the error bound of an existing column selection algorithm to match the lower bound. In this way, we obtain the first optimal column selection algorithm for the prototype model. We also prove that the prototype model is exact under certain conditions. Second, we develop a simple column selection algorithm with a provable error bound. Third, we propose a so-called spectral shifting model to make the approximation more accurate when the eigenvalues of the matrix decay slowly, and the improvement is theoretically quantified. The spectral shifting method can also be applied to improve other SPSD matrix approximation models.</abstract>
   </article>
   <article>
      <title>Stationary Mixing Bandits</title>
      <author>Julien Audiffren, Liva Ralaivola</author>
      <date>2014-06-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the bandit problem where arms are associated with stationary phi-mixing processes and where rewards are therefore dependent: the question that arises from this setting is that of recovering some independence by ignoring the value of some rewards. As we shall see, the bandit problem we tackle requires us to address the exploration/exploitation/independence trade-off. To do so, we provide a UCB strategy together with a general regret analysis for the case where the size of the independence blocks (the ignored rewards) is fixed and we go a step beyond by providing an algorithm that is able to compute the size of the independence blocks from the data. Finally, we give an analysis of our bandit problem in the restless case, i.e., in the situation where the time counters for all mixing processes simultaneously evolve.</abstract>
   </article>
   <article>
      <title>Mining Recurrent Concepts in Data Streams using the Discrete Fourier
  Transform</title>
      <author>Sakthithasan Sripirakas, Russel Pears</author>
      <date>2014-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this research we address the problem of capturing recurring concepts in a data stream environment. Recurrence capture enables the re-use of previously learned classifiers without the need for re-learning while providing for better accuracy during the concept recurrence interval. We capture concepts by applying the Discrete Fourier Transform (DFT) to Decision Tree classifiers to obtain highly compressed versions of the trees at concept drift points in the stream and store such trees in a repository for future use. Our empirical results on real world and synthetic data exhibiting varying degrees of recurrence show that the Fourier compressed trees are more robust to noise and are able to capture recurring concepts with higher precision than a meta learning approach that chooses to re-use classifiers in their originally occurring form.</abstract>
   </article>
   <article>
      <title>Generalized Mixability via Entropic Duality</title>
      <author>Mark D. Reid, Rafael M. Frongillo, Robert C. Williamson, Nishant Mehta</author>
      <date>2014-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Mixability is a property of a loss which characterizes when fast convergence is possible in the game of prediction with expert advice. We show that a key property of mixability generalizes, and the exp and log operations present in the usual theory are not as special as one might have thought. In doing this we introduce a more general notion of $\Phi$-mixability where $\Phi$ is a general entropy (\ie, any convex function on probabilities). We show how a property shared by the convex dual of any such entropy yields a natural algorithm (the minimizer of a regret bound) which, analogous to the classical aggregating algorithm, is guaranteed a constant regret when used with $\Phi$-mixable losses. We characterize precisely which $\Phi$ have $\Phi$-mixable losses and put forward a number of conjectures about the optimality and relationships between different choices of entropy.</abstract>
   </article>
   <article>
      <title>Composite Likelihood Estimation for Restricted Boltzmann machines</title>
      <author>Muneki Yasuda, Shun Kataoka, Yuji Waizumi, Kazuyuki Tanaka</author>
      <date>2014-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Learning the parameters of graphical models using the maximum likelihood estimation is generally hard which requires an approximation. Maximum composite likelihood estimations are statistical approximations of the maximum likelihood estimation which are higher-order generalizations of the maximum pseudo-likelihood estimation. In this paper, we propose a composite likelihood method and investigate its property. Furthermore, we apply our composite likelihood method to restricted Boltzmann machines.</abstract>
   </article>
   <article>
      <title>Incremental Clustering: The Case for Extra Clusters</title>
      <author>Margareta Ackerman, Sanjoy Dasgupta</author>
      <date>2014-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The explosion in the amount of data available for analysis often necessitates a transition from batch to incremental clustering methods, which process one element at a time and typically store only a small subset of the data. In this paper, we initiate the formal analysis of incremental clustering methods focusing on the types of cluster structure that they are able to detect. We find that the incremental setting is strictly weaker than the batch model, proving that a fundamental class of cluster structures that can readily be detected in the batch setting is impossible to identify using any incremental method. Furthermore, we show how the limitations of incremental clustering can be overcome by allowing additional clusters.</abstract>
   </article>
   <article>
      <title>Comparison of SVM Optimization Techniques in the Primal</title>
      <author>Jonathan Katzman, Diane Duros</author>
      <date>2014-06-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper examines the efficacy of different optimization techniques in a primal formulation of a <term>support vector machine</term> (SVM). Three main techniques are compared. The dataset used to compare all three techniques was the Sentiment Analysis on Movie Reviews dataset, from kaggle.com.</abstract>
   </article>
   <article>
      <title>Contrastive Feature Induction for Efficient Structure Learning of
  Conditional Random Fields</title>
      <author>Ni Lao, Jun Zhu</author>
      <date>2014-06-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Structure learning of Conditional Random Fields (CRFs) can be cast into an L1-regularized optimization problem. To avoid optimizing over a fully linked model, gain-based or gradient-based feature selection methods start from an empty model and incrementally add top ranked features to it. However, for high-dimensional problems like statistical relational learning, training time of these incremental methods can be dominated by the cost of evaluating the gain or gradient of a large collection of candidate features. In this study we propose a fast feature evaluation algorithm called Contrastive Feature Induction (CFI), which only evaluates a subset of features that involve both variables with high signals (deviation from mean) and variables with high errors (residue). We prove that the gradient of candidate features can be represented solely as a function of signals and errors, and that CFI is an efficient approximation of gradient-based evaluation methods. Experiments on synthetic and real data sets show competitive learning speed and accuracy of CFI on pairwise CRFs, compared to state-of-the-art structure learning methods such as full optimization over all features, and Grafting.</abstract>
   </article>
   <article>
      <title>Unimodal Bandits without Smoothness</title>
      <author>Richard Combes, Alexandre Proutiere</author>
      <date>2014-06-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider stochastic bandit problems with a continuous set of arms and where the expected reward is a continuous and unimodal function of the arm. No further assumption is made regarding the smoothness and the structure of the expected reward function. For these problems, we propose the Stochastic Pentachotomy (SP) algorithm, and derive finite-time upper bounds on its regret and optimization error. In particular, we show that, for any expected reward function $\mu$ that behaves as $\mu(x)=\mu(x^\star)-C|x-x^\star|^\xi$ locally around its maximizer $x^\star$ for some $\xi, C&gt;0$, the SP algorithm is order-optimal. Namely its regret and optimization error scale as $O(\sqrt{T\log(T)})$ and $O(\sqrt{\log(T)/T})$, respectively, when the time horizon $T$ grows large. These scalings are achieved without the knowledge of $\xi$ and $C$. Our algorithm is based on asymptotically optimal sequential statistical tests used to successively trim an interval that contains the best arm with high probability. To our knowledge, the SP algorithm constitutes the first sequential arm selection rule that achieves a regret and optimization error scaling as $O(\sqrt{T})$ and $O(1/\sqrt{T})$, respectively, up to a logarithmic factor for non-smooth expected reward functions, as well as for smooth functions with unknown smoothness.</abstract>
   </article>
   <article>
      <title>Randomized Block Coordinate Descent for Online and Stochastic
  Optimization</title>
      <author>Huahua Wang, Arindam Banerjee</author>
      <date>2014-07-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Two types of low cost-per-iteration <term>gradient descent</term> methods have been extensively studied in parallel. One is online or stochastic <term>gradient descent</term> (OGD/SGD), and the other is randomzied coordinate descent (RBCD). In this paper, we combine the two types of methods together and propose online randomized block coordinate descent (ORBCD). At each iteration, ORBCD only computes the partial gradient of one block coordinate of one mini-batch samples. ORBCD is well suited for the composite minimization problem where one function is the average of the losses of a large number of samples and the other is a simple regularizer defined on high dimensional variables. We show that the iteration complexity of ORBCD has the same order as OGD or SGD. For strongly convex functions, by reducing the variance of stochastic gradients, we show that ORBCD can converge at a geometric rate in expectation, matching the convergence rate of SGD with variance reduction and RBCD.</abstract>
   </article>
   <article>
      <title>Online Submodular Maximization under a Matroid Constraint with
  Application to Learning Assignments</title>
      <author>Daniel Golovin, Andreas Krause, Matthew Streeter</author>
      <date>2014-07-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Which ads should we display in sponsored search in order to maximize our revenue? How should we dynamically rank information sources to maximize the value of the ranking? These applications exhibit strong diminishing returns: Redundancy decreases the marginal utility of each ad or information source. We show that these and other problems can be formalized as repeatedly selecting an assignment of items to positions to maximize a sequence of monotone submodular functions that arrive one by one. We present an efficient algorithm for this general problem and analyze it in the no-regret model. Our algorithm possesses strong theoretical guarantees, such as a performance ratio that converges to the optimal constant of 1 - 1/e. We empirically evaluate our algorithm on two real-world online optimization problems on the web: ad allocation with submodular utilities, and dynamically ranking blogs to detect information cascades. Finally, we present a second algorithm that handles the more general case in which the feasible sets are given by a matroid constraint, while still maintaining a 1 - 1/e asymptotic performance ratio.</abstract>
   </article>
   <article>
      <title>Large-Scale Multi-Label Learning with Incomplete Label Assignments</title>
      <author>Xiangnan Kong, Zhaoming Wu, Li-Jia Li, Ruofei Zhang, Philip S. Yu, Hang Wu, Wei Fan</author>
      <date>2014-07-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multi-label learning deals with the classification problems where each instance can be assigned with multiple labels simultaneously. Conventional multi-label learning approaches mainly focus on exploiting label correlations. It is usually assumed, explicitly or implicitly, that the label sets for training instances are fully labeled without any missing labels. However, in many real-world multi-label datasets, the label assignments for training instances can be incomplete. Some ground-truth labels can be missed by the labeler from the label set. This problem is especially typical when the number instances is very large, and the labeling cost is very high, which makes it almost impossible to get a fully labeled training set. In this paper, we study the problem of large-scale multi-label learning with incomplete label assignments. We propose an approach, called MPU, based upon positive and unlabeled stochastic <term>gradient descent</term> and stacked models. Unlike prior works, our method can effectively and efficiently consider missing labels and label correlations simultaneously, and is very scalable, that has linear time complexities over the size of the data. Extensive experiments on two real-world multi-label datasets show that our MPU model consistently outperform other commonly-used baselines.</abstract>
   </article>
   <article>
      <title>Learning Deep Structured Models</title>
      <author>Liang-Chieh Chen, Alexander G. Schwing, Alan L. Yuille, Raquel Urtasun</author>
      <date>2014-07-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many problems in real-world applications involve predicting several random variables which are statistically related. Markov random fields (MRFs) are a great mathematical tool to encode such relationships. The goal of this paper is to combine MRFs with <term>deep learning</term> algorithms to estimate complex representations while taking into account the dependencies between the output random variables. Towards this goal, we propose a training algorithm that is able to learn structured models jointly with deep features that form the MRF potentials. Our approach is efficient as it blends learning and inference and makes use of GPU acceleration. We demonstrate the effectiveness of our algorithm in the tasks of predicting words from noisy images, as well as multi-class classification of Flickr photographs. We show that joint learning of the deep features and the MRF parameters results in significant performance gains.</abstract>
   </article>
   <article>
      <title>A multi-instance learning algorithm based on a stacked ensemble of lazy
  learners</title>
      <author>Ramasubramanian Sundararajan, Hima Patel, Manisha Srivastava</author>
      <date>2014-07-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This document describes a novel learning algorithm that classifies "bags" of instances rather than individual instances. A bag is labeled positive if it contains at least one positive instance (which may or may not be specifically identified), and negative otherwise. This class of problems is known as multi-instance learning problems, and is useful in situations where the class label at an instance level may be unavailable or imprecise or difficult to obtain, or in situations where the problem is naturally posed as one of classifying instance groups. The algorithm described here is an ensemble-based method, wherein the members of the ensemble are lazy learning classifiers learnt using the Citation Nearest Neighbour method. Diversity among the ensemble members is achieved by optimizing their parameters using a multi-objective optimization method, with the objectives being to maximize Class 1 accuracy and minimize false positive rate. The method has been found to be effective on the Musk1 benchmark dataset.</abstract>
   </article>
   <article>
      <title>Subspace Restricted Boltzmann Machine</title>
      <author>Jakub M. Tomczak, Adam Gonczarek</author>
      <date>2014-07-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The subspace Restricted Boltzmann Machine (subspaceRBM) is a third-order Boltzmann machine where multiplicative interactions are between one visible and two hidden units. There are two kinds of hidden units, namely, gate units and subspace units. The subspace units reflect variations of a pattern in data and the gate unit is responsible for activating the subspace units. Additionally, the gate unit can be seen as a pooling feature. We evaluate the behavior of subspaceRBM through experiments with MNIST digit recognition task, measuring reconstruction error and classification error.</abstract>
   </article>
   <article>
      <title>A feature construction framework based on outlier detection and
  discriminative pattern mining</title>
      <author>Albrecht Zimmermann</author>
      <date>2014-07-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>No matter the expressive power and sophistication of supervised learning algorithms, their effectiveness is restricted by the features describing the data. This is not a new insight in ML and many methods for feature selection, transformation, and construction have been developed. But while this is on-going for general techniques for feature selection and transformation, i.e. dimensionality reduction, work on feature construction, i.e. enriching the data, is by now mainly the domain of image, particularly character, recognition, and NLP.   In this work, we propose a new general framework for feature construction. The need for feature construction in a data set is indicated by class outliers and discriminative pattern mining used to derive features on their k-neighborhoods. We instantiate the framework with LOF and C4.5-Rules, and evaluate the usefulness of the derived features on a diverse collection of UCI data sets. The derived features are more often useful than ones derived by DC-Fringe, and our approach is much less likely to overfit. But while a weak learner, Naive Bayes, benefits strongly from the feature construction, the effect is less pronounced for C4.5, and almost vanishes for an SVM leaner.   Keywords: feature construction, classification, outlier detection</abstract>
   </article>
   <article>
      <title>Exploiting Smoothness in Statistical Learning, Sequential Prediction,
  and Stochastic Optimization</title>
      <author>Mehrdad Mahdavi</author>
      <date>2014-07-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In the last several years, the intimate connection between convex optimization and learning problems, in both statistical and sequential frameworks, has shifted the focus of algorithmic machine learning to examine this interplay. In particular, on one hand, this intertwinement brings forward new challenges in reassessment of the performance of learning algorithms including generalization and regret bounds under the assumptions imposed by convexity such as analytical properties of loss functions (e.g., Lipschitzness, strong convexity, and smoothness). On the other hand, emergence of datasets of an unprecedented size, demands the development of novel and more efficient optimization algorithms to tackle large-scale learning problems.   The overarching goal of this thesis is to reassess the smoothness of loss functions in statistical learning, sequential prediction/online learning, and stochastic optimization and explicate its consequences. In particular we examine how smoothness of loss function could be beneficial or detrimental in these settings in terms of sample complexity, statistical consistency, regret analysis, and convergence rate, and investigate how smoothness can be leveraged to devise more efficient learning algorithms.</abstract>
   </article>
   <article>
      <title>A Fast Synchronization Clustering Algorithm</title>
      <author>Xinquan Chen</author>
      <date>2014-07-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a Fast Synchronization Clustering algorithm (FSynC), which is an improved version of SynC algorithm. In order to decrease the time complexity of the original SynC algorithm, we combine grid cell partitioning method and Red-Black tree to construct the near neighbor point set of every point. By simulated experiments of some artificial data sets and several real data sets, we observe that FSynC algorithm can often get less time than SynC algorithm for many kinds of data sets. At last, it gives some research expectations to popularize this algorithm.</abstract>
   </article>
   <article>
      <title>Chasing Ghosts: Competing with Stateful Policies</title>
      <author>Uriel Feige, Tomer Koren, Moshe Tennenholtz</author>
      <date>2014-07-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider sequential decision making in a setting where regret is measured with respect to a set of stateful reference policies, and feedback is limited to observing the rewards of the actions performed (the so called "bandit" setting). If either the reference policies are stateless rather than stateful, or the feedback includes the rewards of all actions (the so called "expert" setting), previous work shows that the optimal regret grows like $\Theta(\sqrt{T})$ in terms of the number of decision rounds $T$.   The difficulty in our setting is that the decision maker unavoidably loses track of the internal states of the reference policies, and thus cannot reliably attribute rewards observed in a certain round to any of the reference policies. In fact, in this setting it is impossible for the algorithm to estimate which policy gives the highest (or even approximately highest) total reward. Nevertheless, we design an algorithm that achieves expected regret that is sublinear in $T$, of the form $O( T/\log^{1/4}{T})$. Our algorithm is based on a certain local repetition lemma that may be of independent interest. We also show that no algorithm can guarantee expected regret better than $O( T/\log^{3/2} T)$.</abstract>
   </article>
   <article>
      <title>A Hash-based Co-Clustering Algorithm for Categorical Data</title>
      <author>Fabricio Olivetti de França</author>
      <date>2014-07-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many real-life data are described by categorical attributes without a pre-classification. A common data mining method used to extract information from this type of data is clustering. This method group together the samples from the data that are more similar than all other samples. But, categorical data pose a challenge when extracting information because: the calculation of two objects similarity is usually done by measuring the number of common features, but ignore a possible importance weighting; if the data may be divided differently according to different subsets of the features, the algorithm may find clusters with different meanings from each other, difficulting the post analysis. Data Co-Clustering of categorical data is the technique that tries to find subsets of samples that share a subset of features in common. By doing so, not only a sample may belong to more than one cluster but, the feature selection of each cluster describe its own characteristics. In this paper a novel Co-Clustering technique for categorical data is proposed by using Locality Sensitive Hashing technique in order to preprocess a list of Co-Clusters seeds based on a previous research. Results indicate this technique is capable of finding high quality Co-Clusters in many different categorical data sets and scales linearly with the data set size.</abstract>
   </article>
   <article>
      <title>How Auto-Encoders Could Provide Credit Assignment in Deep Networks via
  Target Propagation</title>
      <author>Yoshua Bengio</author>
      <date>2014-07-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose to exploit {\em reconstruction} as a layer-local training signal for <term>deep learning</term>. Reconstructions can be propagated in a form of target propagation playing a role similar to back-propagation but helping to reduce the reliance on derivatives in order to perform credit assignment across many levels of possibly strong non-linearities (which is difficult for back-propagation). A regularized auto-encoder tends produce a reconstruction that is a more likely version of its input, i.e., a small move in the direction of higher likelihood. By generalizing gradients, target propagation may also allow to train deep networks with discrete hidden units. If the auto-encoder takes both a representation of input and target (or of any side information) in input, then its reconstruction of input representation provides a target towards a representation that is more likely, conditioned on all the side information. A deep auto-encoder decoding path generalizes gradient propagation in a learned way that can could thus handle not just infinitesimal changes but larger, discrete changes, hopefully allowing credit assignment through a long chain of non-linear operations. In addition to each layer being a good auto-encoder, the encoder also learns to please the upper layers by transforming the data into a space where it is easier to model by them, flattening manifolds and disentangling factors. The motivations and theoretical justifications for this approach are laid down in this paper, along with conjectures that will have to be verified either mathematically or experimentally, including a hypothesis stating that such auto-encoder mediated target propagation could play in brains the role of credit assignment through many non-linear, noisy and discrete transformations.</abstract>
   </article>
   <article>
      <title>DuSK: A Dual Structure-preserving Kernel for Supervised Tensor Learning
  with Applications to Neuroimages</title>
      <author>Lifang He, Xiangnan Kong, Philip S. Yu, Ann B. Ragin, Zhifeng Hao, Xiaowei Yang</author>
      <date>2014-07-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>With advances in data collection technologies, tensor data is assuming increasing prominence in many applications and the problem of supervised tensor learning has emerged as a topic of critical significance in the data mining and machine learning community. Conventional methods for supervised tensor learning mainly focus on learning kernels by flattening the tensor into vectors or matrices, however structural information within the tensors will be lost. In this paper, we introduce a new scheme to design structure-preserving kernels for supervised tensor learning. Specifically, we demonstrate how to leverage the naturally available structure within the tensorial representation to encode prior knowledge in the kernel. We proposed a tensor kernel that can preserve tensor structures based upon dual-tensorial mapping. The dual-tensorial mapping function can map each tensor instance in the input space to another tensor in the feature space while preserving the tensorial structure. Theoretically, our approach is an extension of the conventional kernels in the vector space to tensor space. We applied our novel kernel in conjunction with SVM to real-world tensor classification problems including brain fMRI classification for three different diseases (i.e., Alzheimer's disease, ADHD and brain damage by HIV). Extensive empirical studies demonstrate that our proposed approach can effectively boost tensor classification performances, particularly with small sample sizes.</abstract>
   </article>
   <article>
      <title>Combinatorial Multi-Armed Bandit and Its Extension to Probabilistically
  Triggered Arms</title>
      <author>Wei Chen, Yajun Wang, Yang Yuan, Qinshi Wang</author>
      <date>2014-07-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We define a general framework for a large class of combinatorial multi-armed bandit (CMAB) problems, where subsets of base arms with unknown distributions form super arms. In each round, a super arm is played and the base arms contained in the super arm are played and their outcomes are observed. We further consider the extension in which more based arms could be probabilistically triggered based on the outcomes of already triggered arms. The reward of the super arm depends on the outcomes of all played arms, and it only needs to satisfy two mild assumptions, which allow a large class of nonlinear reward instances. We assume the availability of an offline (\alpha,\beta)-approximation oracle that takes the means of the outcome distributions of arms and outputs a super arm that with probability {\beta} generates an {\alpha} fraction of the optimal expected reward. The objective of an online learning algorithm for CMAB is to minimize (\alpha,\beta)-approximation regret, which is the difference between the \alpha{\beta} fraction of the expected reward when always playing the optimal super arm, and the expected reward of playing super arms according to the algorithm. We provide CUCB algorithm that achieves O(log n) distribution-dependent regret, where n is the number of rounds played, and we further provide distribution-independent bounds for a large class of reward functions. Our regret analysis is tight in that it matches the bound of UCB1 algorithm (up to a constant factor) for the classical MAB problem, and it significantly improves the regret bound in a earlier paper on combinatorial bandits with linear rewards. We apply our CMAB framework to two new applications, probabilistic maximum coverage and social influence maximization, both having nonlinear reward structures. In particular, application to social influence maximization requires our extension on probabilistically triggered arms.</abstract>
   </article>
   <article>
      <title>On the Consistency of Ordinal Regression Methods</title>
      <author>Fabian Pedregosa, Francis Bach, Alexandre Gramfort</author>
      <date>2014-08-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many of the ordinal regression models that have been proposed in the literature can be seen as methods that minimize a convex surrogate of the zero-one, absolute, or squared loss functions. A key property that allows to study the statistical implications of such approximations is that of Fisher consistency. Fisher consistency is a desirable property for surrogate loss functions and implies that in the population setting, i.e., if the probability distribution that generates the data were available, then optimization of the surrogate would yield the best possible model. In this paper we will characterize the Fisher consistency of a rich family of surrogate loss functions used in the context of ordinal regression, including support vector ordinal regression, ORBoosting and least absolute deviation. We will see that, for a family of surrogate loss functions that subsumes support vector ordinal regression and ORBoosting, consistency can be fully characterized by the derivative of a real-valued function at zero, as happens for convex margin-based surrogates in binary classification. We also derive excess risk bounds for a surrogate of the absolute error that generalize existing risk bounds for binary classification. Finally, our analysis suggests a novel surrogate of the squared error loss. We compare this novel surrogate with competing approaches on 9 different datasets. Our method shows to be highly competitive in practice, outperforming the least squares loss on 7 out of 9 datasets.</abstract>
   </article>
   <article>
      <title>On the Complexity of Bandit Linear Optimization</title>
      <author>Ohad Shamir</author>
      <date>2014-08-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the attainable regret for online linear optimization problems with bandit feedback, where unlike the full-information setting, the player can only observe its own loss rather than the full loss vector. We show that the price of bandit information in this setting can be as large as $d$, disproving the well-known conjecture that the regret for bandit linear optimization is at most $\sqrt{d}$ times the full-information regret. Surprisingly, this is shown using "trivial" modifications of standard domains, which have no effect in the full-information setting. This and other results we present highlight some interesting differences between full-information and bandit learning, which were not considered in previous literature.</abstract>
   </article>
   <article>
      <title>Learning a hyperplane classifier by minimizing an exact bound on the VC
  dimension</title>
      <author>Jayadeva</author>
      <date>2014-08-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The VC dimension measures the capacity of a learning machine, and a low VC dimension leads to good generalization. While SVMs produce state-of-the-art learning performance, it is well known that the VC dimension of a SVM can be unbounded; despite good results in practice, there is no guarantee of good generalization. In this paper, we show how to learn a hyperplane classifier by minimizing an exact, or \boldmath{$\Theta$} bound on its VC dimension. The proposed approach, termed as the Minimal Complexity Machine (MCM), involves solving a simple linear programming problem. Experimental results show, that on a number of benchmark datasets, the proposed approach learns classifiers with error rates much less than conventional SVMs, while often using fewer support vectors. On many benchmark datasets, the number of support vectors is less than one-tenth the number used by SVMs, indicating that the MCM does indeed learn simpler representations.</abstract>
   </article>
   <article>
      <title>Robust OS-ELM with a novel selective ensemble based on particle swarm
  optimization</title>
      <author>Yang Liu, Bo He, Diya Dong, Yue Shen, Tianhong Yan, Rui Nian, Amaury Lendase</author>
      <date>2014-08-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, a robust online sequential extreme learning machine (ROS-ELM) is proposed. It is based on the original OS-ELM with an adaptive selective ensemble framework. Two novel insights are proposed in this paper. First, a novel selective ensemble algorithm referred to as particle swarm optimization selective ensemble (PSOSEN) is proposed. Noting that PSOSEN is a general selective ensemble method which is applicable to any learning algorithms, including batch learning and online learning. Second, an adaptive selective ensemble framework for online learning is designed to balance the robustness and complexity of the algorithm. Experiments for both regression and classification problems with UCI data sets are carried out. Comparisons between OS-ELM, simple ensemble OS-ELM (EOS-ELM) and the proposed ROS-ELM empirically show that ROS-ELM significantly improves the robustness and stability.</abstract>
   </article>
   <article>
      <title>Linear Contour Learning: A Method for Supervised Dimension Reduction</title>
      <author>Bing Li, Hongyuan Zha, Francesca Chiaromonte</author>
      <date>2014-08-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a novel approach to sufficient dimension reduction in regression, based on estimating contour directions of negligible variation for the response surface. These directions span the orthogonal complement of the minimal space relevant for the regression, and can be extracted according to a measure of the variation in the response, leading to General Contour Regression(GCR). In comparison to exiisting sufficient dimension reduction techniques, this sontour-based mothology guarantees exhaustive estimation of the central space under ellipticity of the predictoor distribution and very mild additional assumptions, while maintaining vn-consisytency and somputational ease. Moreover, it proves to be robust to departures from ellipticity. We also establish some useful population properties for GCR. Simulations to compare performance with that of standard techniques such as ordinary least squares, sliced inverse regression, principal hessian directions, and sliced average variance estimation confirm the advntages anticipated by theoretical analyses. We also demonstrate the use of contour-based methods on a data set concerning grades of students from Massachusetts colleges.</abstract>
   </article>
   <article>
      <title>Multi-Sensor Event Detection using Shape Histograms</title>
      <author>Ehtesham Hassan, Gautam Shroff, Puneet Agarwal</author>
      <date>2014-08-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Vehicular sensor data consists of multiple time-series arising from a number of sensors. Using such multi-sensor data we would like to detect occurrences of specific events that vehicles encounter, e.g., corresponding to particular maneuvers that a vehicle makes or conditions that it encounters. Events are characterized by similar waveform patterns re-appearing within one or more sensors. Further such patterns can be of variable duration. In this work, we propose a method for detecting such events in time-series data using a novel feature descriptor motivated by similar ideas in image processing. We define the shape histogram: a constant dimension descriptor that nevertheless captures patterns of variable duration. We demonstrate the efficacy of using shape histograms as features to detect events in an SVM-based, multi-sensor, supervised learning scenario, i.e., multiple time-series are used to detect an event. We present results on real-life vehicular sensor data and show that our technique performs better than available pattern detection implementations on our data, and that it can also be used to combine features from multiple sensors resulting in better accuracy than using any single sensor. Since previous work on pattern detection in time-series has been in the single series context, we also present results using our technique on multiple standard time-series datasets and show that it is the most versatile in terms of how it ranks compared to other published results.</abstract>
   </article>
   <article>
      <title>AFP Algorithm and a Canonical Normal Form for Horn Formulas</title>
      <author>Ruhollah Majdoddin</author>
      <date>2014-08-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>AFP Algorithm is a learning algorithm for Horn formulas. We show that it does not improve the complexity of AFP Algorithm, if after each negative counterexample more that just one refinements are performed. Moreover, a canonical normal form for Horn formulas is presented, and it is proved that the output formula of AFP Algorithm is in this normal form.</abstract>
   </article>
   <article>
      <title>Conic Multi-Task Classification</title>
      <author>Cong Li, Michael Georgiopoulos, Georgios C. Anagnostopoulos</author>
      <date>2014-08-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Traditionally, Multi-task Learning (MTL) models optimize the average of task-related objective functions, which is an intuitive approach and which we will be referring to as Average MTL. However, a more general framework, referred to as Conic MTL, can be formulated by considering conic combinations of the objective functions instead; in this framework, Average MTL arises as a special case, when all combination coefficients equal 1. Although the advantage of Conic MTL over Average MTL has been shown experimentally in previous works, no theoretical justification has been provided to date. In this paper, we derive a generalization bound for the Conic MTL method, and demonstrate that the tightest bound is not necessarily achieved, when all combination coefficients equal 1; hence, Average MTL may not always be the optimal choice, and it is important to consider Conic MTL. As a byproduct of the generalization bound, it also theoretically explains the good experimental results of previous relevant works. Finally, we propose a new Conic MTL model, whose conic combination coefficients minimize the generalization bound, instead of choosing them heuristically as has been done in previous methods. The rationale and advantage of our model is demonstrated and verified via a series of experiments by comparing with several other methods.</abstract>
   </article>
   <article>
      <title>Improved Distributed Principal Component Analysis</title>
      <author>Maria-Florina Balcan, Vandana Kanchanapally, Yingyu Liang, David Woodruff</author>
      <date>2014-08-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the distributed computing setting in which there are multiple servers, each holding a set of points, who wish to compute functions on the union of their point sets. A key task in this setting is Principal Component Analysis (PCA), in which the servers would like to compute a low dimensional subspace capturing as much of the variance of the union of their point sets as possible. Given a procedure for approximate PCA, one can use it to approximately solve $\ell_2$-error fitting problems such as $k$-means clustering and subspace clustering. The essential properties of an approximate distributed PCA algorithm are its communication cost and computational efficiency for a given desired accuracy in downstream applications. We give new algorithms and analyses for distributed PCA which lead to improved communication and computational costs for $k$-means clustering and related problems. Our empirical study on real world data shows a speedup of orders of magnitude, preserving communication with only a negligible degradation in solution quality. Some of these techniques we develop, such as a general transformation from a constant success probability subspace embedding to a high success probability subspace embedding with a dimension and sparsity independent of the success probability, may be of independent interest.</abstract>
   </article>
   <article>
      <title>Label Distribution Learning</title>
      <author>Xin Geng</author>
      <date>2014-08-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Although multi-label learning can deal with many problems with label ambiguity, it does not fit some real applications well where the overall distribution of the importance of the labels matters. This paper proposes a novel learning paradigm named \emph{label distribution learning} (LDL) for such kind of applications. The label distribution covers a certain number of labels, representing the degree to which each label describes the instance. LDL is a more general learning framework which includes both single-label and multi-label learning as its special cases. This paper proposes six working LDL algorithms in three ways: problem transformation, algorithm adaptation, and specialized algorithm design. In order to compare the performance of the LDL algorithms, six representative and diverse evaluation measures are selected via a clustering analysis, and the first batch of label distribution datasets are collected and made publicly available. Experimental results on one artificial and fifteen real-world datasets show clear advantages of the specialized algorithms, which indicates the importance of special design for the characteristics of the LDL problem.</abstract>
   </article>
   <article>
      <title>Large Scale Purchase Prediction with Historical User Actions on B2C
  Online Retail Platform</title>
      <author>Yuyu Zhang, Liang Pang, Lei Shi, Bin Wang</author>
      <date>2014-08-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper describes the solution of Bazinga Team for Tmall Recommendation Prize 2014. With real-world user action data provided by Tmall, one of the largest B2C online retail platforms in China, this competition requires to predict future user purchases on Tmall website. Predictions are judged on F1Score, which considers both precision and recall for fair evaluation. The data set provided by Tmall contains more than half billion action records from over ten million distinct users. Such massive data volume poses a big challenge, and drives competitors to write every single program in MapReduce fashion and run it on distributed cluster. We model the purchase prediction problem as standard machine learning problem, and mainly employ regression and classification methods as single models. Individual models are then aggregated in a two-stage approach, using linear regression for blending, and finally a linear ensemble of blended models. The competition is approaching the end but still in running during writing this paper. In the end, our team achieves F1Score 6.11 and ranks 7th (out of 7,276 teams in total).</abstract>
   </article>
   <article>
      <title>Task-group Relatedness and Generalization Bounds for Regularized
  Multi-task Learning</title>
      <author>Chao Zhang, Dacheng Tao, Tao Hu, Xiang Li</author>
      <date>2014-08-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we study the generalization performance of regularized multi-task learning (RMTL) in a vector-valued framework, where MTL is considered as a learning process for vector-valued functions. We are mainly concerned with two theoretical questions: 1) under what conditions does RMTL perform better with a smaller task sample size than STL? 2) under what conditions is RMTL generalizable and can guarantee the consistency of each task during simultaneous learning?   In particular, we investigate two types of task-group relatedness: the observed discrepancy-dependence measure (ODDM) and the empirical discrepancy-dependence measure (EDDM), both of which detect the dependence between two groups of multiple related tasks (MRTs). We then introduce the Cartesian product-based uniform entropy number (CPUEN) to measure the complexities of vector-valued function classes. By applying the specific deviation and the symmetrization inequalities to the vector-valued framework, we obtain the generalization bound for RMTL, which is the upper bound of the joint probability of the event that there is at least one task with a large empirical discrepancy between the expected and empirical risks. Finally, we present a sufficient condition to guarantee the consistency of each task in the simultaneous learning process, and we discuss how task relatedness affects the generalization performance of RMTL. Our theoretical findings answer the aforementioned two questions.</abstract>
   </article>
   <article>
      <title>A Multi-Plane Block-Coordinate Frank-Wolfe Algorithm for Training
  Structural SVMs with a Costly max-Oracle</title>
      <author>Neel Shah, Vladimir Kolmogorov, Christoph H. Lampert</author>
      <date>2014-08-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Structural <term>support vector machine</term>s (SSVMs) are amongst the best performing models for structured computer vision tasks, such as semantic image segmentation or human pose estimation. Training SSVMs, however, is computationally costly, because it requires repeated calls to a structured prediction subroutine (called \emph{max-oracle}), which has to solve an optimization problem itself, e.g. a graph cut.   In this work, we introduce a new algorithm for SSVM training that is more efficient than earlier techniques when the max-oracle is computationally expensive, as it is frequently the case in computer vision tasks. The main idea is to (i) combine the recent stochastic Block-Coordinate Frank-Wolfe algorithm with efficient hyperplane caching, and (ii) use an automatic selection rule for deciding whether to call the exact max-oracle or to rely on an approximate one based on the cached hyperplanes.   We show experimentally that this strategy leads to faster convergence to the optimum with respect to the number of requires oracle calls, and that this translates into faster convergence with respect to the total runtime when the max-oracle is slow compared to the other steps of the algorithm.   A publicly available C++ implementation is provided at http://pub.ist.ac.at/~vnk/papers/SVM.html .</abstract>
   </article>
   <article>
      <title>Data classification using the Dempster-Shafer method</title>
      <author>Qi Chen, Amanda Whitbrook, Uwe Aickelin, Chris Roadknight</author>
      <date>2014-09-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, the Dempster-Shafer method is employed as the theoretical basis for creating data classification systems. Testing is carried out using three popular (multiple attribute) benchmark datasets that have two, three and four classes. In each case, a subset of the available data is used for training to establish thresholds, limits or likelihoods of class membership for each attribute, and hence create mass functions that establish probability of class membership for each attribute of the test data. Classification of each data item is achieved by combination of these probabilities via Dempster's Rule of Combination. Results for the first two datasets show extremely high classification accuracy that is competitive with other popular methods. The third dataset is non-numerical and difficult to classify, but good results can be achieved provided the system and mass functions are designed carefully and the right attributes are chosen for combination. In all cases the Dempster-Shafer method provides comparable performance to other more popular algorithms, but the overhead of generating accurate mass functions increases the complexity with the addition of new attributes. Overall, the results suggest that the D-S approach provides a suitable framework for the design of classification systems and that automating the mass function design and calculation would increase the viability of the algorithm for complex classification problems.</abstract>
   </article>
   <article>
      <title>Solving the Problem of the K Parameter in the KNN Classifier Using an
  Ensemble Learning Approach</title>
      <author>Ahmad Basheer Hassanat, Mohammad Ali Abbadi, Ghada Awad Altarawneh, Ahmad Ali Alhasanat</author>
      <date>2014-09-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a new solution for choosing the K parameter in the k-nearest neighbor (KNN) algorithm, the solution depending on the idea of ensemble learning, in which a weak KNN classifier is used each time with a different K, starting from one to the square root of the size of the training set. The results of the weak classifiers are combined using the weighted sum rule. The proposed solution was tested and compared to other solutions using a group of experiments in real life problems. The experimental results show that the proposed classifier outperforms the traditional KNN classifier that uses a different number of neighbors, is competitive with other classifiers, and is a promising classifier with strong potential for a wide range of applications.</abstract>
   </article>
   <article>
      <title>Dimensionality Invariant Similarity Measure</title>
      <author>Ahmad Basheer Hassanat</author>
      <date>2014-09-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a new similarity measure to be used for general tasks including supervised learning, which is represented by the K-nearest neighbor classifier (KNN). The proposed similarity measure is invariant to large differences in some dimensions in the feature space. The proposed metric is proved mathematically to be a metric. To test its viability for different applications, the KNN used the proposed metric for classifying test examples chosen from a number of real datasets. Compared to some other well known metrics, the experimental results show that the proposed metric is a promising distance measure for the KNN classifier with strong potential for a wide range of applications.</abstract>
   </article>
   <article>
      <title>Domain Transfer Structured Output Learning</title>
      <author>Jim Jing-Yan Wang</author>
      <date>2014-09-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose the problem of domain transfer structured output learn- ing and the first solution to solve it. The problem is defined on two different data domains sharing the same input and output spaces, named as source domain and target domain. The outputs are structured, and for the data samples of the source domain, the corresponding outputs are available, while for most data samples of the target domain, the corresponding outputs are missing. The input distributions of the two domains are significantly different. The problem is to learn a predictor for the target domain to predict the structured outputs from the input. Due to the limited number of outputs available for the samples form the target domain, it is difficult to directly learn the predictor from the target domain, thus it is necessary to use the output information available in source domain. We propose to learn the target domain predictor by adapting a auxiliary predictor trained by using source domain data to the target domain. The adaptation is implemented by adding a delta function on the basis of the auxiliary predictor. An algorithm is developed to learn the parameter of the delta function to minimize loss functions associat- ed with the predicted outputs against the true outputs of the data samples with available outputs of the target domain.</abstract>
   </article>
   <article>
      <title>Novel Methods for Activity Classification and Occupany Prediction
  Enabling Fine-grained HVAC Control</title>
      <author>Rajib Rana, Brano Kusy, Josh Wall, Wen Hu</author>
      <date>2014-09-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Much of the energy consumption in buildings is due to HVAC systems, which has motivated several recent studies on making these systems more energy- efficient. Occupancy and activity are two important aspects, which need to be correctly estimated for optimal HVAC control. However, state-of-the-art methods to estimate occupancy and classify activity require infrastructure and/or wearable sensors which suffers from lower acceptability due to higher cost. Encouragingly, with the advancement of the smartphones, these are becoming more achievable. Most of the existing occupancy estimation tech- niques have the underlying assumption that the phone is always carried by its user. However, phones are often left at desk while attending meeting or other events, which generates estimation error for the existing phone based occupancy algorithms. Similarly, in the recent days the emerging theory of Sparse Random Classifier (SRC) has been applied for activity classification on smartphone, however, there are rooms to improve the on-phone process- ing. We propose a novel sensor fusion method which offers almost 100% accuracy for occupancy estimation. We also propose an activity classifica- tion algorithm, which offers similar accuracy as of the state-of-the-art SRC algorithms while offering 50% reduction in processing.</abstract>
   </article>
   <article>
      <title>Non-Convex Boosting Overcomes Random Label Noise</title>
      <author>Sunsern Cheamanunkul, Evan Ettinger, Yoav Freund</author>
      <date>2014-09-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The sensitivity of Adaboost to random label noise is a well-studied problem. LogitBoost, BrownBoost and RobustBoost are boosting algorithms claimed to be less sensitive to noise than AdaBoost. We present the results of experiments evaluating these algorithms on both synthetic and real datasets. We compare the performance on each of datasets when the labels are corrupted by different levels of independent label noise. In presence of random label noise, we found that BrownBoost and RobustBoost perform significantly better than AdaBoost and LogitBoost, while the difference between each pair of algorithms is insignificant. We provide an explanation for the difference based on the margin distributions of the algorithms.</abstract>
   </article>
   <article>
      <title>Metric Learning for Temporal Sequence Alignment</title>
      <author>Damien Garreau, Rémi Lajugie, Sylvain Arlot, Francis Bach</author>
      <date>2014-09-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose to learn a Mahalanobis distance to perform alignment of multivariate time series. The learning examples for this task are time series for which the true alignment is known. We cast the alignment problem as a structured prediction task, and propose realistic losses between alignments for which the optimization is tractable. We provide experiments on real data in the audio to audio context, where we show that the learning of a similarity measure leads to improvements in the performance of the alignment task. We also propose to use this metric learning framework to perform feature selection and, from basic audio features, build a combination of these with better performance for the alignment.</abstract>
   </article>
   <article>
      <title>Consensus-Based Modelling using Distributed Feature Construction</title>
      <author>Haimonti Dutta, Ashwin Srinivasan</author>
      <date>2014-09-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A particularly successful role for Inductive Logic Programming (ILP) is as a tool for discovering useful relational features for subsequent use in a predictive model. Conceptually, the case for using ILP to construct relational features rests on treating these features as functions, the automated discovery of which necessarily requires some form of first-order learning. Practically, there are now several reports in the literature that suggest that augmenting any existing features with ILP-discovered relational features can substantially improve the predictive power of a model. While the approach is straightforward enough, much still needs to be done to scale it up to explore more fully the space of possible features that can be constructed by an ILP system. This is in principle, infinite and in practice, extremely large. Applications have been confined to heuristic or random selections from this space. In this paper, we address this computational difficulty by allowing features to be constructed in a distributed manner. That is, there is a network of computational units, each of which employs an ILP engine to construct some small number of features and then builds a (local) model. We then employ a consensus-based algorithm, in which neighboring nodes share information to update local models. For a category of models (those with convex loss functions), it can be shown that the algorithm will result in all nodes converging to a consensus model. In practice, it may be slow to achieve this convergence. Nevertheless, our results on synthetic and real datasets that suggests that in relatively short time the "best" node in the network reaches a model whose predictive accuracy is comparable to that obtained using more computational effort in a non-distributed setting (the best node is identified as the one whose weights converge first).</abstract>
   </article>
   <article>
      <title>Active Metric Learning from Relative Comparisons</title>
      <author>Sicheng Xiong, Rómer Rosales, Yuanli Pei, Xiaoli Z. Fern</author>
      <date>2014-09-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work focuses on active learning of distance metrics from relative comparison information. A relative comparison specifies, for a data point triplet $(x_i,x_j,x_k)$, that instance $x_i$ is more similar to $x_j$ than to $x_k$. Such constraints, when available, have been shown to be useful toward defining appropriate distance metrics. In real-world applications, acquiring constraints often require considerable human effort. This motivates us to study how to select and query the most useful relative comparisons to achieve effective metric learning with minimum user effort. Given an underlying class concept that is employed by the user to provide such constraints, we present an information-theoretic criterion that selects the triplet whose answer leads to the highest expected gain in information about the classes of a set of examples. Directly applying the proposed criterion requires examining $O(n^3)$ triplets with $n$ instances, which is prohibitive even for datasets of moderate size. We show that a randomized selection strategy can be used to reduce the selection pool from $O(n^3)$ to $O(n)$, allowing us to scale up to larger-size problems. Experiments show that the proposed method consistently outperforms two baseline policies.</abstract>
   </article>
   <article>
      <title>A Mixtures-of-Experts Framework for Multi-Label Classification</title>
      <author>Charmgil Hong, Iyad Batal, Milos Hauskrecht</author>
      <date>2014-09-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We develop a novel probabilistic approach for multi-label classification that is based on the mixtures-of-experts architecture combined with recently introduced conditional tree-structured Bayesian networks. Our approach captures different input-output relations from multi-label data using the efficient tree-structured classifiers, while the mixtures-of-experts architecture aims to compensate for the tree-structured restrictions and build a more accurate model. We develop and present algorithms for learning the model from data and for performing multi-label predictions on future data instances. Experiments on multiple benchmark datasets demonstrate that our approach achieves highly competitive results and outperforms the existing state-of-the-art multi-label classification methods.</abstract>
   </article>
   <article>
      <title>Predictive Capacity of Meteorological Data - Will it rain tomorrow</title>
      <author>Bilal Ahmed</author>
      <date>2014-09-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>With the availability of high precision digital sensors and cheap storage medium, it is not uncommon to find large amounts of data collected on almost all measurable attributes, both in nature and man-made habitats. Weather in particular has been an area of keen interest for researchers to develop more accurate and reliable prediction models. This paper presents a set of experiments which involve the use of prevalent machine learning techniques to build models to predict the day of the week given the weather data for that particular day i.e. temperature, wind, rain etc., and test their reliability across four cities in Australia {Brisbane, Adelaide, Perth, Hobart}. The results provide a comparison of accuracy of these machine learning techniques and their reliability to predict the day of the week by analysing the weather data. We then apply the models to predict weather conditions based on the available data.</abstract>
   </article>
   <article>
      <title>Learning and approximation capability of orthogonal super greedy
  algorithm</title>
      <author>Jian Fang, Shaobo Lin, Zongben Xu</author>
      <date>2014-09-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the approximation capability of orthogonal super greedy algorithms (OSGA) and its applications in supervised learning. OSGA is concerned with selecting more than one atoms in each iteration step, which, of course, greatly reduces the computational burden when compared with the conventional orthogonal greedy algorithm (OGA). We prove that even for function classes that are not the convex hull of the dictionary, OSGA does not degrade the approximation capability of OGA provided the dictionary is incoherent. Based on this, we deduce a tight generalization error bound for OSGA learning. Our results show that in the realm of supervised learning, OSGA provides a possibility to further reduce the computational burden of OGA in the premise of maintaining its prominent generalization capability.</abstract>
   </article>
   <article>
      <title>Efficient Feature Group Sequencing for Anytime Linear Prediction</title>
      <author>Hanzhang Hu, Alexander Grubb, J. Andrew Bagnell, Martial Hebert</author>
      <date>2014-09-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider \textit{anytime} linear prediction in the common machine learning setting, where features are in groups that have costs. We achieve anytime (or interruptible) predictions by sequencing the computation of feature groups and reporting results using the computed features at interruption. We extend Orthogonal Matching Pursuit (OMP) and Forward Regression (FR) to learn the sequencing greedily under this group setting with costs. We theoretically guarantee that our algorithms achieve near-optimal linear predictions at each budget when a feature group is chosen. With a novel analysis of OMP, we improve its theoretical bound to the same strength as that of FR. In addition, we develop a novel algorithm that consumes cost $4B$ to approximate the optimal performance of \textit{any} cost $B$, and prove that with cost less than $4B$, such an approximation is impossible. To our knowledge, these are the first anytime bounds at \textit{all} budgets. We test our algorithms on two real-world data-sets and evaluate them in terms of anytime linear prediction performance against cost-weighted Group Lasso and alternative greedy algorithms.</abstract>
   </article>
   <article>
      <title>A Survey on Soft Subspace Clustering</title>
      <author>Zhaohong Deng, Kup-Sze Choi, Yizhang Jiang, Jun Wang, Shitong Wang</author>
      <date>2014-09-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Subspace clustering (SC) is a promising clustering technology to identify clusters based on their associations with subspaces in high dimensional spaces. SC can be classified into hard subspace clustering (HSC) and soft subspace clustering (SSC). While HSC algorithms have been extensively studied and well accepted by the scientific community, SSC algorithms are relatively new but gaining more attention in recent years due to better adaptability. In the paper, a comprehensive survey on existing SSC algorithms and the recent development are presented. The SSC algorithms are classified systematically into three main categories, namely, conventional SSC (CSSC), independent SSC (ISSC) and extended SSC (XSSC). The characteristics of these algorithms are highlighted and the potential future development of SSC is also discussed.</abstract>
   </article>
   <article>
      <title>Transfer Prototype-based Fuzzy Clustering</title>
      <author>Zhaohong Deng, Yizhang Jiang, Fu-Lai Chung, Hisao Ishibuchi, Kup-Sze Choi, Shitong Wang</author>
      <date>2014-09-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The traditional prototype based clustering methods, such as the well-known fuzzy c-mean (FCM) algorithm, usually need sufficient data to find a good clustering partition. If the available data is limited or scarce, most of the existing prototype based clustering algorithms will no longer be effective. While the data for the current clustering task may be scarce, there is usually some useful knowledge available in the related scenes/domains. In this study, the concept of transfer learning is applied to prototype based fuzzy clustering (PFC). Specifically, the idea of leveraging knowledge from the source domain is exploited to develop a set of transfer prototype based fuzzy clustering (TPFC) algorithms. Three prototype based fuzzy clustering algorithms, namely, FCM, fuzzy k-plane clustering (FKPC) and fuzzy subspace clustering (FSC), have been chosen to incorporate with knowledge leveraging mechanism to develop the corresponding transfer clustering algorithms. Novel objective functions are proposed to integrate the knowledge of source domain with the data of target domain for clustering in the target domain. The proposed algorithms have been validated on different synthetic and real-world datasets and the results demonstrate their effectiveness when compared with both the original prototype based fuzzy clustering algorithms and the related clustering algorithms like multi-task clustering and co-clustering.</abstract>
   </article>
   <article>
      <title>The Information Theoretically Efficient Model (ITEM): A model for
  computerized analysis of large datasets</title>
      <author>Tyler Ward</author>
      <date>2014-09-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This document discusses the Information Theoretically Efficient Model (ITEM), a computerized system to generate an information theoretically efficient multinomial logistic regression from a general dataset. More specifically, this model is designed to succeed even where the logit transform of the dependent variable is not necessarily linear in the independent variables. This research shows that for large datasets, the resulting models can be produced on modern computers in a tractable amount of time. These models are also resistant to overfitting, and as such they tend to produce interpretable models with only a limited number of features, all of which are designed to be well behaved.</abstract>
   </article>
   <article>
      <title>Best-Arm Identification in Linear Bandits</title>
      <author>Marta Soare, Alessandro Lazaric, Rémi Munos</author>
      <date>2014-09-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the best-arm identification problem in linear bandit, where the rewards of the arms depend linearly on an unknown parameter $\theta^*$ and the objective is to return the arm with the largest reward. We characterize the complexity of the problem and introduce sample allocation strategies that pull arms to identify the best arm with a fixed confidence, while minimizing the sample budget. In particular, we show the importance of exploiting the global linear structure to improve the estimate of the reward of near-optimal arms. We analyze the proposed strategies and compare their empirical performance. Finally, as a by-product of our analysis, we point out the connection to the $G$-optimality criterion used in optimal experimental design.</abstract>
   </article>
   <article>
      <title>A Boosting Framework on Grounds of Online Learning</title>
      <author>Tofigh Naghibi, Beat Pfister</author>
      <date>2014-09-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>By exploiting the duality between boosting and online learning, we present a boosting framework which proves to be extremely powerful thanks to employing the vast knowledge available in the online learning area. Using this framework, we develop various algorithms to address multiple practically and theoretically interesting questions including sparse boosting, smooth-distribution boosting, agnostic learning and some generalization to double-projection online learning algorithms, as a by-product.</abstract>
   </article>
   <article>
      <title>A Semidefinite Programming Based Search Strategy for Feature Selection
  with Mutual Information Measure</title>
      <author>Tofigh Naghibi, Sarah Hoffmann, Beat Pfister</author>
      <date>2014-09-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Feature subset selection, as a special case of the general subset selection problem, has been the topic of a considerable number of studies due to the growing importance of data-mining applications. In the feature subset selection problem there are two main issues that need to be addressed: (i) Finding an appropriate measure function than can be fairly fast and robustly computed for high-dimensional data. (ii) A search strategy to optimize the measure over the subset space in a reasonable amount of time. In this article mutual information between features and class labels is considered to be the measure function. Two series expansions for mutual information are proposed, and it is shown that most heuristic criteria suggested in the literature are truncated approximations of these expansions. It is well-known that searching the whole subset space is an NP-hard problem. Here, instead of the conventional sequential search algorithms, we suggest a parallel search strategy based on semidefinite programming (SDP) that can search through the subset space in polynomial time. By exploiting the similarities between the proposed algorithm and an instance of the maximum-cut problem in graph theory, the approximation ratio of this algorithm is derived and is compared with the approximation ratio of the backward elimination method. The experiments show that it can be misleading to judge the quality of a measure solely based on the classification accuracy, without taking the effect of the non-optimum search strategy into account.</abstract>
   </article>
   <article>
      <title>Maximum mutual information regularized classification</title>
      <author>Jim Jing-Yan Wang, Yi Wang, Shiguang Zhao, Xin Gao</author>
      <date>2014-09-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, a novel pattern classification approach is proposed by regularizing the classifier learning to maximize mutual information between the classification response and the true class label. We argue that, with the learned classifier, the uncertainty of the true class label of a data sample should be reduced by knowing its classification response as much as possible. The reduced uncertainty is measured by the mutual information between the classification response and the true class label. To this end, when learning a linear classifier, we propose to maximize the mutual information between classification responses and true class labels of training samples, besides minimizing the classification error and reduc- ing the classifier complexity. An objective function is constructed by modeling mutual information with entropy estimation, and it is optimized by a gradi- ent descend method in an iterative algorithm. Experiments on two real world pattern classification problems show the significant improvements achieved by maximum mutual information regularization.</abstract>
   </article>
   <article>
      <title>Cognitive Learning of Statistical Primary Patterns via Bayesian Network</title>
      <author>Weijia Han, Huiyan Sang, Min Sheng, Jiandong Li, Shuguang Cui</author>
      <date>2014-09-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In cognitive radio (CR) technology, the trend of sensing is no longer to only detect the presence of active primary users. A large number of applications demand for more comprehensive knowledge on primary user behaviors in spatial, temporal, and frequency domains. To satisfy such requirements, we study the statistical relationship among primary users by introducing a Bayesian network (BN) based framework. How to learn such a BN structure is a long standing issue, not fully understood even in the statistical learning community. Besides, another key problem in this learning scenario is that the CR has to identify how many variables are in the BN, which is usually considered as prior knowledge in statistical learning applications. To solve such two issues simultaneously, this paper proposes a BN structure learning scheme consisting of an efficient structure learning algorithm and a blind variable identification scheme. The proposed approach incurs significantly lower computational complexity compared with previous ones, and is capable of determining the structure without assuming much prior knowledge about variables. With this result, cognitive users could efficiently understand the statistical pattern of primary networks, such that more efficient cognitive protocols could be designed across different network layers.</abstract>
   </article>
   <article>
      <title>Efficient multivariate sequence classification</title>
      <author>Pavel P. Kuksa</author>
      <date>2014-09-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Kernel-based approaches for sequence classification have been successfully applied to a variety of domains, including the text categorization, image classification, speech analysis, biological sequence analysis, time series and music classification, where they show some of the most accurate results.   Typical kernel functions for sequences in these domains (e.g., bag-of-words, mismatch, or subsequence kernels) are restricted to {\em discrete univariate} (i.e. one-dimensional) string data, such as sequences of words in the text analysis, codeword sequences in the image analysis, or nucleotide or amino acid sequences in the DNA and protein sequence analysis. However, original sequence data are often of real-valued multivariate nature, i.e. are not univariate and discrete as required by typical $k$-mer based sequence kernel functions.   In this work, we consider the problem of the {\em multivariate} sequence classification such as classification of multivariate music sequences, or multidimensional protein sequence representations. To this end, we extend {\em univariate} kernel functions typically used in sequence analysis and propose efficient {\em multivariate} similarity kernel method (MVDFQ-SK) based on (1) a direct feature quantization (DFQ) of each sequence dimension in the original {\em real-valued} multivariate sequences and (2) applying novel multivariate discrete kernel measures on these multivariate discrete DFQ sequence representations to more accurately capture similarity relationships among sequences and improve classification performance.   Experiments using the proposed MVDFQ-SK kernel method show excellent classification performance on three challenging music classification tasks as well as protein sequence classification with significant 25-40% improvements over univariate kernel methods and existing state-of-the-art sequence classification methods.</abstract>
   </article>
   <article>
      <title>Generalized Laguerre Reduction of the Volterra Kernel for Practical
  Identification of Nonlinear Dynamic Systems</title>
      <author>Brett W. Israelsen, Dale A. Smith</author>
      <date>2014-10-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The Volterra series can be used to model a large subset of nonlinear, dynamic systems. A major drawback is the number of coefficients required model such systems. In order to reduce the number of required coefficients, Laguerre polynomials are used to estimate the Volterra kernels. Existing literature proposes algorithms for a fixed number of Volterra kernels, and Laguerre series. This paper presents a novel algorithm for generalized calculation of the finite order Volterra-Laguerre (VL) series for a MIMO system. An example addresses the utility of the algorithm in practical application.</abstract>
   </article>
   <article>
      <title>Online Ranking with Top-1 Feedback</title>
      <author>Sougata Chaudhuri, Ambuj Tewari</author>
      <date>2014-10-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a setting where a system learns to rank a fixed set of $m$ items. The goal is produce good item rankings for users with diverse interests who interact online with the system for $T$ rounds. We consider a novel top-$1$ feedback model: at the end of each round, the relevance score for only the top ranked object is revealed. However, the performance of the system is judged on the entire ranked list. We provide a comprehensive set of results regarding learnability under this challenging setting. For PairwiseLoss and DCG, two popular ranking measures, we prove that the minimax regret is $\Theta(T^{2/3})$. Moreover, the minimax regret is achievable using an efficient strategy that only spends $O(m \log m)$ time per round. The same efficient strategy achieves $O(T^{2/3})$ regret for Precision@$k$. Surprisingly, we show that for normalized versions of these ranking measures, i.e., AUC, NDCG \&amp; MAP, no online ranking algorithm can have sublinear regret.</abstract>
   </article>
   <article>
      <title>Stochastic Discriminative EM</title>
      <author>Andres R. Masegosa</author>
      <date>2014-10-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic discriminative EM (sdEM) is an online-EM-type algorithm for discriminative training of probabilistic generative models belonging to the exponential family. In this work, we introduce and justify this algorithm as a stochastic natural <term>gradient descent</term> method, i.e. a method which accounts for the information geometry in the parameter space of the statistical model. We show how this learning algorithm can be used to train probabilistic generative models by minimizing different discriminative loss functions, such as the negative conditional log-likelihood and the Hinge loss. The resulting models trained by sdEM are always generative (i.e. they define a joint probability distribution) and, in consequence, allows to deal with missing data and latent variables in a principled way either when being learned or when making predictions. The performance of this method is illustrated by several text classification problems for which a multinomial naive Bayes and a latent Dirichlet allocation based classifier are learned using different discriminative loss functions.</abstract>
   </article>
   <article>
      <title>Learning manifold to regularize nonnegative matrix factorization</title>
      <author>Jim Jing-Yan Wang, Xin Gao</author>
      <date>2014-10-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Inthischapterwediscusshowtolearnanoptimalmanifoldpresentationto regularize nonegative matrix factorization (NMF) for data representation problems. NMF,whichtriestorepresentanonnegativedatamatrixasaproductoftwolowrank nonnegative matrices, has been a popular method for data representation due to its ability to explore the latent part-based structure of data. Recent study shows that lots of data distributions have manifold structures, and we should respect the manifold structure when the data are represented. Recently, manifold regularized NMF used a nearest neighbor graph to regulate the learning of factorization parameter matrices and has shown its advantage over traditional NMF methods for data representation problems. However, how to construct an optimal graph to present the manifold prop- erly remains a difficultproblem due to the graph modelselection, noisy features, and nonlinear distributed data. In this chapter, we introduce three effective methods to solve these problems of graph construction for manifold regularized NMF. Multiple graph learning is proposed to solve the problem of graph model selection, adaptive graph learning via feature selection is proposed to solve the problem of constructing a graph from noisy features, while multi-kernel learning-based graph construction is used to solve the problem of learning a graph from nonlinearly distributed data.</abstract>
   </article>
   <article>
      <title>A Logic-based Approach to Generatively Defined Discriminative Modeling</title>
      <author>Taisuke Sato, Keiichi Kubota, Yoshitaka Kameya</author>
      <date>2014-10-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Conditional random fields (CRFs) are usually specified by graphical models but in this paper we propose to use probabilistic logic programs and specify them generatively. Our intension is first to provide a unified approach to CRFs for complex modeling through the use of a Turing complete language and second to offer a convenient way of realizing generative-discriminative pairs in machine learning to compare generative and discriminative models and choose the best model. We implemented our approach as the D-PRISM language by modifying PRISM, a logic-based probabilistic modeling language for generative modeling, while exploiting its dynamic programming mechanism for efficient probability computation. We tested D-PRISM with logistic regression, a linear-chain CRF and a CRF-CFG and empirically confirmed their excellent discriminative performance compared to their generative counterparts, i.e.\ naive Bayes, an HMM and a PCFG. We also introduced new CRF models, CRF-BNCs and CRF-LCGs. They are CRF versions of Bayesian network classifiers and probabilistic left-corner grammars respectively and easily implementable in D-PRISM. We empirically showed that they outperform their generative counterparts as expected.</abstract>
   </article>
   <article>
      <title>Two-Layer Feature Reduction for Sparse-Group Lasso via Decomposition of
  Convex Sets</title>
      <author>Jie Wang, Jieping Ye</author>
      <date>2014-10-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Sparse-Group Lasso (SGL) has been shown to be a powerful regression technique for simultaneously discovering group and within-group sparse patterns by using a combination of the $\ell_1$ and $\ell_2$ norms. However, in large-scale applications, the complexity of the regularizers entails great computational challenges. In this paper, we propose a novel Two-Layer Feature REduction method (TLFre) for SGL via a decomposition of its dual feasible set. The two-layer reduction is able to quickly identify the inactive groups and the inactive features, respectively, which are guaranteed to be absent from the sparse representation and can be removed from the optimization. Existing feature reduction methods are only applicable for sparse models with one sparsity-inducing regularizer. To our best knowledge, TLFre is the first one that is capable of dealing with multiple sparsity-inducing regularizers. Moreover, TLFre has a very low computational cost and can be integrated with any existing solvers. We also develop a screening method---called DPC (DecomPosition of Convex set)---for the nonnegative Lasso problem. Experiments on both synthetic and real data sets show that TLFre and DPC improve the efficiency of SGL and nonnegative Lasso by several orders of magnitude.</abstract>
   </article>
   <article>
      <title>Learning a hyperplane regressor by minimizing an exact bound on the VC
  dimension</title>
      <author>Jayadeva, Suresh Chandra, Siddarth Sabharwal, Sanjit S. Batra</author>
      <date>2014-10-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The capacity of a learning machine is measured by its Vapnik-Chervonenkis dimension, and learning machines with a low VC dimension generalize better. It is well known that the VC dimension of SVMs can be very large or unbounded, even though they generally yield state-of-the-art learning performance. In this paper, we show how to learn a hyperplane regressor by minimizing an exact, or \boldmath{$\Theta$} bound on its VC dimension. The proposed approach, termed as the Minimal Complexity Machine (MCM) Regressor, involves solving a simple linear programming problem. Experimental results show, that on a number of benchmark datasets, the proposed approach yields regressors with error rates much less than those obtained with conventional SVM regresssors, while often using fewer support vectors. On some benchmark datasets, the number of support vectors is less than one tenth the number used by SVMs, indicating that the MCM does indeed learn simpler representations.</abstract>
   </article>
   <article>
      <title>Naive Bayes and Text Classification I - Introduction and Theory</title>
      <author>Sebastian Raschka</author>
      <date>2014-10-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Naive Bayes classifiers, a family of classifiers that are based on the popular Bayes' probability theorem, are known for creating simple yet well performing models, especially in the fields of document classification and disease prediction. In this article, we will look at the main concepts of naive Bayes classification in the context of document categorization.</abstract>
   </article>
   <article>
      <title>An Overview of General Performance Metrics of Binary Classifier Systems</title>
      <author>Sebastian Raschka</author>
      <date>2014-10-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This document provides a brief overview of different metrics and terminology that is used to measure the performance of binary classification systems.</abstract>
   </article>
   <article>
      <title>Feature Selection Based on Confidence Machine</title>
      <author>Chang Liu, Yi Xu</author>
      <date>2014-10-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In machine learning and pattern recognition, feature selection has been a hot topic in the literature. Unsupervised feature selection is challenging due to the loss of labels which would supply the related information.How to define an appropriate metric is the key for feature selection. We propose a filter method for unsupervised feature selection which is based on the Confidence Machine. Confidence Machine offers an estimation of confidence on a feature'reliability. In this paper, we provide the math model of Confidence Machine in the context of feature selection, which maximizes the relevance and minimizes the redundancy of the selected feature. We compare our method against classic feature selection methods Laplacian Score, Pearson Correlation and Principal Component Analysis on benchmark data sets. The experimental results demonstrate the efficiency and effectiveness of our method.</abstract>
   </article>
   <article>
      <title>Cosine Similarity Measure According to a Convex Cost Function</title>
      <author>Osman Gunay, Cem Emre Akbas, A. Enis Cetin</author>
      <date>2014-10-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we describe a new vector similarity measure associated with a convex cost function. Given two vectors, we determine the surface normals of the convex function at the vectors. The angle between the two surface normals is the similarity measure. Convex cost function can be the negative entropy function, total variation (TV) function and filtered variation function. The convex cost function need not be differentiable everywhere. In general, we need to compute the gradient of the cost function to compute the surface normals. If the gradient does not exist at a given vector, it is possible to use the subgradients and the normal producing the smallest angle between the two vectors is used to compute the similarity measure.</abstract>
   </article>
   <article>
      <title>Differentially- and non-differentially-private random decision trees</title>
      <author>Mariusz Bojarski, Anna Choromanska, Krzysztof Choromanski, Yann LeCun</author>
      <date>2014-10-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider supervised learning with random decision trees, where the tree construction is completely random. The method is popularly used and works well in practice despite the simplicity of the setting, but its statistical mechanism is not yet well-understood. In this paper we provide strong theoretical guarantees regarding learning with random decision trees. We analyze and compare three different variants of the algorithm that have minimal memory requirements: majority voting, threshold averaging and probabilistic averaging. The random structure of the tree enables us to adapt these methods to a differentially-private setting thus we also propose differentially-private versions of all three schemes. We give upper-bounds on the generalization error and mathematically explain how the accuracy depends on the number of random decision trees. Furthermore, we prove that only logarithmic (in the size of the dataset) number of independently selected random decision trees suffice to correctly classify most of the data, even when differential-privacy guarantees must be maintained. We empirically show that majority voting and threshold averaging give the best accuracy, also for conservative users requiring high privacy guarantees. Furthermore, we demonstrate that a simple majority voting rule is an especially good candidate for the differentially-private classifier since it is much less sensitive to the choice of forest parameters than other methods.</abstract>
   </article>
   <article>
      <title>Notes on using Determinantal Point Processes for Clustering with
  Applications to Text Clustering</title>
      <author>Apoorv Agarwal, Anna Choromanska, Krzysztof Choromanski</author>
      <date>2014-10-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we compare three initialization schemes for the KMEANS clustering algorithm: 1) random initialization (KMEANSRAND), 2) KMEANS++, and 3) KMEANSD++. Both KMEANSRAND and KMEANS++ have a major that the value of k needs to be set by the user of the algorithms. (Kang 2013) recently proposed a novel use of determinantal point processes for sampling the initial centroids for the KMEANS algorithm (we call it KMEANSD++). They, however, do not provide any evaluation establishing that KMEANSD++ is better than other algorithms. In this paper, we show that the performance of KMEANSD++ is comparable to KMEANS++ (both of which are better than KMEANSRAND) with KMEANSD++ having an additional that it can automatically approximate the value of k.</abstract>
   </article>
   <article>
      <title>Feature Selection through Minimization of the VC dimension</title>
      <author>Jayadeva, Sanjit S. Batra, Siddharth Sabharwal</author>
      <date>2014-10-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Feature selection involes identifying the most relevant subset of input features, with a view to improving generalization of predictive models by reducing overfitting. Directly searching for the most relevant combination of attributes is NP-hard. Variable selection is of critical importance in many applications, such as micro-array data analysis, where selecting a small number of discriminative features is crucial to developing useful models of disease mechanisms, as well as for prioritizing targets for drug discovery. The recently proposed Minimal Complexity Machine (MCM) provides a way to learn a hyperplane classifier by minimizing an exact (\boldmath{$\Theta$}) bound on its VC dimension. It is well known that a lower VC dimension contributes to good generalization. For a linear hyperplane classifier in the input space, the VC dimension is upper bounded by the number of features; hence, a linear classifier with a small VC dimension is parsimonious in the set of features it employs. In this paper, we use the linear MCM to learn a classifier in which a large number of weights are zero; features with non-zero weights are the ones that are chosen. Selected features are used to learn a kernel SVM classifier. On a number of benchmark datasets, the features chosen by the linear MCM yield comparable or better test set accuracy than when methods such as ReliefF and FCBF are used for the task. The linear MCM typically chooses one-tenth the number of attributes chosen by the other methods; on some very high dimensional datasets, the MCM chooses about $0.6\%$ of the features; in comparison, ReliefF and FCBF choose 70 to 140 times more features, thus demonstrating that minimizing the VC dimension may provide a new, and very effective route for feature selection and for learning sparse representations.</abstract>
   </article>
   <article>
      <title>Fast Learning of Relational Dependency Networks</title>
      <author>Oliver Schulte, Zhensong Qian, Arthur E. Kirkpatrick, Xiaoqian Yin, Yan Sun</author>
      <date>2014-10-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A Relational Dependency Network (RDN) is a directed graphical model widely used for multi-relational data. These networks allow cyclic dependencies, necessary to represent relational autocorrelations. We describe an approach for learning both the RDN's structure and its parameters, given an input relational database: First learn a Bayesian network (BN), then transform the Bayesian network to an RDN. Thus fast Bayes net learning can provide fast RDN learning. The BN-to-RDN transform comprises a simple, local adjustment of the Bayes net structure and a closed-form transform of the Bayes net parameters. This method can learn an RDN for a dataset with a million tuples in minutes. We empirically compare our approach to state-of-the art RDN learning methods that use functional gradient boosting, on five benchmark datasets. Learning RDNs via BNs scales much better to large datasets than learning RDNs with boosting, and provides competitive accuracy in predictions.</abstract>
   </article>
   <article>
      <title>Global Bandits with Holder Continuity</title>
      <author>Onur Atan, Cem Tekin, Mihaela van der Schaar</author>
      <date>2014-10-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Standard Multi-Armed Bandit (MAB) problems assume that the arms are independent. However, in many application scenarios, the information obtained by playing an arm provides information about the remainder of the arms. Hence, in such applications, this informativeness can and should be exploited to enable faster convergence to the optimal solution. In this paper, we introduce and formalize the Global MAB (GMAB), in which arms are globally informative through a global parameter, i.e., choosing an arm reveals information about all the arms. We propose a greedy policy for the GMAB which always selects the arm with the highest estimated expected reward, and prove that it achieves bounded parameter-dependent regret. Hence, this policy selects suboptimal arms only finitely many times, and after a finite number of initial time steps, the optimal arm is selected in all of the remaining time steps with probability one. In addition, we also study how the informativeness of the arms about each other's rewards affects the speed of learning. Specifically, we prove that the parameter-free (worst-case) regret is sublinear in time, and decreases with the informativeness of the arms. We also prove a sublinear in time Bayesian risk bound for the GMAB which reduces to the well-known Bayesian risk bound for linearly parameterized bandits when the arms are fully informative. GMABs have applications ranging from drug and treatment discovery to dynamic pricing.</abstract>
   </article>
   <article>
      <title>Notes on Noise Contrastive Estimation and Negative Sampling</title>
      <author>Chris Dyer</author>
      <date>2014-10-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Estimating the parameters of probabilistic models of language such as maxent models and probabilistic neural models is computationally difficult since it involves evaluating partition functions by summing over an entire vocabulary, which may be millions of word types in size. Two closely related strategies---noise contrastive estimation (Mnih and Teh, 2012; Mnih and Kavukcuoglu, 2013; Vaswani et al., 2013) and negative sampling (Mikolov et al., 2012; Goldberg and Levy, 2014)---have emerged as popular solutions to this computational problem, but some confusion remains as to which is more appropriate and when. This document explicates their relationships to each other and to other estimation techniques. The analysis shows that, although they are superficially similar, NCE is a general parameter estimation technique that is asymptotically unbiased, while negative sampling is best understood as a family of binary classification models that are useful for learning word representations but not as a general-purpose estimator.</abstract>
   </article>
   <article>
      <title>NICE: Non-linear Independent Components Estimation</title>
      <author>Laurent Dinh, David Krueger, Yoshua Bengio</author>
      <date>2014-10-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a <term>deep learning</term> framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep <term>neural network</term>. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.</abstract>
   </article>
   <article>
      <title>Learning Mixtures of Ranking Models</title>
      <author>Pranjal Awasthi, Avrim Blum, Or Sheffet, Aravindan Vijayaraghavan</author>
      <date>2014-10-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work concerns learning probabilistic models for ranking data in a heterogeneous population. The specific problem we study is learning the parameters of a Mallows Mixture Model. Despite being widely studied, current heuristics for this problem do not have theoretical guarantees and can get stuck in bad local optima. We present the first polynomial time algorithm which provably learns the parameters of a mixture of two Mallows models. A key component of our algorithm is a novel use of tensor decomposition techniques to learn the top-k prefix in both the rankings. Before this work, even the question of identifiability in the case of a mixture of two Mallows models was unresolved.</abstract>
   </article>
   <article>
      <title>Factorbird - a Parameter Server Approach to Distributed Matrix
  Factorization</title>
      <author>Sebastian Schelter, Venu Satuluri, Reza Zadeh</author>
      <date>2014-11-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present Factorbird, a prototype of a parameter server approach for factorizing large matrices with Stochastic Gradient Descent-based algorithms. We designed Factorbird to meet the following desiderata: (a) scalability to tall and wide matrices with dozens of billions of non-zeros, (b) extensibility to different kinds of models and loss functions as long as they can be optimized using Stochastic Gradient Descent (SGD), and (c) adaptability to both batch and streaming scenarios. Factorbird uses a parameter server in order to scale to models that exceed the memory of an individual machine, and employs lock-free Hogwild!-style learning with a special partitioning scheme to drastically reduce conflicting updates. We also discuss other aspects of the design of our system such as how to efficiently grid search for hyperparameters at scale. We present experiments of Factorbird on a matrix built from a subset of Twitter's interaction graph, consisting of more than 38 billion non-zeros and about 200 million rows and columns, which is to the best of our knowledge the largest matrix on which factorization results have been reported in the literature.</abstract>
   </article>
   <article>
      <title>CUR Algorithm for Partially Observed Matrices</title>
      <author>Miao Xu, Rong Jin, Zhi-Hua Zhou</author>
      <date>2014-11-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>CUR matrix decomposition computes the low rank approximation of a given matrix by using the actual rows and columns of the matrix. It has been a very useful tool for handling large matrices. One limitation with the existing algorithms for CUR matrix decomposition is that they need an access to the {\it full} matrix, a requirement that can be difficult to fulfill in many real world applications. In this work, we alleviate this limitation by developing a CUR decomposition algorithm for partially observed matrices. In particular, the proposed algorithm computes the low rank approximation of the target matrix based on (i) the randomly sampled rows and columns, and (ii) a subset of observed entries that are randomly sampled from the matrix. Our analysis shows the relative error bound, measured by spectral norm, for the proposed algorithm when the target matrix is of full rank. We also show that only $O(n r\ln r)$ observed entries are needed by the proposed algorithm to perfectly recover a rank $r$ matrix of size $n\times n$, which improves the sample complexity of the existing algorithms for matrix completion. Empirical studies on both synthetic and real-world datasets verify our theoretical claims and demonstrate the effectiveness of the proposed algorithm.</abstract>
   </article>
   <article>
      <title>Eigenvectors of Orthogonally Decomposable Functions</title>
      <author>Mikhail Belkin, Luis Rademacher, James Voss</author>
      <date>2014-11-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The Eigendecomposition of quadratic forms (symmetric matrices) guaranteed by the spectral theorem is a foundational result in applied mathematics. Motivated by a shared structure found in inferential problems of recent interest---namely orthogonal tensor decompositions, Independent Component Analysis (ICA), topic models, spectral clustering, and Gaussian mixture learning---we generalize the eigendecomposition from quadratic forms to a broad class of "orthogonally decomposable" functions. We identify a key role of convexity in our extension, and we generalize two traditional characterizations of eigenvectors: First, the eigenvectors of a quadratic form arise from the optima structure of the quadratic form on the sphere. Second, the eigenvectors are the fixed points of the power iteration.   In our setting, we consider a simple first order generalization of the power method which we call gradient iteration. It leads to efficient and easily implementable methods for basis recovery. It includes influential Machine Learning methods such as cumulant-based FastICA and the tensor power iteration for orthogonally decomposable tensors as special cases.   We provide a complete theoretical analysis of gradient iteration using the structure theory of discrete dynamical systems to show almost sure convergence and fast (super-linear) convergence rates. The analysis also extends to the case when the observed function is only approximately orthogonally decomposable, with bounds that are polynomial in dimension and other relevant parameters, such as perturbation size. Our perturbation results can be considered as a non-linear version of the classical Davis-Kahan theorem for perturbations of eigenvectors of symmetric matrices.</abstract>
   </article>
   <article>
      <title>On the Information Theoretic Limits of Learning Ising Models</title>
      <author>Karthikeyan Shanmugam, Rashish Tandon, Alexandros G. Dimakis, Pradeep Ravikumar</author>
      <date>2014-11-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We provide a general framework for computing lower-bounds on the sample complexity of recovering the underlying graphs of Ising models, given i.i.d samples. While there have been recent results for specific graph classes, these involve fairly extensive technical arguments that are specialized to each specific graph class. In contrast, we isolate two key graph-structural ingredients that can then be used to specify sample complexity lower-bounds. Presence of these structural properties makes the graph class hard to learn. We derive corollaries of our main result that not only recover existing recent results, but also provide lower bounds for novel graph classes not considered previously. We also extend our framework to the random graph setting and derive corollaries for Erd\H{o}s-R\'{e}nyi graphs in a certain dense setting.</abstract>
   </article>
   <article>
      <title>Efficient Representations for Life-Long Learning and Autoencoding</title>
      <author>Maria-Florina Balcan, Avrim Blum, Santosh Vempala</author>
      <date>2014-11-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It has been a long-standing goal in machine learning, as well as in AI more generally, to develop life-long learning systems that learn many different tasks over time, and reuse insights from tasks learned, "learning to learn" as they do so. In this work we pose and provide efficient algorithms for several natural theoretical formulations of this goal. Specifically, we consider the problem of learning many different target functions over time, that share certain commonalities that are initially unknown to the learning algorithm. Our aim is to learn new internal representations as the algorithm learns new target functions, that capture this commonality and allow subsequent learning tasks to be solved more efficiently and from less data. We develop efficient algorithms for two very different kinds of commonalities that target functions might share: one based on learning common low-dimensional and unions of low-dimensional subspaces and one based on learning nonlinear Boolean combinations of features. Our algorithms for learning Boolean feature combinations additionally have a dual interpretation, and can be viewed as giving an efficient procedure for constructing near-optimal sparse Boolean autoencoders under a natural "anchor-set" assumption.</abstract>
   </article>
   <article>
      <title>A Hybrid Recurrent Neural Network For Music Transcription</title>
      <author>Siddharth Sigtia, Emmanouil Benetos, Nicolas Boulanger-Lewandowski, Tillman Weyde, Artur S. d'Avila Garcez, Simon Dixon</author>
      <date>2014-11-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We investigate the problem of incorporating higher-level symbolic score-like information into Automatic Music Transcription (AMT) systems to improve their performance. We use recurrent <term>neural network</term>s (RNNs) and their variants as music language models (MLMs) and present a generative architecture for combining these models with predictions from a frame level acoustic classifier. We also compare different <term>neural network</term> architectures for acoustic modeling. The proposed model computes a distribution over possible output sequences given the acoustic input signal and we present an algorithm for performing a global search for good candidate transcriptions. The performance of the proposed model is evaluated on piano music from the MAPS dataset and we observe that the proposed model consistently outperforms existing transcription methods.</abstract>
   </article>
   <article>
      <title>Online Collaborative-Filtering on Graphs</title>
      <author>Siddhartha Banerjee, Sujay Sanghavi, Sanjay Shakkottai</author>
      <date>2014-11-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A common phenomena in modern recommendation systems is the use of feedback from one user to infer the `value' of an item to other users. This results in an exploration vs. exploitation trade-off, in which items of possibly low value have to be presented to users in order to ascertain their value. Existing approaches to solving this problem focus on the case where the number of items are small, or admit some underlying structure -- it is unclear, however, if good recommendation is possible when dealing with content-rich settings with unstructured content.   We consider this problem under a simple natural model, wherein the number of items and the number of item-views are of the same order, and an `access-graph' constrains which user is allowed to see which item. Our main insight is that the presence of the access-graph in fact makes good recommendation possible -- however this requires the exploration policy to be designed to take advantage of the access-graph. Our results demonstrate the importance of `serendipity' in exploration, and how higher graph-expansion translates to a higher quality of recommendations; it also suggests a reason why in some settings, simple policies like Twitter's `Latest-First' policy achieve a good performance.   From a technical perspective, our model presents a way to study exploration-exploitation tradeoffs in settings where the number of `trials' and `strategies' are large (potentially infinite), and more importantly, of the same order. Our algorithms admit competitive-ratio guarantees which hold for the worst-case user, under both finite-population and infinite-horizon settings, and are parametrized in terms of properties of the underlying graph. Conversely, we also demonstrate that improperly-designed policies can be highly sub-optimal, and that in many settings, our results are order-wise optimal.</abstract>
   </article>
   <article>
      <title>A chain rule for the expected suprema of Gaussian processes</title>
      <author>Andreas Maurer</author>
      <date>2014-11-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The expected supremum of a Gaussian process indexed by the image of an index set under a function class is bounded in terms of separate properties of the index set and the function class. The bound is relevant to the estimation of nonlinear transformations or the analysis of learning algorithms whenever hypotheses are chosen from composite classes, as is the case for multi-layer models.</abstract>
   </article>
   <article>
      <title>Bounded Regret for Finite-Armed Structured Bandits</title>
      <author>Tor Lattimore, Remi Munos</author>
      <date>2014-11-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study a new type of K-armed bandit problem where the expected return of one arm may depend on the returns of other arms. We present a new algorithm for this general class of problems and show that under certain circumstances it is possible to achieve finite expected cumulative regret. We also give problem-dependent lower bounds on the cumulative regret showing that at least in special cases the new algorithm is nearly optimal.</abstract>
   </article>
   <article>
      <title>Greedy metrics in orthogonal greedy learning</title>
      <author>Lin Xu, Shaobo Lin, Jinshan Zeng, Zongben Xu</author>
      <date>2014-11-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Orthogonal greedy learning (OGL) is a stepwise learning scheme that adds a new atom from a dictionary via the steepest <term>gradient descent</term> and build the estimator via orthogonal projecting the target function to the space spanned by the selected atoms in each greedy step. Here, "greed" means choosing a new atom according to the steepest <term>gradient descent</term> principle. OGL then avoids the overfitting/underfitting by selecting an appropriate iteration number. In this paper, we point out that the overfitting/underfitting can also be avoided via redefining "greed" in OGL. To this end, we introduce a new greedy metric, called $\delta$-greedy thresholds, to refine "greed" and theoretically verifies its feasibility. Furthermore, we reveals that such a greedy metric can bring an adaptive termination rule on the premise of maintaining the prominent learning performance of OGL. Our results show that the steepest <term>gradient descent</term> is not the unique greedy metric of OGL and some other more suitable metric may lessen the hassle of model-selection of OGL.</abstract>
   </article>
   <article>
      <title>Minimal Realization Problems for Hidden Markov Models</title>
      <author>Qingqing Huang, Rong Ge, Sham Kakade, Munther Dahleh</author>
      <date>2014-11-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Consider a stationary discrete random process with alphabet size d, which is assumed to be the output process of an unknown stationary Hidden Markov Model (HMM). Given the joint probabilities of finite length strings of the process, we are interested in finding a finite state generative model to describe the entire process. In particular, we focus on two classes of models: HMMs and quasi-HMMs, which is a strictly larger class of models containing HMMs. In the main theorem, we show that if the random process is generated by an HMM of order less or equal than k, and whose transition and observation probability matrix are in general position, namely almost everywhere on the parameter space, both the minimal quasi-HMM realization and the minimal HMM realization can be efficiently computed based on the joint probabilities of all the length N strings, for N &gt; 4 lceil log_d(k) rceil +1. In this paper, we also aim to compare and connect the two lines of literature: realization theory of HMMs, and the recent development in learning latent variable models with tensor decomposition techniques.</abstract>
   </article>
   <article>
      <title>Sample-targeted clinical trial adaptation</title>
      <author>Ognjen Arandjelovic</author>
      <date>2014-11-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Clinical trial adaptation refers to any adjustment of the trial protocol after the onset of the trial. The main goal is to make the process of introducing new medical interventions to patients more efficient by reducing the cost and the time associated with evaluating their safety and efficacy. The principal question is how should adaptation be performed so as to minimize the chance of distorting the outcome of the trial. We propose a novel method for achieving this. Unlike previous work our approach focuses on trial adaptation by sample size adjustment. We adopt a recently proposed stratification framework based on collected auxiliary data and show that this information together with the primary measured variables can be used to make a probabilistically informed choice of the particular sub-group a sample should be removed from. Experiments on simulated data are used to illustrate the effectiveness of our method and its application in practice.</abstract>
   </article>
   <article>
      <title>Differentially Private Algorithms for Empirical Machine Learning</title>
      <author>Ben Stoddard, Yan Chen, Ashwin Machanavajjhala</author>
      <date>2014-11-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>An important use of private data is to build machine learning classifiers. While there is a burgeoning literature on differentially private classification algorithms, we find that they are not practical in real applications due to two reasons. First, existing differentially private classifiers provide poor accuracy on real world datasets. Second, there is no known differentially private algorithm for empirically evaluating the private classifier on a private test dataset.   In this paper, we develop differentially private algorithms that mirror real world empirical machine learning workflows. We consider the private classifier training algorithm as a blackbox. We present private algorithms for selecting features that are input to the classifier. Though adding a preprocessing step takes away some of the privacy budget from the actual classification process (thus potentially making it noisier and less accurate), we show that our novel preprocessing techniques significantly increase classifier accuracy on three real-world datasets. We also present the first private algorithms for empirically constructing receiver operating characteristic (ROC) curves on a private test set.</abstract>
   </article>
   <article>
      <title>No-Regret Learnability for Piecewise Linear Losses</title>
      <author>Arthur Flajolet, Patrick Jaillet</author>
      <date>2014-11-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In the convex optimization approach to online regret minimization, many methods have been developed to guarantee a $O(\sqrt{T})$ bound on regret for subdifferentiable convex loss functions with bounded subgradients, by using a reduction to linear loss functions. This suggests that linear loss functions tend to be the hardest ones to learn against, regardless of the underlying decision spaces. We investigate this question in a systematic fashion looking at the interplay between the set of possible moves for both the decision maker and the adversarial environment. This allows us to highlight sharp distinctive behaviors about the learnability of piecewise linear loss functions. On the one hand, when the decision set of the decision maker is a polyhedron, we establish $\Omega(\sqrt{T})$ lower bounds on regret for a large class of piecewise linear loss functions with important applications in online linear optimization, repeated zero-sum Stackelberg games, online prediction with side information, and online two-stage optimization. On the other hand, we exhibit $o(\sqrt{T})$ learning rates, achieved by the Follow-The-Leader algorithm, in online linear optimization when the boundary of the decision maker's decision set is curved and when $0$ does not lie in the convex hull of the environment's decision set. Hence, the curvature of the decision maker's decision set is a determining factor for the optimal learning rate. These results hold in a completely adversarial setting.</abstract>
   </article>
   <article>
      <title>Compound Rank-k Projections for Bilinear Analysis</title>
      <author>Xiaojun Chang, Feiping Nie, Sen Wang, Yi Yang, Xiaofang Zhou, Chengqi Zhang</author>
      <date>2014-11-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In many real-world applications, data are represented by matrices or high-order tensors. Despite the promising performance, the existing two-dimensional discriminant analysis algorithms employ a single projection model to exploit the discriminant information for projection, making the model less flexible. In this paper, we propose a novel Compound Rank-k Projection (CRP) algorithm for bilinear analysis. CRP deals with matrices directly without transforming them into vectors, and it therefore preserves the correlations within the matrix and decreases the computation complexity. Different from the existing two dimensional discriminant analysis algorithms, objective function values of CRP increase monotonically.In addition, CRP utilizes multiple rank-k projection models to enable a larger search space in which the optimal solution can be found. In this way, the discriminant ability is enhanced.</abstract>
   </article>
   <article>
      <title>Semi-supervised Feature Analysis by Mining Correlations among Multiple
  Tasks</title>
      <author>Xiaojun Chang, Yi Yang</author>
      <date>2014-11-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose a novel semi-supervised feature selection framework by mining correlations among multiple tasks and apply it to different multimedia applications. Instead of independently computing the importance of features for each task, our algorithm leverages shared knowledge from multiple related tasks, thus, improving the performance of feature selection. Note that we build our algorithm on assumption that different tasks share common structures. The proposed algorithm selects features in a batch mode, by which the correlations between different features are taken into consideration. Besides, considering the fact that labeling a large amount of training data in real world is both time-consuming and tedious, we adopt manifold learning which exploits both labeled and unlabeled training data for feature space analysis. Since the objective function is non-smooth and difficult to solve, we propose an iterative algorithm with fast convergence. Extensive experiments on different applications demonstrate that our algorithm outperforms other state-of-the-art feature selection algorithms.</abstract>
   </article>
   <article>
      <title>A Convex Sparse PCA for Feature Analysis</title>
      <author>Xiaojun Chang, Feiping Nie, Yi Yang, Heng Huang</author>
      <date>2014-11-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Principal component analysis (PCA) has been widely applied to dimensionality reduction and data pre-processing for different applications in engineering, biology and social science. Classical PCA and its variants seek for linear projections of the original variables to obtain a low dimensional feature representation with maximal variance. One limitation is that it is very difficult to interpret the results of PCA. In addition, the classical PCA is vulnerable to certain noisy data. In this paper, we propose a convex sparse principal component analysis (CSPCA) algorithm and apply it to feature analysis. First we show that PCA can be formulated as a low-rank regression optimization problem. Based on the discussion, the l 2 , 1 -norm minimization is incorporated into the objective function to make the regression coefficients sparse, thereby robust to the outliers. In addition, based on the sparse model used in CSPCA, an optimal weight is assigned to each of the original feature, which in turn provides the output with good interpretability. With the output of our CSPCA, we can effectively analyze the importance of each feature under the PCA criteria. The objective function is convex, and we propose an iterative algorithm to optimize it. We apply the CSPCA algorithm to feature selection and conduct extensive experiments on six different benchmark datasets. Experimental results demonstrate that the proposed algorithm outperforms state-of-the-art unsupervised feature selection algorithms.</abstract>
   </article>
   <article>
      <title>Balanced k-Means and Min-Cut Clustering</title>
      <author>Xiaojun Chang, Feiping Nie, Zhigang Ma, Yi Yang</author>
      <date>2014-11-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Clustering is an effective technique in data mining to generate groups that are the matter of interest. Among various clustering approaches, the family of k-means algorithms and min-cut algorithms gain most popularity due to their simplicity and efficacy. The classical k-means algorithm partitions a number of data points into several subsets by iteratively updating the clustering centers and the associated data points. By contrast, a weighted undirected graph is constructed in min-cut algorithms which partition the vertices of the graph into two sets. However, existing clustering algorithms tend to cluster minority of data points into a subset, which shall be avoided when the target dataset is balanced. To achieve more accurate clustering for balanced dataset, we propose to leverage exclusive lasso on k-means and min-cut to regulate the balance degree of the clustering results. By optimizing our objective functions that build atop the exclusive lasso, we can make the clustering result as much balanced as possible. Extensive experiments on several large-scale datasets validate the advantage of the proposed algorithms compared to the state-of-the-art clustering algorithms.</abstract>
   </article>
   <article>
      <title>Improved Spectral Clustering via Embedded Label Propagation</title>
      <author>Xiaojun Chang, Feiping Nie, Yi Yang, Heng Huang</author>
      <date>2014-11-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Spectral clustering is a key research topic in the field of machine learning and data mining. Most of the existing spectral clustering algorithms are built upon Gaussian Laplacian matrices, which are sensitive to parameters. We propose a novel parameter free, distance consistent Locally Linear Embedding. The proposed distance consistent LLE promises that edges between closer data points have greater weight.Furthermore, we propose a novel improved spectral clustering via embedded label propagation. Our algorithm is built upon two advancements of the state of the art:1) label propagation,which propagates a node\'s labels to neighboring nodes according to their proximity; and 2) manifold learning, which has been widely used in its capacity to leverage the manifold structure of data points. First we perform standard spectral clustering on original data and assign each cluster to k nearest data points. Next, we propagate labels through dense, unlabeled data regions. Extensive experiments with various datasets validate the superiority of the proposed algorithm compared to current state of the art spectral algorithms.</abstract>
   </article>
   <article>
      <title>Structure Regularization for Structured Prediction: Theories and
  Experiments</title>
      <author>Xu Sun</author>
      <date>2014-11-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>While there are many studies on weight regularization, the study on structure regularization is rare. Many existing systems on structured prediction focus on increasing the level of structural dependencies within the model. However, this trend could have been misdirected, because our study suggests that complex structures are actually harmful to generalization ability in structured prediction. To control structure-based overfitting, we propose a structure regularization framework via \emph{structure decomposition}, which decomposes training samples into mini-samples with simpler structures, deriving a model with better generalization power. We show both theoretically and empirically that structure regularization can effectively control overfitting risk and lead to better accuracy. As a by-product, the proposed method can also substantially accelerate the training speed. The method and the theoretical results can apply to general graphical models with arbitrary structures. Experiments on well-known tasks demonstrate that our method can easily beat the benchmark systems on those highly-competitive tasks, achieving state-of-the-art accuracies yet with substantially faster training speed.</abstract>
   </article>
   <article>
      <title>Revenue Optimization in Posted-Price Auctions with Strategic Buyers</title>
      <author>Mehryar Mohri, Andres Muñoz Medina</author>
      <date>2014-11-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study revenue optimization learning algorithms for posted-price auctions with strategic buyers. We analyze a very broad family of monotone regret minimization algorithms for this problem, which includes the previously best known algorithm, and show that no algorithm in that family admits a strategic regret more favorable than $\Omega(\sqrt{T})$. We then introduce a new algorithm that achieves a strategic regret differing from the lower bound only by a factor in $O(\log T)$, an exponential improvement upon the previous best algorithm. Our new algorithm admits a natural analysis and simpler proofs, and the ideas behind its design are general. We also report the results of empirical evaluations comparing our algorithm with the previous state of the art and show a consistent exponential improvement in several different scenarios.</abstract>
   </article>
   <article>
      <title>A Convex Formulation for Spectral Shrunk Clustering</title>
      <author>Xiaojun Chang, Feiping Nie, Zhigang Ma, Yi Yang, Xiaofang Zhou</author>
      <date>2014-11-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Spectral clustering is a fundamental technique in the field of data mining and information processing. Most existing spectral clustering algorithms integrate dimensionality reduction into the clustering process assisted by manifold learning in the original space. However, the manifold in reduced-dimensional subspace is likely to exhibit altered properties in contrast with the original space. Thus, applying manifold information obtained from the original space to the clustering process in a low-dimensional subspace is prone to inferior performance. Aiming to address this issue, we propose a novel convex algorithm that mines the manifold structure in the low-dimensional subspace. In addition, our unified learning process makes the manifold learning particularly tailored for the clustering. Compared with other related methods, the proposed algorithm results in more structured clustering result. To validate the efficacy of the proposed algorithm, we perform extensive experiments on several benchmark datasets in comparison with some state-of-the-art clustering approaches. The experimental results demonstrate that the proposed algorithm has quite promising clustering performance.</abstract>
   </article>
   <article>
      <title>Accelerated Parallel Optimization Methods for Large Scale Machine
  Learning</title>
      <author>Haipeng Luo, Patrick Haffner, Jean-Francois Paiement</author>
      <date>2014-11-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The growing amount of high dimensional data in different machine learning applications requires more efficient and scalable optimization algorithms. In this work, we consider combining two techniques, parallelism and Nesterov's acceleration, to design faster algorithms for L1-regularized loss. We first simplify BOOM, a variant of <term>gradient descent</term>, and study it in a unified framework, which allows us to not only propose a refined measurement of sparsity to improve BOOM, but also show that BOOM is provably slower than FISTA. Moving on to parallel coordinate descent methods, we then propose an efficient accelerated version of Shotgun, improving the convergence rate from $O(1/t)$ to $O(1/t^2)$. Our algorithm enjoys a concise form and analysis compared to previous work, and also allows one to study several connected work in a unified way.</abstract>
   </article>
   <article>
      <title>Worst-Case Linear Discriminant Analysis as Scalable Semidefinite
  Feasibility Problems</title>
      <author>Hui Li, Chunhua Shen, Anton van den Hengel, Qinfeng Shi</author>
      <date>2014-11-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose an efficient semidefinite programming (SDP) approach to worst-case linear discriminant analysis (WLDA). Compared with the traditional LDA, WLDA considers the dimensionality reduction problem from the worst-case viewpoint, which is in general more robust for classification. However, the original problem of WLDA is non-convex and difficult to optimize. In this paper, we reformulate the optimization problem of WLDA into a sequence of semidefinite feasibility problems. To efficiently solve the semidefinite feasibility problems, we design a new scalable optimization method with quasi-Newton methods and eigen-decomposition being the core components. The proposed method is orders of magnitude faster than standard interior-point based SDP solvers.   Experiments on a variety of classification problems demonstrate that our approach achieves better performance than standard LDA. Our method is also much faster and more scalable than standard interior-point SDP solvers based WLDA. The computational complexity for an SDP with $m$ constraints and matrices of size $d$ by $d$ is roughly reduced from $\mathcal{O}(m^3+md^3+m^2d^2)$ to $\mathcal{O}(d^3)$ ($m&gt;d$ in our case).</abstract>
   </article>
   <article>
      <title>Graph Sensitive Indices for Comparing Clusterings</title>
      <author>Zaeem Hussain, Marina Meila</author>
      <date>2014-11-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This report discusses two new indices for comparing clusterings of a set of points. The motivation for looking at new ways for comparing clusterings stems from the fact that the existing clustering indices are based on set cardinality alone and do not consider the positions of data points. The new indices, namely, the Random Walk index (RWI) and Variation of Information with Neighbors (VIN), are both inspired by the clustering metric Variation of Information (VI). VI possesses some interesting theoretical properties which are also desirable in a metric for comparing clusterings. We define our indices and discuss some of their explored properties which appear relevant for a clustering index. We also include the results of these indices on clusterings of some example data sets.</abstract>
   </article>
   <article>
      <title>Guaranteed Matrix Completion via Non-convex Factorization</title>
      <author>Ruoyu Sun, Zhi-Quan Luo</author>
      <date>2014-11-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Matrix factorization is a popular approach for large-scale matrix completion. The optimization formulation based on matrix factorization can be solved very efficiently by standard algorithms in practice. However, due to the non-convexity caused by the factorization model, there is a limited theoretical understanding of this formulation. In this paper, we establish a theoretical guarantee for the factorization formulation to correctly recover the underlying low-rank matrix. In particular, we show that under similar conditions to those in previous works, many standard optimization algorithms converge to the global optima of a factorization formulation, and recover the true low-rank matrix. We study the local geometry of a properly regularized factorization formulation and prove that any stationary point in a certain local region is globally optimal. A major difference of our work from the existing results is that we do not need resampling in either the algorithm or its analysis. Compared to other works on nonconvex optimization, one extra difficulty lies in analyzing nonconvex constrained optimization when the constraint (or the corresponding regularizer) is not "consistent" with the gradient direction. One technical contribution is the perturbation analysis for non-symmetric matrix factorization.</abstract>
   </article>
   <article>
      <title>The Loss Surfaces of Multilayer Networks</title>
      <author>Anna Choromanska, Mikael Henaff, Michael Mathieu, Gérard Ben Arous, Yann LeCun</author>
      <date>2014-11-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward <term>neural network</term> and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled <term>neural network</term> through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large- and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.</abstract>
   </article>
   <article>
      <title>Easy Hyperparameter Search Using Optunity</title>
      <author>Marc Claesen, Jaak Simm, Dusan Popovic, Yves Moreau, Bart De Moor</author>
      <date>2014-12-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Optunity is a free software package dedicated to hyperparameter optimization. It contains various types of solvers, ranging from undirected methods to direct search, particle swarm and evolutionary optimization. The design focuses on ease of use, flexibility, code clarity and interoperability with existing software in all machine learning environments. Optunity is written in Python and contains interfaces to environments such as R and MATLAB. Optunity uses a BSD license and is freely available online at http://www.optunity.net.</abstract>
   </article>
   <article>
      <title>Fast Rates by Transferring from Auxiliary Hypotheses</title>
      <author>Ilja Kuzborskij, Francesco Orabona</author>
      <date>2014-12-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this work we consider the learning setting where, in addition to the training set, the learner receives a collection of auxiliary hypotheses originating from other tasks. We focus on a broad class of ERM-based linear algorithms that can be instantiated with any non-negative smooth loss function and any strongly convex regularizer. We establish generalization and excess risk bounds, showing that, if the algorithm is fed with a good combination of source hypotheses, generalization happens at the fast rate $\mathcal{O}(1/m)$ instead of the usual $\mathcal{O}(1/\sqrt{m})$. On the other hand, if the source hypotheses combination is a misfit for the target task, we recover the usual learning rate. As a byproduct of our study, we also prove a new bound on the Rademacher complexity of the smooth loss class under weaker assumptions compared to previous works.</abstract>
   </article>
   <article>
      <title>A parallel sampling based clustering</title>
      <author>Aditya AV Sastry, Kalyan Netti</author>
      <date>2014-12-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The problem of automatically clustering data is an age old problem. People have created numerous algorithms to tackle this problem. The execution time of any of this algorithm grows with the number of input points and the number of cluster centers required. To reduce the number of input points we could average the points locally and use the means or the local centers as the input for clustering. However since the required number of local centers is very high, running the clustering algorithm on the entire dataset to obtain these representational points is very time consuming. To remedy this problem, in this paper we are proposing two subclustering schemes where by we subdivide the dataset into smaller sets and run the clustering algorithm on the smaller datasets to obtain the required number of datapoints to run our clustering algorithm with. As we are subdividing the given dataset, we could run clustering algorithm on each smaller piece of the dataset in parallel. We found that both parallel and serial execution of this method to be much faster than the original clustering algorithm and error in running the clustering algorithm on a reduced set to be very less.</abstract>
   </article>
   <article>
      <title>Consistent optimization of AMS by logistic loss minimization</title>
      <author>Wojciech Kotłowski</author>
      <date>2014-12-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we theoretically justify an approach popular among participants of the Higgs Boson Machine Learning Challenge to optimize approximate median significance (AMS). The approach is based on the following two-stage procedure. First, a real-valued function is learned by minimizing a surrogate loss for binary classification, such as logistic loss, on the training sample. Then, a threshold is tuned on a separate validation sample, by direct optimization of AMS. We show that the regret of the resulting (thresholded) classifier measured with respect to the squared AMS, is upperbounded by the regret of the underlying real-valued function measured with respect to the logistic loss. Hence, we prove that minimizing logistic surrogate is a consistent method of optimizing AMS.</abstract>
   </article>
   <article>
      <title>Theano-based Large-Scale Visual Recognition with Multiple GPUs</title>
      <author>Weiguang Ding, Ruoyan Wang, Fei Mao, Graham Taylor</author>
      <date>2014-12-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this report, we describe a Theano-based AlexNet (Krizhevsky et al., 2012) implementation and its naive data parallelism on multiple GPUs. Our performance on 2 GPUs is comparable with the state-of-art Caffe library (Jia et al., 2014) run on 1 GPU. To the best of our knowledge, this is the first open-source Python-based AlexNet implementation to-date.</abstract>
   </article>
   <article>
      <title>Accurate Streaming Support Vector Machines</title>
      <author>Vikram Nathan, Sharath Raghvendra</author>
      <date>2014-12-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A widely-used tool for binary classification is the Support Vector Machine (SVM), a supervised learning technique that finds the "maximum margin" linear separator between the two classes. While SVMs have been well studied in the batch (offline) setting, there is considerably less work on the streaming (online) setting, which requires only a single pass over the data using sub-linear space. Existing streaming algorithms are not yet competitive with the batch implementation. In this paper, we use the formulation of the SVM as a minimum enclosing ball (MEB) problem to provide a streaming SVM algorithm based off of the blurred ball cover originally proposed by Agarwal and Sharathkumar. Our implementation consistently outperforms existing streaming SVM approaches and provides higher accuracies than libSVM on several datasets, thus making it competitive with the standard SVM batch implementation.</abstract>
   </article>
   <article>
      <title>Sequential Labeling with online Deep Learning</title>
      <author>Gang Chen, Ran Xu, Sargur Srihari</author>
      <date>2014-12-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Deep learning has attracted great attention recently and yielded the state of the art performance in dimension reduction and classification problems. However, it cannot effectively handle the structured output prediction, e.g. sequential labeling. In this paper, we propose a <term>deep learning</term> structure, which can learn discriminative features for sequential labeling problems. More specifically, we add the inter-relationship between labels in our <term>deep learning</term> structure, in order to incorporate the context information from the sequential data. Thus, our model is more powerful than linear Conditional Random Fields (CRFs) because the objective function learns latent non-linear features so that target labeling can be better predicted. We pretrain the deep structure with stacked restricted Boltzmann machines (RBMs) for feature learning and optimize our objective function with online learning algorithm, a mixture of perceptron training and stochastic <term>gradient descent</term>. We test our model on different challenge tasks, and show that our model outperforms significantly over the completive baselines.</abstract>
   </article>
   <article>
      <title>An Evaluation of Support Vector Machines as a Pattern Recognition Tool</title>
      <author>Eugene Borovikov</author>
      <date>2014-12-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The purpose of this report is in examining the generalization performance of Support Vector Machines (SVM) as a tool for pattern recognition and object classification. The work is motivated by the growing popularity of the method that is claimed to guarantee a good generalization performance for the task in hand. The method is implemented in MATLAB. SVMs based on various kernels are tested for classifying data from various domains.</abstract>
   </article>
   <article>
      <title>Max-Margin based Discriminative Feature Learning</title>
      <author>Changsheng Li, Qingshan Liu, Weishan Dong, Xin Zhang, Lin Yang</author>
      <date>2014-12-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose a new max-margin based discriminative feature learning method. Specifically, we aim at learning a low-dimensional feature representation, so as to maximize the global margin of the data and make the samples from the same class as close as possible. In order to enhance the robustness to noise, a $l_{2,1}$ norm constraint is introduced to make the transformation matrix in group sparsity. In addition, for multi-class classification tasks, we further intend to learn and leverage the correlation relationships among multiple class tasks for assisting in learning discriminative features. The experimental results demonstrate the power of the proposed method against the related state-of-the-art methods.</abstract>
   </article>
   <article>
      <title>Learning from Data with Heterogeneous Noise using SGD</title>
      <author>Shuang Song, Kamalika Chaudhuri, Anand D. Sarwate</author>
      <date>2014-12-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider learning from data of variable quality that may be obtained from different heterogeneous sources. Addressing learning from heterogeneous data in its full generality is a challenging problem. In this paper, we adopt instead a model in which data is observed through heterogeneous noise, where the noise level reflects the quality of the data source. We study how to use stochastic gradient algorithms to learn in this model. Our study is motivated by two concrete examples where this problem arises naturally: learning with local differential privacy based on data from multiple sources with different privacy requirements, and learning from data with labels of variable quality.   The main contribution of this paper is to identify how heterogeneous noise impacts performance. We show that given two datasets with heterogeneous noise, the order in which to use them in standard SGD depends on the learning rate. We propose a method for changing the learning rate as a function of the heterogeneity, and prove new regret bounds for our method in two cases of interest. Experiments on real data show that our method performs better than using a single learning rate and using only the less noisy of the two datasets when the noise level is low to moderate.</abstract>
   </article>
   <article>
      <title>Dynamic Structure Embedded Online Multiple-Output Regression for Stream
  Data</title>
      <author>Changsheng Li, Fan Wei, Weishan Dong, Qingshan Liu, Xiangfeng Wang, Xin Zhang</author>
      <date>2014-12-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Online multiple-output regression is an important machine learning technique for modeling, predicting, and compressing multi-dimensional correlated data streams. In this paper, we propose a novel online multiple-output regression method, called MORES, for stream data. MORES can \emph{dynamically} learn the structure of the coefficients change in each update step to facilitate the model's continuous refinement. We observe that limited expressive ability of the regression model, especially in the preliminary stage of online update, often leads to the variables in the residual errors being dependent. In light of this point, MORES intends to \emph{dynamically} learn and leverage the structure of the residual errors to improve the prediction accuracy. Moreover, we define three statistical variables to \emph{exactly} represent all the seen samples for \emph{incrementally} calculating prediction loss in each online update round, which can avoid loading all the training data into memory for updating model, and also effectively prevent drastic fluctuation of the model in the presence of noise. Furthermore, we introduce a forgetting factor to set different weights on samples so as to track the data streams' evolving characteristics quickly from the latest samples. Experiments on one synthetic dataset and three real-world datasets validate the effectiveness of the proposed method. In addition, the update speed of MORES is at least 2000 samples processed per second on the three real-world datasets, more than 15 times faster than the state-of-the-art online learning algorithm.</abstract>
   </article>
   <article>
      <title>Large Scale Distributed Distance Metric Learning</title>
      <author>Pengtao Xie, Eric Xing</author>
      <date>2014-12-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In large scale machine learning and data mining problems with high feature dimensionality, the Euclidean distance between data points can be uninformative, and Distance Metric Learning (DML) is often desired to learn a proper similarity measure (using side information such as example data pairs being similar or dissimilar). However, high dimensionality and large volume of pairwise constraints in modern big data can lead to prohibitive computational cost for both the original DML formulation in Xing et al. (2002) and later extensions. In this paper, we present a distributed algorithm for DML, and a large-scale implementation on a parameter server architecture. Our approach builds on a parallelizable reformulation of Xing et al. (2002), and an asynchronous stochastic <term>gradient descent</term> optimization procedure. To our knowledge, this is the first distributed solution to DML, and we show that, on a system with 256 CPU cores, our program is able to complete a DML task on a dataset with 1 million data points, 22-thousand features, and 200 million labeled data pairs, in 15 hours; and the learned metric shows great effectiveness in properly measuring distances.</abstract>
   </article>
   <article>
      <title>Algorithmic Robustness for Learning via $(ε, γ, τ)$-Good
  Similarity Functions</title>
      <author>Maria-Irina Nicolae, Marc Sebban, Amaury Habrard, Éric Gaussier, Massih-Reza Amini</author>
      <date>2014-12-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The notion of metric plays a key role in machine learning problems such as classification, clustering or ranking. However, it is worth noting that there is a severe lack of theoretical guarantees that can be expected on the generalization capacity of the classifier associated to a given metric. The theoretical framework of $(\epsilon, \gamma, \tau)$-good similarity functions (Balcan et al., 2008) has been one of the first attempts to draw a link between the properties of a similarity function and those of a linear classifier making use of it. In this paper, we extend and complete this theory by providing a new generalization bound for the associated classifier based on the algorithmic robustness framework.</abstract>
   </article>
   <article>
      <title>Fast Label Embeddings via Randomized Linear Algebra</title>
      <author>Paul Mineiro, Nikos Karampatziakis</author>
      <date>2014-12-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many modern multiclass and multilabel problems are characterized by increasingly large output spaces. For these problems, label embeddings have been shown to be a useful primitive that can improve computational and statistical efficiency. In this work we utilize a correspondence between rank constrained estimation and low dimensional label embeddings that uncovers a fast label embedding algorithm which works in both the multiclass and multilabel settings. The result is a randomized algorithm whose running time is exponentially faster than naive algorithms. We demonstrate our techniques on two large-scale public datasets, from the Large Scale Hierarchical Text Challenge and the Open Directory Project, where we obtain state of the art results.</abstract>
   </article>
   <article>
      <title>Hot Swapping for Online Adaptation of Optimization Hyperparameters</title>
      <author>Kevin Bache, Dennis DeCoste, Padhraic Smyth</author>
      <date>2014-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We describe a general framework for online adaptation of optimization hyperparameters by `hot swapping' their values during learning. We investigate this approach in the context of adaptive learning rate selection using an explore-exploit strategy from the multi-armed bandit literature. Experiments on a benchmark <term>neural network</term> show that the hot swapping approach leads to consistently better solutions compared to well-known alternatives such as AdaDelta and stochastic gradient with exhaustive hyperparameter search.</abstract>
   </article>
   <article>
      <title>Understanding Minimum Probability Flow for RBMs Under Various Kinds of
  Dynamics</title>
      <author>Daniel Jiwoong Im, Ethan Buchman, Graham W. Taylor</author>
      <date>2014-12-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Energy-based models are popular in machine learning due to the elegance of their formulation and their relationship to statistical physics. Among these, the Restricted Boltzmann Machine (RBM), and its staple training algorithm contrastive divergence (CD), have been the prototype for some recent advancements in the unsupervised training of deep <term>neural network</term>s. However, CD has limited theoretical motivation, and can in some cases produce undesirable behavior. Here, we investigate the performance of Minimum Probability Flow (MPF) learning for training RBMs. Unlike CD, with its focus on approximating an intractable partition function via Gibbs sampling, MPF proposes a tractable, consistent, objective function defined in terms of a Taylor expansion of the KL divergence with respect to sampling dynamics. Here we propose a more general form for the sampling dynamics in MPF, and explore the consequences of different choices for these dynamics for training RBMs. Experimental results show MPF outperforming CD for various RBM configurations.</abstract>
   </article>
   <article>
      <title>Adam: A Method for Stochastic Optimization</title>
      <author>Diederik P. Kingma, Jimmy Ba</author>
      <date>2014-12-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.</abstract>
   </article>
   <article>
      <title>Discriminative Clustering with Relative Constraints</title>
      <author>Yuanli Pei, Xiaoli Z. Fern, Rómer Rosales, Teresa Vania Tjahja</author>
      <date>2014-12-30</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the problem of clustering with relative constraints, where each constraint specifies relative similarities among instances. In particular, each constraint $(x_i, x_j, x_k)$ is acquired by posing a query: is instance $x_i$ more similar to $x_j$ than to $x_k$? We consider the scenario where answers to such queries are based on an underlying (but unknown) class concept, which we aim to discover via clustering. Different from most existing methods that only consider constraints derived from yes and no answers, we also incorporate don't know responses. We introduce a Discriminative Clustering method with Relative Constraints (DCRC) which assumes a natural probabilistic relationship between instances, their underlying cluster memberships, and the observed constraints. The objective is to maximize the model likelihood given the constraints, and in the meantime enforce cluster separation and cluster balance by also making use of the unlabeled instances. We evaluated the proposed method using constraints generated from ground-truth class labels, and from (noisy) human judgments from a user study. Experimental results demonstrate: 1) the usefulness of relative constraints, in particular when don't know answers are considered; 2) the improved performance of the proposed method over state-of-the-art methods that utilize either relative or pairwise constraints; and 3) the robustness of our method in the presence of noisy constraints, such as those provided by human judgement.</abstract>
   </article>
   <article>
      <title>Comprehend DeepWalk as Matrix Factorization</title>
      <author>Cheng Yang, Zhiyuan Liu</author>
      <date>2015-01-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Word2vec, as an efficient tool for learning vector representation of words has shown its effectiveness in many natural language processing tasks. Mikolov et al. issued Skip-Gram and Negative Sampling model for developing this toolbox. Perozzi et al. introduced the Skip-Gram model into the study of social network for the first time, and designed an algorithm named DeepWalk for learning node embedding on a graph. We prove that the DeepWalk algorithm is actually factoring a matrix M where each entry M_{ij} is logarithm of the average probability that node i randomly walks to node j in fix steps.</abstract>
   </article>
   <article>
      <title>On Enhancing The Performance Of Nearest Neighbour Classifiers Using
  Hassanat Distance Metric</title>
      <author>Mouhammd Alkasassbeh, Ghada A. Altarawneh, Ahmad B. A. Hassanat</author>
      <date>2015-01-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We showed in this work how the Hassanat distance metric enhances the performance of the nearest neighbour classifiers. The results demonstrate the superiority of this distance metric over the traditional and most-used distances, such as Manhattan distance and Euclidian distance. Moreover, we proved that the Hassanat distance metric is invariant to data scale, noise and outliers. Throughout this work, it is clearly notable that both ENN and IINC performed very well with the distance investigated, as their accuracy increased significantly by 3.3% and 3.1% respectively, with no significant advantage of the ENN over the IINC in terms of accuracy. Correspondingly, it can be noted from our results that there is no optimal algorithm that can solve all real-life problems perfectly; this is supported by the no-free-lunch theorem</abstract>
   </article>
   <article>
      <title>Differential Search Algorithm-based Parametric Optimization of Fuzzy
  Generalized Eigenvalue Proximal Support Vector Machine</title>
      <author>M. H. Marghny, Rasha M. Abd ElAziz, Ahmed I. Taloba</author>
      <date>2015-01-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Support Vector Machine (SVM) is an effective model for many classification problems. However, SVM needs the solution of a quadratic program which require specialized code. In addition, SVM has many parameters, which affects the performance of SVM classifier. Recently, the Generalized Eigenvalue Proximal SVM (GEPSVM) has been presented to solve the SVM complexity. In real world applications data may affected by error or noise, working with this data is a challenging problem. In this paper, an approach has been proposed to overcome this problem. This method is called DSA-GEPSVM. The main improvements are carried out based on the following: 1) a novel fuzzy values in the linear case. 2) A new Kernel function in the nonlinear case. 3) Differential Search Algorithm (DSA) is reformulated to find near optimal values of the GEPSVM parameters and its kernel parameters. The experimental results show that the proposed approach is able to find the suitable parameter values, and has higher classification accuracy compared with some other algorithms.</abstract>
   </article>
   <article>
      <title>Efficient Online Relative Comparison Kernel Learning</title>
      <author>Eric Heim, Matthew Berger, Lee M. Seversky, Milos Hauskrecht</author>
      <date>2015-01-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Learning a kernel matrix from relative comparison human feedback is an important problem with applications in collaborative filtering, object retrieval, and search. For learning a kernel over a large number of objects, existing methods face significant scalability issues inhibiting the application of these methods to settings where a kernel is learned in an online and timely fashion. In this paper we propose a novel framework called Efficient online Relative comparison Kernel LEarning (ERKLE), for efficiently learning the similarity of a large set of objects in an online manner. We learn a kernel from relative comparisons via stochastic <term>gradient descent</term>, one query response at a time, by taking advantage of the sparse and low-rank properties of the gradient to efficiently restrict the kernel to lie in the space of positive semidefinite matrices. In addition, we derive a passive-aggressive online update for minimally satisfying new relative comparisons as to not disrupt the influence of previously obtained comparisons. Experimentally, we demonstrate a considerable improvement in speed while obtaining improved or comparable accuracy compared to current methods in the online learning setting.</abstract>
   </article>
   <article>
      <title>Deep Autoencoders for Dimensionality Reduction of High-Content Screening
  Data</title>
      <author>Lee Zamparo, Zhaolei Zhang</author>
      <date>2015-01-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>High-content screening uses large collections of unlabeled cell image data to reason about genetics or cell biology. Two important tasks are to identify those cells which bear interesting phenotypes, and to identify sub-populations enriched for these phenotypes. This exploratory data analysis usually involves dimensionality reduction followed by clustering, in the hope that clusters represent a phenotype. We propose the use of stacked de-noising auto-encoders to perform dimensionality reduction for high-content screening. We demonstrate the superior performance of our approach over PCA, Local Linear Embedding, Kernel PCA and Isomap.</abstract>
   </article>
   <article>
      <title>A Gaussian Particle Filter Approach for Sensors to Track Multiple Moving
  Targets</title>
      <author>Haojun Li</author>
      <date>2015-01-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In a variety of problems, the number and state of multiple moving targets are unknown and are subject to be inferred from their measurements obtained by a sensor with limited sensing ability. This type of problems is raised in a variety of applications, including monitoring of endangered species, cleaning, and surveillance. Particle filters are widely used to estimate target state from its prior information and its measurements that recently become available, especially for the cases when the measurement model and the prior distribution of state of interest are non-Gaussian. However, the problem of estimating number of total targets and their state becomes intractable when the number of total targets and the measurement-target association are unknown. This paper presents a novel Gaussian particle filter technique that combines Kalman filter and particle filter for estimating the number and state of total targets based on the measurement obtained online. The estimation is represented by a set of weighted particles, different from classical particle filter, where each particle is a Gaussian distribution instead of a point mass.</abstract>
   </article>
   <article>
      <title>Learning a Fuzzy Hyperplane Fat Margin Classifier with Minimum VC
  dimension</title>
      <author>Jayadeva, Sanjit Singh Batra, Siddarth Sabharwal</author>
      <date>2015-01-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The Vapnik-Chervonenkis (VC) dimension measures the complexity of a learning machine, and a low VC dimension leads to good generalization. The recently proposed Minimal Complexity Machine (MCM) learns a hyperplane classifier by minimizing an exact bound on the VC dimension. This paper extends the MCM classifier to the fuzzy domain. The use of a fuzzy membership is known to reduce the effect of outliers, and to reduce the effect of noise on learning. Experimental results show, that on a number of benchmark datasets, the the fuzzy MCM classifier outperforms SVMs and the conventional MCM in terms of generalization, and that the fuzzy MCM uses fewer support vectors. On several benchmark datasets, the fuzzy MCM classifier yields excellent test set accuracies while using one-tenth the number of support vectors used by SVMs.</abstract>
   </article>
   <article>
      <title>Max-Cost Discrete Function Evaluation Problem under a Budget</title>
      <author>Feng Nan, Joseph Wang, Venkatesh Saligrama</author>
      <date>2015-01-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose novel methods for max-cost Discrete Function Evaluation Problem (DFEP) under budget constraints. We are motivated by applications such as clinical diagnosis where a patient is subjected to a sequence of (possibly expensive) tests before a decision is made. Our goal is to develop strategies for minimizing max-costs. The problem is known to be NP hard and greedy methods based on specialized impurity functions have been proposed. We develop a broad class of \emph{admissible} impurity functions that admit monomials, classes of polynomials, and hinge-loss functions that allow for flexible impurity design with provably optimal approximation bounds. This flexibility is important for datasets when max-cost can be overly sensitive to "outliers." Outliers bias max-cost to a few examples that require a large number of tests for classification. We design admissible functions that allow for accuracy-cost trade-off and result in $O(\log n)$ guarantees of the optimal cost among trees with corresponding classification accuracy levels.</abstract>
   </article>
   <article>
      <title>Deep Learning with Nonparametric Clustering</title>
      <author>Gang Chen</author>
      <date>2015-01-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Clustering is an essential problem in machine learning and data mining. One vital factor that impacts clustering performance is how to learn or design the data representation (or features). Fortunately, recent advances in <term>deep learning</term> can learn unsupervised features effectively, and have yielded state of the art performance in many classification problems, such as character recognition, object recognition and document categorization. However, little attention has been paid to the potential of <term>deep learning</term> for unsupervised clustering problems. In this paper, we propose a deep belief network with nonparametric clustering. As an unsupervised method, our model first leverages the advantages of <term>deep learning</term> for feature representation and dimension reduction. Then, it performs nonparametric clustering under a maximum margin framework -- a discriminative clustering model and can be trained online efficiently in the code space. Lastly model parameters are refined in the deep belief network. Thus, this model can learn features for clustering and infer model complexity in an unified framework. The experimental results show the advantage of our approach over competitive baselines.</abstract>
   </article>
   <article>
      <title>Classification with Low Rank and Missing Data</title>
      <author>Elad Hazan, Roi Livni, Yishay Mansour</author>
      <date>2015-01-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider classification and regression tasks where we have missing data and assume that the (clean) data resides in a low rank subspace. Finding a hidden subspace is known to be computationally hard. Nevertheless, using a non-proper formulation we give an efficient agnostic algorithm that classifies as good as the best linear classifier coupled with the best low-dimensional subspace in which the data resides. A direct implication is that our algorithm can linearly (and non-linearly through kernels) classify provably as well as the best classifier that has access to the full data.</abstract>
   </article>
   <article>
      <title>A Proximal Approach for Sparse Multiclass SVM</title>
      <author>G. Chierchia, Nelly Pustelnik, Jean-Christophe Pesquet, B. Pesquet-Popescu</author>
      <date>2015-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Sparsity-inducing penalties are useful tools to design multiclass <term>support vector machine</term>s (SVMs). In this paper, we propose a convex optimization approach for efficiently and exactly solving the multiclass SVM learning problem involving a sparse regularization and the multiclass hinge loss formulated by Crammer and Singer. We provide two algorithms: the first one dealing with the hinge loss as a penalty term, and the other one addressing the case when the hinge loss is enforced through a constraint. The related convex optimization problems can be efficiently solved thanks to the flexibility offered by recent primal-dual proximal algorithms and epigraphical splitting techniques. Experiments carried out on several datasets demonstrate the interest of considering the exact expression of the hinge loss rather than a smooth approximation. The efficiency of the proposed algorithms w.r.t. several state-of-the-art methods is also assessed through comparisons of execution times.</abstract>
   </article>
   <article>
      <title>Multi-view learning for multivariate performance measures optimization</title>
      <author>Jim Jing-Yan Wang</author>
      <date>2015-01-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose the problem of optimizing multivariate performance measures from multi-view data, and an effective method to solve it. This problem has two features: the data points are presented by multiple views, and the target of learning is to optimize complex multivariate performance measures. We propose to learn a linear discriminant functions for each view, and combine them to construct a overall multivariate mapping function for mult-view data. To learn the parameters of the linear dis- criminant functions of different views to optimize multivariate performance measures, we formulate a optimization problem. In this problem, we propose to minimize the complexity of the linear discriminant functions of each view, encourage the consistences of the responses of different views over the same data points, and minimize the upper boundary of a given multivariate performance measure. To optimize this problem, we employ the cutting-plane method in an iterative algorithm. In each iteration, we update a set of constrains, and optimize the mapping function parameter of each view one by one.</abstract>
   </article>
   <article>
      <title>Generalised Random Forest Space Overview</title>
      <author>Miron B. Kursa</author>
      <date>2015-01-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Assuming a view of the Random Forest as a special case of a nested ensemble of interchangeable modules, we construct a generalisation space allowing one to easily develop novel methods based on this algorithm. We discuss the role and required properties of modules at each level, especially in context of some already proposed RF generalisations.</abstract>
   </article>
   <article>
      <title>Comment on "Clustering by fast search and find of density peaks"</title>
      <author>Shuliang Wang, Dakui Wang, Caoyuan Li, Yan Li</author>
      <date>2015-01-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In [1], a clustering algorithm was given to find the centers of clusters quickly. However, the accuracy of this algorithm heavily depend on the threshold value of d-c. Furthermore, [1] has not provided any efficient way to select the threshold value of d-c, that is, one can have to estimate the value of d_c depend on one's subjective experience. In this paper, based on the data field [2], we propose a new way to automatically extract the threshold value of d_c from the original data set by using the potential entropy of data field. For any data set to be clustered, the most reasonable value of d_c can be objectively calculated from the data set by using our proposed method. The same experiments in [1] are redone with our proposed method on the same experimental data set used in [1], the results of which shows that the problem to calculate the threshold value of d_c in [1] has been solved by using our method.</abstract>
   </article>
   <article>
      <title>Regularized maximum correntropy machine</title>
      <author>Jim Jing-Yan Wang, Yunji Wang, Bing-Yi Jing, Xin Gao</author>
      <date>2015-01-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we investigate the usage of regularized correntropy framework for learning of classifiers from noisy labels. The class label predictors learned by minimizing transitional loss functions are sensitive to the noisy and outlying labels of training samples, because the transitional loss functions are equally applied to all the samples. To solve this problem, we propose to learn the class label predictors by maximizing the correntropy between the predicted labels and the true labels of the training samples, under the regularized Maximum Correntropy Criteria (MCC) framework. Moreover, we regularize the predictor parameter to control the complexity of the predictor. The learning problem is formulated by an objective function considering the parameter regularization and MCC simultaneously. By optimizing the objective function alternately, we develop a novel predictor learning algorithm. The experiments on two chal- lenging pattern classification tasks show that it significantly outperforms the machines with transitional loss functions.</abstract>
   </article>
   <article>
      <title>Extreme Entropy Machines: Robust information theoretic classification</title>
      <author>Wojciech Marian Czarnecki, Jacek Tabor</author>
      <date>2015-01-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Most of the existing classification methods are aimed at minimization of empirical risk (through some simple point-based error measured with loss function) with added regularization. We propose to approach this problem in a more information theoretic way by investigating applicability of entropy measures as a classification model objective function. We focus on quadratic Renyi's entropy and connected Cauchy-Schwarz Divergence which leads to the construction of Extreme Entropy Machines (EEM).   The main contribution of this paper is proposing a model based on the information theoretic concepts which on the one hand shows new, entropic perspective on known linear classifiers and on the other leads to a construction of very robust method competetitive with the state of the art non-information theoretic ones (including Support Vector Machines and Extreme Learning Machines).   Evaluation on numerous problems spanning from small, simple ones from UCI repository to the large (hundreads of thousands of samples) extremely unbalanced (up to 100:1 classes' ratios) datasets shows wide applicability of the EEM in real life problems and that it scales well.</abstract>
   </article>
   <article>
      <title>Deep Transductive Semi-supervised Maximum Margin Clustering</title>
      <author>Gang Chen</author>
      <date>2015-01-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Semi-supervised clustering is an very important topic in machine learning and computer vision. The key challenge of this problem is how to learn a metric, such that the instances sharing the same label are more likely close to each other on the embedded space. However, little attention has been paid to learn better representations when the data lie on non-linear manifold. Fortunately, <term>deep learning</term> has led to great success on feature learning recently. Inspired by the advances of <term>deep learning</term>, we propose a deep transductive semi-supervised maximum margin clustering approach. More specifically, given pairwise constraints, we exploit both labeled and unlabeled data to learn a non-linear mapping under maximum margin framework for clustering analysis. Thus, our model unifies transductive learning, feature learning and maximum margin techniques in the semi-supervised clustering framework. We pretrain the deep network structure with restricted Boltzmann machines (RBMs) layer by layer greedily, and optimize our objective function with <term>gradient descent</term>. By checking the most violated constraints, our approach updates the model parameters through error <term>backpropagation</term>, in which deep features are learned automatically. The experimental results shows that our model is significantly better than the state of the art on semi-supervised clustering.</abstract>
   </article>
   <article>
      <title>On a Family of Decomposable Kernels on Sequences</title>
      <author>Andrea Baisero, Florian T. Pokorny, Carl Henrik Ek</author>
      <date>2015-01-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In many applications data is naturally presented in terms of orderings of some basic elements or symbols. Reasoning about such data requires a notion of similarity capable of handling sequences of different lengths. In this paper we describe a family of Mercer kernel functions for such sequentially structured data. The family is characterized by a decomposable structure in terms of symbol-level and structure-level similarities, representing a specific combination of kernels which allows for efficient computation. We provide an experimental evaluation on sequential classification tasks comparing kernels from our family of kernels to a state of the art sequence kernel called the Global Alignment kernel which has been shown to outperform Dynamic Time Warping</abstract>
   </article>
   <article>
      <title>Compressed Support Vector Machines</title>
      <author>Zhixiang Xu, Jacob R. Gardner, Stephen Tyree, Kilian Q. Weinberger</author>
      <date>2015-01-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Support vector machines (SVM) can classify data sets along highly non-linear decision boundaries because of the kernel-trick. This expressiveness comes at a price: During test-time, the SVM classifier needs to compute the kernel inner-product between a test sample and all support vectors. With large training data sets, the time required for this computation can be substantial. In this paper, we introduce a post-processing algorithm, which compresses the learned SVM model by reducing and optimizing support vectors. We evaluate our algorithm on several medium-scaled real-world data sets, demonstrating that it maintains high test accuracy while reducing the test-time evaluation cost by several orders of magnitude---in some cases from hours to seconds. It is fair to say that most of the work in this paper was previously been invented by Burges and Sch\"olkopf almost 20 years ago. For most of the time during which we conducted this research, we were unaware of this prior work. However, in the past two decades, computing power has increased drastically, and we can therefore provide empirical insights that were not possible in their original paper.</abstract>
   </article>
   <article>
      <title>Novel Approaches for Predicting Risk Factors of Atherosclerosis</title>
      <author>V. Sree Hari Rao, M. Naresh Kumar</author>
      <date>2015-01-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Coronary heart disease (CHD) caused by hardening of artery walls due to cholesterol known as atherosclerosis is responsible for large number of deaths world-wide. The disease progression is slow, asymptomatic and may lead to sudden cardiac arrest, stroke or myocardial infraction. Presently, imaging techniques are being employed to understand the molecular and metabolic activity of atherosclerotic plaques to estimate the risk. Though imaging methods are able to provide some information on plaque metabolism they lack the required resolution and sensitivity for detection. In this paper we consider the clinical observations and habits of individuals for predicting the risk factors of CHD. The identification of risk factors helps in stratifying patients for further intensive tests such as nuclear imaging or coronary angiography. We present a novel approach for predicting the risk factors of atherosclerosis with an in-built imputation algorithm and particle swarm optimization (PSO). We compare the performance of our methodology with other machine learning techniques on STULONG dataset which is based on longitudinal study of middle aged individuals lasting for twenty years. Our methodology powered by PSO search has identified physical inactivity as one of the risk factor for the onset of atherosclerosis in addition to other already known factors. The decision rules extracted by our methodology are able to predict the risk factors with an accuracy of $99.73%$ which is higher than the accuracies obtained by application of the state-of-the-art machine learning techniques presently being employed in the identification of atherosclerosis risk studies.</abstract>
   </article>
   <article>
      <title>Per-Block-Convex Data Modeling by Accelerated Stochastic Approximation</title>
      <author>Konstantinos Slavakis, Georgios B. Giannakis</author>
      <date>2015-01-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Applications involving dictionary learning, non-negative matrix factorization, subspace clustering, and parallel factor tensor decomposition tasks motivate well algorithms for per-block-convex and non-smooth optimization problems. By leveraging the stochastic approximation paradigm and first-order acceleration schemes, this paper develops an online and modular learning algorithm for a large class of non-convex data models, where convexity is manifested only per-block of variables whenever the rest of them are held fixed. The advocated algorithm incurs computational complexity that scales linearly with the number of unknowns. Under minimal assumptions on the cost functions of the composite optimization task, without bounding constraints on the optimization variables, or any explicit information on bounds of Lipschitz coefficients, the expected cost evaluated online at the resultant iterates is provably convergent with quadratic rate to an accumulation point of the (per-block) minima, while subgradients of the expected cost asymptotically vanish in the mean-squared sense. The merits of the general approach are demonstrated in two online learning setups: (i) Robust linear regression using a sparsity-cognizant total least-squares criterion; and (ii) semi-supervised dictionary learning for network-wide link load tracking and imputation with missing entries. Numerical tests on synthetic and real data highlight the potential of the proposed framework for streaming data analytics by demonstrating superior performance over block coordinate descent, and reduced complexity relative to the popular alternating-direction method of multipliers.</abstract>
   </article>
   <article>
      <title>Efficient Divide-And-Conquer Classification Based on Feature-Space
  Decomposition</title>
      <author>Qi Guo, Bo-Wei Chen, Feng Jiang, Xiangyang Ji, Sun-Yuan Kung</author>
      <date>2015-01-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This study presents a divide-and-conquer (DC) approach based on feature space decomposition for classification. When large-scale datasets are present, typical approaches usually employed truncated kernel methods on the feature space or DC approaches on the sample space. However, this did not guarantee separability between classes, owing to overfitting. To overcome such problems, this work proposes a novel DC approach on feature spaces consisting of three steps. Firstly, we divide the feature space into several subspaces using the decomposition method proposed in this paper. Subsequently, these feature subspaces are sent into individual local classifiers for training. Finally, the outcomes of local classifiers are fused together to generate the final classification results. Experiments on large-scale datasets are carried out for performance evaluation. The results show that the error rates of the proposed DC method decreased comparing with the state-of-the-art fast SVM solvers, e.g., reducing error rates by 10.53% and 7.53% on RCV1 and covtype datasets respectively.</abstract>
   </article>
   <article>
      <title>Representing Objects, Relations, and Sequences</title>
      <author>Stephen I. Gallant, T. Wendy Okaywe</author>
      <date>2015-01-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Vector Symbolic Architectures (VSAs) are high-dimensional vector representations of objects (eg., words, image parts), relations (eg., sentence structures), and sequences for use with machine learning algorithms. They consist of a vector addition operator for representing a collection of unordered objects, a Binding operator for associating groups of objects, and a methodology for encoding complex structures.   We first develop Constraints that machine learning imposes upon VSAs: for example, similar structures must be represented by similar vectors. The constraints suggest that current VSAs should represent phrases ("The smart Brazilian girl") by binding sums of terms, in addition to simply binding the terms directly.   We show that matrix multiplication can be used as the binding operator for a VSA, and that matrix elements can be chosen at random. A consequence for living systems is that binding is mathematically possible without the need to specify, in advance, precise neuron-to-neuron connection properties for large numbers of synapses.   A VSA that incorporates these ideas, MBAT (Matrix Binding of Additive Terms), is described that satisfies all Constraints.   With respect to machine learning, for some types of problems appropriate VSA representations permit us to prove learnability, rather than relying on simulations. We also propose dividing machine (and neural) learning and representation into three Stages, with differing roles for learning in each stage.   For neural modeling, we give "representational reasons" for nervous systems to have many recurrent connections, as well as for the importance of phrases in language processing.   Sizing simulations and analyses suggest that VSAs in general, and MBAT in particular, are ready for real-world applications.</abstract>
   </article>
   <article>
      <title>A Batchwise Monotone Algorithm for Dictionary Learning</title>
      <author>Huan Wang, John Wright, Daniel Spielman</author>
      <date>2015-01-31</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a batchwise monotone algorithm for dictionary learning. Unlike the state-of-the-art dictionary learning algorithms which impose sparsity constraints on a sample-by-sample basis, we instead treat the samples as a batch, and impose the sparsity constraint on the whole. The benefit of batchwise optimization is that the non-zeros can be better allocated across the samples, leading to a better approximation of the whole. To accomplish this, we propose procedures to switch non-zeros in both rows and columns in the support of the coefficient matrix to reduce the reconstruction error. We prove in the proposed support switching procedure the objective of the algorithm, i.e., the reconstruction error, decreases monotonically and converges. Furthermore, we introduce a block orthogonal matching pursuit algorithm that also operates on sample batches to provide a warm start. Experiments on both natural image patches and UCI data sets show that the proposed algorithm produces a better approximation with the same sparsity levels compared to the state-of-the-art algorithms.</abstract>
   </article>
   <article>
      <title>Lock in Feedback in Sequential Experiments</title>
      <author>Maurits Kaptein, Davide Iannuzzi</author>
      <date>2015-02-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We often encounter situations in which an experimenter wants to find, by sequential experimentation, $x_{max} = \arg\max_{x} f(x)$, where $f(x)$ is a (possibly unknown) function of a well controllable variable $x$. Taking inspiration from physics and engineering, we have designed a new method to address this problem. In this paper, we first introduce the method in continuous time, and then present two algorithms for use in sequential experiments. Through a series of simulation studies, we show that the method is effective for finding maxima of unknown functions by experimentation, even when the maximum of the functions drifts or when the signal to noise ratio is low.</abstract>
   </article>
   <article>
      <title>Learning Parametric-Output HMMs with Two Aliased States</title>
      <author>Roi Weiss, Boaz Nadler</author>
      <date>2015-02-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In various applications involving hidden Markov models (HMMs), some of the hidden states are aliased, having identical output distributions. The minimality, identifiability and learnability of such aliased HMMs have been long standing problems, with only partial solutions provided thus far. In this paper we focus on parametric-output HMMs, whose output distributions come from a parametric family, and that have exactly two aliased states. For this class, we present a complete characterization of their minimality and identifiability. Furthermore, for a large family of parametric output distributions, we derive computationally efficient and statistically consistent algorithms to detect the presence of aliasing and learn the aliased HMM transition and emission parameters. We illustrate our theoretical analysis by several simulations.</abstract>
   </article>
   <article>
      <title>SDNA: Stochastic Dual Newton Ascent for Empirical Risk Minimization</title>
      <author>Zheng Qu, Peter Richtárik, Martin Takáč, Olivier Fercoq</author>
      <date>2015-02-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a new algorithm for minimizing regularized empirical loss: Stochastic Dual Newton Ascent (SDNA). Our method is dual in nature: in each iteration we update a random subset of the dual variables. However, unlike existing methods such as stochastic dual coordinate ascent, SDNA is capable of utilizing all curvature information contained in the examples, which leads to striking improvements in both theory and practice - sometimes by orders of magnitude. In the special case when an L2-regularizer is used in the primal, the dual problem is a concave quadratic maximization problem plus a separable term. In this regime, SDNA in each step solves a proximal subproblem involving a random principal submatrix of the Hessian of the quadratic function; whence the name of the method. If, in addition, the loss functions are quadratic, our method can be interpreted as a novel variant of the recently introduced Iterative Hessian Sketch.</abstract>
   </article>
   <article>
      <title>Rademacher Observations, Private Data, and Boosting</title>
      <author>Richard Nock, Giorgio Patrini, Arik Friedman</author>
      <date>2015-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The minimization of the logistic loss is a popular approach to batch supervised learning. Our paper starts from the surprising observation that, when fitting linear (or kernelized) classifiers, the minimization of the logistic loss is \textit{equivalent} to the minimization of an exponential \textit{rado}-loss computed (i) over transformed data that we call Rademacher observations (rados), and (ii) over the \textit{same} classifier as the one of the logistic loss. Thus, a classifier learnt from rados can be \textit{directly} used to classify \textit{observations}. We provide a learning algorithm over rados with boosting-compliant convergence rates on the \textit{logistic loss} (computed over examples). Experiments on domains with up to millions of examples, backed up by theoretical arguments, display that learning over a small set of random rados can challenge the state of the art that learns over the \textit{complete} set of examples. We show that rados comply with various privacy requirements that make them good candidates for machine learning in a privacy framework. We give several algebraic, geometric and computational hardness results on reconstructing examples from rados. We also show how it is possible to craft, and efficiently learn from, rados in a differential privacy framework. Tests reveal that learning from differentially private rados can compete with learning from random rados, and hence with batch learning from examples, achieving non-trivial privacy vs accuracy tradeoffs.</abstract>
   </article>
   <article>
      <title>An Infinite Restricted Boltzmann Machine</title>
      <author>Marc-Alexandre Côté, Hugo Larochelle</author>
      <date>2015-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a mathematical construction for the restricted Boltzmann machine (RBM) that doesn't require specifying the number of hidden units. In fact, the hidden layer size is adaptive and can grow during training. This is obtained by first extending the RBM to be sensitive to the ordering of its hidden units. Then, thanks to a carefully chosen definition of the energy function, we show that the limit of infinitely many hidden units is well defined. As with RBM, approximate maximum likelihood training can be performed, resulting in an algorithm that naturally and adaptively adds trained hidden units during learning. We empirically study the behaviour of this infinite RBM, showing that its performance is competitive to that of the RBM, while not requiring the tuning of a hidden layer size.</abstract>
   </article>
   <article>
      <title>Adaptive Random SubSpace Learning (RSSL) Algorithm for Prediction</title>
      <author>Mohamed Elshrif, Ernest Fokoue</author>
      <date>2015-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a novel adaptive random subspace learning algorithm (RSSL) for prediction purpose. This new framework is flexible where it can be adapted with any learning technique. In this paper, we tested the algorithm for regression and classification problems. In addition, we provide a variety of weighting schemes to increase the robustness of the developed algorithm. These different wighting flavors were evaluated on simulated as well as on real-world data sets considering the cases where the ratio between features (attributes) and instances (samples) is large and vice versa. The framework of the new algorithm consists of many stages: first, calculate the weights of all features on the data set using the correlation coefficient and F-statistic statistical measurements. Second, randomly draw n samples with replacement from the data set. Third, perform regular bootstrap sampling (bagging). Fourth, draw without replacement the indices of the chosen variables. The decision was taken based on the heuristic subspacing scheme. Fifth, call base learners and build the model. Sixth, use the model for prediction purpose on test set of the data. The results show the advancement of the adaptive RSSL algorithm in most of the cases compared with the synonym (conventional) machine learning algorithms.</abstract>
   </article>
   <article>
      <title>Optimal and Adaptive Algorithms for Online Boosting</title>
      <author>Alina Beygelzimer, Satyen Kale, Haipeng Luo</author>
      <date>2015-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study online boosting, the task of converting any weak online learner into a strong online learner. Based on a novel and natural definition of weak online learnability, we develop two online boosting algorithms. The first algorithm is an online version of boost-by-majority. By proving a matching lower bound, we show that this algorithm is essentially optimal in terms of the number of weak learners and the sample complexity needed to achieve a specified accuracy. This optimal algorithm is not adaptive however. Using tools from online loss minimization, we derive an adaptive online boosting algorithm that is also parameter-free, but not optimal. Both algorithms work with base learners that can handle example importance weights directly, as well as by rejection sampling examples with probability defined by the booster. Results are complemented with an extensive experimental study.</abstract>
   </article>
   <article>
      <title>Learning Reductions that Really Work</title>
      <author>Alina Beygelzimer, Hal Daumé III, John Langford, Paul Mineiro</author>
      <date>2015-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We provide a summary of the mathematical and computational techniques that have enabled learning reductions to effectively address a wide class of problems, and show that this approach to solving machine learning problems can be broadly useful.</abstract>
   </article>
   <article>
      <title>Scalable Multilabel Prediction via Randomized Methods</title>
      <author>Nikos Karampatziakis, Paul Mineiro</author>
      <date>2015-02-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Modeling the dependence between outputs is a fundamental challenge in multilabel classification. In this work we show that a generic regularized nonlinearity mapping independent predictions to joint predictions is sufficient to achieve state-of-the-art performance on a variety of benchmark problems. Crucially, we compute the joint predictions without ever obtaining any independent predictions, while incorporating low-rank and smoothness regularization. We achieve this by leveraging randomized algorithms for matrix decomposition and kernel approximation. Furthermore, our techniques are applicable to the multiclass setting. We apply our method to a variety of multiclass and multilabel data sets, obtaining state-of-the-art results.</abstract>
   </article>
   <article>
      <title>Learning Transferable Features with Deep Adaptation Networks</title>
      <author>Mingsheng Long, Yue Cao, Jianmin Wang, Michael I. Jordan</author>
      <date>2015-02-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Recent studies reveal that a deep <term>neural network</term> can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional <term>neural network</term> to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multi-kernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks.</abstract>
   </article>
   <article>
      <title>Batch Normalization: Accelerating Deep Network Training by Reducing
  Internal Covariate Shift</title>
      <author>Sergey Ioffe, Christian Szegedy</author>
      <date>2015-02-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters.</abstract>
   </article>
   <article>
      <title>Supervised LogEuclidean Metric Learning for Symmetric Positive Definite
  Matrices</title>
      <author>Florian Yger, Masashi Sugiyama</author>
      <date>2015-02-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Metric learning has been shown to be highly effective to improve the performance of nearest neighbor classification. In this paper, we address the problem of metric learning for Symmetric Positive Definite (SPD) matrices such as covariance matrices, which arise in many real-world applications. Naively using standard Mahalanobis metric learning methods under the Euclidean geometry for SPD matrices is not appropriate, because the difference of SPD matrices can be a non-SPD matrix and thus the obtained solution can be uninterpretable. To cope with this problem, we propose to use a properly parameterized LogEuclidean distance and optimize the metric with respect to kernel-target alignment, which is a supervised criterion for kernel learning. Then the resulting non-trivial optimization problem is solved by utilizing the Riemannian geometry. Finally, we experimentally demonstrate the usefulness of our LogEuclidean metric learning algorithm on real-world classification tasks for EEG signals and texture patches.</abstract>
   </article>
   <article>
      <title>Adding vs. Averaging in Distributed Primal-Dual Optimization</title>
      <author>Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan, Peter Richtárik, Martin Takáč</author>
      <date>2015-02-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Distributed optimization methods for large-scale machine learning suffer from a communication bottleneck. It is difficult to reduce this bottleneck while still efficiently and accurately aggregating partial work from different machines. In this paper, we present a novel generalization of the recent communication-efficient primal-dual framework (CoCoA) for distributed optimization. Our framework, CoCoA+, allows for additive combination of local updates to the global parameters at each iteration, whereas previous schemes with convergence guarantees only allow conservative averaging. We give stronger (primal-dual) convergence rate guarantees for both CoCoA as well as our new variants, and generalize the theory for both methods to cover non-smooth convex loss functions. We provide an extensive experimental comparison that shows the markedly improved performance of CoCoA+ on several real-world distributed datasets, especially when scaling up the number of machines.</abstract>
   </article>
   <article>
      <title>Scalable Stochastic Alternating Direction Method of Multipliers</title>
      <author>Shen-Yi Zhao, Wu-Jun Li, Zhi-Hua Zhou</author>
      <date>2015-02-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic alternating direction method of multipliers (ADMM), which visits only one sample or a mini-batch of samples each time, has recently been proved to achieve better performance than batch ADMM. However, most stochastic methods can only achieve a convergence rate $O(1/\sqrt T)$ on general convex problems,where T is the number of iterations. Hence, these methods are not scalable with respect to convergence rate (computation cost). There exists only one stochastic method, called SA-ADMM, which can achieve convergence rate $O(1/T)$ on general convex problems. However, an extra memory is needed for SA-ADMM to store the historic gradients on all samples, and thus it is not scalable with respect to storage cost. In this paper, we propose a novel method, called scalable stochastic ADMM(SCAS-ADMM), for large-scale optimization and learning problems. Without the need to store the historic gradients, SCAS-ADMM can achieve the same convergence rate $O(1/T)$ as the best stochastic method SA-ADMM and batch ADMM on general convex problems. Experiments on graph-guided fused lasso show that SCAS-ADMM can achieve state-of-the-art performance in real applications</abstract>
   </article>
   <article>
      <title>A Predictive System for detection of Bankruptcy using Machine Learning
  techniques</title>
      <author>Kalyan Nagaraj, Amulyashree Sridhar</author>
      <date>2015-02-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Bankruptcy is a legal procedure that claims a person or organization as a debtor. It is essential to ascertain the risk of bankruptcy at initial stages to prevent financial losses. In this perspective, different soft computing techniques can be employed to ascertain bankruptcy. This study proposes a bankruptcy prediction system to categorize the companies based on extent of risk. The prediction system acts as a decision support tool for detection of bankruptcy   Keywords: Bankruptcy, soft computing, decision support tool</abstract>
   </article>
   <article>
      <title>Non-Adaptive Learning a Hidden Hipergraph</title>
      <author>Hasan Abasi, Nader H. Bshouty, Hanna Mazzawi</author>
      <date>2015-02-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We give a new deterministic algorithm that non-adaptively learns a hidden hypergraph from edge-detecting queries. All previous non-adaptive algorithms either run in exponential time or have non-optimal query complexity. We give the first polynomial time non-adaptive learning algorithm for learning hypergraph that asks almost optimal number of queries.</abstract>
   </article>
   <article>
      <title>Towards Biologically Plausible Deep Learning</title>
      <author>Yoshua Bengio, Dong-Hyun Lee, Jorg Bornschein, Thomas Mesnard, Zhouhan Lin</author>
      <date>2015-02-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Neuroscientists have long criticised <term>deep learning</term> algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on <term>unsupervised learning</term> but developing a learning mechanism that could account for supervised, unsupervised and <term>reinforcement learning</term>. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-Timing-Dependent Plasticity) arises out of a simple update rule that makes a lot of sense from a machine learning point of view and can be interpreted as <term>gradient descent</term> on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.</abstract>
   </article>
   <article>
      <title>Application of Deep Neural Network in Estimation of the Weld Bead
  Parameters</title>
      <author>Soheil Keshmiri, Xin Zheng, Chee Meng Chew, Chee Khiang Pang</author>
      <date>2015-02-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a <term>deep learning</term> approach to estimation of the bead parameters in welding tasks. Our model is based on a four-hidden-layer <term>neural network</term> architecture. More specifically, the first three hidden layers of this architecture utilize Sigmoid function to produce their respective intermediate outputs. On the other hand, the last hidden layer uses a linear transformation to generate the final output of this architecture. This transforms our deep network architecture from a classifier to a non-linear regression model. We compare the performance of our deep network with a selected number of results in the literature to show a considerable improvement in reducing the errors in estimation of these values. Furthermore, we show its scalability on estimating the weld bead parameters with same level of accuracy on combination of datasets that pertain to different welding techniques. This is a nontrivial result that is counter-intuitive to the general belief in this field of research.</abstract>
   </article>
   <article>
      <title>The Ladder: A Reliable Leaderboard for Machine Learning Competitions</title>
      <author>Avrim Blum, Moritz Hardt</author>
      <date>2015-02-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The organizer of a machine learning competition faces the problem of maintaining an accurate leaderboard that faithfully represents the quality of the best submission of each competing team. What makes this estimation problem particularly challenging is its sequential and adaptive nature. As participants are allowed to repeatedly evaluate their submissions on the leaderboard, they may begin to overfit to the holdout data that supports the leaderboard. Few theoretical results give actionable advice on how to design a reliable leaderboard. Existing approaches therefore often resort to poorly understood heuristics such as limiting the bit precision of answers and the rate of re-submission.   In this work, we introduce a notion of "leaderboard accuracy" tailored to the format of a competition. We introduce a natural algorithm called "the Ladder" and demonstrate that it simultaneously supports strong theoretical guarantees in a fully adaptive model of estimation, withstands practical adversarial attacks, and achieves high utility on real submission files from an actual competition hosted by Kaggle.   Notably, we are able to sidestep a powerful recent hardness result for adaptive risk estimation that rules out algorithms such as ours under a seemingly very similar notion of accuracy. On a practical note, we provide a completely parameter-free variant of our algorithm that can be deployed in a real competition with no tuning required whatsoever.</abstract>
   </article>
   <article>
      <title>Deep Transform: Error Correction via Probabilistic Re-Synthesis</title>
      <author>Andrew J. R. Simpson</author>
      <date>2015-02-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Errors in data are usually unwelcome and so some means to correct them is useful. However, it is difficult to define, detect or correct errors in an unsupervised way. Here, we train a deep <term>neural network</term> to re-synthesize its inputs at its output layer for a given class of data. We then exploit the fact that this abstract transformation, which we call a deep transform (DT), inherently rejects information (errors) existing outside of the abstract feature space. Using the DT to perform probabilistic re-synthesis, we demonstrate the recovery of data that has been subject to extreme degradation.</abstract>
   </article>
   <article>
      <title>Generalized Gradient Learning on Time Series under Elastic
  Transformations</title>
      <author>Brijnesh Jain</author>
      <date>2015-02-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The majority of machine learning algorithms assumes that objects are represented as vectors. But often the objects we want to learn on are more naturally represented by other data structures such as sequences and time series. For these representations many standard learning algorithms are unavailable. We generalize gradient-based learning algorithms to time series under dynamic time warping. To this end, we introduce elastic functions, which extend functions on time series to matrix spaces. Necessary conditions are presented under which generalized gradient learning on time series is consistent. We indicate how results carry over to arbitrary elastic distance functions and to sequences consisting of symbolic elements. Specifically, four linear classifiers are extended to time series under dynamic time warping and applied to benchmark datasets. Results indicate that generalized gradient learning via elastic functions have the potential to complement the state-of-the-art in statistical pattern recognition on time series.</abstract>
   </article>
   <article>
      <title>Real time clustering of time series using triangular potentials</title>
      <author>Aldo Pacchiano, Oliver Williams</author>
      <date>2015-02-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Motivated by the problem of computing investment portfolio weightings we investigate various methods of clustering as alternatives to traditional mean-variance approaches. Such methods can have significant benefits from a practical point of view since they remove the need to invert a sample covariance matrix, which can suffer from estimation error and will almost certainly be non-stationary. The general idea is to find groups of assets which share similar return characteristics over time and treat each group as a single composite asset. We then apply inverse volatility weightings to these new composite assets. In the course of our investigation we devise a method of clustering based on triangular potentials and we present associated theoretical results as well as various examples based on synthetic data.</abstract>
   </article>
   <article>
      <title>CSAL: Self-adaptive Labeling based Clustering Integrating Supervised
  Learning on Unlabeled Data</title>
      <author>Fangfang Li, Guandong Xu, Longbing Cao</author>
      <date>2015-02-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Supervised classification approaches can predict labels for unknown data because of the supervised training process. The success of classification is heavily dependent on the labeled training data. Differently, clustering is effective in revealing the aggregation property of unlabeled data, but the performance of most clustering methods is limited by the absence of labeled data. In real applications, however, it is time-consuming and sometimes impossible to obtain labeled data. The combination of clustering and classification is a promising and active approach which can largely improve the performance. In this paper, we propose an innovative and effective clustering framework based on self-adaptive labeling (CSAL) which integrates clustering and classification on unlabeled data. Clustering is first employed to partition data and a certain proportion of clustered data are selected by our proposed labeling approach for training classifiers. In order to refine the trained classifiers, an iterative process of Expectation-Maximization algorithm is devised into the proposed clustering framework CSAL. Experiments are conducted on publicly data sets to test different combinations of clustering algorithms and classification models as well as various training data labeling methods. The experimental results show that our approach along with the self-adaptive method outperforms other methods.</abstract>
   </article>
   <article>
      <title>Supervised cross-modal factor analysis for multiple modal data
  classification</title>
      <author>Jingbin Wang, Yihua Zhou, Kanghong Duan, Jim Jing-Yan Wang, Halima Bensmail</author>
      <date>2015-02-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we study the problem of learning from multiple modal data for purpose of document classification. In this problem, each document is composed two different modals of data, i.e., an image and a text. Cross-modal factor analysis (CFA) has been proposed to project the two different modals of data to a shared data space, so that the classification of a image or a text can be performed directly in this space. A disadvantage of CFA is that it has ignored the supervision information. In this paper, we improve CFA by incorporating the supervision information to represent and classify both image and text modals of documents. We project both image and text data to a shared data space by factor analysis, and then train a class label predictor in the shared space to use the class label information. The factor analysis parameter and the predictor parameter are learned jointly by solving one single objective function. With this objective function, we minimize the distance between the projections of image and text of the same document, and the classification error of the projection measured by hinge loss function. The objective function is optimized by an alternate optimization strategy in an iterative algorithm. Experiments in two different multiple modal document data sets show the advantage of the proposed algorithm over other CFA methods.</abstract>
   </article>
   <article>
      <title>Trust Region Policy Optimization</title>
      <author>John Schulman, Sergey Levine, Philipp Moritz, Michael I. Jordan, Pieter Abbeel</author>
      <date>2015-02-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We describe an iterative procedure for optimizing policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified procedure, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is similar to natural policy gradient methods and is effective for optimizing large nonlinear policies such as <term>neural network</term>s. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.</abstract>
   </article>
   <article>
      <title>Achieving All with No Parameters: Adaptive NormalHedge</title>
      <author>Haipeng Luo, Robert E. Schapire</author>
      <date>2015-02-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the classic online learning problem of predicting with expert advice, and propose a truly parameter-free and adaptive algorithm that achieves several objectives simultaneously without using any prior information. The main component of this work is an improved version of the NormalHedge.DT algorithm (Luo and Schapire, 2014), called AdaNormalHedge. On one hand, this new algorithm ensures small regret when the competitor has small loss and almost constant regret when the losses are stochastic. On the other hand, the algorithm is able to compete with any convex combination of the experts simultaneously, with a regret in terms of the relative entropy of the prior and the competitor. This resolves an open problem proposed by Chaudhuri et al. (2009) and Chernov and Vovk (2010). Moreover, we extend the results to the sleeping expert setting and provide two applications to illustrate the power of AdaNormalHedge: 1) competing with time-varying unknown competitors and 2) predicting almost as well as the best pruning tree. Our results on these applications significantly improve previous work from different aspects, and a special case of the first application resolves another open problem proposed by Warmuth and Koolen (2014) on whether one can simultaneously achieve optimal shifting regret for both adversarial and stochastic losses.</abstract>
   </article>
   <article>
      <title>SDCA without Duality</title>
      <author>Shai Shalev-Shwartz</author>
      <date>2015-02-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic Dual Coordinate Ascent is a popular method for solving regularized loss minimization for the case of convex losses. In this paper we show how a variant of SDCA can be applied for non-convex losses. We prove linear convergence rate even if individual loss functions are non-convex as long as the expected loss is convex.</abstract>
   </article>
   <article>
      <title>Teaching and compressing for low VC-dimension</title>
      <author>Shay Moran, Amir Shpilka, Avi Wigderson, Amir Yehudayoff</author>
      <date>2015-02-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this work we study the quantitative relation between VC-dimension and two other basic parameters related to learning and teaching. Namely, the quality of sample compression schemes and of teaching sets for classes of low VC-dimension. Let $C$ be a binary concept class of size $m$ and VC-dimension $d$. Prior to this work, the best known upper bounds for both parameters were $\log(m)$, while the best lower bounds are linear in $d$. We present significantly better upper bounds on both as follows. Set $k = O(d 2^d \log \log |C|)$.   We show that there always exists a concept $c$ in $C$ with a teaching set (i.e. a list of $c$-labeled examples uniquely identifying $c$ in $C$) of size $k$. This problem was studied by Kuhlmann (1999). Our construction implies that the recursive teaching (RT) dimension of $C$ is at most $k$ as well. The RT-dimension was suggested by Zilles et al. and Doliwa et al. (2010). The same notion (under the name partial-ID width) was independently studied by Wigderson and Yehudayoff (2013). An upper bound on this parameter that depends only on $d$ is known just for the very simple case $d=1$, and is open even for $d=2$. We also make small progress towards this seemingly modest goal.   We further construct sample compression schemes of size $k$ for $C$, with additional information of $k \log(k)$ bits. Roughly speaking, given any list of $C$-labelled examples of arbitrary length, we can retain only $k$ labeled examples in a way that allows to recover the labels of all others examples in the list, using additional $k\log (k)$ information bits. This problem was first suggested by Littlestone and Warmuth (1986).</abstract>
   </article>
   <article>
      <title>Contextual Dueling Bandits</title>
      <author>Miroslav Dudík, Katja Hofmann, Robert E. Schapire, Aleksandrs Slivkins, Masrour Zoghi</author>
      <date>2015-02-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the problem of learning to choose actions using contextual information when provided with limited feedback in the form of relative pairwise comparisons. We study this problem in the dueling-bandits framework of Yue et al. (2009), which we extend to incorporate context. Roughly, the learner's goal is to find the best policy, or way of behaving, in some space of policies, although "best" is not always so clearly defined. Here, we propose a new and natural solution concept, rooted in game theory, called a von Neumann winner, a randomized policy that beats or ties every other policy. We show that this notion overcomes important limitations of existing solutions, particularly the Condorcet winner which has typically been used in the past, but which requires strong and often unrealistic assumptions. We then present three efficient algorithms for online learning in our setting, and for approximating a von Neumann winner from batch-like data. The first of these algorithms achieves particularly low regret, even when data is adversarial, although its time and space requirements are linear in the size of the policy space. The other two algorithms require time and space only logarithmic in the size of the policy space when provided access to an oracle for solving classification problems on the space.</abstract>
   </article>
   <article>
      <title>Reified Context Models</title>
      <author>Jacob Steinhardt, Percy Liang</author>
      <date>2015-02-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A classic tension exists between exact inference in a simple model and approximate inference in a complex model. The latter offers expressivity and thus accuracy, but the former provides coverage of the space, an important property for confidence estimation and learning with indirect supervision. In this work, we introduce a new approach, reified context models, to reconcile this tension. Specifically, we let the amount of context (the arity of the factors in a graphical model) be chosen "at run-time" by reifying it---that is, letting this choice itself be a random variable inside the model. Empirically, we show that our approach obtains expressivity and coverage on three natural language tasks.</abstract>
   </article>
   <article>
      <title>Learning Fast-Mixing Models for Structured Prediction</title>
      <author>Jacob Steinhardt, Percy Liang</author>
      <date>2015-02-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Markov Chain Monte Carlo (MCMC) algorithms are often used for approximate inference inside learning, but their slow mixing can be difficult to diagnose and the approximations can seriously degrade learning. To alleviate these issues, we define a new model family using strong Doeblin Markov chains, whose mixing times can be precisely controlled by a parameter. We also develop an algorithm to learn such models, which involves maximizing the data likelihood under the induced stationary distribution of these chains. We show empirical improvements on two challenging inference tasks.</abstract>
   </article>
   <article>
      <title>Strongly Adaptive Online Learning</title>
      <author>Amit Daniely, Alon Gonen, Shai Shalev-Shwartz</author>
      <date>2015-02-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Strongly adaptive algorithms are algorithms whose performance on every time interval is close to optimal. We present a reduction that can transform standard low-regret algorithms to strongly adaptive. As a consequence, we derive simple, yet efficient, strongly adaptive algorithms for a handful of problems.</abstract>
   </article>
   <article>
      <title>The VC-Dimension of Similarity Hypotheses Spaces</title>
      <author>Mark Herbster, Paul Rubenstein, James Townsend</author>
      <date>2015-02-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Given a set $X$ and a function $h:X\longrightarrow\{0,1\}$ which labels each element of $X$ with either $0$ or $1$, we may define a function $h^{(s)}$ to measure the similarity of pairs of points in $X$ according to $h$. Specifically, for $h\in \{0,1\}^X$ we define $h^{(s)}\in \{0,1\}^{X\times X}$ by $h^{(s)}(w,x):= \mathbb{1}[h(w) = h(x)]$. This idea can be extended to a set of functions, or hypothesis space $\mathcal{H} \subseteq \{0,1\}^X$ by defining a similarity hypothesis space $\mathcal{H}^{(s)}:=\{h^{(s)}:h\in\mathcal{H}\}$. We show that ${{vc-dimension}}(\mathcal{H}^{(s)}) \in \Theta({{vc-dimension}}(\mathcal{H}))$.</abstract>
   </article>
   <article>
      <title>Online Learning with Feedback Graphs: Beyond Bandits</title>
      <author>Noga Alon, Nicolò Cesa-Bianchi, Ofer Dekel, Tomer Koren</author>
      <date>2015-02-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study a general class of online learning problems where the feedback is specified by a graph. This class includes online prediction with expert advice and the multi-armed bandit problem, but also several learning problems where the online player does not necessarily observe his own loss. We analyze how the structure of the feedback graph controls the inherent difficulty of the induced $T$-round learning problem. Specifically, we show that any feedback graph belongs to one of three classes: strongly observable graphs, weakly observable graphs, and unobservable graphs. We prove that the first class induces learning problems with $\widetilde\Theta(\alpha^{1/2} T^{1/2})$ minimax regret, where $\alpha$ is the independence number of the underlying graph; the second class induces problems with $\widetilde\Theta(\delta^{1/3}T^{2/3})$ minimax regret, where $\delta$ is the domination number of a certain portion of the graph; and the third class induces problems with linear minimax regret. Our results subsume much of the previous work on learning with feedback graphs and reveal new connections to partial monitoring games. We also show how the regret is affected if the graphs are allowed to vary with time.</abstract>
   </article>
   <article>
      <title>Unsupervised Feature Selection with Adaptive Structure Learning</title>
      <author>Liang Du, Yi-Dong Shen</author>
      <date>2015-04-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The problem of feature selection has raised considerable interests in the past decade. Traditional unsupervised methods select the features which can faithfully preserve the intrinsic structures of data, where the intrinsic structures are estimated using all the input features of data. However, the estimated intrinsic structures are unreliable/inaccurate when the redundant and noisy features are not removed. Therefore, we face a dilemma here: one need the true structures of data to identify the informative features, and one need the informative features to accurately estimate the true structures of data. To address this, we propose a unified learning framework which performs structure learning and feature selection simultaneously. The structures are adaptively learned from the results of feature selection, and the informative features are reselected to preserve the refined structures of data. By leveraging the interactions between these two essential tasks, we are able to capture accurate structures and select more informative features. Experimental results on many benchmark data sets demonstrate that the proposed method outperforms many state of the art unsupervised feature selection methods.</abstract>
   </article>
   <article>
      <title>The Child is Father of the Man: Foresee the Success at the Early Stage</title>
      <author>Liangyue Li, Hanghang Tong</author>
      <date>2015-04-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Understanding the dynamic mechanisms that drive the high-impact scientific work (e.g., research papers, patents) is a long-debated research topic and has many important implications, ranging from personal career development and recruitment search, to the jurisdiction of research resources. Recent advances in characterizing and modeling scientific success have made it possible to forecast the long-term impact of scientific work, where data mining techniques, supervised learning in particular, play an essential role. Despite much progress, several key algorithmic challenges in relation to predicting long-term scientific impact have largely remained open. In this paper, we propose a joint predictive model to forecast the long-term scientific impact at the early stage, which simultaneously addresses a number of these open challenges, including the scholarly feature design, the non-linearity, the domain-heterogeneity and dynamics. In particular, we formulate it as a regularized optimization problem and propose effective and scalable algorithms to solve it. We perform extensive empirical evaluations on large, real scholarly data sets to validate the effectiveness and the efficiency of our method.</abstract>
   </article>
   <article>
      <title>EM-Based Channel Estimation from Crowd-Sourced RSSI Samples Corrupted by
  Noise and Interference</title>
      <author>Silvija Kokalj-Filipovic, Larry Greenstein</author>
      <date>2015-04-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a method for estimating channel parameters from RSSI measurements and the lost packet count, which can work in the presence of losses due to both interference and signal attenuation below the noise floor. This is especially important in the wireless networks, such as vehicular, where propagation model changes with the density of nodes. The method is based on Stochastic Expectation Maximization, where the received data is modeled as a mixture of distributions (no/low interference and strong interference), incomplete (censored) due to packet losses. The PDFs in the mixture are Gamma, according to the commonly accepted model for wireless signal and interference power. This approach leverages the loss count as additional information, hence outperforming maximum likelihood estimation, which does not use this information (ML-), for a small number of received RSSI samples. Hence, it allows inexpensive on-line channel estimation from ad-hoc collected data. The method also outperforms ML- on uncensored data mixtures, as ML- assumes that samples are from a single-mode PDF.</abstract>
   </article>
   <article>
      <title>PASSCoDe: Parallel ASynchronous Stochastic dual Co-ordinate Descent</title>
      <author>Cho-Jui Hsieh, Hsiang-Fu Yu, Inderjit S. Dhillon</author>
      <date>2015-04-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic Dual Coordinate Descent (SDCD) has become one of the most efficient ways to solve the family of $\ell_2$-regularized empirical risk minimization problems, including linear SVM, logistic regression, and many others. The vanilla implementation of DCD is quite slow; however, by maintaining primal variables while updating dual variables, the time complexity of SDCD can be significantly reduced. Such a strategy forms the core algorithm in the widely-used LIBLINEAR package. In this paper, we parallelize the SDCD algorithms in LIBLINEAR. In recent research, several synchronized parallel SDCD algorithms have been proposed, however, they fail to achieve good speedup in the shared memory multi-core setting. In this paper, we propose a family of asynchronous stochastic dual coordinate descent algorithms (ASDCD). Each thread repeatedly selects a random dual variable and conducts coordinate updates using the primal variables that are stored in the shared memory. We analyze the convergence properties when different locking/atomic mechanisms are applied. For implementation with atomic operations, we show linear convergence under mild conditions. For implementation without any atomic operations or locking, we present the first {\it backward error analysis} for ASDCD under the multi-core environment, showing that the converged solution is the exact solution for a primal problem with perturbed regularizer. Experimental results show that our methods are much faster than previous parallel coordinate descent solvers.</abstract>
   </article>
   <article>
      <title>Autonomous CRM Control via CLV Approximation with Deep Reinforcement
  Learning in Discrete and Continuous Action Space</title>
      <author>Yegor Tkachenko</author>
      <date>2015-04-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The paper outlines a framework for autonomous control of a CRM (customer relationship management) system. First, it explores how a modified version of the widely accepted Recency-Frequency-Monetary Value system of metrics can be used to define the state space of clients or donors. Second, it describes a procedure to determine the optimal direct marketing action in discrete and continuous action space for the given individual, based on his position in the state space. The procedure involves the use of model-free Q-learning to train a deep <term>neural network</term> that relates a client's position in the state space to rewards associated with possible marketing actions. The estimated value function over the client state space can be interpreted as customer lifetime value, and thus allows for a quick plug-in estimation of CLV for a given client. Experimental results are presented, based on KDD Cup 1998 mailing dataset of donation solicitations.</abstract>
   </article>
   <article>
      <title>Data Mining for Prediction of Human Performance Capability in the
  Software-Industry</title>
      <author>Gaurav Singh Thakur, Anubhav Gupta, Sangita Gupta</author>
      <date>2015-04-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The recruitment of new personnel is one of the most essential business processes which affect the quality of human capital within any company. It is highly essential for the companies to ensure the recruitment of right talent to maintain a competitive edge over the others in the market. However IT companies often face a problem while recruiting new people for their ongoing projects due to lack of a proper framework that defines a criteria for the selection process. In this paper we aim to develop a framework that would allow any project manager to take the right decision for selecting new talent by correlating performance parameters with the other domain-specific attributes of the candidates. Also, another important motivation behind this project is to check the validity of the selection procedure often followed by various big companies in both public and private sectors which focus only on academic scores, GPA/grades of students from colleges and other academic backgrounds. We test if such a decision will produce optimal results in the industry or is there a need for change that offers a more holistic approach to recruitment of new talent in the software companies. The scope of this work extends beyond the IT domain and a similar procedure can be adopted to develop a recruitment framework in other fields as well. Data-mining techniques provide useful information from the historical projects depending on which the hiring-manager can make decisions for recruiting high-quality workforce. This study aims to bridge this hiatus by developing a data-mining framework based on an ensemble-learning technique to refocus on the criteria for personnel selection. The results from this research clearly demonstrated that there is a need to refocus on the selection-criteria for quality objectives.</abstract>
   </article>
   <article>
      <title>Maximum Entropy Linear Manifold for Learning Discriminative
  Low-dimensional Representation</title>
      <author>Wojciech Marian Czarnecki, Rafał Józefowicz, Jacek Tabor</author>
      <date>2015-04-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Representation learning is currently a very hot topic in modern machine learning, mostly due to the great success of the <term>deep learning</term> methods. In particular low-dimensional representation which discriminates classes can not only enhance the classification procedure, but also make it faster, while contrary to the high-dimensional embeddings can be efficiently used for visual based exploratory data analysis.   In this paper we propose Maximum Entropy Linear Manifold (MELM), a multidimensional generalization of Multithreshold Entropy Linear Classifier model which is able to find a low-dimensional linear data projection maximizing discriminativeness of projected classes. As a result we obtain a linear embedding which can be used for classification, class aware dimensionality reduction and data visualization. MELM provides highly discriminative 2D projections of the data which can be used as a method for constructing robust classifiers.   We provide both empirical evaluation as well as some interesting theoretical properties of our objective function such us scale and affine transformation invariance, connections with PCA and bounding of the expected balanced accuracy error.</abstract>
   </article>
   <article>
      <title>A Deep Embedding Model for Co-occurrence Learning</title>
      <author>Yelong Shen, Ruoming Jin, Jianshu Chen, Xiaodong He, Jianfeng Gao, Li Deng</author>
      <date>2015-04-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Co-occurrence Data is a common and important information source in many areas, such as the word co-occurrence in the sentences, friends co-occurrence in social networks and products co-occurrence in commercial transaction data, etc, which contains rich correlation and clustering information about the items. In this paper, we study co-occurrence data using a general energy-based probabilistic model, and we analyze three different categories of energy-based model, namely, the $L_1$, $L_2$ and $L_k$ models, which are able to capture different levels of dependency in the co-occurrence data. We also discuss how several typical existing models are related to these three types of energy models, including the Fully Visible Boltzmann Machine (FVBM) ($L_2$), Matrix Factorization ($L_2$), Log-BiLinear (LBL) models ($L_2$), and the Restricted Boltzmann Machine (RBM) model ($L_k$). Then, we propose a Deep Embedding Model (DEM) (an $L_k$ model) from the energy model in a \emph{principled} manner. Furthermore, motivated by the observation that the partition function in the energy model is intractable and the fact that the major objective of modeling the co-occurrence data is to predict using the conditional probability, we apply the \emph{maximum pseudo-likelihood} method to learn DEM. In consequence, the developed model and its learning method naturally avoid the above difficulties and can be easily used to compute the conditional probability in prediction. Interestingly, our method is equivalent to learning a special structured deep <term>neural network</term> using back-propagation and a special sampling strategy, which makes it scalable on large-scale datasets. Finally, in the experiments, we show that the DEM can achieve comparable or better results than state-of-the-art methods on datasets across several application domains.</abstract>
   </article>
   <article>
      <title>Classification with Extreme Learning Machine and Ensemble Algorithms
  Over Randomly Partitioned Data</title>
      <author>Ferhat Özgür Çatak</author>
      <date>2015-04-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this age of Big Data, machine learning based data mining methods are extensively used to inspect large scale data sets. Deriving applicable predictive modeling from these type of data sets is a challenging obstacle because of their high complexity. Opportunity with high data availability levels, automated classification of data sets has become a critical and complicated function. In this paper, the power of applying MapReduce based Distributed AdaBoosting of Extreme Learning Machine (ELM) are explored to build reliable predictive bag of classification models. Thus, (i) dataset ensembles are build; (ii) ELM algorithm is used to build weak classification models; and (iii) build a strong classification model from a set of weak classification models. This training model is applied to the publicly available knowledge discovery and data mining datasets.</abstract>
   </article>
   <article>
      <title>Convex Learning of Multiple Tasks and their Structure</title>
      <author>Carlo Ciliberto, Youssef Mroueh, Tomaso Poggio, Lorenzo Rosasco</author>
      <date>2015-04-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Reducing the amount of human supervision is a key problem in machine learning and a natural approach is that of exploiting the relations (structure) among different tasks. This is the idea at the core of multi-task learning. In this context a fundamental question is how to incorporate the tasks structure in the learning problem.We tackle this question by studying a general computational framework that allows to encode a-priori knowledge of the tasks structure in the form of a convex penalty; in this setting a variety of previously proposed methods can be recovered as special cases, including linear and non-linear approaches. Within this framework, we show that tasks and their structure can be efficiently learned considering a convex optimization problem that can be approached by means of block coordinate methods such as alternating minimization and for which we prove convergence to the global minimum.</abstract>
   </article>
   <article>
      <title>Scale Up Nonlinear Component Analysis with Doubly Stochastic Gradients</title>
      <author>Bo Xie, Yingyu Liang, Le Song</author>
      <date>2015-04-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Nonlinear component analysis such as kernel Principle Component Analysis (KPCA) and kernel Canonical Correlation Analysis (KCCA) are widely used in machine learning, statistics and data analysis, but they can not scale up to big datasets. Recent attempts have employed random feature approximations to convert the problem to the primal form for linear computational complexity. However, to obtain high quality solutions, the number of random features should be the same order of magnitude as the number of data points, making such approach not directly applicable to the regime with millions of data points.   We propose a simple, computationally efficient, and memory friendly algorithm based on the "doubly stochastic gradients" to scale up a range of kernel nonlinear component analysis, such as kernel PCA, CCA and SVD. Despite the \emph{non-convex} nature of these problems, our method enjoys theoretical guarantees that it converges at the rate $\tilde{O}(1/t)$ to the global optimum, even for the top $k$ eigen subspace. Unlike many alternatives, our algorithm does not require explicit orthogonalization, which is infeasible on big datasets. We demonstrate the effectiveness and scalability of our algorithm on large scale synthetic and real world datasets.</abstract>
   </article>
   <article>
      <title>Linear Maximum Margin Classifier for Learning from Uncertain Data</title>
      <author>Christos Tzelepis, Vasileios Mezaris, Ioannis Patras</author>
      <date>2015-04-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we propose a maximum margin classifier that deals with uncertainty in data input. More specifically, we reformulate the SVM framework such that each training example can be modeled by a multi-dimensional Gaussian distribution described by its mean vector and its covariance matrix -- the latter modeling the uncertainty. We address the classification problem and define a cost function that is the expected value of the classical SVM cost when data samples are drawn from the multi-dimensional Gaussian distributions that form the set of the training examples. Our formulation approximates the classical SVM formulation when the training examples are isotropic Gaussians with variance tending to zero. We arrive at a convex optimization problem, which we solve efficiently in the primal form using a stochastic <term>gradient descent</term> approach. The resulting classifier, which we name SVM with Gaussian Sample Uncertainty (SVM-GSU), is tested on synthetic data and five publicly available and popular datasets; namely, the MNIST, WDBC, DEAP, TV News Channel Commercial Detection, and TRECVID MED datasets. Experimental results verify the effectiveness of the proposed method.</abstract>
   </article>
   <article>
      <title>The Nataf-Beta Random Field Classifier: An Extension of the Beta
  Conjugate Prior to Classification Problems</title>
      <author>James-A. Goulet</author>
      <date>2015-04-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents the Nataf-Beta Random Field Classifier, a discriminative approach that extends the applicability of the Beta conjugate prior to classification problems. The approach's key feature is to model the probability of a class conditional on attribute values as a random field whose marginals are Beta distributed, and where the parameters of marginals are themselves described by random fields. Although the classification accuracy of the approach proposed does not statistically outperform the best accuracies reported in the literature, it ranks among the top tier for the six benchmark datasets tested. The Nataf-Beta Random Field Classifier is suited as a general purpose classification approach for real-continuous and real-integer attribute value problems.</abstract>
   </article>
   <article>
      <title>Performance Evaluation of Machine Learning Algorithms in Post-operative
  Life Expectancy in the Lung Cancer Patients</title>
      <author>Kwetishe Joro Danjuma</author>
      <date>2015-04-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The nature of clinical data makes it difficult to quickly select, tune and apply machine learning algorithms to clinical prognosis. As a result, a lot of time is spent searching for the most appropriate machine learning algorithms applicable in clinical prognosis that contains either binary-valued or multi-valued attributes. The study set out to identify and evaluate the performance of machine learning classification schemes applied in clinical prognosis of post-operative life expectancy in the lung cancer patients. Multilayer Perceptron, J48, and the Naive Bayes algorithms were used to train and test models on Thoracic Surgery datasets obtained from the University of California Irvine machine learning repository. Stratified 10-fold cross-validation was used to evaluate baseline performance accuracy of the classifiers. The comparative analysis shows that multilayer perceptron performed best with classification accuracy of 82.3%, J48 came out second with classification accuracy of 81.8%, and Naive Bayes came out the worst with classification accuracy of 74.4%. The quality and outcome of the chosen machine learning algorithms depends on the ingenuity of the clinical miner.</abstract>
   </article>
   <article>
      <title>Instance Optimal Learning</title>
      <author>Gregory Valiant, Paul Valiant</author>
      <date>2015-04-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider the following basic learning task: given independent draws from an unknown distribution over a discrete support, output an approximation of the distribution that is as accurate as possible in $\ell_1$ distance (i.e. total variation or statistical distance). Perhaps surprisingly, it is often possible to "de-noise" the empirical distribution of the samples to return an approximation of the true distribution that is significantly more accurate than the empirical distribution, without relying on any prior assumptions on the distribution. We present an instance optimal learning algorithm which optimally performs this de-noising for every distribution for which such a de-noising is possible. More formally, given $n$ independent draws from a distribution $p$, our algorithm returns a labelled vector whose expected distance from $p$ is equal to the minimum possible expected error that could be obtained by any algorithm that knows the true unlabeled vector of probabilities of distribution $p$ and simply needs to assign labels, up to an additive subconstant term that is independent of $p$ and goes to zero as $n$ gets large. One conceptual implication of this result is that for large samples, Bayesian assumptions on the "shape" or bounds on the tail probabilities of a distribution over discrete support are not helpful for the task of learning the distribution.   As a consequence of our techniques, we also show that given a set of $n$ samples from an arbitrary distribution, one can accurately estimate the expected number of distinct elements that will be observed in a sample of any size up to $n \log n$. This sort of extrapolation is practically relevant, particularly to domains such as genomics where it is important to understand how much more might be discovered given larger sample sizes, and we are optimistic that our approach is practically viable.</abstract>
   </article>
   <article>
      <title>Effective Discriminative Feature Selection with Non-trivial Solutions</title>
      <author>Hong Tao, Chenping Hou, Feiping Nie, Yuanyuan Jiao, Dongyun Yi</author>
      <date>2015-04-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Feature selection and feature transformation, the two main ways to reduce dimensionality, are often presented separately. In this paper, a feature selection method is proposed by combining the popular transformation based dimensionality reduction method Linear Discriminant Analysis (LDA) and sparsity regularization. We impose row sparsity on the transformation matrix of LDA through ${\ell}_{2,1}$-norm regularization to achieve feature selection, and the resultant formulation optimizes for selecting the most discriminative features and removing the redundant ones simultaneously. The formulation is extended to the ${\ell}_{2,p}$-norm regularized case: which is more likely to offer better sparsity when $0&lt;p&lt;1$. Thus the formulation is a better approximation to the feature selection problem. An efficient algorithm is developed to solve the ${\ell}_{2,p}$-norm based optimization problem and it is proved that the algorithm converges when $0&lt;p\le 2$. Systematical experiments are conducted to understand the work of the proposed method. Promising experimental results on various types of real-world data sets demonstrate the effectiveness of our algorithm.</abstract>
   </article>
   <article>
      <title>Temporal-Difference Networks</title>
      <author>Richard S. Sutton, Brian Tanner</author>
      <date>2015-04-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We introduce a generalization of temporal-difference (TD) learning to networks of interrelated predictions. Rather than relating a single prediction to itself at a later time, as in conventional TD methods, a TD network relates each prediction in a set of predictions to other predictions in the set at a later time. TD networks can represent and apply TD learning to a much wider class of predictions than has previously been possible. Using a random-walk example, we show that these networks can be used to learn to predict by a fixed interval, which is not possible with conventional TD methods. Secondly, we show that if the inter-predictive relationships are made conditional on action, then the usual learning-efficiency advantage of TD methods over Monte Carlo (supervised learning) methods becomes particularly pronounced. Thirdly, we demonstrate that TD networks can learn predictive state representations that enable exact solution of a non-Markov problem. A very broad range of inter-predictive temporal relationships can be expressed in these networks. Overall we argue that TD networks represent a substantial extension of the abilities of TD methods and bring us closer to the goal of representing world knowledge in entirely predictive, grounded terms.</abstract>
   </article>
   <article>
      <title>Discriminative Switching Linear Dynamical Systems applied to
  Physiological Condition Monitoring</title>
      <author>Konstantinos Georgatzis, Christopher K. I. Williams</author>
      <date>2015-04-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a Discriminative Switching Linear Dynamical System (DSLDS) applied to patient monitoring in Intensive Care Units (ICUs). Our approach is based on identifying the state-of-health of a patient given their observed vital signs using a discriminative classifier, and then inferring their underlying physiological values conditioned on this status. The work builds on the Factorial Switching Linear Dynamical System (FSLDS) (Quinn et al., 2009) which has been previously used in a similar setting. The FSLDS is a generative model, whereas the DSLDS is a discriminative model. We demonstrate on two real-world datasets that the DSLDS is able to outperform the FSLDS in most cases of interest, and that an $\alpha$-mixture of the two models achieves higher performance than either of the two models separately.</abstract>
   </article>
   <article>
      <title>Online Convex Optimization Using Predictions</title>
      <author>Niangjun Chen, Anish Agarwal, Adam Wierman, Siddharth Barman, Lachlan L. H. Andrew</author>
      <date>2015-04-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Making use of predictions is a crucial, but under-explored, area of online algorithms. This paper studies a class of online optimization problems where we have external noisy predictions available. We propose a stochastic prediction error model that generalizes prior models in the learning and stochastic control communities, incorporates correlation among prediction errors, and captures the fact that predictions improve as time passes. We prove that achieving sublinear regret and constant competitive ratio for online algorithms requires the use of an unbounded prediction window in adversarial settings, but that under more realistic stochastic prediction error models it is possible to use Averaging Fixed Horizon Control (AFHC) to simultaneously achieve sublinear regret and constant competitive ratio in expectation using only a constant-sized prediction window. Furthermore, we show that the performance of AFHC is tightly concentrated around its mean.</abstract>
   </article>
   <article>
      <title>Random Forest for the Contextual Bandit Problem - extended version</title>
      <author>Raphaël Féraud, Robin Allesiardo, Tanguy Urvoy, Fabrice Clérot</author>
      <date>2015-04-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>To address the contextual bandit problem, we propose an online <term>random forest</term> algorithm. The analysis of the proposed algorithm is based on the sample complexity needed to find the optimal decision stump. Then, the decision stumps are assembled in a random collection of decision trees, Bandit Forest. We show that the proposed algorithm is optimal up to logarithmic factors. The dependence of the sample complexity upon the number of contextual variables is logarithmic. The computational cost of the proposed algorithm with respect to the time horizon is linear. These analytical results allow the proposed algorithm to be efficient in real applications, where the number of events to process is huge, and where we expect that some contextual variables, chosen from a large set, have potentially non- linear dependencies with the rewards. In the experiments done to illustrate the theoretical analysis, Bandit Forest obtain promising results in comparison with state-of-the-art algorithms.</abstract>
   </article>
   <article>
      <title>Accelerated kernel discriminant analysis</title>
      <author>Nikolaos Gkalelis, Vasileios Mezaris</author>
      <date>2015-04-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, using a novel matrix factorization and simultaneous reduction to diagonal form approach (or in short simultaneous reduction approach), Accelerated Kernel Discriminant Analysis (AKDA) and Accelerated Kernel Subclass Discriminant Analysis (AKSDA) are proposed. Specifically, instead of performing the simultaneous reduction of the between- and within-class or subclass scatter matrices, the nonzero eigenpairs (NZEP) of the so-called core matrix, which is of relatively small dimensionality, and the Cholesky factorization of the kernel matrix are computed, achieving more than one order of magnitude speed up over kernel discriminant analysis (KDA). Moreover, consisting of a few elementary matrix operations and very stable numerical algorithms, AKDA and AKSDA offer improved classification accuracy. The experimental evaluation on various datasets confirms that the proposed approaches provide state-of-the-art performance in terms of both training time and classification accuracy.</abstract>
   </article>
   <article>
      <title>Surrogate regret bounds for generalized classification performance
  metrics</title>
      <author>Wojciech Kotłowski, Krzysztof Dembczyński</author>
      <date>2015-04-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider optimization of generalized performance metrics for binary classification by means of surrogate losses. We focus on a class of metrics, which are linear-fractional functions of the false positive and false negative rates (examples of which include $F_{\beta}$-measure, Jaccard similarity coefficient, AM measure, and many others). Our analysis concerns the following two-step procedure. First, a real-valued function $f$ is learned by minimizing a surrogate loss for binary classification on the training sample. It is assumed that the surrogate loss is a strongly proper composite loss function (examples of which include logistic loss, squared-error loss, exponential loss, etc.). Then, given $f$, a threshold $\widehat{\theta}$ is tuned on a separate validation sample, by direct optimization of the target performance metric. We show that the regret of the resulting classifier (obtained from thresholding $f$ on $\widehat{\theta}$) measured with respect to the target metric is upperbounded by the regret of $f$ measured with respect to the surrogate loss. We also extend our results to cover multilabel classification and provide regret bounds for micro- and macro-averaging measures. Our findings are further analyzed in a computational study on both synthetic and real data sets.</abstract>
   </article>
   <article>
      <title>Or's of And's for Interpretable Classification, with Application to
  Context-Aware Recommender Systems</title>
      <author>Tong Wang, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, Perry MacNeille</author>
      <date>2015-04-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a machine learning algorithm for building classifiers that are comprised of a small number of disjunctions of conjunctions (or's of and's). An example of a classifier of this form is as follows: If X satisfies (x1 = 'blue' AND x3 = 'middle') OR (x1 = 'blue' AND x2 = '&lt;15') OR (x1 = 'yellow'), then we predict that Y=1, ELSE predict Y=0. An attribute-value pair is called a literal and a conjunction of literals is called a pattern. Models of this form have the advantage of being interpretable to human experts, since they produce a set of conditions that concisely describe a specific class. We present two probabilistic models for forming a pattern set, one with a Beta-Binomial prior, and the other with Poisson priors. In both cases, there are prior parameters that the user can set to encourage the model to have a desired size and shape, to conform with a domain-specific definition of interpretability. We provide two scalable MAP inference approaches: a pattern level search, which involves association rule mining, and a literal level search. We show stronger priors reduce computation. We apply the Bayesian Or's of And's (BOA) model to predict user behavior with respect to in-vehicle context-aware personalized recommender systems.</abstract>
   </article>
   <article>
      <title>Evaluation of Explore-Exploit Policies in Multi-result Ranking Systems</title>
      <author>Dragomir Yankov, Pavel Berkhin, Lihong Li</author>
      <date>2015-04-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We analyze the problem of using Explore-Exploit techniques to improve precision in multi-result ranking systems such as web search, query autocompletion and news recommendation. Adopting an exploration policy directly online, without understanding its impact on the production system, may have unwanted consequences - the system may sustain large losses, create user dissatisfaction, or collect exploration data which does not help improve ranking quality. An offline framework is thus necessary to let us decide what policy and how we should apply in a production environment to ensure positive outcome. Here, we describe such an offline framework.   Using the framework, we study a popular exploration policy - Thompson sampling. We show that there are different ways of implementing it in multi-result ranking systems, each having different semantic interpretation and leading to different results in terms of sustained click-through-rate (CTR) loss and expected model improvement. In particular, we demonstrate that Thompson sampling can act as an online learner optimizing CTR, which in some cases can lead to an interesting outcome: lift in CTR during exploration. The observation is important for production systems as it suggests that one can get both valuable exploration data to improve ranking performance on the long run, and at the same time increase CTR while exploration lasts.</abstract>
   </article>
   <article>
      <title>Learning Contextualized Music Semantics from Tags via a Siamese Network</title>
      <author>Ubai Sandouk, Ke Chen</author>
      <date>2015-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Music information retrieval faces a challenge in modeling contextualized musical concepts formulated by a set of co-occurring tags. In this paper, we investigate the suitability of our recently proposed approach based on a Siamese <term>neural network</term> in fighting off this challenge. By means of tag features and probabilistic topic models, the network captures contextualized semantics from tags via <term>unsupervised learning</term>. This leads to a distributed semantics space and a potential solution to the out of vocabulary problem which has yet to be sufficiently addressed. We explore the nature of the resultant music-based semantics and address computational needs. We conduct experiments on three public music tag collections -namely, CAL500, MagTag5K and Million Song Dataset- and compare our approach to a number of state-of-the-art semantics learning approaches. Comparative results suggest that this approach outperforms previous approaches in terms of semantic priming and music tag completion.</abstract>
   </article>
   <article>
      <title>Note on Equivalence Between Recurrent Neural Network Time Series Models
  and Variational Bayesian Models</title>
      <author>Jascha Sohl-Dickstein, Diederik P. Kingma</author>
      <date>2015-04-29</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We observe that the standard log likelihood training objective for a Recurrent Neural Network (RNN) model of time series data is equivalent to a variational Bayesian training objective, given the proper choice of generative and inference models. This perspective may motivate extensions to both RNNs and variational Bayesian models. We propose one such extension, where multiple particles are used for the hidden state of an RNN, allowing a natural representation of uncertainty or multimodality.</abstract>
   </article>
   <article>
      <title>Thompson Sampling for Budgeted Multi-armed Bandits</title>
      <author>Yingce Xia, Haifang Li, Tao Qin, Nenghai Yu, Tie-Yan Liu</author>
      <date>2015-05-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Thompson sampling is one of the earliest randomized algorithms for multi-armed bandits (MAB). In this paper, we extend the Thompson sampling to Budgeted MAB, where there is random cost for pulling an arm and the total cost is constrained by a budget. We start with the case of Bernoulli bandits, in which the random rewards (costs) of an arm are independently sampled from a Bernoulli distribution. To implement the Thompson sampling algorithm in this case, at each round, we sample two numbers from the posterior distributions of the reward and cost for each arm, obtain their ratio, select the arm with the maximum ratio, and then update the posterior distributions. We prove that the distribution-dependent regret bound of this algorithm is $O(\ln B)$, where $B$ denotes the budget. By introducing a Bernoulli trial, we further extend this algorithm to the setting that the rewards (costs) are drawn from general distributions, and prove that its regret bound remains almost the same. Our simulation results demonstrate the effectiveness of the proposed algorithm.</abstract>
   </article>
   <article>
      <title>Theory of Optimizing Pseudolinear Performance Measures: Application to
  F-measure</title>
      <author>Shameem A Puthiya Parambath, Nicolas Usunier, Yves Grandvalet</author>
      <date>2015-05-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Non-linear performance measures are widely used for the evaluation of learning algorithms. For example, $F$-measure is a commonly used performance measure for classification problems in machine learning and information retrieval community. We study the theoretical properties of a subset of non-linear performance measures called pseudo-linear performance measures which includes $F$-measure, \emph{Jaccard Index}, among many others. We establish that many notions of $F$-measures and \emph{Jaccard Index} are pseudo-linear functions of the per-class false negatives and false positives for binary, multiclass and multilabel classification. Based on this observation, we present a general reduction of such performance measure optimization problem to cost-sensitive classification problem with unknown costs. We then propose an algorithm with provable guarantees to obtain an approximately optimal classifier for the $F$-measure by solving a series of cost-sensitive classification problems. The strength of our analysis is to be valid on any dataset and any class of classifiers, extending the existing theoretical results on pseudo-linear measures, which are asymptotic in nature. We also establish the multi-objective nature of the $F$-score maximization problem by linking the algorithm with the weighted-sum approach used in multi-objective optimization. We present numerical experiments to illustrate the relative importance of cost asymmetry and thresholding when learning linear classifiers on various $F$-measure optimization tasks.</abstract>
   </article>
   <article>
      <title>Can deep learning help you find the perfect match?</title>
      <author>Harm de Vries, Jason Yosinski</author>
      <date>2015-05-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Is he/she my type or not? The answer to this question depends on the personal preferences of the one asking it. The individual process of obtaining a full answer may generally be difficult and time consuming, but often an approximate answer can be obtained simply by looking at a photo of the potential match. Such approximate answers based on visual cues can be produced in a fraction of a second, a phenomenon that has led to a series of recently successful dating apps in which users rate others positively or negatively using primarily a single photo. In this paper we explore using <term>convolutional network</term>s to create a model of an individual's personal preferences based on rated photos. This introduced task is difficult due to the large number of variations in profile pictures and the noise in attractiveness labels. Toward this task we collect a dataset comprised of $9364$ pictures and binary labels for each. We compare performance of convolutional models trained in three ways: first directly on the collected dataset, second with features transferred from a network trained to predict gender, and third with features transferred from a network trained on ImageNet. Our findings show that ImageNet features transfer best, producing a model that attains $68.1\%$ accuracy on the test set and is moderately successful at predicting matches.</abstract>
   </article>
   <article>
      <title>Reinforcement Learning Neural Turing Machines - Revised</title>
      <author>Wojciech Zaremba, Ilya Sutskever</author>
      <date>2015-05-04</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The Neural Turing Machine (NTM) is more expressive than all previously considered models because of its external memory. It can be viewed as a broader effort to use abstract external Interfaces and to learn a parametric model that interacts with them.   The capabilities of a model can be extended by providing it with proper Interfaces that interact with the world. These external Interfaces include memory, a database, a search engine, or a piece of software such as a theorem verifier. Some of these Interfaces are provided by the developers of the model. However, many important existing Interfaces, such as databases and search engines, are discrete.   We examine feasibility of learning models to interact with discrete Interfaces. We investigate the following discrete Interfaces: a memory Tape, an input Tape, and an output Tape. We use a Reinforcement Learning algorithm to train a <term>neural network</term> that interacts with such Interfaces to solve simple algorithmic tasks. Our Interfaces are expressive enough to make our model Turing complete.</abstract>
   </article>
   <article>
      <title>Reinforced Decision Trees</title>
      <author>Aurélia Léon, Ludovic Denoyer</author>
      <date>2015-05-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In order to speed-up classification models when facing a large number of categories, one usual approach consists in organizing the categories in a particular structure, this structure being then used as a way to speed-up the prediction computation. This is for example the case when using error-correcting codes or even hierarchies of categories. But in the majority of approaches, this structure is chosen \textit{by hand}, or during a preliminary step, and not integrated in the learning process. We propose a new model called Reinforced Decision Tree which simultaneously learns how to organize categories in a tree structure and how to classify any input based on this structure. This approach keeps the advantages of existing techniques (low inference complexity) but allows one to build efficient classifiers in one learning step. The learning algorithm is inspired by <term>reinforcement learning</term> and policy-gradient techniques which allows us to integrate the two steps (building the tree, and learning the classifier) in one single algorithm.</abstract>
   </article>
   <article>
      <title>A Comprehensive Study On The Applications Of Machine Learning For
  Diagnosis Of Cancer</title>
      <author>Mohnish Chakravarti, Tanay Kothari</author>
      <date>2015-05-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Collectively, lung cancer, breast cancer and melanoma was diagnosed in over 535,340 people out of which, 209,400 deaths were reported [13]. It is estimated that over 600,000 people will be diagnosed with these forms of cancer in 2015. Most of the deaths from lung cancer, breast cancer and melanoma result due to late detection. All of these cancers, if detected early, are 100% curable. In this study, we develop and evaluate algorithms to diagnose Breast cancer, Melanoma, and Lung cancer. In the first part of the study, we employed a normalised Gradient Descent and an Artificial Neural Network to diagnose breast cancer with an overall accuracy of 91% and 95% respectively. In the second part of the study, an artificial <term>neural network</term> coupled with image processing and analysis algorithms was employed to achieve an overall accuracy of 93% A naive mobile based application that allowed people to take diagnostic tests on their phones was developed. Finally, a Support Vector Machine algorithm incorporating image processing and image analysis algorithms was developed to diagnose lung cancer with an accuracy of 94%. All of the aforementioned systems had very low false positive and false negative rates. We are developing an online network that incorporates all of these systems and allows people to collaborate globally.</abstract>
   </article>
   <article>
      <title>Learning and Optimization with Submodular Functions</title>
      <author>Bharath Sankaran, Marjan Ghazvininejad, Xinran He, David Kale, Liron Cohen</author>
      <date>2015-05-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In many naturally occurring optimization problems one needs to ensure that the definition of the optimization problem lends itself to solutions that are tractable to compute. In cases where exact solutions cannot be computed tractably, it is beneficial to have strong guarantees on the tractable approximate solutions. In order operate under these criterion most optimization problems are cast under the umbrella of convexity or submodularity. In this report we will study design and optimization over a common class of functions called submodular functions. Set functions, and specifically submodular set functions, characterize a wide variety of naturally occurring optimization problems, and the property of submodularity of set functions has deep theoretical consequences with wide ranging applications. Informally, the property of submodularity of set functions concerns the intuitive "principle of diminishing returns. This property states that adding an element to a smaller set has more value than adding it to a larger set. Common examples of submodular monotone functions are entropies, concave functions of cardinality, and matroid rank functions; non-monotone examples include graph cuts, network flows, and mutual information.   In this paper we will review the formal definition of submodularity; the optimization of submodular functions, both maximization and minimization; and finally discuss some applications in relation to learning and reasoning using submodular functions.</abstract>
   </article>
   <article>
      <title>A Survey of Predictive Modelling under Imbalanced Distributions</title>
      <author>Paula Branco, Luis Torgo, Rita Ribeiro</author>
      <date>2015-05-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Many real world data mining applications involve obtaining predictive models using data sets with strongly imbalanced distributions of the target variable. Frequently, the least common values of this target variable are associated with events that are highly relevant for end users (e.g. fraud detection, unusual returns on stock markets, anticipation of catastrophes, etc.). Moreover, the events may have different costs and benefits, which when associated with the rarity of some of them on the available training data creates serious problems to predictive modelling techniques. This paper presents a survey of existing techniques for handling these important applications of predictive analytics. Although most of the existing work addresses classification tasks (nominal target variables), we also describe methods designed to handle similar problems within regression tasks (numeric target variables). In this survey we discuss the main challenges raised by imbalanced distributions, describe the main approaches to these problems, propose a taxonomy of these methods and refer to some related problems within predictive modelling.</abstract>
   </article>
   <article>
      <title>Bounded-Distortion Metric Learning</title>
      <author>Renjie Liao, Jianping Shi, Ziyang Ma, Jun Zhu, Jiaya Jia</author>
      <date>2015-05-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Metric learning aims to embed one metric space into another to benefit tasks like classification and clustering. Although a greatly distorted metric space has a high degree of freedom to fit training data, it is prone to overfitting and numerical inaccuracy. This paper presents {\it bounded-distortion metric learning} (BDML), a new metric learning framework which amounts to finding an optimal Mahalanobis metric space with a bounded-distortion constraint. An efficient solver based on the multiplicative weights update method is proposed. Moreover, we generalize BDML to pseudo-metric learning and devise the semidefinite relaxation and a randomized algorithm to approximately solve it. We further provide theoretical analysis to show that distortion is a key ingredient for stability and generalization ability of our BDML algorithm. Extensive experiments on several benchmark datasets yield promising results.</abstract>
   </article>
   <article>
      <title>Safe Screening for Multi-Task Feature Learning with Multiple Data
  Matrices</title>
      <author>Jie Wang, Jieping Ye</author>
      <date>2015-05-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Multi-task feature learning (MTFL) is a powerful technique in boosting the predictive performance by learning multiple related classification/regression/clustering tasks simultaneously. However, solving the MTFL problem remains challenging when the feature dimension is extremely large. In this paper, we propose a novel screening rule---that is based on the dual projection onto convex sets (DPC)---to quickly identify the inactive features---that have zero coefficients in the solution vectors across all tasks. One of the appealing features of DPC is that: it is safe in the sense that the detected inactive features are guaranteed to have zero coefficients in the solution vectors across all tasks. Thus, by removing the inactive features from the training phase, we may have substantial savings in the computational cost and memory usage without sacrificing accuracy. To the best of our knowledge, it is the first screening rule that is applicable to sparse models with multiple data matrices. A key challenge in deriving DPC is to solve a nonconvex problem. We show that we can solve for the global optimum efficiently via a properly chosen parametrization of the constraint set. Moreover, DPC has very low computational cost and can be integrated with any existing solvers. We have evaluated the proposed DPC rule on both synthetic and real data sets. The experiments indicate that DPC is very effective in identifying the inactive features---especially for high dimensional data---which leads to a speedup up to several orders of magnitude.</abstract>
   </article>
   <article>
      <title>Shrinkage degree in $L_2$-re-scale boosting for regression</title>
      <author>Lin Xu, Shaobo Lin, Yao Wang, Zongben Xu</author>
      <date>2015-05-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Re-scale boosting (RBoosting) is a variant of boosting which can essentially improve the generalization performance of boosting learning. The key feature of RBoosting lies in introducing a shrinkage degree to re-scale the ensemble estimate in each gradient-descent step. Thus, the shrinkage degree determines the performance of RBoosting.   The aim of this paper is to develop a concrete analysis concerning how to determine the shrinkage degree in $L_2$-RBoosting. We propose two feasible ways to select the shrinkage degree. The first one is to parameterize the shrinkage degree and the other one is to develope a data-driven approach of it. After rigorously analyzing the importance of the shrinkage degree in $L_2$-RBoosting learning, we compare the pros and cons of the proposed methods. We find that although these approaches can reach the same learning rates, the structure of the final estimate of the parameterized approach is better, which sometimes yields a better generalization capability when the number of sample is finite. With this, we recommend to parameterize the shrinkage degree of $L_2$-RBoosting. To this end, we present an adaptive parameter-selection strategy for shrinkage degree and verify its feasibility through both theoretical analysis and numerical verification.   The obtained results enhance the understanding of RBoosting and further give guidance on how to use $L_2$-RBoosting for regression tasks.</abstract>
   </article>
   <article>
      <title>Ensemble of Example-Dependent Cost-Sensitive Decision Trees</title>
      <author>Alejandro Correa Bahnsen, Djamila Aouada, Bjorn Ottersten</author>
      <date>2015-05-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Several real-world classification problems are example-dependent cost-sensitive in nature, where the costs due to misclassification vary between examples and not only within classes. However, standard classification methods do not take these costs into account, and assume a constant cost of misclassification errors. In previous works, some methods that take into account the financial costs into the training of different algorithms have been proposed, with the example-dependent cost-sensitive decision tree algorithm being the one that gives the highest savings. In this paper we propose a new framework of ensembles of example-dependent cost-sensitive decision-trees. The framework consists in creating different example-dependent cost-sensitive decision trees on random subsamples of the training set, and then combining them using three different combination approaches. Moreover, we propose two new cost-sensitive combination approaches; cost-sensitive weighted voting and cost-sensitive stacking, the latter being based on the cost-sensitive logistic regression method. Finally, using five different databases, from four real-world applications: credit card fraud detection, churn modeling, credit scoring and direct marketing, we evaluate the proposed method against state-of-the-art example-dependent cost-sensitive techniques, namely, cost-proportionate sampling, Bayes minimum risk and cost-sensitive decision trees. The results show that the proposed algorithms have better results for all databases, in the sense of higher savings.</abstract>
   </article>
   <article>
      <title>Learning with a Drifting Target Concept</title>
      <author>Steve Hanneke, Varun Kanade, Liu Yang</author>
      <date>2015-05-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the problem of learning in the presence of a drifting target concept. Specifically, we provide bounds on the error rate at a given time, given a learner with access to a history of independent samples labeled according to a target concept that can change on each round. One of our main contributions is a refinement of the best previous results for polynomial-time algorithms for the space of linear separators under a uniform distribution. We also provide general results for an algorithm capable of adapting to a variable rate of drift of the target concept. Some of the results also describe an active learning variant of this setting, and provide bounds on the number of queries for the labels of points in the sequence sufficient to obtain the stated bounds on the error rates.</abstract>
   </article>
   <article>
      <title>Bounds on the Minimax Rate for Estimating a Prior over a VC Class from
  Independent Learning Tasks</title>
      <author>Liu Yang, Steve Hanneke, Jaime Carbonell</author>
      <date>2015-05-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the optimal rates of convergence for estimating a prior distribution over a VC class from a sequence of independent data sets respectively labeled by independent target functions sampled from the prior. We specifically derive upper and lower bounds on the optimal rates under a smoothness condition on the correct prior, with the number of samples per data set equal the VC dimension. These results have implications for the improvements achievable via transfer learning. We additionally extend this setting to real-valued function, where we establish consistency of an estimator for the prior, and discuss an additional application to a preference elicitation problem in algorithmic economics.</abstract>
   </article>
   <article>
      <title>Safe Policy Search for Lifelong Reinforcement Learning with Sublinear
  Regret</title>
      <author>Haitham Bou Ammar, Rasul Tutunov, Eric Eaton</author>
      <date>2015-05-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Lifelong <term>reinforcement learning</term> provides a promising framework for developing versatile agents that can accumulate knowledge over a lifetime of experience and rapidly learn new tasks by building upon prior knowledge. However, current lifelong learning methods exhibit non-vanishing regret as the amount of experience increases and include limitations that can lead to suboptimal or unsafe control policies. To address these issues, we develop a lifelong policy gradient learner that operates in an adversarial set- ting to learn multiple tasks online while enforcing safety constraints on the learned policies. We demonstrate, for the first time, sublinear regret for lifelong policy search, and validate our algorithm on several benchmark dynamical systems and an application to quadrotor control.</abstract>
   </article>
   <article>
      <title>Instant Learning: Parallel Deep Neural Networks and Convolutional
  Bootstrapping</title>
      <author>Andrew J. R. Simpson</author>
      <date>2015-05-22</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Although deep <term>neural network</term>s (DNN) are able to scale with direct advances in computational power (e.g., memory and processing speed), they are not well suited to exploit the recent trends for parallel architectures. In particular, <term>gradient descent</term> is a sequential process and the resulting serial dependencies mean that DNN training cannot be parallelized effectively. Here, we show that a DNN may be replicated over a massive parallel architecture and used to provide a cumulative sampling of local solution space which results in rapid and robust learning. We introduce a complimentary convolutional bootstrapping approach that enhances performance of the parallel architecture further. Our parallelized convolutional bootstrapping DNN out-performs an identical fully-trained traditional DNN after only a single iteration of training.</abstract>
   </article>
   <article>
      <title>Monotonic Calibrated Interpolated Look-Up Tables</title>
      <author>Maya Gupta, Andrew Cotter, Jan Pfeifer, Konstantin Voevodski, Kevin Canini, Alexander Mangylov, Wojtek Moczydlowski, Alex van Esbroeck</author>
      <date>2015-05-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Real-world machine learning applications may require functions that are fast-to-evaluate and interpretable. In particular, guaranteed monotonicity of the learned function can be critical to user trust. We propose meeting these goals for low-dimensional machine learning problems by learning flexible, monotonic functions using calibrated interpolated look-up tables. We extend the structural risk minimization framework of lattice regression to train monotonic look-up tables by solving a convex problem with appropriate linear inequality constraints. In addition, we propose jointly learning interpretable calibrations of each feature to normalize continuous features and handle categorical or missing data, at the cost of making the objective non-convex. We address large-scale learning through parallelization, mini-batching, and propose random sampling of additive regularizer terms. Case studies with real-world problems with five to sixteen features and thousands to millions of training samples demonstrate the proposed monotonic functions can achieve state-of-the-art accuracy on practical problems while providing greater transparency to users.</abstract>
   </article>
   <article>
      <title>Domain Adaptation Extreme Learning Machines for Drift Compensation in
  E-nose Systems</title>
      <author>Lei Zhang, David Zhang</author>
      <date>2015-05-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper addresses an important issue, known as sensor drift that behaves a nonlinear dynamic property in electronic nose (E-nose), from the viewpoint of machine learning. Traditional methods for drift compensation are laborious and costly due to the frequent acquisition and labeling process for gases samples recalibration. Extreme learning machines (ELMs) have been confirmed to be efficient and effective learning techniques for pattern recognition and regression. However, ELMs primarily focus on the supervised, semi-supervised and <term>unsupervised learning</term> problems in single domain (i.e. source domain). To our best knowledge, ELM with cross-domain learning capability has never been studied. This paper proposes a unified framework, referred to as Domain Adaptation Extreme Learning Machine (DAELM), which learns a robust classifier by leveraging a limited number of labeled data from target domain for drift compensation as well as gases recognition in E-nose systems, without loss of the computational efficiency and learning ability of traditional ELM. In the unified framework, two algorithms called DAELM-S and DAELM-T are proposed for the purpose of this paper, respectively. In order to percept the differences among ELM, DAELM-S and DAELM-T, two remarks are provided. Experiments on the popular sensor drift data with multiple batches collected by E-nose system clearly demonstrate that the proposed DAELM significantly outperforms existing drift compensation methods without cumbersome measures, and also bring new perspectives for ELM.</abstract>
   </article>
   <article>
      <title>Efficient Elastic Net Regularization for Sparse Linear Models</title>
      <author>Zachary C. Lipton, Charles Elkan</author>
      <date>2015-05-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents an algorithm for efficient training of sparse linear models with elastic net regularization. Extending previous work on delayed updates, the new algorithm applies stochastic gradient updates to non-zero features only, bringing weights current as needed with closed-form updates. Closed-form delayed updates for the $\ell_1$, $\ell_{\infty}$, and rarely used $\ell_2$ regularizers have been described previously. This paper provides closed-form updates for the popular squared norm $\ell^2_2$ and elastic net regularizers.   We provide dynamic programming algorithms that perform each delayed update in constant time. The new $\ell^2_2$ and elastic net methods handle both fixed and varying learning rates, and both standard {stochastic <term>gradient descent</term>} (SGD) and {forward backward splitting (FoBoS)}. Experimental results show that on a bag-of-words dataset with $260,941$ features, but only $88$ nonzero features on average per training example, the dynamic programming method trains a logistic regression classifier with elastic net regularization over $2000$ times faster than otherwise.</abstract>
   </article>
   <article>
      <title>Differentially Private Distributed Online Learning</title>
      <author>Chencheng Li, Pan Zhou</author>
      <date>2015-05-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Online learning has been in the spotlight from the machine learning society for a long time. To handle massive data in Big Data era, one single learner could never efficiently finish this heavy task. Hence, in this paper, we propose a novel distributed online learning algorithm to solve the problem. Comparing to typical centralized online learner, the distributed learners optimize their own learning parameters based on local data sources and timely communicate with neighbors. However, communication may lead to a privacy breach. Thus, we use differential privacy to preserve the privacy of learners, and study the influence of guaranteeing differential privacy on the utility of the distributed online learning algorithm. Furthermore, by using the results from Kakade and Tewari (2009), we use the regret bounds of online learning to achieve fast convergence rates for offline learning algorithms in distributed scenarios, which provides tighter utility performance than the existing state-of-the-art results. In simulation, we demonstrate that the differentially private offline learning algorithm has high variance, but we can use mini-batch to improve the performance. Finally, the simulations show that the analytical results of our proposed theorems are right and our private distributed online learning algorithm is a general framework.</abstract>
   </article>
   <article>
      <title>Fantasy Football Prediction</title>
      <author>Roman Lutz</author>
      <date>2015-05-26</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The ubiquity of professional sports and specifically the NFL have lead to an increase in popularity for Fantasy Football. Users have many tools at their disposal: statistics, predictions, rankings of experts and even recommendations of peers. There are issues with all of these, though. Especially since many people pay money to play, the prediction tools should be enhanced as they provide unbiased and easy-to-use assistance for users. This paper provides and discusses approaches to predict Fantasy Football scores of Quarterbacks with relatively limited data. In addition to that, it includes several suggestions on how the data could be enhanced to achieve better results. The dataset consists only of game data from the last six NFL seasons. I used two different methods to predict the Fantasy Football scores of NFL players: Support Vector Regression (SVR) and Neural Networks. The results of both are promising given the limited data that was used.</abstract>
   </article>
   <article>
      <title>Learning with Symmetric Label Noise: The Importance of Being Unhinged</title>
      <author>Brendan van Rooyen, Aditya Krishna Menon, Robert C. Williamson</author>
      <date>2015-05-28</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Convex potential minimisation is the de facto approach to binary classification. However, Long and Servedio [2010] proved that under symmetric label noise (SLN), minimisation of any convex potential over a linear function class can result in classification performance equivalent to random guessing. This ostensibly shows that convex losses are not SLN-robust. In this paper, we propose a convex, classification-calibrated loss and prove that it is SLN-robust. The loss avoids the Long and Servedio [2010] result by virtue of being negatively unbounded. The loss is a modification of the hinge loss, where one does not clamp at zero; hence, we call it the unhinged loss. We show that the optimal unhinged solution is equivalent to that of a strongly regularised SVM, and is the limiting solution for any convex potential; this implies that strong l2 regularisation makes most standard learners SLN-robust. Experiments confirm the SLN-robustness of the unhinged loss.</abstract>
   </article>
   <article>
      <title>Copeland Dueling Bandits</title>
      <author>Masrour Zoghi, Zohar Karnin, Shimon Whiteson, Maarten de Rijke</author>
      <date>2015-06-01</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>A version of the dueling bandit problem is addressed in which a Condorcet winner may not exist. Two algorithms are proposed that instead seek to minimize regret with respect to the Copeland winner, which, unlike the Condorcet winner, is guaranteed to exist. The first, Copeland Confidence Bound (CCB), is designed for small numbers of arms, while the second, Scalable Copeland Bandits (SCB), works better for large-scale problems. We provide theoretical results bounding the regret accumulated by CCB and SCB, both substantially improving existing results. Such existing results either offer bounds of the form $O(K \log T)$ but require restrictive assumptions, or offer bounds of the form $O(K^2 \log T)$ without requiring such assumptions. Our results offer the best of both worlds: $O(K \log T)$ bounds without restrictive assumptions.</abstract>
   </article>
   <article>
      <title>Unsupervised Learning on Neural Network Outputs: with Application in
  Zero-shot Learning</title>
      <author>Yao Lu</author>
      <date>2015-06-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The outputs of a trained <term>neural network</term> contain much richer information than just an one-hot classifier. For example, a <term>neural network</term> might give an image of a dog the probability of one in a million of being a cat but it is still much larger than the probability of being a car. To reveal the hidden structure in them, we apply two <term>unsupervised learning</term> algorithms, PCA and ICA, to the outputs of a deep Convolutional Neural Network trained on the ImageNet of 1000 classes. The PCA/ICA embedding of the object classes reveals their visual similarity and the PCA/ICA components can be interpreted as common visual features shared by similar object classes. For an application, we proposed a new zero-shot learning method, in which the visual features learned by PCA/ICA are employed. Our zero-shot learning method achieves the state-of-the-art results on the ImageNet of over 20000 classes.</abstract>
   </article>
   <article>
      <title>Global and Local Structure Preserving Sparse Subspace Learning: An
  Iterative Approach to Unsupervised Feature Selection</title>
      <author>Nan Zhou, Yangyang Xu, Hong Cheng, Jun Fang, Witold Pedrycz</author>
      <date>2015-06-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>As we aim at alleviating the curse of high-dimensionality, subspace learning is becoming more popular. Existing approaches use either information about global or local structure of the data, and few studies simultaneously focus on global and local structures as the both of them contain important information. In this paper, we propose a global and local structure preserving sparse subspace learning (GLoSS) model for unsupervised feature selection. The model can simultaneously realize feature selection and subspace learning. In addition, we develop a greedy algorithm to establish a generic combinatorial model, and an iterative strategy based on an accelerated block coordinate descent is used to solve the GLoSS problem. We also provide whole iterate sequence convergence analysis of the proposed iterative algorithm. Extensive experiments are conducted on real-world datasets to show the superiority of the proposed approach over several state-of-the-art unsupervised feature selection approaches.</abstract>
   </article>
   <article>
      <title>On bicluster aggregation and its benefits for enumerative solutions</title>
      <author>Saullo Haniell Galvão de Oliveira, Rosana Veroneze, Fernando José Von Zuben</author>
      <date>2015-06-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Biclustering involves the simultaneous clustering of objects and their attributes, thus defining local two-way clustering models. Recently, efficient algorithms were conceived to enumerate all biclusters in real-valued datasets. In this case, the solution composes a complete set of maximal and non-redundant biclusters. However, the ability to enumerate biclusters revealed a challenging scenario: in noisy datasets, each true bicluster may become highly fragmented and with a high degree of overlapping. It prevents a direct analysis of the obtained results. To revert the fragmentation, we propose here two approaches for properly aggregating the whole set of enumerated biclusters: one based on single linkage and the other directly exploring the rate of overlapping. Both proposals were compared with each other and with the actual state-of-the-art in several experiments, and they not only significantly reduced the number of biclusters but also consistently increased the quality of the solution.</abstract>
   </article>
   <article>
      <title>Towards Structured Deep Neural Network for Automatic Speech Recognition</title>
      <author>Yi-Hsiu Liao, Hung-Yi Lee, Lin-shan Lee</author>
      <date>2015-06-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper we propose the Structured Deep Neural Network (Structured DNN) as a structured and <term>deep learning</term> algorithm, learning to find the best structured object (such as a label sequence) given a structured input (such as a vector sequence) by globally considering the mapping relationships between the structure rather than item by item.   When automatic speech recognition is viewed as a special case of such a structured learning problem, where we have the acoustic vector sequence as the input and the phoneme label sequence as the output, it becomes possible to comprehensively learned utterance by utterance as a whole, rather than frame by frame.   Structured Support Vector Machine (structured SVM) was proposed to perform ASR with structured learning previously, but limited by the linear nature of SVM. Here we propose structured DNN to use nonlinear transformations in multi-layers as a structured and <term>deep learning</term> algorithm. It was shown to beat structured SVM in preliminary experiments on TIMIT.</abstract>
   </article>
   <article>
      <title>Unsupervised Feature Analysis with Class Margin Optimization</title>
      <author>Sen Wang, Feiping Nie, Xiaojun Chang, Lina Yao, Xue Li, Quan Z. Sheng</author>
      <date>2015-06-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Unsupervised feature selection has been always attracting research attention in the communities of machine learning and data mining for decades. In this paper, we propose an unsupervised feature selection method seeking a feature coefficient matrix to select the most distinctive features. Specifically, our proposed algorithm integrates the Maximum Margin Criterion with a sparsity-based model into a joint framework, where the class margin and feature correlation are taken into account at the same time. To maximize the total data separability while preserving minimized within-class scatter simultaneously, we propose to embed Kmeans into the framework generating pseudo class label information in a scenario of unsupervised feature selection. Meanwhile, a sparsity-based model, ` 2 ,p-norm, is imposed to the regularization term to effectively discover the sparse structures of the feature coefficient matrix. In this way, noisy and irrelevant features are removed by ruling out those features whose corresponding coefficients are zeros. To alleviate the local optimum problem that is caused by random initializations of K-means, a convergence guaranteed algorithm with an updating strategy for the clustering indicator matrix, is proposed to iteractively chase the optimal solution. Performance evaluation is extensively conducted over six benchmark data sets. From plenty of experimental results, it is demonstrated that our method has superior performance against all other compared approaches.</abstract>
   </article>
   <article>
      <title>Exploiting an Oracle that Reports AUC Scores in Machine Learning
  Contests</title>
      <author>Jacob Whitehill</author>
      <date>2015-06-03</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In machine learning contests such as the ImageNet Large Scale Visual Recognition Challenge and the KDD Cup, contestants can submit candidate solutions and receive from an oracle (typically the organizers of the competition) the accuracy of their guesses compared to the ground-truth labels. One of the most commonly used accuracy metrics for binary classification tasks is the Area Under the Receiver Operating Characteristics Curve (AUC). In this paper we provide proofs-of-concept of how knowledge of the AUC of a set of guesses can be used, in two different kinds of attacks, to improve the accuracy of those guesses. On the other hand, we also demonstrate the intractability of one kind of AUC exploit by proving that the number of possible binary labelings of $n$ examples for which a candidate solution obtains a AUC score of $c$ grows exponentially in $n$, for every $c\in (0,1)$.</abstract>
   </article>
   <article>
      <title>Semidefinite and Spectral Relaxations for Multi-Label Classification</title>
      <author>Rémi Lajugie, Piotr Bojanowski, Sylvain Arlot, Francis Bach</author>
      <date>2015-06-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we address the problem of multi-label classification. We consider linear classifiers and propose to learn a prior over the space of labels to directly leverage the performance of such methods. This prior takes the form of a quadratic function of the labels and permits to encode both attractive and repulsive relations between labels. We cast this problem as a structured prediction one aiming at optimizing either the accuracies of the predictors or the F 1-score. This leads to an optimization problem closely related to the max-cut problem, which naturally leads to semidefinite and spectral relaxations. We show on standard datasets how such a general prior can improve the performances of multi-label techniques.</abstract>
   </article>
   <article>
      <title>Learning Multiple Tasks with Multilinear Relationship Networks</title>
      <author>Mingsheng Long, Zhangjie Cao, Jianmin Wang, Philip S. Yu</author>
      <date>2015-06-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Deep networks trained on large-scale data can learn transferable features to promote learning multiple tasks. Since deep features eventually transition from general to specific along deep networks, a fundamental problem of multi-task learning is how to exploit the task relatedness underlying parameter tensors and improve feature transferability in the multiple task-specific layers. This paper presents Multilinear Relationship Networks (MRN) that discover the task relationships based on novel tensor normal priors over parameter tensors of multiple task-specific layers in deep <term>convolutional network</term>s. By jointly learning transferable features and multilinear relationships of tasks and features, MRN is able to alleviate the dilemma of negative-transfer in the feature layers and under-transfer in the classifier layer. Experiments show that MRN yields state-of-the-art results on three multi-task learning datasets.</abstract>
   </article>
   <article>
      <title>A Recurrent Latent Variable Model for Sequential Data</title>
      <author>Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron Courville, Yoshua Bengio</author>
      <date>2015-06-07</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we explore the inclusion of latent random variables into the dynamic hidden state of a recurrent <term>neural network</term> (RNN) by combining elements of the variational autoencoder. We argue that through the use of high-level latent random variables, the variational RNN (VRNN)1 can model the kind of variability observed in highly structured sequential data such as natural speech. We empirically evaluate the proposed model against related sequential models on four speech datasets and one handwriting dataset. Our results show the important roles that latent random variables can play in the RNN dynamic hidden state.</abstract>
   </article>
   <article>
      <title>Efficient Learning of Ensembles with QuadBoost</title>
      <author>Louis Fortier-Dubois, François Laviolette, Mario Marchand, Louis-Emile Robitaille, Jean-Francis Roy</author>
      <date>2015-06-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We first present a general risk bound for ensembles that depends on the Lp norm of the weighted combination of voters which can be selected from a continuous set. We then propose a boosting method, called QuadBoost, which is strongly supported by the general risk bound and has very simple rules for assigning the voters' weights. Moreover, QuadBoost exhibits a rate of decrease of its empirical error which is slightly faster than the one achieved by AdaBoost. The experimental results confirm the expectation of the theory that QuadBoost is a very efficient method for learning ensembles.</abstract>
   </article>
   <article>
      <title>On Convergence of Emphatic Temporal-Difference Learning</title>
      <author>Huizhen Yu</author>
      <date>2015-06-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider emphatic temporal-difference learning algorithms for policy evaluation in discounted Markov decision processes with finite spaces. Such algorithms were recently proposed by Sutton, Mahmood, and White (2015) as an improved solution to the problem of divergence of off-policy temporal-difference learning with linear function approximation. We present in this paper the first convergence proofs for two emphatic algorithms, ETD($\lambda$) and ELSTD($\lambda$). We prove, under general off-policy conditions, the convergence in $L^1$ for ELSTD($\lambda$) iterates, and the almost sure convergence of the approximate value functions calculated by both algorithms using a single infinitely long trajectory. Our analysis involves new techniques with applications beyond emphatic algorithms leading, for example, to the first proof that standard TD($\lambda$) also converges under off-policy training for $\lambda$ sufficiently large.</abstract>
   </article>
   <article>
      <title>Optimal Sparse Kernel Learning for Hyperspectral Anomaly Detection</title>
      <author>Zhimin Peng, Prudhvi Gurram, Heesung Kwon, Wotao Yin</author>
      <date>2015-06-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, a novel framework of sparse kernel learning for Support Vector Data Description (SVDD) based anomaly detection is presented. In this work, optimal sparse feature selection for anomaly detection is first modeled as a Mixed Integer Programming (MIP) problem. Due to the prohibitively high computational complexity of the MIP, it is relaxed into a Quadratically Constrained Linear Programming (QCLP) problem. The QCLP problem can then be practically solved by using an iterative optimization method, in which multiple subsets of features are iteratively found as opposed to a single subset. The QCLP-based iterative optimization problem is solved in a finite space called the \emph{Empirical Kernel Feature Space} (EKFS) instead of in the input space or \emph{Reproducing Kernel Hilbert Space} (RKHS). This is possible because of the fact that the geometrical properties of the EKFS and the corresponding RKHS remain the same. Now, an explicit nonlinear exploitation of the data in a finite EKFS is achievable, which results in optimal feature ranking. Experimental results based on a hyperspectral image show that the proposed method can provide improved performance over the current state-of-the-art techniques.</abstract>
   </article>
   <article>
      <title>On the Interpretability of Conditional Probability Estimates in the
  Agnostic Setting</title>
      <author>Yihan Gao, Aditya Parameswaran, Jian Peng</author>
      <date>2015-06-09</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the interpretability of conditional probability estimates for binary classification under the agnostic setting or scenario. Under the agnostic setting, conditional probability estimates do not necessarily reflect the true conditional probabilities. Instead, they have a certain calibration property: among all data points that the classifier has predicted P(Y = 1|X) = p, p portion of them actually have label Y = 1. For cost-sensitive decision problems, this calibration property provides adequate support for us to use Bayes Decision Theory. In this paper, we define a novel measure for the calibration property together with its empirical counterpart, and prove an uniform convergence result between them. This new measure enables us to formally justify the calibration property of conditional probability estimations, and provides new insights on the problem of estimating and calibrating conditional probabilities.</abstract>
   </article>
   <article>
      <title>Max-Entropy Feed-Forward Clustering Neural Network</title>
      <author>Han Xiao, Xiaoyan Zhu</author>
      <date>2015-06-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The outputs of non-linear feed-forward <term>neural network</term> are positive, which could be treated as probability when they are normalized to one. If we take Entropy-Based Principle into consideration, the outputs for each sample could be represented as the distribution of this sample for different clusters. Entropy-Based Principle is the principle with which we could estimate the unknown distribution under some limited conditions. As this paper defines two processes in Feed-Forward Neural Network, our limited condition is the abstracted features of samples which are worked out in the abstraction process. And the final outputs are the probability distribution for different clusters in the clustering process. As Entropy-Based Principle is considered into the feed-forward <term>neural network</term>, a clustering method is born. We have conducted some experiments on six open UCI datasets, comparing with a few baselines and applied purity as the measurement . The results illustrate that our method outperforms all the other baselines that are most popular clustering methods.</abstract>
   </article>
   <article>
      <title>Margin-Based Feed-Forward Neural Network Classifiers</title>
      <author>Han Xiao, Xiaoyan Zhu</author>
      <date>2015-06-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Margin-Based Principle has been proposed for a long time, it has been proved that this principle could reduce the structural risk and improve the performance in both theoretical and practical aspects. Meanwhile, feed-forward <term>neural network</term> is a traditional classifier, which is very hot at present with a deeper architecture. However, the training algorithm of feed-forward <term>neural network</term> is developed and generated from Widrow-Hoff Principle that means to minimize the squared error. In this paper, we propose a new training algorithm for feed-forward <term>neural network</term>s based on Margin-Based Principle, which could effectively promote the accuracy and generalization ability of <term>neural network</term> classifiers with less labelled samples and flexible network. We have conducted experiments on four UCI open datasets and achieved good results as expected. In conclusion, our model could handle more sparse labelled and more high-dimension dataset in a high accuracy while modification from old ANN method to our method is easy and almost free of work.</abstract>
   </article>
   <article>
      <title>On the Equivalence of CoCoA+ and DisDCA</title>
      <author>Ching-pei Lee</author>
      <date>2015-06-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this document, we show that the algorithm CoCoA+ (Ma et al., ICML, 2015) under the setting used in their experiments, which is also the best setting suggested by the authors that proposed this algorithm, is equivalent to the practical variant of DisDCA (Yang, NIPS, 2013).</abstract>
   </article>
   <article>
      <title>Multi-class SVMs: From Tighter Data-Dependent Generalization Bounds to
  Novel Algorithms</title>
      <author>Yunwen Lei, Ürün Dogan, Alexander Binder, Marius Kloft</author>
      <date>2015-06-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper studies the generalization performance of multi-class classification algorithms, for which we obtain, for the first time, a data-dependent generalization error bound with a logarithmic dependence on the class size, substantially improving the state-of-the-art linear dependence in the existing data-dependent generalization analysis. The theoretical analysis motivates us to introduce a new multi-class classification machine based on $\ell_p$-norm regularization, where the parameter $p$ controls the complexity of the corresponding bounds. We derive an efficient optimization algorithm based on Fenchel duality theory. Benchmarks on several real-world datasets show that the proposed algorithm can achieve significant accuracy gains over the state of the art.</abstract>
   </article>
   <article>
      <title>Localized Multiple Kernel Learning---A Convex Approach</title>
      <author>Yunwen Lei, Alexander Binder, Ürün Dogan, Marius Kloft</author>
      <date>2015-06-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a localized approach to multiple kernel learning that can be formulated as a convex optimization problem over a given cluster structure. For which we obtain generalization error guarantees and derive an optimization algorithm based on the Fenchel dual representation. Experiments on real-world datasets from the application domains of computational biology and computer vision show that convex localized multiple kernel learning can achieve higher prediction accuracies than its global and non-convex local counterparts.</abstract>
   </article>
   <article>
      <title>A Fast Incremental Gaussian Mixture Model</title>
      <author>Rafael Pinto, Paulo Engel</author>
      <date>2015-06-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work builds upon previous efforts in online incremental learning, namely the Incremental Gaussian Mixture Network (IGMN). The IGMN is capable of learning from data streams in a single-pass by improving its model after analyzing each data point and discarding it thereafter. Nevertheless, it suffers from the scalability point-of-view, due to its asymptotic time complexity of $\operatorname{O}\bigl(NKD^3\bigr)$ for $N$ data points, $K$ Gaussian components and $D$ dimensions, rendering it inadequate for high-dimensional data. In this paper, we manage to reduce this complexity to $\operatorname{O}\bigl(NKD^2\bigr)$ by deriving formulas for working directly with precision matrices instead of covariance matrices. The final result is a much faster and scalable algorithm which can be applied to high dimensional tasks. This is confirmed by applying the modified algorithm to high-dimensional classification datasets.</abstract>
   </article>
   <article>
      <title>Dual Memory Architectures for Fast Deep Learning of Stream Data via an
  Online-Incremental-Transfer Strategy</title>
      <author>Sang-Woo Lee, Min-Oh Heo, Jiwon Kim, Jeonghee Kim, Byoung-Tak Zhang</author>
      <date>2015-06-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The online learning of deep <term>neural network</term>s is an interesting problem of machine learning because, for example, major IT companies want to manage the information of the massive data uploaded on the web daily, and this technology can contribute to the next generation of lifelong learning. We aim to train deep models from new data that consists of new classes, distributions, and tasks at minimal computational cost, which we call online <term>deep learning</term>. Unfortunately, deep <term>neural network</term> learning through classical online and incremental methods does not work well in both theory and practice. In this paper, we introduce dual memory architectures for online incremental <term>deep learning</term>. The proposed architecture consists of deep representation learners and fast learnable shallow kernel networks, both of which synergize to track the information of new data. During the training phase, we use various online, incremental ensemble, and transfer learning techniques in order to achieve lower error of the architecture. On the MNIST, CIFAR-10, and ImageNet image recognition tasks, the proposed dual memory architectures performs much better than the classical online and incremental ensemble algorithm, and their accuracies are similar to that of the batch learner.</abstract>
   </article>
   <article>
      <title>Learning Deep Generative Models with Doubly Stochastic MCMC</title>
      <author>Chao Du, Jun Zhu, Bo Zhang</author>
      <date>2015-06-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present doubly stochastic gradient MCMC, a simple and generic method for (approximate) Bayesian inference of deep generative models (DGMs) in a collapsed continuous parameter space. At each MCMC sampling step, the algorithm randomly draws a mini-batch of data samples to estimate the gradient of log-posterior and further estimates the intractable expectation over hidden variables via a neural adaptive importance sampler, where the proposal distribution is parameterized by a deep <term>neural network</term> and learnt jointly. We demonstrate the effectiveness on learning various DGMs in a wide range of tasks, including density estimation, data generation and missing data imputation. Our method outperforms many state-of-the-art competitors.</abstract>
   </article>
   <article>
      <title>Latent Regression Bayesian Network for Data Representation</title>
      <author>Siqi Nie, Qiang Ji</author>
      <date>2015-06-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Deep directed generative models have attracted much attention recently due to their expressive representation power and the ability of ancestral sampling. One major difficulty of learning directed models with many latent variables is the intractable inference. To address this problem, most existing algorithms make assumptions to render the latent variables independent of each other, either by designing specific priors, or by approximating the true posterior using a factorized distribution. We believe the correlations among latent variables are crucial for faithful data representation. Driven by this idea, we propose an inference method based on the conditional pseudo-likelihood that preserves the dependencies among the latent variables. For learning, we propose to employ the hard Expectation Maximization (EM) algorithm, which avoids the intractability of the traditional EM by max-out instead of sum-out to compute the data likelihood. Qualitative and quantitative evaluations of our model against state of the art deep models on benchmark datasets demonstrate the effectiveness of the proposed algorithm in data representation and reconstruction.</abstract>
   </article>
   <article>
      <title>Cheap Bandits</title>
      <author>Manjesh Kumar Hanawal, Venkatesh Saligrama, Michal Valko, R\' emi Munos</author>
      <date>2015-06-15</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider stochastic sequential learning problems where the learner can observe the \textit{average reward of several actions}. Such a setting is interesting in many applications involving monitoring and surveillance, where the set of the actions to observe represent some (geographical) area. The importance of this setting is that in these applications, it is actually \textit{cheaper} to observe average reward of a group of actions rather than the reward of a single action. We show that when the reward is \textit{smooth} over a given graph representing the neighboring actions, we can maximize the cumulative reward of learning while \textit{minimizing the sensing cost}. In this paper we propose CheapUCB, an algorithm that matches the regret guarantees of the known algorithms for this setting and at the same time guarantees a linear cost again over them. As a by-product of our analysis, we establish a $\Omega(\sqrt{dT})$ lower bound on the cumulative regret of spectral bandits for a class of graphs with effective dimension $d$.</abstract>
   </article>
   <article>
      <title>Online Gradient Boosting</title>
      <author>Alina Beygelzimer, Elad Hazan, Satyen Kale, Haipeng Luo</author>
      <date>2015-06-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We extend the theory of boosting for regression problems to the online learning setting. Generalizing from the batch setting for boosting, the notion of a weak learning algorithm is modeled as an online learning algorithm with linear loss functions that competes with a base class of regression functions, while a strong learning algorithm is an online learning algorithm with convex loss functions that competes with a larger class of regression functions. Our main result is an online gradient boosting algorithm which converts a weak online learning algorithm into a strong one where the larger class of functions is the linear span of the base class. We also give a simpler boosting algorithm that converts a weak online learning algorithm into a strong one where the larger class of functions is the convex hull of the base class, and prove its optimality.</abstract>
   </article>
   <article>
      <title>Learning with Clustering Structure</title>
      <author>Vincent Roulet, Fajwel Fogel, Alexandre d'Aspremont, Francis Bach</author>
      <date>2015-06-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study supervised learning problems using clustering constraints to impose structure on either features or samples, seeking to help both prediction and interpretation. The problem of clustering features arises naturally in text classification for instance, to reduce dimensionality by grouping words together and identify synonyms. The sample clustering problem on the other hand, applies to multiclass problems where we are allowed to make multiple predictions and the performance of the best answer is recorded. We derive a unified optimization formulation highlighting the common structure of these problems and produce algorithms whose core iteration complexity amounts to a k-means clustering step, which can be approximated efficiently. We extend these results to combine sparsity and clustering constraints, and develop a new projection algorithm on the set of clustered sparse vectors. We prove convergence of our algorithms on random instances, based on a union of subspaces interpretation of the clustering structure. Finally, we test the robustness of our methods on artificial data sets as well as real data extracted from movie reviews.</abstract>
   </article>
   <article>
      <title>Numeric Input Relations for Relational Learning with Applications to
  Community Structure Analysis</title>
      <author>Jiuchuan Jiang, Manfred Jaeger</author>
      <date>2015-06-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Most work in the area of statistical relational learning (SRL) is focussed on discrete data, even though a few approaches for hybrid SRL models have been proposed that combine numerical and discrete variables. In this paper we distinguish numerical random variables for which a probability distribution is defined by the model from numerical input variables that are only used for conditioning the distribution of discrete response variables. We show how numerical input relations can very easily be used in the Relational Bayesian Network framework, and that existing inference and learning methods need only minor adjustments to be applied in this generalized setting. The resulting framework provides natural relational extensions of classical probabilistic models for categorical data. We demonstrate the usefulness of RBN models with numeric input relations by several examples.   In particular, we use the augmented RBN framework to define probabilistic models for multi-relational (social) networks in which the probability of a link between two nodes depends on numeric latent feature vectors associated with the nodes. A generic learning procedure can be used to obtain a maximum-likelihood fit of model parameters and latent feature values for a variety of models that can be expressed in the high-level RBN representation. Specifically, we propose a model that allows us to interpret learned latent feature values as community centrality degrees by which we can identify nodes that are central for one community, that are hubs between communities, or that are isolated nodes. In a multi-relational setting, the model also provides a characterization of how different relations are associated with each community.</abstract>
   </article>
   <article>
      <title>On the Depth of Deep Neural Networks: A Theoretical View</title>
      <author>Shizhao Sun, Wei Chen, Liwei Wang, Xiaoguang Liu, Tie-Yan Liu</author>
      <date>2015-06-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>People believe that depth plays an important role in success of deep <term>neural network</term>s (DNN). However, this belief lacks solid theoretical justifications as far as we know. We investigate role of depth from perspective of margin bound. In margin bound, expected error is upper bounded by empirical margin error plus Rademacher Average (RA) based capacity term. First, we derive an upper bound for RA of DNN, and show that it increases with increasing depth. This indicates negative impact of depth on test performance. Second, we show that deeper networks tend to have larger representation power (measured by Betti numbers based complexity) than shallower networks in multi-class setting, and thus can lead to smaller empirical margin error. This implies positive impact of depth. The combination of these two results shows that for DNN with restricted number of hidden units, increasing depth is not always good since there is a tradeoff between positive and negative impacts. These results inspire us to seek alternative ways to achieve positive impact of depth, e.g., imposing margin-based penalty terms to cross entropy loss so as to reduce empirical margin error without increasing depth. Our experiments show that in this way, we achieve significantly better test performance.</abstract>
   </article>
   <article>
      <title>Gradient Estimation Using Stochastic Computation Graphs</title>
      <author>John Schulman, Nicolas Heess, Theophane Weber, Pieter Abbeel</author>
      <date>2015-06-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In a variety of problems originating in supervised, unsupervised, and <term>reinforcement learning</term>, the loss function is defined by an expectation over a collection of random variables, which might be part of a probabilistic model or the external world. Estimating the gradient of this loss function, using samples, lies at the core of gradient-based learning algorithms for these problems. We introduce the formalism of stochastic computation graphs---directed acyclic graphs that include both deterministic functions and conditional probability distributions---and describe how to easily and automatically derive an unbiased estimator of the loss function's gradient. The resulting algorithm for computing the gradient estimator is a simple modification of the standard <term>backpropagation</term> algorithm. The generic scheme we propose unifies estimators derived in variety of prior work, along with variance-reduction techniques therein. It could assist researchers in developing intricate models involving a combination of stochastic and deterministic operations, enabling, for example, attention, memory, and control actions.</abstract>
   </article>
   <article>
      <title>Scalable Semi-Supervised Aggregation of Classifiers</title>
      <author>Akshay Balsubramani, Yoav Freund</author>
      <date>2015-06-18</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present and empirically evaluate an efficient algorithm that learns to aggregate the predictions of an ensemble of binary classifiers. The algorithm uses the structure of the ensemble predictions on unlabeled data to yield significant performance improvements. It does this without making assumptions on the structure or origin of the ensemble, without parameters, and as scalably as linear learning. We empirically demonstrate these performance gains with <term>random forest</term>s.</abstract>
   </article>
   <article>
      <title>The Extreme Value Machine</title>
      <author>Ethan M. Rudd, Lalit P. Jain, Walter J. Scheirer, Terrance E. Boult</author>
      <date>2015-06-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It is often desirable to be able to recognize when inputs to a recognition function learned in a supervised manner correspond to classes unseen at training time. With this ability, new class labels could be assigned to these inputs by a human operator, allowing them to be incorporated into the recognition function --- ideally under an efficient incremental update mechanism. While good algorithms that assume inputs from a fixed set of classes exist, e.g., artificial <term>neural network</term>s and kernel machines, it is not immediately obvious how to extend them to perform incremental learning in the presence of unknown query classes. Existing algorithms take little to no distributional information into account when learning recognition functions and lack a strong theoretical foundation. We address this gap by formulating a novel, theoretically sound classifier --- the Extreme Value Machine (EVM). The EVM has a well-grounded interpretation derived from statistical Extreme Value Theory (EVT), and is the first classifier to be able to perform nonlinear kernel-free variable bandwidth incremental learning. Compared to other classifiers in the same deep network derived feature space, the EVM is accurate and efficient on an established benchmark partition of the ImageNet dataset.</abstract>
   </article>
   <article>
      <title>Strategic Classification</title>
      <author>Moritz Hardt, Nimrod Megiddo, Christos Papadimitriou, Mary Wootters</author>
      <date>2015-06-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Machine learning relies on the assumption that unseen test instances of a classification problem follow the same distribution as observed training data. However, this principle can break down when machine learning is used to make important decisions about the welfare (employment, education, health) of strategic individuals. Knowing information about the classifier, such individuals may manipulate their attributes in order to obtain a better classification outcome. As a result of this behavior---often referred to as gaming---the performance of the classifier may deteriorate sharply. Indeed, gaming is a well-known obstacle for using machine learning methods in practice; in financial policy-making, the problem is widely known as Goodhart's law. In this paper, we formalize the problem, and pursue algorithms for learning classifiers that are robust to gaming.   We model classification as a sequential game between a player named "Jury" and a player named "Contestant." Jury designs a classifier, and Contestant receives an input to the classifier, which he may change at some cost. Jury's goal is to achieve high classification accuracy with respect to Contestant's original input and some underlying target classification function. Contestant's goal is to achieve a favorable classification outcome while taking into account the cost of achieving it.   For a natural class of cost functions, we obtain computationally efficient learning algorithms which are near-optimal. Surprisingly, our algorithms are efficient even on concept classes that are computationally hard to learn. For general cost functions, designing an approximately optimal strategy-proof classifier, for inverse-polynomial approximation, is NP-hard.</abstract>
   </article>
   <article>
      <title>Unconfused ultraconservative multiclass algorithms</title>
      <author>Ugo Louche, Liva Ralaivola</author>
      <date>2015-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We tackle the problem of learning linear classifiers from noisy datasets in a multiclass setting. The two-class version of this problem was studied a few years ago where the proposed approaches to combat the noise revolve around a Per-ceptron learning scheme fed with peculiar examples computed through a weighted average of points from the noisy training set. We propose to build upon these approaches and we introduce a new algorithm called UMA (for Unconfused Multiclass additive Algorithm) which may be seen as a generalization to the multiclass setting of the previous approaches. In order to characterize the noise we use the confusion matrix as a multiclass extension of the classification noise studied in the aforemen-tioned literature. Theoretically well-founded, UMA furthermore displays very good empirical noise robustness, as evidenced by numerical simulations conducted on both synthetic and real data.</abstract>
   </article>
   <article>
      <title>Flexible Multi-layer Sparse Approximations of Matrices and Applications</title>
      <author>Luc Le Magoarou, Rémi Gribonval</author>
      <date>2015-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The computational cost of many signal processing and machine learning techniques is often dominated by the cost of applying certain linear operators to high-dimensional vectors. This paper introduces an algorithm aimed at reducing the complexity of applying linear operators in high dimension by approximately factorizing the corresponding matrix into few sparse factors. The approach relies on recent advances in non-convex optimization. It is first explained and analyzed in details and then demonstrated experimentally on various problems including dictionary learning for image denoising, and the approximation of large matrices arising in inverse problems.</abstract>
   </article>
   <article>
      <title>Splash: User-friendly Programming Interface for Parallelizing Stochastic
  Algorithms</title>
      <author>Yuchen Zhang, Michael I. Jordan</author>
      <date>2015-06-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Stochastic algorithms are efficient approaches to solving machine learning and optimization problems. In this paper, we propose a general framework called Splash for parallelizing stochastic algorithms on multi-node distributed systems. Splash consists of a programming interface and an execution engine. Using the programming interface, the user develops sequential stochastic algorithms without concerning any detail about distributed computing. The algorithm is then automatically parallelized by a communication-efficient execution engine. We provide theoretical justifications on the optimal rate of convergence for parallelizing stochastic <term>gradient descent</term>. Splash is built on top of Apache Spark. The real-data experiments on logistic regression, collaborative filtering and topic modeling verify that Splash yields order-of-magnitude speedup over single-thread stochastic algorithms and over state-of-the-art implementations on Spark.</abstract>
   </article>
   <article>
      <title>Conservativeness of untied auto-encoders</title>
      <author>Daniel Jiwoong Im, Mohamed Ishmael Diwan Belghazi, Roland Memisevic</author>
      <date>2015-06-25</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We discuss necessary and sufficient conditions for an auto-encoder to define a conservative vector field, in which case it is associated with an energy function akin to the unnormalized log-probability of the data. We show that the conditions for conservativeness are more general than for encoder and decoder weights to be the same ("tied weights"), and that they also depend on the form of the hidden unit activation function, but that contractive training criteria, such as denoising, will enforce these conditions locally. Based on these observations, we show how we can use auto-encoders to extract the conservative component of a vector field.</abstract>
   </article>
   <article>
      <title>Occam's Gates</title>
      <author>Jonathan Raiman, Szymon Sidor</author>
      <date>2015-06-27</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We present a complimentary objective for training recurrent <term>neural network</term>s (RNN) with gating units that helps with regularization and interpretability of the trained model. Attention-based RNN models have shown success in many difficult sequence to sequence classification problems with long and short term dependencies, however these models are prone to overfitting. In this paper, we describe how to regularize these models through an L1 penalty on the activation of the gating units, and show that this technique reduces overfitting on a variety of tasks while also providing to us a human-interpretable visualization of the inputs used by the network. These tasks include sentiment analysis, paraphrase recognition, and question answering.</abstract>
   </article>
   <article>
      <title>Non-convex Regularizations for Feature Selection in Ranking With Sparse
  SVM</title>
      <author>Léa Laporte, Rémi Flamary, Stephane Canu, Sébastien Déjean, Josiane Mothe</author>
      <date>2015-07-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Feature selection in learning to rank has recently emerged as a crucial issue. Whereas several preprocessing approaches have been proposed, only a few works have been focused on integrating the feature selection into the learning process. In this work, we propose a general framework for feature selection in learning to rank using SVM with a sparse regularization term. We investigate both classical convex regularizations such as $\ell\_1$ or weighted $\ell\_1$ and non-convex regularization terms such as log penalty, Minimax Concave Penalty (MCP) or $\ell\_p$ pseudo norm with $p\textless{}1$. Two algorithms are proposed, first an accelerated proximal approach for solving the convex problems, second a reweighted $\ell\_1$ scheme to address the non-convex regularizations. We conduct intensive experiments on nine datasets from Letor 3.0 and Letor 4.0 corpora. Numerical results show that the use of non-convex regularizations we propose leads to more sparsity in the resulting models while prediction performance is preserved. The number of features is decreased by up to a factor of six compared to the $\ell\_1$ regularization. In addition, the software is publicly available on the web.</abstract>
   </article>
   <article>
      <title>Optimal Transport for Domain Adaptation</title>
      <author>Nicolas Courty, Rémi Flamary, Devis Tuia, Alain Rakotomamonjy</author>
      <date>2015-07-02</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Domain adaptation from one data space (or domain) to another is one of the most challenging tasks of modern data analytics. If the adaptation is done correctly, models built on a specific data space become more robust when confronted to data depicting the same semantic concepts (the classes), but observed by another observation system with its own specificities. Among the many strategies proposed to adapt a domain to another, finding a common representation has shown excellent properties: by finding a common representation for both domains, a single classifier can be effective in both and use labelled samples from the source domain to predict the unlabelled samples of the target domain. In this paper, we propose a regularized unsupervised optimal transportation model to perform the alignment of the representations in the source and target domains. We learn a transportation plan matching both PDFs, which constrains labelled samples in the source domain to remain close during transport. This way, we exploit at the same time the few labeled information in the source and the unlabelled distributions observed in both domains. Experiments in toy and challenging real visual adaptation examples show the interest of the method, that consistently outperforms state of the art approaches.</abstract>
   </article>
   <article>
      <title>Combining Models of Approximation with Partial Learning</title>
      <author>Ziyuan Gao, Frank Stephan, Sandra Zilles</author>
      <date>2015-07-05</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In Gold's framework of inductive inference, the model of partial learning requires the learner to output exactly one correct index for the target object and only the target object infinitely often. Since infinitely many of the learner's hypotheses may be incorrect, it is not obvious whether a partial learner can be modifed to "approximate" the target object.   Fulk and Jain (Approximate inference and scientific method. Information and Computation 114(2):179--191, 1994) introduced a model of approximate learning of recursive functions. The present work extends their research and solves an open problem of Fulk and Jain by showing that there is a learner which approximates and partially identifies every recursive function by outputting a sequence of hypotheses which, in addition, are also almost all finite variants of the target function.   The subsequent study is dedicated to the question how these findings generalise to the learning of r.e. languages from positive data. Here three variants of approximate learning will be introduced and investigated with respect to the question whether they can be combined with partial learning. Following the line of Fulk and Jain's research, further investigations provide conditions under which partial language learners can eventually output only finite variants of the target language. The combinabilities of other partial learning criteria will also be briefly studied.</abstract>
   </article>
   <article>
      <title>A Simple Algorithm for Maximum Margin Classification, Revisited</title>
      <author>Sariel Har-Peled</author>
      <date>2015-07-06</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this note, we revisit the algorithm of Har-Peled et. al. [HRZ07] for computing a linear maximum margin classifier. Our presentation is self contained, and the algorithm itself is slightly simpler than the original algorithm. The algorithm itself is a simple Perceptron like iterative algorithm. For more details and background, the reader is referred to the original paper.</abstract>
   </article>
   <article>
      <title>A Bayesian Approach for Online Classifier Ensemble</title>
      <author>Qinxun Bai, Henry Lam, Stan Sclaroff</author>
      <date>2015-07-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We propose a Bayesian approach for recursively estimating the classifier weights in online learning of a classifier ensemble. In contrast with past methods, such as stochastic <term>gradient descent</term> or online boosting, our approach estimates the weights by recursively updating its posterior distribution. For a specified class of loss functions, we show that it is possible to formulate a suitably defined likelihood function and hence use the posterior distribution as an approximation to the global empirical loss minimizer. If the stream of training data is sampled from a stationary process, we can also show that our approach admits a superior rate of convergence to the expected loss minimizer than is possible with standard stochastic <term>gradient descent</term>. In experiments with real-world datasets, our formulation often performs better than state-of-the-art stochastic <term>gradient descent</term> and online boosting algorithms.</abstract>
   </article>
   <article>
      <title>An Empirical Study on Budget-Aware Online Kernel Algorithms for Streams
  of Graphs</title>
      <author>Giovanni Da San Martino, Nicolò Navarin, Alessandro Sperduti</author>
      <date>2015-07-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Kernel methods are considered an effective technique for on-line learning. Many approaches have been developed for compactly representing the dual solution of a kernel method when the problem imposes memory constraints. However, in literature no work is specifically tailored to streams of graphs. Motivated by the fact that the size of the feature space representation of many state-of-the-art graph kernels is relatively small and thus it is explicitly computable, we study whether executing kernel algorithms in the feature space can be more effective than the classical dual approach. We study three different algorithms and various strategies for managing the budget. Efficiency and efficacy of the proposed approaches are experimentally assessed on relatively large graph streams exhibiting concept drift. It turns out that, when strict memory budget constraints have to be enforced, working in feature space, given the current state of the art on graph kernels, is more than a viable alternative to dual approaches, both in terms of speed and classification performance.</abstract>
   </article>
   <article>
      <title>Extending local features with contextual information in graph kernels</title>
      <author>Nicolò Navarin, Alessandro Sperduti, Riccardo Tesselli</author>
      <date>2015-07-08</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Graph kernels are usually defined in terms of simpler kernels over local substructures of the original graphs. Different kernels consider different types of substructures. However, in some cases they have similar predictive performances, probably because the substructures can be interpreted as approximations of the subgraphs they induce. In this paper, we propose to associate to each feature a piece of information about the context in which the feature appears in the graph. A substructure appearing in two different graphs will match only if it appears with the same context in both graphs. We propose a kernel based on this idea that considers trees as substructures, and where the contexts are features too. The kernel is inspired from the framework in [6], even if it is not part of it. We give an efficient algorithm for computing the kernel and show promising results on real-world graph classification datasets.</abstract>
   </article>
   <article>
      <title>Utility-based Dueling Bandits as a Partial Monitoring Game</title>
      <author>Pratik Gajane, Tanguy Urvoy</author>
      <date>2015-07-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Partial monitoring is a generic framework for sequential decision-making with incomplete feedback. It encompasses a wide class of problems such as dueling bandits, learning with expect advice, dynamic pricing, dark pools, and label efficient prediction. We study the utility-based dueling bandit problem as an instance of partial monitoring problem and prove that it fits the time-regret partial monitoring hierarchy as an easy - i.e. Theta (sqrt{T})- instance. We survey some partial monitoring algorithms and see how they could be used to solve dueling bandits efficiently. Keywords: Online learning, Dueling Bandits, Partial Monitoring, Partial Feedback, Multiarmed Bandits</abstract>
   </article>
   <article>
      <title>Spectral Smoothing via Random Matrix Perturbations</title>
      <author>Jacob Abernethy, Chansoo Lee, Ambuj Tewari</author>
      <date>2015-07-10</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider stochastic smoothing of spectral functions of matrices using perturbations commonly studied in random matrix theory. We show that a spectral function remains spectral when smoothed using a unitarily invariant perturbation distribution. We then derive state-of-the-art smoothing bounds for the maximum eigenvalue function using the Gaussian Orthogonal Ensemble (GOE). Smoothing the maximum eigenvalue function is important for applications in semidefinite optimization and online learning. As a direct consequence of our GOE smoothing results, we obtain an $O((N \log N)^{1/4} \sqrt{T})$ expected regret bound for the online variance minimization problem using an algorithm that performs only a single maximum eigenvector computation per time step. Here $T$ is the number of rounds and $N$ is the matrix dimension. Our algorithm and its analysis also extend to the more general online PCA problem where the learner has to output a rank $k$ subspace. The algorithm just requires computing $k$ maximum eigenvectors per step and enjoys an $O(k (N \log N)^{1/4} \sqrt{T})$ expected regret bound.</abstract>
   </article>
   <article>
      <title>A new boosting algorithm based on dual averaging scheme</title>
      <author>Nan Wang</author>
      <date>2015-07-11</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The fields of machine learning and mathematical optimization increasingly intertwined. The special topic on supervised learning and convex optimization examines this interplay. The training part of most supervised learning algorithms can usually be reduced to an optimization problem that minimizes a loss between model predictions and training data. While most optimization techniques focus on accuracy and speed of convergence, the qualities of good optimization algorithm from the machine learning perspective can be quite different since machine learning is more than fitting the data. Better optimization algorithms that minimize the training loss can possibly give very poor generalization performance. In this paper, we examine a particular kind of machine learning algorithm, boosting, whose training process can be viewed as functional coordinate descent on the exponential loss. We study the relation between optimization techniques and machine learning by implementing a new boosting algorithm. DABoost, based on dual-averaging scheme and study its generalization performance. We show that DABoost, although slower in reducing the training error, in general enjoys a better generalization error than AdaBoost.</abstract>
   </article>
   <article>
      <title>Cluster-Aided Mobility Predictions</title>
      <author>Jaeseong Jeong, Mathieu Leconte, Alexandre Proutiere</author>
      <date>2015-07-12</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Predicting the future location of users in wireless net- works has numerous applications, and can help service providers to improve the quality of service perceived by their clients. The location predictors proposed so far estimate the next location of a specific user by inspecting the past individual trajectories of this user. As a consequence, when the training data collected for a given user is limited, the resulting prediction is inaccurate. In this paper, we develop cluster-aided predictors that exploit past trajectories collected from all users to predict the next location of a given user. These predictors rely on clustering techniques and extract from the training data similarities among the mobility patterns of the various users to improve the prediction accuracy. Specifically, we present CAMP (Cluster-Aided Mobility Predictor), a cluster-aided predictor whose design is based on recent non-parametric bayesian statistical tools. CAMP is robust and adaptive in the sense that it exploits similarities in users' mobility only if such similarities are really present in the training data. We analytically prove the consistency of the predictions provided by CAMP, and investigate its performance using two large-scale datasets. CAMP significantly outperforms existing predictors, and in particular those that only exploit individual past trajectories.</abstract>
   </article>
   <article>
      <title>Ordered Decompositional DAG Kernels Enhancements</title>
      <author>Giovanni Da San Martino, Nicolò Navarin, Alessandro Sperduti</author>
      <date>2015-07-13</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we show how the Ordered Decomposition DAGs (ODD) kernel framework, a framework that allows the definition of graph kernels from tree kernels, allows to easily define new state-of-the-art graph kernels. Here we consider a fast graph kernel based on the Subtree kernel (ST), and we propose various enhancements to increase its expressiveness. The proposed DAG kernel has the same worst-case complexity as the one based on ST, but an improved expressivity due to an augmented set of features. Moreover, we propose a novel weighting scheme for the features, which can be applied to other kernels of the ODD framework. These improvements allow the proposed kernels to improve on the classification performances of the ST-based kernel for several real-world datasets, reaching state-of-the-art performances.</abstract>
   </article>
   <article>
      <title>Training artificial neural networks to learn a nondeterministic game</title>
      <author>Thomas E. Portegys</author>
      <date>2015-07-14</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>It is well known that artificial <term>neural network</term>s (ANNs) can learn deterministic automata. Learning nondeterministic automata is another matter. This is important because much of the world is nondeterministic, taking the form of unpredictable or probabilistic events that must be acted upon. If ANNs are to engage such phenomena, then they must be able to learn how to deal with nondeterminism. In this project the game of Pong poses a nondeterministic environment. The learner is given an incomplete view of the game state and underlying deterministic physics, resulting in a nondeterministic game. Three models were trained and tested on the game: Mona, Elman, and Numenta's NuPIC.</abstract>
   </article>
   <article>
      <title>Towards Predicting First Daily Departure Times: a Gaussian Modeling
  Approach for Load Shift Forecasting</title>
      <author>Nicholas H. Kirk, Ilya Dianov</author>
      <date>2015-07-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This work provides two statistical Gaussian forecasting methods for predicting First Daily Departure Times (FDDTs) of everyday use electric vehicles. This is important in smart grid applications to understand disconnection times of such mobile storage units, for instance to forecast storage of non dispatchable loads (e.g. wind and solar power). We provide a review of the relevant state-of-the-art driving behavior features towards FDDT prediction, to then propose an approximated Gaussian method which qualitatively forecasts how many vehicles will depart within a given time frame, by assuming that departure times follow a normal distribution. This method considers sampling sessions as Poisson distributions which are superimposed to obtain a single approximated Gaussian model. Given the Gaussian distribution assumption of the departure times, we also model the problem with Gaussian Mixture Models (GMM), in which the priorly set number of clusters represents the desired time granularity. Evaluation has proven that for the dataset tested, low error and high confidence ($\approx 95\%$) is possible for 15 and 10 minute intervals, and that GMM outperforms traditional modeling but is less generalizable across datasets, as it is a closer fit to the sampling data. Conclusively we discuss future possibilities and practical applications of the discussed model.</abstract>
   </article>
   <article>
      <title>Upper-Confidence-Bound Algorithms for Active Learning in Multi-Armed
  Bandits</title>
      <author>Alexandra Carpentier, Alessandro Lazaric, Mohammad Ghavamzadeh, Rémi Munos, Peter Auer, András Antos</author>
      <date>2015-07-16</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>In this paper, we study the problem of estimating uniformly well the mean values of several distributions given a finite budget of samples. If the variance of the distributions were known, one could design an optimal sampling strategy by collecting a number of independent samples per distribution that is proportional to their variance. However, in the more realistic case where the distributions are not known in advance, one needs to design adaptive sampling strategies in order to select which distribution to sample from according to the previously observed samples. We describe two strategies based on pulling the distributions a number of times that is proportional to a high-probability upper-confidence-bound on their variance (built from previous observed samples) and report a finite-sample performance analysis on the excess estimation error compared to the optimal allocation. We show that the performance of these allocation strategies depends not only on the variances but also on the full shape of the distributions.</abstract>
   </article>
   <article>
      <title>Maximum Entropy Deep Inverse Reinforcement Learning</title>
      <author>Markus Wulfmeier, Peter Ondruska, Ingmar Posner</author>
      <date>2015-07-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>This paper presents a general framework for exploiting the representational capacity of <term>neural network</term>s to approximate complex, nonlinear reward functions in the context of solving the inverse <term>reinforcement learning</term> (IRL) problem. We show in this context that the Maximum Entropy paradigm for IRL lends itself naturally to the efficient training of deep architectures. At test time, the approach leads to a computational complexity independent of the number of demonstrations, which makes it especially well-suited for applications in life-long learning scenarios. Our approach achieves performance commensurate to the state-of-the-art on existing benchmarks while exceeding on an alternative benchmark based on highly varying reward structures. Finally, we extend the basic architecture - which is equivalent to a simplified subclass of Fully Convolutional Neural Networks (FCNNs) with width one - to include larger convolutions in order to eliminate dependency on precomputed spatial features and work on raw input representations.</abstract>
   </article>
   <article>
      <title>Lower Bounds for Multi-armed Bandit with Non-equivalent Multiple Plays</title>
      <author>Aleksandr Vorobev, Gleb Gusev</author>
      <date>2015-07-17</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We study the stochastic multi-armed bandit problem with non-equivalent multiple plays where, at each step, an agent chooses not only a set of arms, but also their order, which influences reward distribution. In several problem formulations with different assumptions, we provide lower bounds for regret with standard asymptotics $O(\log{t})$ but novel coefficients and provide optimal algorithms, thus proving that these bounds cannot be improved.</abstract>
   </article>
   <article>
      <title>2 Notes on Classes with Vapnik-Chervonenkis Dimension 1</title>
      <author>Shai Ben-David</author>
      <date>2015-07-19</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The Vapnik-Chervonenkis dimension is a combinatorial parameter that reflects the "complexity" of a set of sets (a.k.a. concept classes). It has been introduced by Vapnik and Chervonenkis in their seminal 1971 paper and has since found many applications, most notably in machine learning theory and in computational geometry. Arguably the most influential consequence of the VC analysis is the fundamental theorem of statistical machine learning, stating that a concept class is learnable (in some precise sense) if and only if its VC-dimension is finite. Furthermore, for such classes a most simple learning rule - empirical risk minimization (ERM) - is guaranteed to succeed.   The simplest non-trivial structures, in terms of the VC-dimension, are the classes (i.e., sets of subsets) for which that dimension is 1.   In this note we show a couple of curious results concerning such classes. The first result shows that such classes share a very simple structure, and, as a corollary, the labeling information contained in any sample labeled by such a class can be compressed into a single instance.   The second result shows that due to some subtle measurability issues, in spite of the above mentioned fundamental theorem, there are classes of dimension 1 for which an ERM learning rule fails miserably.</abstract>
   </article>
   <article>
      <title>AMP: a new time-frequency feature extraction method for intermittent
  time-series data</title>
      <author>Duncan Barrack, James Goulding, Keith Hopcraft, Simon Preston, Gavin Smith</author>
      <date>2015-07-20</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>The characterisation of time-series data via their most salient features is extremely important in a range of machine learning task, not least of all with regards to classification and clustering. While there exist many feature extraction techniques suitable for non-intermittent time-series data, these approaches are not always appropriate for intermittent time-series data, where intermittency is characterized by constant values for large periods of time punctuated by sharp and transient increases or decreases in value.   Motivated by this, we present aggregation, mode decomposition and projection (AMP) a feature extraction technique particularly suited to intermittent time-series data which contain time-frequency patterns. For our method all individual time-series within a set are combined to form a non-intermittent aggregate. This is decomposed into a set of components which represent the intrinsic time-frequency signals within the data set. Individual time-series can then be fit to these components to obtain a set of numerical features that represent their intrinsic time-frequency patterns. To demonstrate the effectiveness of AMP, we evaluate against the real word task of clustering intermittent time-series data. Using synthetically generated data we show that a clustering approach which uses the features derived from AMP significantly outperforms traditional clustering methods. Our technique is further exemplified on a real world data set where AMP can be used to discover groupings of individuals which correspond to real world sub-populations.</abstract>
   </article>
   <article>
      <title>Bandit-Based Task Assignment for Heterogeneous Crowdsourcing</title>
      <author>Hao Zhang, Yao Ma, Masashi Sugiyama</author>
      <date>2015-07-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>We consider a task assignment problem in crowdsourcing, which is aimed at collecting as many reliable labels as possible within a limited budget. A challenge in this scenario is how to cope with the diversity of tasks and the task-dependent reliability of workers, e.g., a worker may be good at recognizing the name of sports teams, but not be familiar with cosmetics brands. We refer to this practical setting as heterogeneous crowdsourcing. In this paper, we propose a contextual bandit formulation for task assignment in heterogeneous crowdsourcing, which is able to deal with the exploration-exploitation trade-off in worker selection. We also theoretically investigate the regret bounds for the proposed method, and demonstrate its practical usefulness experimentally.</abstract>
   </article>
   <article>
      <title>A study of the classification of low-dimensional data with supervised
  manifold learning</title>
      <author>Elif Vural, Christine Guillemot</author>
      <date>2015-07-21</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Supervised manifold learning methods learn data representations by preserving the geometric structure of data while enhancing the separation between data samples from different classes. In this work, we propose a theoretical study of supervised manifold learning for classification. We consider nonlinear dimensionality reduction algorithms that yield linearly separable embeddings of training data and present generalization bounds for this type of algorithms. A necessary condition for satisfactory generalization performance is that the embedding allow the construction of a sufficiently regular interpolation function in relation with the separation margin of the embedding. We show that for supervised embeddings satisfying this condition, the classification error decays at an exponential rate with the number of training samples. Finally, we examine the separability of supervised nonlinear embeddings that aim to preserve the low-dimensional geometric structure of data based on graph representations. The proposed analysis is supported by experiments on several real data sets.</abstract>
   </article>
   <article>
      <title>Deep Recurrent Q-Learning for Partially Observable MDPs</title>
      <author>Matthew Hausknecht, Peter Stone</author>
      <date>2015-07-23</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Deep Reinforcement Learning has yielded proficient controllers for complex tasks. However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point. To address these shortcomings, this article investigates the effects of adding recurrency to a Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM. The resulting \textit{Deep Recurrent Q-Network} (DRQN), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates DQN's performance on standard Atari games and partially observed equivalents featuring flickering game screens. Additionally, when trained with partial observations and evaluated with incrementally more complete observations, DRQN's performance scales as a function of observability. Conversely, when trained with full observations and evaluated with partial observations, DRQN's performance degrades less than DQN's. Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the DQN's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.</abstract>
   </article>
   <article>
      <title>A Reinforcement Learning Approach to Online Learning of Decision Trees</title>
      <author>Abhinav Garlapati, Aditi Raghunathan, Vaishnavh Nagarajan, Balaraman Ravindran</author>
      <date>2015-07-24</date>
      <discipline>cs.LG</discipline>
      <source>arXiv</source>
      <abstract>Online decision tree learning algorithms typically examine all features of a new data point to update model parameters. We propose a novel alternative, Reinforcement Learning- based Decision Trees (RLDT), that uses Reinforcement Learning (RL) to actively examine a minimal number of features of a data point to classify it with high accuracy. Furthermore, RLDT optimizes a long term return, providing a better alternative to the traditional myopic greedy approach to growing decision trees. We demonstrate that this approach performs as well as batch learning algorithms and other online decision tree learning algorithms, while making significantly fewer queries about the features of the data points. We also show that RLDT can effectively handle concept drift.</abstract>
   </article>
</articles>
